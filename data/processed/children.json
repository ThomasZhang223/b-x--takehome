[
  {
    "child_id": "390dbbbd-7373-4348-810d-59cf3a2946ad",
    "parent_id": "2036ee31-7783-4994-8a35-bbcf53917b0a",
    "text": "Boston   Columbus   Indianapolis   New York   San Francisco   Upper Saddle River  \nAmsterdam   Cape Town   Dubai   London   Madrid   Milan   Munich   Paris   Montr\u00e9al   Toronto  \nDelhi   Mexico City   S\u00e3o Paulo   Sydney   Hong Kong   Seoul   Singapore   Taipei   Tokyo\nQUANTUM MECHANICS\nA Paradigms Approach\nDavid H. McIntyre\nOregon State University\nwith contributions from Corinne A. Manogue, Janet Tate  \nand the Paradigms in Physics group at Oregon State University\n\nPublisher: Jim Smith\nEditorial Manager: Laura Kenney\nSenior Project Editor: Katie Conley\nAssistant Editors: Peter Alston and Steven Le\nSenior Marketing Manager: Kerry McGinnis\nManaging Editor: Corinne Benson\nProduction Project Manager: Mary O\u2019Connell\nProduction Management and Composition: \nElement LLC\nCover Design: Mark Ong\nManufacturing Buyer: Kathy Sleys\nManager, Rights and Permissions: Zina Arabia\nManager, Cover Visual Research & \nPermissions: Karen Sanatar\nPrinter and Binder: Courier, Westford\nCover Printer: Courier, Westford\nCover Images: David H. McIntyre\nCopyright \u00a9 2012 Pearson Education, Inc., publishing as Pearson Addison-Wesley, 1301 Sansome St., San Francisco, \nCA 94111. All rights reserved. Manufactured in the United States of America. This publication is protected by Copyright \nand permission should be obtained from the publisher prior to any prohibited reproduction, storage in a retrieval system, \nor transmission in any form or by any means, electronic, mechanical, photocopying, recording, or likewise. To obtain \npermission(s) to use material from this work, please submit a written request to Pearson Education, Inc., Permissions \nDepartment, 1900 E. Lake Ave., Glenview, IL 60025. For information regarding permissions, call (847) 486-2635.\nMany of the designations used by manufacturers and sellers to distinguish their products are claimed as trademarks. Where \nthose designations appear in this book, and the publisher was aware of a trademark claim, the designations have been printed \nin initial caps or all caps.\nLibrary of Congress Cataloging-in-Publication Data\nMcIntyre, David H.\n Quantum mechanics : a paradigms approach / David H. McIntyre ; with  \ncontributions from Corinne A. Manogue, Janet Tate, and the Paradigms in \nPhysics group at Oregon State University.\n  p. cm.\n Includes bibliographical references and index.\n ISBN-13: 978-0-321-76579-6\n ISBN-10: 0-321-76579-6\n 1. Quantum theory. 2. Mechanics.  I. Manogue, Corinne A. II. Tate, Janet.\nIII. Oregon State University. IV. Title.\n QC174.12.M3785 2012\n 530.12--dc23\n                2011039322\nISBN 10: 0-321-76579-6  \nISBN 13: 978-0-321-76579-6\n1 2 3 4 5 6 7 8 9 10 \u2014CRW\u201416 15 14 13 12 11\nwww.pearsonhighered.com\n\nv\n Brief Contents\n 1 Stern-Gerlach Experiments \n1\n 2 Operators and Measurement \n34\n 3 Schr\u00f6dinger Time Evolution \n68\n 4 Quantum Spookiness \n97\n 5 Quantized Energies: Particle in a Box \n107\n 6 Unbound States \n161\n 7 Angular Momentum \n202\n 8 Hydrogen Atom \n250\n 9 Harmonic Oscillator \n275\n 10 Perturbation Theory \n31",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 5
  },
  {
    "child_id": "9b6fe8f9-6cd1-45e9-ae91-a0289e864547",
    "parent_id": "2036ee31-7783-4994-8a35-bbcf53917b0a",
    "text": "e.\n QC174.12.M3785 2012\n 530.12--dc23\n                2011039322\nISBN 10: 0-321-76579-6  \nISBN 13: 978-0-321-76579-6\n1 2 3 4 5 6 7 8 9 10 \u2014CRW\u201416 15 14 13 12 11\nwww.pearsonhighered.com\n\nv\n Brief Contents\n 1 Stern-Gerlach Experiments \n1\n 2 Operators and Measurement \n34\n 3 Schr\u00f6dinger Time Evolution \n68\n 4 Quantum Spookiness \n97\n 5 Quantized Energies: Particle in a Box \n107\n 6 Unbound States \n161\n 7 Angular Momentum \n202\n 8 Hydrogen Atom \n250\n 9 Harmonic Oscillator \n275\n 10 Perturbation Theory \n312\n 11 Hyper\ufb01ne Structure and the Addition of Angular Momenta \n355\n 12 Perturbation of Hydrogen \n382\n 13 Identical Particles \n410\n 14 Time-Dependent Perturbation Theory \n445\n 15 Periodic Systems \n469\n 16 Modern Applications of Quantum Mechanics \n502\nAppendices \n529\nIndex \n553\n\nvii\nContents\nPreface \nxiii\nPrologue \nxix\n \n1 \u0002 Stern-Gerlach Experiments \n1\n1.1 \nStern-Gerlach Experiment 1\n1.1.1 \nExperiment 1 5\n1.1.2 \nExperiment 2 6\n1.1.3 \nExperiment 3 7\n1.1.4 \nExperiment 4 8\n1.2 \nQuantum State Vectors 10\n1.2.1 \nAnalysis of Experiment 1 16\n1.2.2 \nAnalysis of Experiment 2 16\n1.2.3 \nSuperposition States 19\n1.3 \nMatrix Notation 22\n1.4 \nGeneral Quantum Systems 25\n1.5 \nPostulates  27\nSummary 28\nProblems 29\nResources 32\nActivities 32\nFurther Reading 33\n \n2 \u0002 Operators and Measurement \n34\n2.1 \nOperators, Eigenvalues, and Eigenvectors 34\n2.1.1 \nMatrix Representation of Operators 37\n2.1.2 \nDiagonalization of Operators 38\n2.2 \nNew Operators 41\n2.2.1 \nSpin Component in a General Direction 41\n2.2.2 \nHermitian Operators 44\n2.2.3 \nProjection Operators 44\n2.2.4 \nAnalysis of Experiments 3 and 4 47\n2.3 \nMeasurement 50\n2.4 \nCommuting Observables 54\n2.5 \nUncertainty Principle 56\n2.6 \nS2 Operator 57\n2.7 \nSpin-1 System 59\n\nviii \nContents \n2.8 \nGeneral Quantum Systems 62\nSummary 63\nProblems 64\nResources 67\nActivities 67\n \n3 \u0002 Schr\u00f6dinger Time Evolution \n68\n3.1 \nSchr\u00f6dinger Equation 68\n3.2 \nSpin Precession 72\n3.2.1 \nMagnetic Field in the z-Direction 72\n3.2.2 \nMagnetic Field in a General Direction 78\n3.3 \nNeutrino Oscillations 84\n3.4 \nTime-Dependent Hamiltonians 87\n3.4.1 \nMagnetic Resonance 87\n3.4.2 \nLight-Matter Interactions 92\nSummary 93\nProblems 94\nResources 96\nActivities 96\nFurther Reading 96\n \n4 \u0002 Quantum Spookiness \n97\n4.1 \nEinstein-Podolsky-Rosen Paradox 97\n4.2 \nSchr\u00f6dinger Cat Paradox 102\nProblems 105\nResources 106\nFurther Reading 106\n \n5 \u0002 Quantized Energies: Particle in a Box \n107\n5.1 \nSpectroscopy 107\n5.2 \nEnergy Eigenvalue Equation 110\n5.3 \nThe Wave Function 112\n5.4 \nIn\ufb01nite Square Well 119\n5.5 \nFinite Square Well 128\n5.6 \nCompare and Contrast 133\n5.6.1 \nWave Function Curvature 133\n5.6.2 \nNodes 135\n5.6.3 \nBarrier Penetration 135\n5.6.4 \nInversion Symmetry and Parity 136\n5.6.5 \nOrthonormality 136\n5.6.6 \nCompleteness 137\n5.7 \nSuperposition States and Time Dependence 137\n5.8 \nModern Application: Quantum Wells and Dots 146\n5.9 \n Asymmetric Square Well: Sneak Peek at  \nPerturbations 147\n5.10  Fitting Energy Eigenstates by Eye or by  \nComputer 150\n5.10.1 Qualitative (Eyeball) Soluti",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 5
  },
  {
    "child_id": "a562dd97-e04b-40ab-8777-a4d8f88a681b",
    "parent_id": "2036ee31-7783-4994-8a35-bbcf53917b0a",
    "text": "l 119\n5.5 \nFinite Square Well 128\n5.6 \nCompare and Contrast 133\n5.6.1 \nWave Function Curvature 133\n5.6.2 \nNodes 135\n5.6.3 \nBarrier Penetration 135\n5.6.4 \nInversion Symmetry and Parity 136\n5.6.5 \nOrthonormality 136\n5.6.6 \nCompleteness 137\n5.7 \nSuperposition States and Time Dependence 137\n5.8 \nModern Application: Quantum Wells and Dots 146\n5.9 \n Asymmetric Square Well: Sneak Peek at  \nPerturbations 147\n5.10  Fitting Energy Eigenstates by Eye or by  \nComputer 150\n5.10.1 Qualitative (Eyeball) Solutions 150\n\nContents  \n \nix\n5.10.2 Numerical Solutions 151\n5.10.3 General Potential Wells 154\nSummary 154\nProblems 156\nResources 159\nActivities 159\nFurther Reading 160\n \n6 \u0002 Unbound States \n161\n6.1 \nFree Particle Eigenstates 161\n6.1.1 \nEnergy Eigenstates 161\n6.1.2 \nMomentum Eigenstates 163\n6.2 \nWave Packets 168\n6.2.1 \nDiscrete Superposition 168\n6.2.2 \nContinuous Superposition 171\n6.3 \nUncertainty Principle 176\n6.3.1 \nEnergy Estimation 180\n6.4 \nUnbound States and Scattering 181\n6.5 \nTunneling Through Barriers 188\n6.6 \nAtom Interferometry 192\nSummary 197\nProblems 197\nResources 201\nActivities 201\nFurther Reading 201\n \n7 \u0002 Angular Momentum \n202\n7.1 \n Separating Center-of-Mass and Relative  \nMotion 204\n7.2 \n Energy Eigenvalue Equation in Spherical  \nCoordinates 208\n7.3 \nAngular Momentum 210\n7.3.1 \nClassical Angular Momentum 210\n7.3.2 \n Quantum Mechanical Angular  \nMomentum 210\n7.4 \nSeparation of Variables: Spherical Coordinates 215\n7.5 \nMotion of a Particle on a Ring 218\n7.5.1 \nAzimuthal Solution 220\n7.5.2 \n Quantum Measurements on a Particle  \nCon\ufb01ned to a Ring 223\n7.5.3 \nSuperposition States 224\n7.6 \nMotion on a Sphere 227\n7.6.1 \nSeries Solution of Legendre\u2019s Equation 228\n7.6.2 \nAssociated Legendre Functions 233\n7.6.3 \nEnergy Eigenvalues of a Rigid Rotor 236\n7.6.4 \nSpherical Harmonics 237\n7.6.5 \nVisualization of Spherical Harmonics 240\n\nx \nContents \nSummary 245\nProblems 245\nResources 249\nActivities 249\n \n8 \u0002 Hydrogen Atom \n250\n8.1 \nThe Radial Eigenvalue Equation 250\n8.2 \nSolving the Radial Equation 252\n8.2.1 \n Asymptotic Solutions to the Radial  \nEquation 252\n8.2.2 \nSeries Solution to the Radial Equation 253\n8.3 \nHydrogen Energies and Spectrum 256\n8.4 \nThe Radial Wave Functions 261\n8.5 \nThe Full Hydrogen Wave Functions 263\n8.6 \nSuperposition States 270\nSummary 272\nProblems 272\nResources 274\nActivities 274\nFurther Reading 274\n \n9 \u0002 Harmonic Oscillator \n275\n9.1 \nClassical Harmonic Oscillator 275\n9.2 \nQuantum Mechanical Harmonic Oscillator 277\n9.3 \nWave Functions 284\n9.4 \nDirac Notation 289\n9.5 \nMatrix Representations 293\n9.6 \nMomentum Space Wave Function 296\n9.7 \nThe Uncertainty Principle 298\n9.8 \nTime Dependence 300\n9.9 \nMolecular Vibrations 305\nSummary 307\nProblems 308\nResources 311\nActivities 311\nFurther Reading 311\n \n10 \u0002 Perturbation Theory \n312\n10.1 Spin-1/2 Example 313\n10.2 General Two-Level Example 317\n10.3 Nondegenerate Perturbation Theory 319\n10.3.1 First-Order Energy Correction 320\n10.3.2 First-Order State Vector Correction 324\n10.4  Second-Order Nondeg",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 5
  },
  {
    "child_id": "2786dd35-e154-45ba-8f03-99dbf122449d",
    "parent_id": "2036ee31-7783-4994-8a35-bbcf53917b0a",
    "text": "rac Notation 289\n9.5 \nMatrix Representations 293\n9.6 \nMomentum Space Wave Function 296\n9.7 \nThe Uncertainty Principle 298\n9.8 \nTime Dependence 300\n9.9 \nMolecular Vibrations 305\nSummary 307\nProblems 308\nResources 311\nActivities 311\nFurther Reading 311\n \n10 \u0002 Perturbation Theory \n312\n10.1 Spin-1/2 Example 313\n10.2 General Two-Level Example 317\n10.3 Nondegenerate Perturbation Theory 319\n10.3.1 First-Order Energy Correction 320\n10.3.2 First-Order State Vector Correction 324\n10.4  Second-Order Nondegenerate Perturbation  \nTheory 329\n10.5 Degenerate Perturbation Theory 336\n10.6 More Examples 343\n\nContents  \n \nxi\n10.6.1 Harmonic Oscillator 343\n10.6.2 Stark Effect in Hydrogen 346\nSummary 351\nProblems 352\n \n11 \u0002  Hyper\ufb01ne Structure and the Addition of \nAngular Momenta \n355\n11.1 Hyper\ufb01ne Interaction 355\n11.2 Angular Momentum Review 357\n11.3 Angular Momentum Ladder Operators 359\n11.4 Diagonalization of the Hyper\ufb01ne Perturbation 361\n11.5 The Coupled Basis 365\n11.6 Addition of Generalized Angular Momenta 370\n11.7  Angular Momentum in Atoms and Spectroscopic  \nNotation 377\nSummary 377\nProblems 379\nResources 381\nActivities 381\nFurther Reading 381\n \n12 \u0002 Perturbation of Hydrogen \n382\n12.1 Hydrogen Energy Levels 382\n12.2 Fine Structure of Hydrogen 386\n12.2.1 Relativistic Correction 386\n12.2.2 Spin-Orbit Coupling 388\n12.3 Zeeman Effect 393\n12.3.1 Zeeman Effect without Spin 394\n12.3.2 Zeeman Effect with Spin 396\n12.3.2.1 Weak magnetic \ufb01eld 396\n12.3.2.2 Strong magnetic \ufb01eld 402\n12.3.2.3 Intermediate magnetic \ufb01eld 403\n12.3.3  Zeeman Perturbation of the 1s \nHyper\ufb01ne Structure 405\nSummary 407\nProblems 407\nResources 409\nActivities 409\nFurther Reading 409\n \n13 \u0002 Identical Particles \n410\n13.1 Two Spin-1/2 Particles 410\n13.2 Two Identical Particles in One Dimension 414\n13.2.1 Two-Particle Ground State 415\n13.2.2 Two-Particle Excited State 416\n13.2.3 Visualization of States 417\n13.2.4 Exchange Interaction 420\n\nxii \nContents \n13.2.5  Consequences of the Symmetrization  \nPostulate 421\n13.3 Interacting Particles 423\n13.4 Example: The Helium Atom 427\n13.4.1 Helium Ground State 428\n13.4.2 Helium Excited States 431\n13.5 The Periodic Table 434\n13.6 Example: The Hydrogen Molecule 437\n13.6.1 The Hydrogen Molecular Ion H2\n+ 438\n13.6.2 The Hydrogen Molecule H2 440\nSummary 442\nProblems 442\nResources 444\nFurther Reading 444\n \n14 \u0002 Time-Dependent Perturbation Theory \n445\n14.1 Transition Probability 445\n14.2 Harmonic Perturbation 450\n14.3 Electric Dipole Interaction 454\n14.3.1 Einstein Model: Broadband Excitation 456\n14.3.2 Laser Excitation 460\n14.4 Selection Rules 462\nSummary 466\nProblems 467\nResources 468\nFurther Reading 468\n \n15 \u0002 Periodic Systems \n469\n15.1  The Energy Eigenvalues and Eigenstates of a  \nPeriodic Chain of Wells 471\n15.1.1 A Two-Well Chain 471\n15.1.2 N-Well Chain 473\n15.2  Boundary Conditions and the Allowed Values  \nof k 476\n15.3 The Brillouin Zones 478\n15.4 Multiple Bands from Multiple Atomic Levels 478\n15.5 Bloch\u2019s Theorem and the Molecular States 480\n15.6 Molecular W",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 5
  },
  {
    "child_id": "112edb03-6704-4f2b-9429-06c50c42b28c",
    "parent_id": "2036ee31-7783-4994-8a35-bbcf53917b0a",
    "text": "band Excitation 456\n14.3.2 Laser Excitation 460\n14.4 Selection Rules 462\nSummary 466\nProblems 467\nResources 468\nFurther Reading 468\n \n15 \u0002 Periodic Systems \n469\n15.1  The Energy Eigenvalues and Eigenstates of a  \nPeriodic Chain of Wells 471\n15.1.1 A Two-Well Chain 471\n15.1.2 N-Well Chain 473\n15.2  Boundary Conditions and the Allowed Values  \nof k 476\n15.3 The Brillouin Zones 478\n15.4 Multiple Bands from Multiple Atomic Levels 478\n15.5 Bloch\u2019s Theorem and the Molecular States 480\n15.6 Molecular Wave Functions\u2014a Gallery 482\n15.7 The Density of States 484\n15.8 Calculation of the Model Parameters 486\n15.8.1 LCAO Summary 488\n15.9 The Kronig-Penney Model 489\n15.10  Practical Applications: Metals, Insulators, and  \nSemiconductors 491\n15.11 Effective Mass 494\n15.12 Direct and Indirect Band Gaps 496\n15.13 New Directions\u2014Low-Dimensional Carbon 497\n\nContents  \n \nxiii\nSummary 498\nProblems 499\nResources 500\nActivities 500\nFurther Reading 500\n \n16 \u0002 Modern Applications of Quantum Mechanics \n502\n16.1  Manipulating Atoms with Quantum  \nMechanical Forces 502\n16.1.1 Magnetic Trapping 502\n16.1.2 Laser Cooling 506\n16.2 Quantum Information Processing 514\n16.2.1 Quantum Bits\u2014Qubits 515\n16.2.2 Quantum Gates 518\n16.2.3 Quantum Teleportation 524\nSummary 526\nProblems 527\nResources 528\nFurther Reading 528\nAppendix A: Probability \n529\nAppendix B: Complex Numbers \n533\nAppendix C: Matrices \n537\nAppendix D: Waves and Fourier Analysis \n541\nAppendix E: Separation of Variables \n547\nAppendix F: Integrals \n549\nAppendix G: Physical Constants \n551\nIndex \n553",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 5
  },
  {
    "child_id": "84bce91d-5e37-4860-b854-cf1378e67c8f",
    "parent_id": "e6a8d2ef-0193-4992-a02b-fd112879e839",
    "text": "xv\nPreface\nThis text is designed to introduce undergraduates at the junior and senior levels to quantum mechan-\nics. The text is an outgrowth of the new physics major curriculum developed by the Paradigms in \nPhysics program at Oregon State University. This new curriculum distributes material from the sub-\ndisciplines throughout the two upper-division years and provides students with a more gradual tran-\nsition between introductory and advanced levels. We have also incorporated and developed modern \npedagogical strategies to help improve student learning. This text covers the quantum mechanical \naspects of our curriculum in a way that can also be used in traditional curricula, but that still pre-\nserves the advantages of the Paradigms approach to the ordering of materials and the use of student \nengagement activities.\nPARADIGMS PROGRAM\nThe Paradigms project began in 1997, when the Department of Physics at Oregon State University \nbegan an extensive revision of the upper-division physics major. In an effort to encourage students \nto draw connections between the subdisciplines of physics, the structure of the Paradigms has been \ncrafted to mimic the organization of expert physics knowledge. Students are presented with a model \nof how physicists organize their understanding of physical phenomena and problem solving. Each \nof the nine short junior-year Paradigms courses focuses on a speci\ufb01c paradigm or class of physics \nproblems that serves as the centerpiece of the course and on which different tools and skills are built. \nIn the senior year, students resume a more traditional curriculum, taking six capstone courses in \nthe traditional disciplines. This curriculum incorporates a diverse set of student activities that allow \nstudents to stay actively engaged in the classroom and to work together in constructing their under-\nstanding of physics. Computer resources are used frequently to help students visualize the systems \nthey are studying.\nCONTENT AND APPROACH\nQuantum mechanics is integrated into four of the junior-year Paradigms courses and one senior-year \ncapstone course at Oregon State University. This text includes all the quantum mechanics topics \ncovered in those \ufb01ve courses. We adopt a \u201cspins-\ufb01rst\u201d approach by introducing quantum mechanics \nthrough the analysis of sequential Stern-Gerlach spin measurements. This approach is based upon \nprevious presentations of spin systems by Feynman, Leighton, and Sands; Cohen-Tannoudji, Diu, \nand Laloe; Sakurai; and Townsend. The aim of the spins-\ufb01rst approach is twofold: (1) To imme-\ndiately immerse students in the inherently quantum mechanical aspects of physics by focusing on \nsimple measurements that have no classical explanation, and (2) To give students early and extensive \nexperience with the mechanics of quantum mechanics in the forms of Dirac and matrix notation.\n\nxvi \nPreface \nThe  simplicity of the spin-1/2 and spin-1 systems allows the students to focus on these new features, \nwhich run counte",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 17
  },
  {
    "child_id": "e69eef65-8053-4a19-9bec-2e550f6fe99a",
    "parent_id": "e6a8d2ef-0193-4992-a02b-fd112879e839",
    "text": "d Townsend. The aim of the spins-\ufb01rst approach is twofold: (1) To imme-\ndiately immerse students in the inherently quantum mechanical aspects of physics by focusing on \nsimple measurements that have no classical explanation, and (2) To give students early and extensive \nexperience with the mechanics of quantum mechanics in the forms of Dirac and matrix notation.\n\nxvi \nPreface \nThe  simplicity of the spin-1/2 and spin-1 systems allows the students to focus on these new features, \nwhich run counter to classical mechanics.\nThe \ufb01rst three chapters of this text deal exclusively with spin systems and extensions to general \ntwo- and three-state quantum mechanical systems. The basic postulates of quantum mechanics are \nillustrated through their manifestation in the Stern-Gerlach experiments. After these three chapters, \nstudents have the tools to tackle any quantum mechanical problem presented in Dirac or matrix \nnotation. After a brief interlude into quantum spookiness (the EPR Paradox and Schr\u00f6dinger\u2019s cat) \nin Chapter 4, we tackle the traditional wave function aspects of quantum mechanics. We present \nseveral quantum systems\u2014a particle in a box, on a ring, on a sphere, the hydrogen atom, and the \nharmonic oscillator\u2014and emphasize their common features and their connections to the basic pos-\ntulates. The differential equations of angular momentum and the hydrogen atom radial problem are \nsolved in detail to expose students to the rigor of series solutions, though we stress that these are \nagain eigenvalue equations, no different in principle from the spin eigenvalue equations. Whenever \npossible, we continue the use of Dirac notation and matrix notation learned in the spin chapters, \nemphasizing the importance of \ufb02uency in multiple representations. We build upon the spins-\ufb01rst \napproach by using the spin-1/2 example to introduce perturbation theory, the addition of angular \nmomentum, and identical particles.\nUSAGE\nAt Oregon State University, the content of this text is taught in \ufb01ve courses as shown below.\nJunior-Year Paradigms Courses\nSpin and Quantum \nMeasurement\nWaves\nCentral Forces\nPeriod Systems\n1.  Stern-Gerlach  \nExperiments\n2.  Operators and  \nMeasurement\n3.  Schr\u00f6dinger Time \nEvolution\n4. Quantum Spookiness\nMechanical waves \nand EM waves\n5.  Quantized Energies:  \nParticle in a Box\n6. Unbound States\nPlanetary orbits\n7.  Angular  \nMomentum\n8. Hydrogen Atom\nCoupled \nOscillations\n15.  Periodic  \nSystems\nSenior-Year Quantum Mechanics Capstone Course\n 9. Harmonic Oscillator\n10. Perturbation Theory\n11.  Hyper\ufb01ne Structure \nand the Addition of \nAngular Momentum\n12.  Perturbation of \nHydrogen\n13. Identical Particles\n14.  Time-Dependent \nPerturbation \nTheory\n16.  Modern \nApplications\nFor a traditional curriculum, the content of this text would cover a full-year course, either two \nsemesters or three quarters. A proposed weekly outline for two 15-week semesters or three 10-week \nquarters is shown below.\n\nPreface  \nxvii\nWeek\nChapter\nTopics\n1\n1\nStern-Gerla",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 17
  },
  {
    "child_id": "c4de17f6-bdee-46f7-b5b4-bb3a0d207478",
    "parent_id": "e6a8d2ef-0193-4992-a02b-fd112879e839",
    "text": "onic Oscillator\n10. Perturbation Theory\n11.  Hyper\ufb01ne Structure \nand the Addition of \nAngular Momentum\n12.  Perturbation of \nHydrogen\n13. Identical Particles\n14.  Time-Dependent \nPerturbation \nTheory\n16.  Modern \nApplications\nFor a traditional curriculum, the content of this text would cover a full-year course, either two \nsemesters or three quarters. A proposed weekly outline for two 15-week semesters or three 10-week \nquarters is shown below.\n\nPreface  \nxvii\nWeek\nChapter\nTopics\n1\n1\nStern-Gerlach experiment, Quantum State Vectors, Bra-ket notation \n2\n1\nMatrix notation, General Quantum Systems\n3\n2\nOperators, Measurement, Commuting Observables\n4\n2\nUncertainty Principle, S2 Operator, Spin-1 System\n5\n3\nSchr\u00f6dinger Equation, Time Evolution\n6\n3\nSpin Precession, Neutrino Oscillations, Magnetic Resonance\n7\n4\nEPR Paradox, Bell\u2019s Inequalities, Schr\u00f6dinger\u2019s Cat\n8\n5\nEnergy Eigenvalue Equation, Wave Function\n9\n5\nOne-Dimensional Potentials, Finite Well, In\ufb01nite Well\n10\n6\nFree Particle, Wave Packets, Momentum Space\n11\n6\nUncertainty Principle, Barriers\n12\n7\nThree-Dimensional Energy Eigenvalue Equation, Separation of Variables\n13\n7\nAngular Momentum, Motion on a Ring and Sphere, Spherical Harmonics\n14\n8\nHydrogen Atom, Radial Equation, Energy Eigenvalues\n15\n8\nHydrogen Wave Functions, Spectroscopy\n16\n9\n1-D Harmonic Oscillator, Operator Approach, Energy Spectrum\n17\n9\nHarmonic Oscillator Wave Functions, Matrix Representation\n18\n9\nMomentum Space Wave Functions, Time Dependence, Molecular Vibrations\n19\n10\nTime-Independent Perturbation Theory: Nondegenerate, Degenerate\n20\n10\nPerturbation Examples: Harmonic Oscillator, Stark Effect in Hydrogen\n21\n11\nHyper\ufb01ne Structure, Coupled Basis\n22\n11\nAddition of Angular Momenta, Clebsch-Gordan Coef\ufb01cients\n23\n12\nHydrogen Atom: Fine Structure, Spin-Orbit, Zeeman Effect\n24\n13\nIdentical Particles, Symmetrization, Helium Atom\n25\n14\nTime-Dependent Perturbation Theory, Harmonic Perturbation\n26\n14\nRadiation, Selection Rules\n27\n15\nPeriodic Potentials, Bloch\u2019s Theorem\n28\n15\nDispersion Relation, Density of States, Semiconductors\n29\n16\nModern Applications of Quantum Mechanics, Laser Cooling and Trapping\n30\n16\nQuantum Information Processing\n\nxviii \nPreface \nAUDIENCE AND EXPECTED BACKGROUND\nThe intended audience is junior and senior physics majors, who are expected to have taken intermediate-\nlevel courses in modern physics and linear algebra. No other upper-level physics or mathematics courses \nare required. For our own students, we review matrix algebra in a seven contact hour \u201cpreface\u201d course \nthat precedes the Paradigms courses that teach quantum mechanics. The material for that preface course \nis in Appendix C. The material in Appendix B summarizes an earlier Paradigms course on oscillations, \nand the material in Appendix D summarizes the classical wave part of the Paradigms course on waves.\nSTUDENT ACTIVITIES AND WEBSITE\nStudent engagement activities are an integral part of the Paradigms curriculum. All of the activities \nthat we have deve",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 17
  },
  {
    "child_id": "a2f535b4-460d-40be-a1f5-d9f83bc2b923",
    "parent_id": "e6a8d2ef-0193-4992-a02b-fd112879e839",
    "text": " in a seven contact hour \u201cpreface\u201d course \nthat precedes the Paradigms courses that teach quantum mechanics. The material for that preface course \nis in Appendix C. The material in Appendix B summarizes an earlier Paradigms course on oscillations, \nand the material in Appendix D summarizes the classical wave part of the Paradigms course on waves.\nSTUDENT ACTIVITIES AND WEBSITE\nStudent engagement activities are an integral part of the Paradigms curriculum. All of the activities \nthat we have developed are freely available on our wiki website:\nhttp://physics.oregonstate.edu/portfolioswiki\nThe wiki contains a wealth of information about the Paradigms project, the courses we teach, and the \nmaterials we have developed. Details about individual activities include descriptions, student handouts, \ninstructor\u2019s guides, advice about how to use active engagement strategies, videos of classroom prac-\ntice, narratives of classroom activities, and comments from users\u2014both internal and external to Oregon \nState University. This is a dynamic website that is continually updated as we develop new activities and \nimprove existing ones. We encourage you to visit the website and join the community. E-mail us with \ncorrections, additions, and suggestions.\nEach of the quantum mechanics activities that we use in our \ufb01ve courses is referenced in the \nresource section at the end of the appropriate chapter in the text. The quantum mechanics activities are \ncollected within the wiki website with a direct link: \nwww.physics.oregonstate.edu/qmactivities \nThese activities include different types of activities such as computer-based activities, group activities, \nand class response activities. The most extensive activity is a computer simulation of Stern-Gerlach \nexperiments. This SPINS software is a full-featured, menu-driven application that allows students to \nsimulate successive Stern-Gerlach measurements and explore incompatible observables, eigenstate \nexpansions, interference, and quantum dynamics. The use of the SPINS software facilitates our spins-\n\ufb01rst approach. The beauty of the simulation is that students steeped in classical physics perform a foun-\ndational quantum experiment and learn the most fascinating and counterintuitive aspects of quantum \nmechanics at an early stage.\nACKNOWLEDGMENTS\nThis work is the product of a broad and energetic community of educators and students within the \nParadigms in Physics program. I thank all of our students for their hard work, insights, and innu-\nmerable suggestions. My colleagues Corinne Manogue and Janet Tate have developed some of the \ncourses upon which this text is based. They have worked with me throughout the writing of this text \nand I am indebted to them for their valuable contributions. I gratefully acknowedge my fellow faculty \nwho have developed and taught in the new curriculum: Dedra Demaree, Tevian Dray, Tomasz Gieb-\nultowicz, Elizabeth Gire, William Hetherington, Henri Jansen, Kenneth Krane, Yun-Shik Lee, Victor",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 17
  },
  {
    "child_id": "34ae2f48-9cbf-4687-9037-64a71a1f2bdd",
    "parent_id": "e6a8d2ef-0193-4992-a02b-fd112879e839",
    "text": " and innu-\nmerable suggestions. My colleagues Corinne Manogue and Janet Tate have developed some of the \ncourses upon which this text is based. They have worked with me throughout the writing of this text \nand I am indebted to them for their valuable contributions. I gratefully acknowedge my fellow faculty \nwho have developed and taught in the new curriculum: Dedra Demaree, Tevian Dray, Tomasz Gieb-\nultowicz, Elizabeth Gire, William Hetherington, Henri Jansen, Kenneth Krane, Yun-Shik Lee, Victor \nMadsen, Ethan Minot, Oksana Ostroverkhova, David Roundy, Philip Siemens, Albert Stetz, William",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 17
  },
  {
    "child_id": "64f845b7-b5fb-4187-bca6-5c9c8e5778e1",
    "parent_id": "0836ee27-0676-42f4-bdcd-c7cab51dfe26",
    "text": "Preface   \nxix\nWarren, and Allen Wasserman. I would also like to acknowledge the important contributions of early \nteaching assistants Kerry Browne, Jason Janesky, Cheryl Klipp, Katherine Meyer, Steve Sahyun, and \nEmily Townsend\u2014their expertise, dedication, and enthusiasm were above and beyond the call of \nduty. The many subsequent teaching assistants have also been enthusiastic and valued contributors. \nI also thank those who have contributed in various ways to the development of activities: Mario Bel-\nloni, Tim Budd, Wolfgang Christian, Paco Esquembre, Lichun Jia, and Shannon Mayer. I particularly \nthank Daniel Schroeder for sharing his original SPINS software. I acknowledge useful and construc-\ntive feedback from Jeffrey Dunham, Joshua Folk, Rubin Landau, Edward (Joe) Redish, Joseph Roth-\nberg, Homeyra Sadaghiani, Daniel Schroeder, Chandralekha Singh, and Daniel Styer. The Paradigms \nadvisory committee has also provided valuable feedback and I acknowledge David Grif\ufb01ths, Bruce \nMason, William McCallum, Harriett Platsek, and Michael Wittmann for their help. I am grateful to the \nsuccessive Physics Department chairs, Kenneth Krane and Henri Jansen, and Deans Fred Horne and \nSherman Bloomer at Oregon State University for their endorsement of the Paradigms project.\nThis material is based on work supported by the National Science Foundation under Grant Nos. \n9653250, 0231194, and 0618877. Any opinions, \ufb01ndings, and conclusions or recommendations \nexpressed in this material are those of the authors and do not necessarily re\ufb02ect the views of the \nNational Science Foundation. I thank Duncan McBride and Jack Hehn for their encouragement and \nsupport of our endeavor.\nJim Smith at Addison Wesley has been enthusiastic about this project from the early stages. Peter \nAlston has navigated me through the editorial process with skill and patience. I am grateful to them \nand also to Katie Conley, Steven Le, and the rest of the staff at Addison Wesley for their work to pro-\nduce this text.\nDavid H. McIntyre\nCorvallis, Oregon  \nNovember 2011\n\nxxi\nPrologue\nIt was a dark and stormy night. Erwin huddled under his covers as he had done numerous times that \nsummer. As the wind and rain lashed at the window, he feared having to retreat to the storm cellar \nonce again. The residents of Erwin\u2019s apartment building sought shelter whenever there were threats of \ntornadoes in the area. While it was safe down there, Erwin feared the ridicule he would face once again \nfrom the other school boys. In the rush to the cellar, Erwin seemed to always end up with a random \npair of socks, and the other boys teased him about it mercilessly.\nNot that Erwin hadn\u2019t tried hard to solve this problem. He had a very simple collection of \nsocks\u2014black or white, for either school or play; short or long, for either trousers or lederhosen. \nAfter the \ufb01rst few teasing episodes from the other boys, Erwin had sorted his socks into two sepa-\nrate drawers. He placed all the black socks in one drawer a",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 21
  },
  {
    "child_id": "0f4360ec-af7e-4394-9467-90288bdca622",
    "parent_id": "0836ee27-0676-42f4-bdcd-c7cab51dfe26",
    "text": "hool boys. In the rush to the cellar, Erwin seemed to always end up with a random \npair of socks, and the other boys teased him about it mercilessly.\nNot that Erwin hadn\u2019t tried hard to solve this problem. He had a very simple collection of \nsocks\u2014black or white, for either school or play; short or long, for either trousers or lederhosen. \nAfter the \ufb01rst few teasing episodes from the other boys, Erwin had sorted his socks into two sepa-\nrate drawers. He placed all the black socks in one drawer and all the white socks in another drawer. \nErwin \ufb01gured he could determine an individual sock\u2019s length in the dark of night simply by feel-\ning it, but he had to have them presorted into white and black because the apartment generally lost \npower before the call to the shelter.\nUnfortunately, Erwin found that this presorting of the socks by color was ineffective. Whenever \nhe reached into the white sock drawer and chose two long socks, or two short socks, there was a 50% \nprobability of any one sock being black or white. The results from the black sock drawer were the \nsame. The socks seemed to have \u201cforgotten\u201d the color that Erwin had determined previously.\nErwin also tried sorting the socks into two drawers based upon their length, without regard to \ncolor. When he chose black or white socks from these long and short drawers, the socks had also \u201cfor-\ngotten\u201d whether they were long or short.\nAfter these fruitless attempts to solve his problem through experiments, Erwin decided to save \nhimself the fashion embarrassment, and he replaced his sock collection with a set of medium length \nbrown socks. However, he continued to ponder the mysteries of the socks throughout his childhood.\nAfter many years of daydreaming about the mystery socks, Erwin Schr\u00f6dinger proposed his the-\nory of \u201cQuantum Socks\u201d and become famous. And that is the beginning of the story of the quantum \nsocks.\nThe End.\nFarfetched?? You bet. But Erwin\u2019s adventure with his socks is the way quantum mechanics works. \nRead on.\n\n1\nC H A P T E R \n1\nStern-Gerlach Experiments\nIt was not a dark and stormy night when Otto Stern and Walther  Gerlach performed their now famous \nexperiment in 1922. The Stern-Gerlach experiment demonstrated that measurements on microscopic \nor quantum particles are not always as certain as we might expect. Quantum particles behave as mys-\nteriously as Erwin\u2019s socks\u2014sometimes forgetting what we have already measured. Erwin\u2019s adven-\nture with the mystery socks is farfetched because you know that everyday objects do not behave like \nhis socks. If you observe a sock to be black, it remains black no matter what other properties of the \nsock you observe. However, the Stern- Gerlach experiment goes against these ideas. Microscopic or \nquantum particles do not behave like the classical objects of your everyday experience. The act of \nobserving a quantum particle affects its measurable properties in a way that is foreign to our classical \nexperience.\nIn these \ufb01rst three chapters, we",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 21
  },
  {
    "child_id": "1e01d35a-a1c0-42d2-a7b8-b5a24753af0e",
    "parent_id": "0836ee27-0676-42f4-bdcd-c7cab51dfe26",
    "text": " know that everyday objects do not behave like \nhis socks. If you observe a sock to be black, it remains black no matter what other properties of the \nsock you observe. However, the Stern- Gerlach experiment goes against these ideas. Microscopic or \nquantum particles do not behave like the classical objects of your everyday experience. The act of \nobserving a quantum particle affects its measurable properties in a way that is foreign to our classical \nexperience.\nIn these \ufb01rst three chapters, we focus on the Stern-Gerlach experiment because it is a conceptu-\nally simple experiment that demonstrates many basic principles of quantum mechanics. We discuss \na variety of experimental results and the quantum theory that has been developed to predict those \nresults. The mathematical formalism of quantum mechanics is based upon six postulates that we will \nintroduce as we develop the theoretical framework. (A complete list of these postulates is in Section 1.5.) \nWe use the Stern-Gerlach experiment to learn about quantum mechanics theory for two primary reasons: \n(1) It demonstrates how quantum mechanics works in principle by illustrating the postulates of quan-\ntum mechanics, and (2) it demonstrates how quantum mechanics works in practice through the use \nof Dirac notation and matrix mechanics to solve problems. By using a simple example, we can focus \non the principles and the new mathematics, rather than having the complexity of the physics obscure \nthese new aspects.\n1.1 \u0002 STERN-GERLACH EXPERIMENT\nIn 1922 Otto Stern and Walther Gerlach performed a seminal experiment in the history of quantum \nmechanics. In its simplest form, the experiment consisted of an oven that produced a beam of neu-\ntral atoms, a region of space with an inhomogeneous magnetic \ufb01eld, and a detector for the atoms, as \ndepicted in Fig. 1.1. Stern and Gerlach used a beam of silver atoms and found that the beam was split \ninto two in its passage through the magnetic \ufb01eld. One beam was de\ufb02ected upwards and one down-\nwards in relation to the direction of the magnetic \ufb01eld gradient.\nTo understand why this result is so at odds with our classical expectations, we must \ufb01rst analyze \nthe experiment classically. The results of the experiment suggest an interaction between a neutral parti-\ncle and a magnetic \ufb01eld. We expect such an interaction if the particle possesses a magnetic moment M.\nThe potential energy of this interaction is E = -M~B, which results in a force F = \u00021M~B2. In the\n\n2 \nStern-Gerlach Experiments\nStern-Gerlach experiment, the magnetic \ufb01eld gradient is primarily in the z-direction, and the resulting \nz-component of the force is\n \n Fz =\n0\n0z\n 1M~B2 \n(1.1)\n \n \u0002 mz \n0Bz\n0z\n .\n \nThis force is perpendicular to the direction of motion and de\ufb02ects the beam in proportion to the com-\nponent of the magnetic moment in the direction of the magnetic \ufb01eld gradient.\nNow consider how to understand the origin of the atom\u2019s magnetic moment from a classical view-\npoint. The atom consists of ch",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 21
  },
  {
    "child_id": "724f27d6-8c16-489a-af88-eb890b42d47e",
    "parent_id": "0836ee27-0676-42f4-bdcd-c7cab51dfe26",
    "text": "h Experiments\nStern-Gerlach experiment, the magnetic \ufb01eld gradient is primarily in the z-direction, and the resulting \nz-component of the force is\n \n Fz =\n0\n0z\n 1M~B2 \n(1.1)\n \n \u0002 mz \n0Bz\n0z\n .\n \nThis force is perpendicular to the direction of motion and de\ufb02ects the beam in proportion to the com-\nponent of the magnetic moment in the direction of the magnetic \ufb01eld gradient.\nNow consider how to understand the origin of the atom\u2019s magnetic moment from a classical view-\npoint. The atom consists of charged particles, which, if in motion, can produce loops of current that give \nrise to magnetic moments. A loop of area A and current I produces a magnetic moment\n \nm = IA \n(1.2)\nin MKS units. If this loop of current arises from a charge q traveling at speed v in a circle of radius r, \nthen\n \n m =\nq\n2pr>v\n pr 2 \n \n = qrv\n2\n \n(1.3)\n \n =\nq\n2m\n L ,\n \nwhere L = mrv is the orbital angular momentum of the particle. In the same way that the earth \nrevolves around the sun and rotates around its own axis, we can also imagine a charged particle in \nan atom having orbital angular momentum L and a new property, the intrinsic angular momen-\ntum, which we label S and call spin. The intrinsic angular momentum also creates current loops, \nso we expect a similar relation between the magnetic moment M and S. The exact calculation \nx\nOven\nCollimator\nMagnet\nDetector\nMagnet\nCross-Section\ny\nz\nS\nS\nN\nN\nFIGURE 1.1 Stern-Gerlach experiment to measure the spin component of neutral \nparticles along the z-axis. The magnet cross section at right shows the inhomogeneous \n\ufb01eld used in the experiment.",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 21
  },
  {
    "child_id": "ac7b8323-fa49-4a52-80fa-496948be3329",
    "parent_id": "67aa91c9-ed85-4cde-a4ba-09efe6d81d36",
    "text": "1.1 Stern-Gerlach Experiment \n3\ninvolves an integral over the charge distribution, which we will not do. We simply assume that we \ncan relate the magnetic moment to the intrinsic angular momentum in the same fashion as Eq. (1.3), \ngiving\n \nM = g q\n2m\n S , \n(1.4)\nwhere the dimensionless gyroscopic ratio g contains the details of that integral.\nA silver atom has 47 electrons, 47 protons, and 60 or 62 neutrons (for the most common isotopes). \nThe magnetic moments depend on the inverse of the particle mass, so we expect the heavy protons and \nneutrons (\u00032000 me) to have little effect on the magnetic moment of the atom and so we neglect them. \nFrom your study of the periodic table in chemistry, you recall that silver has an electronic con\ufb01gura-\ntion 1s22s22p63s23p64s23d104p64d105s1, which means that there is only the lone 5s electron outside \nof the closed shells. The electrons in the closed shells can be represented by a spherically symmetric \ncloud with no orbital or intrinsic angular momentum (unfortunately we are injecting some quantum \nmechanical knowledge of atomic physics into this classical discussion). That leaves the lone 5s elec-\ntron as a contributor to the magnetic moment of the atom as a whole. An electron in an s state has no \norbital angular momentum, but it does have spin. Hence the magnetic moment of this electron, and \ntherefore of the entire neutral silver atom, is\n \nM = -g e\n2me\n S , \n(1.5)\nwhere e is the magnitude of the electron charge. The classical force on the atom can now be written as\n \nFz \u0002 -g e\n2me\n Sz \n0Bz\n0z\n . \n(1.6)\nThe de\ufb02ection of the beam in the Stern-Gerlach experiment is thus a measure of the component (or pro-\njection) Sz of the spin along the z-axis, which is the orientation of the magnetic \ufb01eld gradient.\nIf we assume that the 5s electron of each atom has the same magnitude 0 S0  of the intrinsic angular \nmomentum or spin, then classically we would write the z-component as Sz = 0 S0 cos u, where u is \nthe angle between the z-axis and the direction of the spin S. In the thermal environment of the oven, \nwe expect a random distribution of spin directions and hence all possible angles u. Thus we expect \nsome continuous distribution (the details are not important) of spin components from Sz = - 0 S0  to \nSz = + 0 S0 , which would yield a continuous spread in de\ufb02ections of the silver atomic beam. Rather, \nthe experimental result that Stern and Gerlach observed was that there are only two de\ufb02ections, indi-\ncating that there are only two possible values of the z-component of the electron spin. The magnitudes \nof these de\ufb02ections are consistent with values of the spin component of\n \nSz = { U\n2\n ,  \n(1.7)\nwhere U is Planck\u2019s constant h divided by 2p and has the numerical value\n \n U = 1.0546 * 10-34  J~s \n \n = 6.5821 * 10-16  eV~s. \n \n(1.8)\nThis result of the Stern-Gerlach experiment is evidence of the quantization of the electron\u2019s \nspin angular momentum component along an axis. This quantization is at odds with our cla",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 27
  },
  {
    "child_id": "09a47d8d-7bcb-4e4e-9ec0-ac481a7ba6d1",
    "parent_id": "67aa91c9-ed85-4cde-a4ba-09efe6d81d36",
    "text": "e only two possible values of the z-component of the electron spin. The magnitudes \nof these de\ufb02ections are consistent with values of the spin component of\n \nSz = { U\n2\n ,  \n(1.7)\nwhere U is Planck\u2019s constant h divided by 2p and has the numerical value\n \n U = 1.0546 * 10-34  J~s \n \n = 6.5821 * 10-16  eV~s. \n \n(1.8)\nThis result of the Stern-Gerlach experiment is evidence of the quantization of the electron\u2019s \nspin angular momentum component along an axis. This quantization is at odds with our classical\n\n4 \nStern-Gerlach Experiments\nexpectations for this measurement. The factor of 1/2 in Eq. (1.7) leads us to refer to this as a \nspin-1/2 system.\nIn this example, we have chosen the z-axis along which to measure the spin component, but there \nis nothing special about this direction in space. We could have chosen any other axis and we would \nhave obtained the same results.\nNow that we know the \ufb01ne details of the Stern-Gerlach experiment, we simplify the experiment \nfor the rest of our discussions by focusing on the essential features. A simpli\ufb01ed schematic representa-\ntion of the experiment is shown in Fig. 1.2, which depicts an oven that produces the beam of atoms, a \nStern-Gerlach device with two output ports for the two possible values of the spin component, and two \ncounters to detect the atoms leaving the output ports of the Stern-Gerlach device. The Stern-Gerlach \ndevice is labeled with the axis along which the magnetic \ufb01eld is oriented. The up and down arrows \nindicate the two possible measurement results for the device; they correspond respectively to the \nresults Sz = {U>2 in the case where the \ufb01eld is oriented along the z-axis. There are only two possible \nresults in this case, so they are generally referred to as spin up and spin down. The physical quantity \nthat is measured, Sz in this case, is called an observable. In our detailed discussion of the experiment \nabove, we chose the \ufb01eld gradient in such a manner that the spin up states were de\ufb02ected upwards. \nIn this new simpli\ufb01cation, the de\ufb02ection itself is not an important issue. We simply label the output \nport with the desired state and count the particles leaving that port. The Stern-Gerlach device sorts \n(or \ufb01lters, selects or analyzes) the incoming particles into the two possible outputs Sz = {U>2 in the \nsame way that Erwin sorted his socks according to color or length. We follow convention and refer to \na Stern-Gerlach device as an analyzer.\nIn Fig. 1.2, the input and output beams are labeled with a new symbol called a ket. We use the \nket 0  +9 as a mathematical representation of the quantum state of the atoms that exit the upper port \ncorresponding to Sz = +U>2. The lower output beam is labeled with the ket 0  -9, which corresponds \nto Sz = -U>2, and the input beam is labeled with the more generic ket 0  c9. The kets are representa-\ntions of the quantum states. They are used in mathematical expressions and they represent all the \ninformation that we can know about the state. Thi",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 27
  },
  {
    "child_id": "1a70f38e-6a27-41c5-9596-f86db0deeede",
    "parent_id": "67aa91c9-ed85-4cde-a4ba-09efe6d81d36",
    "text": "ed with a new symbol called a ket. We use the \nket 0  +9 as a mathematical representation of the quantum state of the atoms that exit the upper port \ncorresponding to Sz = +U>2. The lower output beam is labeled with the ket 0  -9, which corresponds \nto Sz = -U>2, and the input beam is labeled with the more generic ket 0  c9. The kets are representa-\ntions of the quantum states. They are used in mathematical expressions and they represent all the \ninformation that we can know about the state. This ket notation was developed by Paul A. M. Dirac \nand is central to the approach to quantum mechanics that we take in this text. We will discuss the \nmathematics of these kets in full detail later. With regard to notation, you will \ufb01nd many different \nways of writing the same ket. The symbol within the ket brackets is any simple label to distinguish \nthe ket from other different kets. For example, the kets 0  +9, 0  +U>29, 0 Sz = +U>29, 0  +zn9, and 0 c9 \nare all equivalent ways of writing the same thing, which in this case signi\ufb01es that we have measured \nthe z-component of the spin and found it to be +U>2 or spin up. Though we may label these kets in \ndifferent ways, they all refer to the same physical state and so they all behave the same mathemati-\ncally. The symbol 0 {9 refers to both the 0  +9 and 0  -9 kets. The \ufb01rst postulate of quantum mechanics \ntells us that kets in general describe the quantum state mathematically and that they contain all the \ninformation that we can know about the state. We denote a general ket as 0  c9.\nZ\n50\n50\n\u0002\u0002\u0003\n\u0002\u0003\u0003\n\u0002\u03a8\u0003\nFIGURE 1.2 Simpli\ufb01ed schematic of the Stern-Gerlach experiment, \ndepicting a source of atoms, a Stern-Gerlach analyzer, and two counters.\n\n1.1 Stern-Gerlach Experiment \n5\nPostulate 1\nThe state of a quantum mechanical system, including all the information you \ncan know about it, is represented mathematically by a normalized ket 0  c9.\nWe have chosen the particular simpli\ufb01ed schematic representation of the Stern-Gerlach \nexperiment shown in Fig. 1.2, because it is the same representation used in the SPINS software \nprogram that you may use to simulate these experiments. The SPINS program allows you to per-\nform all the experiments described in this text. This software is freely available, as detailed in \nResources at the end of the chapter. In the SPINS program, the components are connected with \nsimple lines to represent the paths the atoms take. The directions and magnitudes of de\ufb02ections \nof the beams in the program are not relevant. That is, whether the spin up output beam is drawn \nas de\ufb02ected upwards, downwards, or not at all, is not relevant. The labeling on the output port is \nenough to tell us what that state is. Thus the extra ket label 0  +9 on the spin up output beam in Fig. \n1.2 is redundant and will be dropped soon.\nThe SPINS program permits alignment of Stern-Gerlach analyzing devices along all three axes \nand also at any angle f measured from the x-axis in the x-y plane. This would appear to b",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 27
  },
  {
    "child_id": "87d74623-0122-4b11-b0f4-ed0bb50a7212",
    "parent_id": "67aa91c9-ed85-4cde-a4ba-09efe6d81d36",
    "text": " are not relevant. That is, whether the spin up output beam is drawn \nas de\ufb02ected upwards, downwards, or not at all, is not relevant. The labeling on the output port is \nenough to tell us what that state is. Thus the extra ket label 0  +9 on the spin up output beam in Fig. \n1.2 is redundant and will be dropped soon.\nThe SPINS program permits alignment of Stern-Gerlach analyzing devices along all three axes \nand also at any angle f measured from the x-axis in the x-y plane. This would appear to be dif\ufb01cult, if \nnot impossible, given that the atomic beam in Fig. 1.1 is directed along the y-axis, making it unclear \nhow to align the magnet in the y-direction and measure a de\ufb02ection. In our depiction and discussion of \nStern-Gerlach experiments, we ignore this technical complication.\nIn the SPINS program, as in real Stern-Gerlach experiments, the numbers of atoms detected \nin particular states can be predicted by probability rules that we will discuss later. To simplify \nour schematic depictions of Stern-Gerlach experiments, the numbers shown for detected atoms \nare those obtained by using the calculated probabilities without any regard to possible statistical \nuncertainties. That is, if the theoretically predicted probabilities of two measurement possibilities \nare each 50%, then our schematics will display equal numbers for those two possibilities, whereas \nin a real experiment, statistical uncertainties might yield a 55%>45% split in one experiment and \na 47%>53% split in another, etc. The SPINS program simulations are designed to give statistical \nuncertainties, so you will need to perform enough experiments to convince yourself that you have a \nsuf\ufb01ciently good estimate of the probability (see SPINS Lab 1 for more information on statistics).\nNow let\u2019s consider a series of simple Stern-Gerlach experiments with slight variations that help to \nillustrate the main features of quantum mechanics. We \ufb01rst describe the experiments and their results \nand draw some qualitative conclusions about the nature of quantum mechanics. Then we introduce the \nformal mathematics of the ket notation and show how it can be used to predict the results of each of \nthe experiments.\n1.1.1 \u0002 Experiment 1\nThe \ufb01rst experiment is shown in Fig. 1.3 and consists of a source of atoms, two Stern-Gerlach ana-\nlyzers both aligned along the z-axis, and counters for the output ports of the analyzers. The atomic \nbeam coming into the \ufb01rst Stern-Gerlach analyzer is split into two beams at the output, just like the \noriginal experiment. Now instead of counting the atoms in the upper output beam, the spin compo-\nnent is measured again by directing those atoms into the second Stern-Gerlach analyzer. The result of \nthis experiment is that no atoms are ever detected coming out of the lower output port of the second \nStern-Gerlach analyzer. All atoms that are output from the upper port of the \ufb01rst analyzer also pass",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 27
  },
  {
    "child_id": "587d65d0-cf8c-42d7-bcd9-c59157e111e0",
    "parent_id": "ddbc7917-c10a-4925-9c30-70b78c96df1f",
    "text": "6 \nStern-Gerlach Experiments\nthrough the upper port of the second analyzer. Thus we say that when the \ufb01rst Stern-Gerlach analyzer \nmeasures an atom to have a z-component of spin Sz = +U>2, then the second analyzer also measures \nSz = +U>2 for that atom. This result is not surprising, but it sets the stage for results of experiments \nto follow.\nThough both Stern-Gerlach analyzers in Experiment 1 are identical, they play different roles in \nthis experiment. The \ufb01rst analyzer prepares the beam in a particular quantum state 10  +92 and the \nsecond analyzer measures the resultant beam, so we often refer to the \ufb01rst analyzer as a state prepa-\nration device. By preparing the state with the \ufb01rst analyzer, the details of the source of atoms can be \nignored. Thus our main focus in Experiment 1 is what happens at the second analyzer because we \nknow that any atom entering the second analyzer is represented by the 0  +9 ket prepared by the \ufb01rst \nanalyzer. All the experiments we will describe employ a \ufb01rst analyzer as a state preparation device, \nthough the SPINS program has a feature where the state of the atoms coming from the oven is deter-\nmined but unknown, and the user can perform experiments to determine the unknown state using only \none analyzer in the experiment.\n1.1.2 \u0002 Experiment 2\nThe second experiment is shown in Fig. 1.4 and is identical to Experiment 1 except that the sec-\nond Stern-Gerlach analyzer has been rotated by 90\u00b0 to be aligned with the x-axis. Now the second \nanalyzer measures the spin component along the x-axis rather the z-axis. Atoms input to the second \nanalyzer are still represented by the ket 0  +9 because the \ufb01rst analyzer is unchanged. The result of this \nexperiment is that atoms appear at both possible output ports of the second analyzer. Atoms leaving \nthe upper port of the second analyzer have been measured to have Sx = +U>2, and atoms leaving \nZ\nZ\n50\n50\n0\n\u0002\u0002\u0003\n\u0002\u0002\u0003\n\u0002\u0003\u0003\n\u0002\u0003\u0003\n\u0002\u03a8\u0003\nFIGURE 1.3 Experiment 1 measures the spin component along the z-axis twice in succession.\nX\nZ\n50\n25\n25\n\u0002\u0003\u0003\n\u0002\u0003\u0003x\n\u0002\u0002\u0003x\n\u0002\u0002\u0003\n\u0002\u03a8\u0003\nFIGURE 1.4 Experiment 2 measures the spin component along the z-axis and then along the x-axis.\n\n1.1 Stern-Gerlach Experiment \n7\nthe lower port have Sx = -U>2. On average, each of these ports has 50% of the atoms that left the \nupper port of the \ufb01rst analyzer. As shown in Fig. 1.4, the output states of the second analyzer have \nnew labels 0  +9x and 0  -9x, where the x subscript denotes that the spin component has been measured \nalong the x-axis. We assume that if no subscript is present on the quantum ket 1e.g., 0  +92, then the \nspin component is along the z-axis. This use of the z-axis as the default is a common convention \nthroughout our work and also in much of physics.\nA few items are noteworthy about this experiment. First, we notice that there are still only two \npossible outputs of the second Stern-Gerlach analyzer. The fact that it is aligned along a different axis \ndoesn\u2019t affect the fact that we get only two possible ",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 30
  },
  {
    "child_id": "8ba74f4f-2a2d-4267-958e-6f7749ed23ea",
    "parent_id": "ddbc7917-c10a-4925-9c30-70b78c96df1f",
    "text": "x-axis. We assume that if no subscript is present on the quantum ket 1e.g., 0  +92, then the \nspin component is along the z-axis. This use of the z-axis as the default is a common convention \nthroughout our work and also in much of physics.\nA few items are noteworthy about this experiment. First, we notice that there are still only two \npossible outputs of the second Stern-Gerlach analyzer. The fact that it is aligned along a different axis \ndoesn\u2019t affect the fact that we get only two possible results for the case of a spin-1/2 particle. Second, \nit turns out that the results of this experiment would be unchanged if we used the lower port of the \ufb01rst \nanalyzer. That is, atoms entering the second analyzer in state 0  -9 would also result in half the atoms \nin each of the 0 {9x output ports. Finally, we cannot predict which of the second analyzer output ports \nany particular atom will come out. This can be demonstrated in actual experiments by recording the \nindividual counts out of each port. The arrival sequences at any counter are completely random. We \ncan say only that there is a 50% probability that an atom from the second analyzer will exit the upper \nanalyzer port and a 50% probability that it will exit the lower port. The random arrival of atoms at the \ndetectors can be seen clearly in the SPINS program simulations.\nThis probabilistic nature is at the heart of quantum mechanics. One might be tempted to say that \nwe just don\u2019t know enough about the system to predict which port the atom will exit. That is to say, \nthere may be some other variables, of which we are ignorant, that would allow us to predict the results. \nSuch a viewpoint is known as a local hidden variable theory. John Bell proved that such theories are \nnot compatible with the experimental results of quantum mechanics. The conclusion to draw from this \nis that even though quantum mechanics is a probabilistic theory, it is a complete description of reality. \nWe will have more to say about this in Chapter 4.\nNote that the 50% probability referred to above is the probability that an atom input to the second \nanalyzer exits one particular output port. It is not the probability for an atom to pass through the whole sys-\ntem of Stern-Gerlach analyzers. It turns out that the results of this experiment (the 50>50 split at the sec-\nond analyzer) are the same for any combination of two orthogonal axes of the \ufb01rst and second analyzers.\n1.1.3 \u0002 Experiment 3\nExperiment 3, shown in Fig. 1.5, extends Experiment 2 by adding a third Stern-Gerlach analyzer aligned \nalong the z-axis. Atoms entering the third analyzer have been measured by the \ufb01rst Stern-Gerlach \nanalyzer to have spin component up along the z-axis, and by the second analyzer to have spin component \nup along the x-axis. The third analyzer then measures how many atoms have spin component up or down \n125\n125\n500\nX\nZ\nZ\n250\n\u0002\u0002\u0003\n\u0002\u0002\u0003\n\u0002\u0003\u0003\n\u0002\u0003\u0003\n\u0002\u03a8\u0003\n\u0002\u0003\u0003x\n\u0002\u0002\u0003x\nFIGURE 1.5 Experiment 3 measures the spin component three times in succession.\n\n8",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 30
  },
  {
    "child_id": "7ad1c995-bdd0-4a1e-8fbd-cd673225bbe0",
    "parent_id": "ddbc7917-c10a-4925-9c30-70b78c96df1f",
    "text": " Experiment 2 by adding a third Stern-Gerlach analyzer aligned \nalong the z-axis. Atoms entering the third analyzer have been measured by the \ufb01rst Stern-Gerlach \nanalyzer to have spin component up along the z-axis, and by the second analyzer to have spin component \nup along the x-axis. The third analyzer then measures how many atoms have spin component up or down \n125\n125\n500\nX\nZ\nZ\n250\n\u0002\u0002\u0003\n\u0002\u0002\u0003\n\u0002\u0003\u0003\n\u0002\u0003\u0003\n\u0002\u03a8\u0003\n\u0002\u0003\u0003x\n\u0002\u0002\u0003x\nFIGURE 1.5 Experiment 3 measures the spin component three times in succession.\n\n8 \nStern-Gerlach Experiments\nalong the z-axis. Classically, one would expect that the \ufb01nal measurement would yield the result spin \nup along the z-axis, because that was measured at the \ufb01rst analyzer. That is to say: classically the \ufb01rst \ntwo analyzers tell us that the atoms have Sz = +U>2 and Sx = +U>2, so the third measurement must \nyield Sz = +U>2. But that doesn\u2019t happen, as Erwin learned with his quantum socks in the Prologue. \nThe quantum mechanical result is that the atoms are split with 50% probability into each output port at \nthe third analyzer. Thus the last two analyzers behave like the two analyzers of Experiment 2 (except \nwith the order reversed), and the fact that there was an initial measurement that yielded Sz = +U>2 is \nsomehow forgotten or erased.\nThis result demonstrates another key feature of quantum mechanics: a measurement disturbs the \nsystem. The second analyzer has disturbed the system such that the spin component along the z-axis \ndoes not have a unique value, even though we measured it with the \ufb01rst analyzer. Erwin saw this \nwhen he sorted, or measured, his socks by color and then by length. When he looked, or measured, \na third time, he found that the color he had measured originally was now random\u2014the socks had \nforgotten about the \ufb01rst measurement. One might ask: Can I be more clever in designing the experi-\nment such that I don\u2019t disturb the system? The short answer is no. There is a fundamental incompat-\nibility in trying to measure the spin component of the atom along two different directions. So we say \nthat Sx and Sz are incompatible observables. We cannot know the measured values of both simul-\ntaneously. The state of the system can be represented by the ket 0  +9 = 0 Sz = +U>29 or by the ket \n0  +9x = 0 Sx = +U>29, but it cannot be represented by a ket 0 Sz = +U>2, Sx = +U>29 that speci\ufb01es \nvalues of both components. Having said this, it should be said that not all pairs of quantum mechanical \nobservables are incompatible. It is possible to do some experiments without disturbing some of the \nother aspects of the system. We will see in Section 2.4 that whether two observables are compatible or \nnot is very important in how we analyze a quantum mechanical system.\nNot being able to measure both the Sz and Sx spin components is clearly distinct from the classi-\ncal case where we can measure all three components of the spin vector, which tells us which direction \nthe spin is pointing. In quantum mechanics, the incompatibili",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 30
  },
  {
    "child_id": "303436bc-5869-4100-a4f0-3e4048f19779",
    "parent_id": "ddbc7917-c10a-4925-9c30-70b78c96df1f",
    "text": " possible to do some experiments without disturbing some of the \nother aspects of the system. We will see in Section 2.4 that whether two observables are compatible or \nnot is very important in how we analyze a quantum mechanical system.\nNot being able to measure both the Sz and Sx spin components is clearly distinct from the classi-\ncal case where we can measure all three components of the spin vector, which tells us which direction \nthe spin is pointing. In quantum mechanics, the incompatibility of the spin components means that we \ncannot know which direction the spin is pointing. So when we say \u201cthe spin is up,\u201d we really mean \nonly that the spin component along that one axis is up (vs. down). The quantum mechanical spin vec-\ntor cannot be said to be pointing in any given direction. As is often the case, we must check our classi-\ncal intuition at the door of quantum mechanics.\n1.1.4 \u0002 Experiment 4\nExperiment 4 is depicted in Fig. 1.6 and is a slight variation on Experiment 3. Before we get into the \ndetails, note a few changes in the schematic drawings. As promised, we have dropped the ket labels on \nthe beams because they are redundant. We have deleted the counters on all but the last analyzer and \ninstead simply blocked the unwanted beams and given the average number of atoms passing from one \nanalyzer to the next. The beam blocks are shown explicitly in Fig. 1.6 but will not be shown after this to \nbe consistent with the SPINS program. Note also that in Experiment 4c two output beams are combined \nas input to the following analyzer. This is simple in principle and in the SPINS program but can be \ndif\ufb01cult in practice. The recombination of the beams must be done properly so as to avoid \u201cdisturbing\u201d \nthe beams. If you care to read more about this problem, see Feynman\u2019s Lectures on Physics, volume 3. \nWe will have more to say about the \u201cdisturbance\u201d later in Section 2.2. For now we simply assume that \nthe beams can be recombined in the proper manner.\nExperiment 4a is identical to Experiment 3. In Experiment 4b, the upper beam of the second ana-\nlyzer is blocked and the lower beam is sent to the third analyzer. In Experiment 4c, both beams are \ncombined with our new method and sent to the third analyzer. It should be clear from our previous \nexperiments that Experiment 4b has the same results as Experiment 4a. We now ask about the results of\n\n1.1 Stern-Gerlach Experiment \n9\nExperiment 4c. If we were to use classical probability analysis, then Experiment 4a would indicate that \nthe probability for an atom leaving the \ufb01rst analyzer to take the upper path through the second analyzer \nand then exit through the upper port of the third analyzer is 25%, where we are now referring to the total \nprobability for those two steps. Likewise, Experiment 4b would indicate that the total probability to \ntake the lower path through the second  analyzer and exit through the upper port of the third analyzer is \nalso 25%. Hence the total probability to exit from ",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 30
  },
  {
    "child_id": "7b5b6996-8838-427e-b05f-1e67321047ee",
    "parent_id": "ddbc7917-c10a-4925-9c30-70b78c96df1f",
    "text": " 4a would indicate that \nthe probability for an atom leaving the \ufb01rst analyzer to take the upper path through the second analyzer \nand then exit through the upper port of the third analyzer is 25%, where we are now referring to the total \nprobability for those two steps. Likewise, Experiment 4b would indicate that the total probability to \ntake the lower path through the second  analyzer and exit through the upper port of the third analyzer is \nalso 25%. Hence the total probability to exit from the upper port of the third analyzer when both paths \nare available, which is Experiment 4c, would be 50%, and likewise for the exit from the lower port.\nHowever, the quantum mechanical result in Experiment 4c is that all the atoms exit the upper \nport of the third analyzer and none exits the lower port. The atoms now appear to \u201cremember\u201d that \nthey were initially measured to have spin up along the z-axis. By combining the two beams from \nthe second analyzer, we have avoided the quantum mechanical disturbance that was evident in \nExperiments 3, 4a, and 4b. The result is now the same as Experiment 1, which means it is as if the \nsecond analyzer is not there.\nTo see how odd this is, look carefully at what happens at the lower port of the third analyzer. In \nthis discussion, we refer to percentages of atoms leaving the \ufb01rst analyzer, because that analyzer is \nthe same in all three experiments. In Experiments 4a and 4b, 50% of the atoms are blocked after the \nmiddle analyzer and 25% of the atoms exit the lower port of the third analyzer. In Experiment 4c, \n100% of the atoms pass from the second analyzer to the third analyzer, yet fewer atoms come out \nof the lower port. In fact, no atoms make it through the lower port! So we have a situation where \n25\n25\nX\nZ\nZ\n100\n50\n25\n25\nX\nZ\nZ\n100\n(a)\n(b)\n(c)\n50\n100\n0\nX\nZ\nZ\n100\n100\nFIGURE 1.6 Experiment 4 measures the spin component three times in succession \nand uses (a and b) one or (c) two beams from the second analyzer.",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 30
  },
  {
    "child_id": "710874fa-3276-44b4-8730-2e14e63c3232",
    "parent_id": "e5f3966c-76ae-4b2e-8faa-6bf9223d67dc",
    "text": "10 \nStern-Gerlach Experiments\nallowing more ways or paths to reach a counter results in fewer counts. Classical probability theory \ncannot explain this aspect of quantum mechanics. It is as if you opened a second window in a room to \nget more sunlight and the room went dark!\nHowever, you may already know of a way to explain this effect. Imagine a procedure whereby \ncombining two effects leads to cancellation rather than enhancement. The concept of wave interfer-\nence, especially in optics, comes to mind. In the Young\u2019s double-slit experiment, light waves pass \nthrough two narrow slits and create an interference pattern on a distant screen, as shown in Fig. 1.7. \nEither slit by itself produces a nearly uniform illumination of the screen, but the two slits combined \nproduce bright and dark interference fringes, as shown in Fig. 1.7(b). We explain this by adding \ntogether the electric \ufb01eld vectors of the light from the two slits, then squaring the resultant vector to \n\ufb01nd the light intensity. We say that we add the amplitudes and then square the total amplitude to \ufb01nd \nthe resultant intensity. See Section 6.6 or an optics textbook for more details about this experiment.\nWe follow a similar prescription in quantum mechanics. We add together amplitudes and then \ntake the square to \ufb01nd the resultant probability, which opens the door to interference effects. Before \nwe discuss quantum mechanical interference, we must explain what we mean by an amplitude in \nquantum mechanics and how we calculate it.\n1.2 \u0002 QUANTUM STATE VECTORS\nPostulate 1 of quantum mechanics stipulates that kets are to be used for a mathematical description of a \nquantum mechanical system. These kets are abstract entities that obey many of the rules you know about \nordinary spatial vectors. Hence they are called quantum state vectors. As we will show in Example 1.3, \nthese vectors must employ complex numbers in order to properly describe quantum mechanical systems. \nQuantum state vectors are part of a vector space that we call a Hilbert space. The dimensionality of \nthe Hilbert space is determined by the physics of the system at hand. In the Stern-Gerlach example, \nthe two possible results for a spin  component measurement dictate that the vector space has only two \nPinhole\nSource\nDouble\nSlit\n(a)\n(b)\nScreen\nSingle Slit\nPatterns\nDouble Slit\nPattern\nFIGURE 1.7 (a) Young\u2019s double-slit interference experiment and (b) resultant intensity patterns \nobserved on the screen, demonstrating single-slit diffraction and double-slit interference.\n\n1.2 Quantum State Vectors \n11\ndimensions. That makes this problem mathematically as simple as it can be, which is why we have chosen \nto study it. Because the quantum state vectors are abstract, it is hard to say much about what they are, \nother than how they behave mathematically and how they lead to physical predictions.\nIn the two-dimensional vector space of a spin-1/2 system, the two kets 0 {9 form a basis, just like \nthe unit vectors in  , jn , and kn",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 34
  },
  {
    "child_id": "b0fdfb8f-5a9a-446a-a1f7-a2e11ff4963d",
    "parent_id": "e5f3966c-76ae-4b2e-8faa-6bf9223d67dc",
    "text": "fraction and double-slit interference.\n\n1.2 Quantum State Vectors \n11\ndimensions. That makes this problem mathematically as simple as it can be, which is why we have chosen \nto study it. Because the quantum state vectors are abstract, it is hard to say much about what they are, \nother than how they behave mathematically and how they lead to physical predictions.\nIn the two-dimensional vector space of a spin-1/2 system, the two kets 0 {9 form a basis, just like \nthe unit vectors in  , jn , and kn form a basis for describing vectors in three-dimensional space. However, \nthe analogy we want to make with these spatial vectors is only mathematical, not physical. The spatial \nunit vectors have three important mathematical properties that are characteristic of a basis: the basis \nvectors in , jn , and kn are normalized, orthogonal, and complete. Spatial vectors are normalized if their \nmagnitudes are unity, and they are orthogonal if they are geometrically perpendicular to each other. \nThe basis is complete if any general vector in the space can be written as a linear superposition of the \nbasis vectors. These properties of spatial basis vectors can be summarized as follows:\n \n in~in = jn~jn = kn~kn = 1   normalization\n \n in~jn = in~kn = jn~kn = 0   orthogonality  \n(1.9)\n \n A = axin + ay jn + azkn   completeness,\nwhere A is a general vector. Note that the dot product, also called the scalar product, is central to the \ndescription of these properties.\nContinuing the mathematical analogy between spatial vectors and abstract vectors, we require that \nthese same properties (at least conceptually) apply to quantum mechanical basis vectors. For the Sz \nmeasurement, there are only two possible results, corresponding to the states 0  +9 and 0  -9, so these \ntwo states comprise a complete set of basis vectors. This basis is known as the Sz basis. We focus on \nthis basis for now and refer to other possible basis sets later. The completeness of the basis kets 0 {9 \nimplies that a general quantum state vector 0  c9 is a linear combination of the two basis kets:\n \n0  c9 = a0  +9 + b0  -9, \n(1.10)\nwhere a and b are complex scalar numbers multiplying each ket. This addition of two kets yields \nanother ket in the same abstract space. The complex scalar can appear either before or after the ket \nwithout affecting the mathematical properties of the ket 1i.e., a0  +9 = 0  +9a2. It is customary to use \nthe Greek letter c (psi) for a general quantum state. You may have seen c1x2 used before as a quan-\ntum mechanical wave function. However, the state vector or ket 0  c9 is not a wave function. Kets do \nnot have any spatial dependence as wave functions do. We will study wave functions in Chapter 5.\nTo discuss orthogonality and normalization (known together as orthonormality) we must \ufb01rst \nde\ufb01ne scalar products as they apply to these new kets. As we said above, the machinery of quantum \nmechanics requires the use of complex numbers. You may have seen other \ufb01elds of physics use",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 34
  },
  {
    "child_id": "fa683dcc-773c-4a2b-b063-a80e10082f72",
    "parent_id": "e5f3966c-76ae-4b2e-8faa-6bf9223d67dc",
    "text": " before as a quan-\ntum mechanical wave function. However, the state vector or ket 0  c9 is not a wave function. Kets do \nnot have any spatial dependence as wave functions do. We will study wave functions in Chapter 5.\nTo discuss orthogonality and normalization (known together as orthonormality) we must \ufb01rst \nde\ufb01ne scalar products as they apply to these new kets. As we said above, the machinery of quantum \nmechanics requires the use of complex numbers. You may have seen other \ufb01elds of physics use com-\nplex numbers. For example, sinusoidal oscillations can be described using the complex exponential \neivt rather than cos(vt). However, in such cases, the complex numbers are not required, but are rather \na convenience to make the mathematics easier. When using complex notation to describe classical \nvectors like electric and magnetic \ufb01elds, the de\ufb01nition of the dot product is generalized slightly, such \nthat one of the vectors is complex conjugated. A similar approach is taken in quantum mechanics. The \nanalog to the complex conjugated vector of classical physics is called a bra in the Dirac notation of \nquantum mechanics. Thus corresponding to a general ket 0  c9, there is a bra, or bra vector, which is \nwritten as 8c 0 . If a general ket 0  c9 is speci\ufb01ed as 0  c9 = a0  +9 + b0  -9, then the corresponding bra \n8c 0  is de\ufb01ned as\n \n8c 0 = a*8+ 0 + b*8- 0  , \n(1.11)\n\n12 \nStern-Gerlach Experiments\nwhere the basis bras 8  +  0  and 8  -  0  correspond to the basis kets 0  +9 and 0  -9, respectively, and the \ncoef\ufb01cients a and b have been complex conjugated.\nThe scalar product in quantum mechanics is de\ufb01ned as the product of a bra and a ket taken in the \nproper order\u2014bra \ufb01rst, then ket second:\n \n18bra0210 ket92. \n(1.12)\nWhen the bra and ket are combined together in this manner, we get a bracket (bra ket)\u2014a little physics \nhumor\u2014that is written in shorthand as\n \n8bra0 ket9. \n(1.13)\nThus, given the basis kets 0  +9 and 0  -9, one inner product, for example, is written as\n \n18 + 0210  - 92 = 8 + 0  -9 \n(1.14)\nand so on. Note that we have eliminated the extra vertical bar in the middle. The scalar product in \nquantum mechanics is generally referred to as an inner product or a projection.\nSo how do we calculate the inner product 8+  0  +9? We do it the same way we calculate the dot \nproduct in~ in. We de\ufb01ne it to be unity because we like basis vectors to be unit vectors. There is a little \nmore to it than that, because in quantum mechanics (as we will see shortly) using normalized basis \nvectors is more rooted in physics than in our personal preferences for mathematical cleanliness. But \nfor all practical purposes, if someone presents a set of basis vectors to you, you can probably assume \nthat they are normalized. So the normalization of the spin-1/2 basis vectors is expressed in this new \nnotation as 8+  0  +9 = 1 and 8-  0  -9 = 1.\nNow, what about orthogonality? The spatial unit vectors in, jn, and kn used for spatial vectors are \northogonal to each other ",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 34
  },
  {
    "child_id": "44a7d06a-db5b-4f42-9a22-4532c82341bd",
    "parent_id": "e5f3966c-76ae-4b2e-8faa-6bf9223d67dc",
    "text": "g normalized basis \nvectors is more rooted in physics than in our personal preferences for mathematical cleanliness. But \nfor all practical purposes, if someone presents a set of basis vectors to you, you can probably assume \nthat they are normalized. So the normalization of the spin-1/2 basis vectors is expressed in this new \nnotation as 8+  0  +9 = 1 and 8-  0  -9 = 1.\nNow, what about orthogonality? The spatial unit vectors in, jn, and kn used for spatial vectors are \northogonal to each other because they are at 90\u00b0 with respect to each other. That orthogonality is \nexpressed mathematically in the dot products in~jn = in~kn = jn~kn = 0. For the spin basis kets 0  +9 and \n0  -9, there is no spatial geometry involved. Rather, the spin basis kets 0  +9 and 0  -9 are orthogonal in \nthe mathematical sense, which we express with the inner product as 8+  0  -9 = 0. Again, we do not \nprove to you that these basis vectors are orthogonal, but we assume that a well-behaved basis set obeys \northogonality. Though there is no geometry in this property for quantum mechanical basis vectors, \nthe fundamental idea of orthogonality is the same, so we use the same language\u2014if a general vector \n\u201cpoints\u201d in the direction of a basis vector, then there is no component in the \u201cdirection\u201d of the other \nunit vectors.\nIn summary, the properties of normalization, orthogonality, and completeness can be expressed \nin the case of a two-state spin-1/2 quantum system as:\n \n8+  0  +9 = 1\n8-  0  -9 = 1 r    normalization\n \n \n8+ 0  -9 = 0\n8- 0  +9 = 0r    orthogonality\n \n \n(1.15)\n \n0  c9 = a0  +9 + b0  -9    completeness    . \nNote that a product of kets 1e.g., 0  +9 0  +92 or a similar product of bras 1e.g., 8 + 08 + 02 is meaningless \nin this new notation, while a product of a ket and a bra in the \u201cwrong\u201d order 1e.g., 0  + 98 + 02 has a \nmeaning that we will de\ufb01ne in Section 2.2.3. Equations (1.15) are suf\ufb01cient to de\ufb01ne how the basis\n\n1.2 Quantum State Vectors \n13\nkets behave mathematically. Note that the inner product is de\ufb01ned using a bra and a ket, though it is \ncommon to refer to the inner product of two kets, where it is understood that one is converted to a bra \n\ufb01rst. The order does matter, as we will see shortly.\nUsing this new notation, we can learn a little more about general quantum states and derive some \nexpressions that will be useful later. Consider the general state vector 0  c9 = a0  +9 + b0  -9. Take the \ninner product of this ket with the bra 8 + 0  and obtain\n \n 8 + 0  c9 = 8 + 0  1a0  +9 + b0  -92  \n \n = 8 + 0 a0  +9 + 8 + 0 b0  -9 \n(1.16)\n \n = a 8 + 0  +9 + b8 + 0  -9  \n \n = a ,\n \nusing the properties that inner products are distributive and that scalars can be moved freely through \nbras or kets. Likewise, you can show that 8- 0 c9 = b. Hence the coef\ufb01cients multiplying the basis \nkets are simply the inner products or projections of the general state 0 c9 along each basis ket, albeit in \nan abstract complex vector space rather than the concrete three-dimens",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 34
  },
  {
    "child_id": "5d421089-99df-484d-9fef-b4c5aa7d4754",
    "parent_id": "e5f3966c-76ae-4b2e-8faa-6bf9223d67dc",
    "text": " c9 = 8 + 0  1a0  +9 + b0  -92  \n \n = 8 + 0 a0  +9 + 8 + 0 b0  -9 \n(1.16)\n \n = a 8 + 0  +9 + b8 + 0  -9  \n \n = a ,\n \nusing the properties that inner products are distributive and that scalars can be moved freely through \nbras or kets. Likewise, you can show that 8- 0 c9 = b. Hence the coef\ufb01cients multiplying the basis \nkets are simply the inner products or projections of the general state 0 c9 along each basis ket, albeit in \nan abstract complex vector space rather than the concrete three-dimensional space of normal vectors. \nUsing these results, we rewrite the general state as\n \n 0  c9 = a0  +9 + b0  -9\n \n \n = 0  +9a + 0  -9b\n \n(1.17)\n \n = 0  +958 + 0  c96 + 0  -958 - 0  c96, \nwhere the rearrangement of the second equation again uses the property that scalars 1e.g., a = 8 + 0  c92 \ncan be moved through bras or kets.\nFor a general state vector 0  c9 = a0  +9 + b0  -9, we de\ufb01ned the corresponding bra to be \n8c 0 = a*8 + 0  +b*8 - 0 . Thus, the inner product of the state 0  c9 with the basis ket 0  +9 taken in the \nreverse order compared to Eq. (1.16) yields\n \n 8c 0  +9 = 8 + 0 a*0  +9 + 8 - 0 b*0  +9 \n \n = a*8 +\n 0  +9 + b*8 - 0  +9  \n \n = a*.\n \n \n(1.18)\nThus, we see that an inner product with the states reversed results in a complex conjugation of the \ninner product:\n \n8 + 0  c 9 = 8c 0  +9*. \n(1.19)\nThis important property holds for any inner product. For example, the inner product of two general \nstates is\n \n8f0  c9 = 8c 0 f 9*  . \n(1.20)\nNow we come to a new mathematical aspect of quantum vectors that differs from the use of vec-\ntors in classical mechanics. The rules of quantum mechanics (postulate 1) require that all state vectors \ndescribing a quantum system be normalized, not just the basis kets. This is clearly different from \nordinary spatial vectors, where the length or magnitude of a vector means something and only the unit \nvectors in, jn, and kn are normalized to unity. This new rule means that in the quantum mechanical state",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 34
  },
  {
    "child_id": "7c81a1f0-7d95-4bde-b231-0b19416fd304",
    "parent_id": "775395e9-2879-43e7-a46f-3cec3c9a8f95",
    "text": "14 \nStern-Gerlach Experiments\nspace only the direction\u2014in an abstract sense\u2014is important. If we apply this normalization require-\nment to a general state 0  c9, then we obtain\n \n8c 0  c9 = 5a*8 + 0 + b*8- 0 65a 0  +9 + b0  -96 = 1 \n \n 1 a*a 8+ 0  +9 + a*b 8+ 0  -9 + b*a 8 - 0  +9 + b*b 8 - 0  -9 = 1\n \n 1 a*a + b*b = 1\n \n \n(1.21)\n \n 1 0 a0\n2 + 0 b0\n2 = 1 ,\nor using the expressions for the coef\ufb01cients obtained above,\n \n08 + 0  c9 0\n2 + 08 -\n 0  c9 0\n2 = 1. \n(1.22)\nExample 1.1 Normalize the vector 0  c9 = C110  +9 + 2i0  -92. The complex constant C is often \nreferred to as the normalization constant.\nTo normalize 0  c9, we set the inner product of the vector with itself equal to unity and then \nsolve for C\u2014note the requisite complex conjugations\n \n 1 = 8c 0  c9\n \n \n = C*518 + 0 - 2i8- 0 6C510  +9 + 2i0  -96\n \n \n = C*C518 + 0  +9 + 2i8 + 0  -9 - 2i8- 0  +9 + 48 - 0  -96 \n(1.23)\n \n = 50 C0\n2\n \n \n 1 0 C0 =\n1\n25\n .\n \nThe overall phase of the normalization constant is not physically meaningful (Problem 1.3), so \nwe follow the standard convention and choose it to be real and positive. This yields C = 1> 15. \nThe normalized quantum state vector is then\n \n0  c9 =\n1\n25\n 110  +9 + 2i0  -92. \n(1.24)\nNow comes the crucial element of quantum mechanics. We postulate that each term in the sum \nof Eq. (1.22) is equal to the probability that the quantum state described by the ket 0  c9 is measured \nto be in the corresponding basis state. Thus\n \nPSz=+ U>2 = 08+  0  c9 0\n2 \n(1.25)\nis the probability that the state 0  c9 is found to be in the state 0  +9 when a measurement of Sz is made, \nmeaning that the result Sz = +U>2 is obtained. Likewise,\n \nPSz=- U>2 = 08-  0  c9 0\n2 \n(1.26)\nis the probability that the measurement yields the result Sz = -U>2. The subscript on the probability \nindicates the measured value. For the spin component measurements, we will usually abbreviate this \nto, for example, P+ for an Sz = +U>2 result or P-y for an Sy = -U>2 measurement.\n\n1.2 Quantum State Vectors \n15\nWe now have a prescription for predicting the outcomes of the experiments we have been dis-\ncussing. For example, the experiment shown in Fig. 1.8 has the state 0  c9 = 0  +9 prepared by the \n\ufb01rst Stern-Gerlach device and then input to the second Stern-Gerlach device aligned along the z-axis. \nTherefore the probabilities of measuring the input state 0  c9 = 0  +9 to have the two output values are \nas shown. Because the spin-1/2 system has only two possible measurement results, these two prob-\nabilities must sum to unity\u2014there is a 100% probability of recording some value in the experiment. \nThis basic rule of probabilities is why the rules of quantum mechanics require that all state vectors \nbe properly normalized before they are used in any calculation of probabilities. The experimental \npredictions shown in Fig. 1.8 are an example of the fourth postulate of quantum mechanics, which is \npresented below.\n50\n0\nP\u0002\u0005\u0006\u0005\u0002\u0004\u0002\u0002\u0002\u0003\u00022 \u0006\u00051\nP\u0003\u0005\u0006\u0005\u0002\u0004\u0003\u0002\u0002\u0003\u00022 \u0006\u00050\nZ\nZ\n\u0002\u0002\u0003\n\u0002\u0002\u0003\n\u0002\u0003\u0003\nFIGURE 1.8 Probabilitie",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 38
  },
  {
    "child_id": "a0e563a6-e761-4c68-a1d4-68183b06b76c",
    "parent_id": "775395e9-2879-43e7-a46f-3cec3c9a8f95",
    "text": "abilities must sum to unity\u2014there is a 100% probability of recording some value in the experiment. \nThis basic rule of probabilities is why the rules of quantum mechanics require that all state vectors \nbe properly normalized before they are used in any calculation of probabilities. The experimental \npredictions shown in Fig. 1.8 are an example of the fourth postulate of quantum mechanics, which is \npresented below.\n50\n0\nP\u0002\u0005\u0006\u0005\u0002\u0004\u0002\u0002\u0002\u0003\u00022 \u0006\u00051\nP\u0003\u0005\u0006\u0005\u0002\u0004\u0003\u0002\u0002\u0003\u00022 \u0006\u00050\nZ\nZ\n\u0002\u0002\u0003\n\u0002\u0002\u0003\n\u0002\u0003\u0003\nFIGURE 1.8 Probabilities of spin component measurements.\nPostulate 4 (Spin-1/2 system)\nThe probability of obtaining the value {U>2 in a measurement of the observ-\nable Sz on a system in the state 0  c9 is\nP{ = 08{ 0  c9 0\n2,\nwhere 0 {9 is the basis ket of Sz corresponding to the result {U>2.\nThis is labeled as the fourth postulate because we have written this postulate using the language of the \nspin-1/2 system, while the general statement of the fourth postulate presented in Section 1.5 requires \nthe second and third postulates of Section 2.1. A general spin component measurement is shown in \nFig. 1.9, along with a histogram that compactly summarizes the measurement results.\nBecause the quantum mechanical probability is found by squaring an inner product, we refer to \nan inner product, 8+ 0  c9 for example, as a probability amplitude or sometimes just an amplitude; \nmuch like a classical wave intensity is found by squaring the wave amplitude. Note that the conven-\ntion is to put the input or initial state on the right and the output or \ufb01nal state on the left: 8out0 in9, so \none would read from right to left in describing a problem. Because the probability involves the com-\nplex square of the amplitude, and 8out0 in9 = 8in0 out9*, this convention is not critical for calculat-\ning probabilities. Nonetheless, it is the accepted practice and is important in situations where several \namplitudes are combined.\nArmed with these new quantum mechanical rules and tools, let\u2019s continue to analyze the experi-\nments discussed earlier. Using the experimental results and the new rules we have introduced, we can \nlearn more about the mathematical behavior of the kets and the relationships among them. We will \nfocus on the \ufb01rst two experiments for now and return to the others in the next chapter.\n\n16 \nStern-Gerlach Experiments\n1.2.1 \u0002 Analysis of Experiment 1\nIn Experiment 1, the \ufb01rst Stern-Gerlach analyzer prepared the system in the 0  +9 state and the sec-\nond analyzer later measured this state to be in the 0  +9 state and not in the 0  -9 state. The results of \nthe experiment are summarized in the histogram in Fig. 1.10. We can use the fourth postulate to pre-\ndict the results of this experiment. We take the inner product of the input state 0  +9 with each of the \npossible output basis states 0  +9 and 0  -9. Because we know that the basis states are normalized and \northogonal, we calculate the probabilities to be\n \nP+ = 08+  0  +9 0\n2 = 1  \n \nP- = 08  - 0  +9 0\n2 = 0 . \n \n(1.27)\nThese predic",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 38
  },
  {
    "child_id": "636dc23d-82be-439b-9cd4-f77996a4523c",
    "parent_id": "775395e9-2879-43e7-a46f-3cec3c9a8f95",
    "text": " the 0  +9 state and not in the 0  -9 state. The results of \nthe experiment are summarized in the histogram in Fig. 1.10. We can use the fourth postulate to pre-\ndict the results of this experiment. We take the inner product of the input state 0  +9 with each of the \npossible output basis states 0  +9 and 0  -9. Because we know that the basis states are normalized and \northogonal, we calculate the probabilities to be\n \nP+ = 08+  0  +9 0\n2 = 1  \n \nP- = 08  - 0  +9 0\n2 = 0 . \n \n(1.27)\nThese predictions agree exactly with the histogram of experimental results shown in Fig. 1.10. A 0  +9 \nstate is always measured to have Sz = +U>2.\n1.2.2 \u0002 Analysis of Experiment 2\nIn Experiment 2, the \ufb01rst Stern-Gerlach analyzer prepared the system in the 0  +9 state and the sec-\nond analyzer performed a measurement of the spin component along the x-axis, \ufb01nding 50% prob-\nabilities for each of the two possible states 0  +9x and 0  -9x, as shown in the histogram in Fig. 1.11(a). \nFor this experiment, we cannot predict the results of the measurements, because we do not yet have \n\u0002\u03a8\u0003\nZ\nP\u0002\u0005\u0006\u0005\u0002\u0004\u0002\u0002\u03a8\u0003\u00022\nP\u0003\u0005\u0006\u0005\u0002\u0004\u0003\u0002\u03a8\u0003\u00022\n(a)\n(b)\nSz\n1\nP\nP\u0003\nP\u0002\n\u0003\u0002\n2\n\u0002\n2\n\u0002\u0002\u0003\n\u0002\u0003\u0003\nFIGURE 1.9 (a) Spin component measurement for a general input state and \n(b) histogram of measurement results.\n1\nP\nP\u0003\nP\u0002\n\u0002\u03a8in\u0003\u0005\u0006\u0005\u0002\u0002\u0003\nSz\n\u0003\u0002\n2\n\u0002\n2\nFIGURE 1.10 Histogram of Sz spin component measurements \nfor Experiment 1 with 0 cin9 = 0  + 9.\n\n1.2 Quantum State Vectors \n17\nenough information about how the states 0  +9x and 0  -9x behave mathematically. Rather, we will use \nthe results of the experiment to determine these states. Recalling that the experimental results would \nbe the same if the \ufb01rst analyzer prepared the system to be in the 0  -9 state [see Fig. 1.11(b)], we have \nfour results for the two experiments:\n \nP1,+x = 0 x8+  0  +9 0\n2 = 1\n2  \n \nP1,-x = 0 x8 - 0  +9 0\n2 = 1\n2  \n \nP2,+x = 0 x8+  0  -9 0\n2 = 1\n2  \n \n(1.28)\n \nP2,-x = 0 x8 - 0  -9 0\n2 = 1\n2. \nBecause the kets 0  +9 and 0  -9 form a complete basis, the kets describing the Sx measurement, 0  +9x \nand 0  -9x, can be written in terms of them. We do not yet know the speci\ufb01c coef\ufb01cients of the 0 {9x \nstates, so we use general expressions\n \n0  +9x = a0  +9 + b0  -9  \n \n0  -9x = c0  +9 + d0  -9, \n(1.29)\nand now our task is to use the results of Experiment 2 to determine the coef\ufb01cients a, b, c, and d. The \n\ufb01rst measured probability in Eq. (1.28) is\n \nP1,+x = 0 x8+  0  +9 0\n2 = 1\n2. \n(1.30)\nUsing the general expression for 0  +9x in Eq. (1.29), we calculate the probability that the 0  +9 input \nstate is measured to be in the 0  +9x output state, that is, to have Sx = +U>2:\n \n P1,+x = 0 x8+  0  +9 0\n2\n \n \n = 05a*8 + 0 + b*8  - 0 6 0  +9 0\n2 \n \n(1.31)\n \n = 0 a*0\n2 = 0 a0\n2 ,\n \nwhere we convert the 0  +9x ket to a bra x8 + 0  in order to calculate the inner product. Equating the \nexperimental result in Eq. (1.30) and the prediction in Eq. (1.31), we \ufb01nd\n \n0 a0\n2 = 1\n2. \n(1.32)\n(a)\nP\u0003x\n1\nP\nSx\n(b)\nP\u0002x\nP\u0003x\n1\nP\nSx\n\u0003\u0002\n2\n\u0002\n2\n\u0003\u0002\n2\n\u0002\n2\nP\u0002x\n\u0002\u03a8in\u0003\u0005\u0006\u0005\u0002\u0003\u0003\n\u0002\u03a8in\u0003\u0005\u0006\u0005\u0002\u0002\u0003\nFIGURE 1.11",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 38
  },
  {
    "child_id": "b1a0901d-86b4-4c34-b490-8c0e791c9e1c",
    "parent_id": "775395e9-2879-43e7-a46f-3cec3c9a8f95",
    "text": "that the 0  +9 input \nstate is measured to be in the 0  +9x output state, that is, to have Sx = +U>2:\n \n P1,+x = 0 x8+  0  +9 0\n2\n \n \n = 05a*8 + 0 + b*8  - 0 6 0  +9 0\n2 \n \n(1.31)\n \n = 0 a*0\n2 = 0 a0\n2 ,\n \nwhere we convert the 0  +9x ket to a bra x8 + 0  in order to calculate the inner product. Equating the \nexperimental result in Eq. (1.30) and the prediction in Eq. (1.31), we \ufb01nd\n \n0 a0\n2 = 1\n2. \n(1.32)\n(a)\nP\u0003x\n1\nP\nSx\n(b)\nP\u0002x\nP\u0003x\n1\nP\nSx\n\u0003\u0002\n2\n\u0002\n2\n\u0003\u0002\n2\n\u0002\n2\nP\u0002x\n\u0002\u03a8in\u0003\u0005\u0006\u0005\u0002\u0003\u0003\n\u0002\u03a8in\u0003\u0005\u0006\u0005\u0002\u0002\u0003\nFIGURE 1.11 Histograms of Sx spin component measurements for Experiment 2 \nfor different input states (a) 0 cin9 = 0  + 9 and (b) 0 cin9 = 0  -9.\n\n18 \nStern-Gerlach Experiments\nSimilarly, one can calculate the other three probabilities to arrive at 0 b0\n2 = 0 c0\n2 = 0 d0\n2 = 1\n2 . (Prob-\nlem 1.4) Because each coef\ufb01cient is complex, each has an amplitude and phase. However, the overall \nphase of a quantum state vector is not physically meaningful (see Problem 1.3). Only the relative \nphase between different components of the state vector is physically measurable. Hence, we are free to \nchoose one coef\ufb01cient of each vector to be real and positive without any loss of generality. This allows \nus to write the desired states as\n \n 0  +9x =\n1\n12 3 0  +9 + eia0  -94   \n \n 0  -9x =\n1\n12 3 0  +9 + eib0  -94,\n \n \n(1.33)\nwhere a and b are relative phases that we have yet to determine. Note that these states are already nor-\nmalized because we used all of the experimental results, which re\ufb02ect the fact that the probability for \nall possible results of an experiment must sum to unity.\nWe have used all the experimental results from Experiment 2, but the 0 {9x kets are still not deter-\nmined. We need some more information. If we perform Experiment 1 with both analyzers aligned \nalong the x-axis, the results will be as you expect\u2014all 0  +9x states from the \ufb01rst analyzer will be mea-\nsured to have Sx = +U>2 at the second analyzer, that is, all atoms exit in the 0  +9x state and none in the \n0  -9x . The probability calculations for this experiment are\n \nP+x = 0 x8+  0  +9x0\n2 = 1  \n \nP-x = 0 x8  - 0  +9x0\n2 = 0, \n \n(1.34)\nwhich tell us mathematically that the 0 {9x states are orthonormal to each other, just like the 0 {9 \nstates. This also implies that the 0 {9x kets form a basis, the Sx basis, which you might expect because \nthey correspond to the distinct results of a different spin component measurement. The general expres-\nsions we used for the 0 {9x kets are already normalized but are not yet orthogonal. That is the new \npiece of information we need. The orthogonality condition leads to\n \nx8  - 0  +9x = 0\n \n \n1\n12 38+  0 + e-ib8  - 0 4 1\n12 3 0 +9 + eia0  -94 = 0 \n \n1\n2 31 + ei1a-b24 = 0\n \n \n(1.35)\n \nei1a-b2 = -1\n \n \neia = -eib,\n \nwhere the complex conjugation of the second coef\ufb01cient of the x8  - 0  bra should be noted.\nWe now have an equation relating the remaining coef\ufb01cients a and b, but we need some more \ninformation to determine their values. Unfortunately, there is no more",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 38
  },
  {
    "child_id": "5f8f2f29-66e1-4c98-81a5-e2c3e41fdf27",
    "parent_id": "775395e9-2879-43e7-a46f-3cec3c9a8f95",
    "text": "yet orthogonal. That is the new \npiece of information we need. The orthogonality condition leads to\n \nx8  - 0  +9x = 0\n \n \n1\n12 38+  0 + e-ib8  - 0 4 1\n12 3 0 +9 + eia0  -94 = 0 \n \n1\n2 31 + ei1a-b24 = 0\n \n \n(1.35)\n \nei1a-b2 = -1\n \n \neia = -eib,\n \nwhere the complex conjugation of the second coef\ufb01cient of the x8  - 0  bra should be noted.\nWe now have an equation relating the remaining coef\ufb01cients a and b, but we need some more \ninformation to determine their values. Unfortunately, there is no more information to be obtained, so \nwe are free to choose the value of the phase a. This freedom comes from the fact that we have required \nonly that the x-axis be perpendicular to the z-axis, which limits the x-axis only to a plane rather than to \na unique direction. We follow convention here and choose the phase a \u0003 0. Thus we can express the \nSx basis kets in terms of the Sz basis kets as\n \n 0  +9x =\n1\n12 3 0  +9 + 0  -94  \n \n 0  -9x =\n1\n12 3 0  +9 - 0  -94. \n \n(1.36)",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 38
  },
  {
    "child_id": "c4bf59d1-72c3-44eb-84ab-0d60051b85ad",
    "parent_id": "859c269a-b39a-4813-8f96-2ae79d4b373b",
    "text": "1.2 Quantum State Vectors \n19\nWe generally use the Sz basis as the preferred basis for writing general states, but we could use \nany basis we choose. If we were to use the Sx basis, then we could write the 0 {9 kets as general states \nin terms of the 0 {9x kets. This can be done by solving Eq. (1.36) for the 0 {9 kets, yielding\n \n 0  +9 =\n1\n12 3 0  +9x + 0  -9x4  \n \n 0  -9 =\n1\n12 3 0  +9x - 0  -9x4. \n \n(1.37)\nWith respect to the measurements performed in Experiment 2, Eq. (1.37) tells us that the 0  +9 \nstate is a combination of the states 0  +9x and 0  -9x. The coef\ufb01cients tell us that there is a 50% probabil-\nity for measuring the spin component to be up along the x-axis, and likewise for the down possibility, \nwhich is in agreement with the histogram of measurements shown in Fig. 1.11(a). We must now take \na moment to describe carefully what a combination of states, such as in Eqs. (1.36) and (1.37), is and \nwhat it is not.\n1.2.3 \u0002 Superposition States\nA general spin-1/2 state vector 0  c9 can be expressed as a combination of the basis kets 0  +9 and 0  -9\n \n0  c9 = a0  +9 + b0  -9. \n(1.38)\nWe refer to such a combination of states as a superposition state. To understand the importance of a \nquantum mechanical superposition state, consider the particular state\n \n0  c9 =\n1\n12 10  +9 + 0  -92 \n(1.39)\nand measurements on this state, as shown in Fig. 1.12(a). Note that the state 0  c9 is none other \nthan the state 0  +9x that we found in Eq. (1.36), so we already know what the measurement results \nare. If we measure the spin component along the x-axis for this state, then we record the result \nSx = +U>2 with 100% probability (Experiment 1 with both analyzers along the x-axis). If we mea-\nsure the spin component along the orthogonal z-axis, then we record the two results Sz = {U>2 \nwith 50% probability each (Experiment 2 with the \ufb01rst and second analyzers along the x- and \nz-axes, respectively). Based upon this second set of results, one might be tempted to consider the \nstate 0  c9 as describing a beam that contains a mixture of atoms with 50% of the atoms in the 0  +9 \nstate and 50% in the 0  -9 state. Such a state is called a mixed state and is very different from a \nsuperposition state.\nTo clarify the difference between a mixed state and a superposition state, let\u2019s carefully exam-\nine the results of experiments on the proposed mixed-state beam, as shown in Fig. 1.12(b). If \nwe measure the spin component along the z-axis, then each atom in the 0  +9 state yields the result \nSz = +U>2 with 100% certainty and each atom in the 0  -9 state yields the result Sz = -U>2 with \n100% certainty. The net result is that 50% of the atoms yield Sz = +U>2 and 50% yield Sz = -U>2. \nThis is exactly the same result as that obtained with all atoms in the 0  +9x state, as seen in Fig. 1.12(a). \nIf we instead measure the spin component along the x-axis, then each atom in the 0  +9 state yields the \ntwo results Sx = {U>2 with 50% probability each (Experiment 2 with th",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 43
  },
  {
    "child_id": "3a9ddbf9-9c1e-42ff-8e96-2a97789b3241",
    "parent_id": "859c269a-b39a-4813-8f96-2ae79d4b373b",
    "text": " yields the result \nSz = +U>2 with 100% certainty and each atom in the 0  -9 state yields the result Sz = -U>2 with \n100% certainty. The net result is that 50% of the atoms yield Sz = +U>2 and 50% yield Sz = -U>2. \nThis is exactly the same result as that obtained with all atoms in the 0  +9x state, as seen in Fig. 1.12(a). \nIf we instead measure the spin component along the x-axis, then each atom in the 0  +9 state yields the \ntwo results Sx = {U>2 with 50% probability each (Experiment 2 with the \ufb01rst and second analyzers \nalong the z- and x-axes, respectively). The atoms in the 0  -9 state yield the same results. The net result \nis that 50% of the atoms yield Sx = +U>2 and 50% yield Sx = -U>2. This is in stark contrast to the \nresults of Experiment 1, which tell us that once we have prepared the state to be 0  +9x, then subsequent \nmeasurements yield Sx = +U>2 with certainty, as seen in Fig. 1.12(a).\n\n20 \nStern-Gerlach Experiments\nHence we must conclude that the system described by the 0  c9 = 0  +9x state is not a mixed \nstate with some atoms in the 0  +9 state and some in the 0  -9 state. Rather, each atom in the 0  +9x \nbeam is in a state that itself is a superposition of the 0  +9 and 0  -9 states. A superposition state is \noften called a coherent superposition because the relative phase of the two terms is important. For \nexample, if the input beam were in the 0  -9x state, then there would be a relative minus sign between \nthe two coef\ufb01cients, which would result in an Sx = -U>2 measurement but would not affect the Sz \nmeasurement.\nZ\n50\n50\n\u0002\u03a8\u0003\u0005\u0006\u0005\u0002\u0002\u0003x  \u0006\u0005(\u0002\u0002\u0003\u0005\u0002\u0005\u0002\u0003\u0003)\u0007\b2\nX\n100\n0\nZ\n50\n50\n50% \u0002\u0002\u0003\n50% \u0002\u0003\u0003\n50% \u0002\u0002\u0003\n50% \u0002\u0003\u0003\nX\n50\n50\n\u0002\u03a8\u0003\u0005\u0006\u0005\u0002\u0002\u0003x \u0006\u0005(\u0002\u0002\u0003\u0005\u0002\u0005\u0002\u0003\u0003)\u0007\b2\n(b)\n(a)\nFIGURE 1.12 (a) Superposition state measurements and (b) mixed state measurements.\n\n1.2 Quantum State Vectors \n21\nWe will not have any further need to speak of mixed states, so any combination of states we use \nis a superposition state. Note that we cannot even write down a ket describing a mixed state. So if \n someone gives you a quantum state written as a ket, then it must be a superposition state and not a \nmixed state. The random option in the SPINS program produces a mixed state, while the unknown \nstates are all superposition states.\nExample 1.2 Consider the input state\n \n0 cin9 = 30  +9 + 40  -9.  \n(1.40)\nNormalize this state vector and \ufb01nd the probabilities of measuring the spin component along the \nz-axis to be Sz = {U>2.\nTo normalize this state, introduce an overall complex multiplicative factor and solve for this \nfactor by imposing the normalization condition:\n \n0 cin9 = C 330  +9 + 40  -94\n \n \n8cin0 cin9 = 1\n \n \n5C* 338  +  0 + 48 - 0465C 330  +9 + 40  -946 = 1\n \n(1.41)\n \nC*C 398  +  0  +9 + 128  +  0  -9 + 128  - 0  +9 + 168  - 0  -94 = 1 \n \nC*C 3254 = 1\n \n \n0 C0\n2 = 1\n25.\n \nBecause an overall phase is physically meaningless, we choose C to be real and positive: C = 1>5. \nHence the normalized input state is\n \n@ cin9 = 3\n5 @  +9 + 4\n5 @  -9. \n(1.42)\nThe probability of measu",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 43
  },
  {
    "child_id": "b74d775f-7445-45d0-b6ec-b9cbfb89a11e",
    "parent_id": "859c269a-b39a-4813-8f96-2ae79d4b373b",
    "text": "ve factor and solve for this \nfactor by imposing the normalization condition:\n \n0 cin9 = C 330  +9 + 40  -94\n \n \n8cin0 cin9 = 1\n \n \n5C* 338  +  0 + 48 - 0465C 330  +9 + 40  -946 = 1\n \n(1.41)\n \nC*C 398  +  0  +9 + 128  +  0  -9 + 128  - 0  +9 + 168  - 0  -94 = 1 \n \nC*C 3254 = 1\n \n \n0 C0\n2 = 1\n25.\n \nBecause an overall phase is physically meaningless, we choose C to be real and positive: C = 1>5. \nHence the normalized input state is\n \n@ cin9 = 3\n5 @  +9 + 4\n5 @  -9. \n(1.42)\nThe probability of measuring Sz = +U>2 is\n \n P+ = @8+ @cin9@\n2\n \n \n = @8  +  @33\n5 @  +9 + 4\n5 @  -94 @\n2 \n(1.43)\n \n = @ 3\n5 8  +  @  +9 + 4\n5 8  +  @  -9@\n2 \n \n = @ 3\n5 @\n2 =\n9\n25.\n \nThe probability of measuring Sz = -U>2 is\n \n P- = @8- @ cin9@\n2\n \n \n = @8- @33\n5 @  +9 + 4\n5 @  -94 @\n2 \n \n = @ 3\n5 8- @  +9 + 4\n5 8- @  -9@\n2 \n \n = @ 4\n5 @\n2 = 16\n25.\n \n(1.44)\n\n22 \nStern-Gerlach Experiments\nNote that the two probabilities add to unity, which indicates that we normalized the input state \nproperly. A histogram of the predicted measurement results is shown in Fig. 1.13.\n 1.3 \u0002 MATRIX NOTATION\nUp to this point, we have de\ufb01ned kets mathematically in terms of their inner products with other kets. \nThus, in the general case we write a ket as\n \n0  c9 = 8+  0  c9 0  +9 + 8  - 0  c9 0  -9, \n(1.45)\nor in a speci\ufb01c case, we write\n \n 0  +9x = 8+  0  +9x 0  +9 + 8  - 0  +9x 0  -9 \n \n =\n1\n12 0  +9 +\n1\n12 0  -9.\n \n \n(1.46)\nIn both of these cases, we have chosen to write the kets in terms of the 0  +9 and 0  -9 basis kets. If we \nagree on that choice of basis as a convention, then the two coef\ufb01cients 8+  0  +9x and 8  - 0  +9x uniquely \nspecify the quantum state, and we can simplify the notation by using just those numbers. Thus, we \nrepresent a ket as a column vector containing the two coef\ufb01cients that multiply each basis ket. For \nexample, we represent 0  +9x as\n \n0  +9x \u0003\n1\n22\n \u00a21\n1\u2264 , \n(1.47)\nwhere we have used the new symbol \u0003 to signify \u201cis represented by,\u201d and it is understood that we \nare using the 0  +9 and 0  -9 basis or the Sz basis. We cannot say that the ket equals the column vector, \nbecause the ket is an abstract vector in the state space and the column vector is just two complex num-\nbers. If we were to choose a different basis for representing the vector, then the complex coef\ufb01cients \nwould be different even though the vector is unchanged. We need to have a convention for the order-\ning of the amplitudes in the column vector. The standard convention is to put the spin up amplitude \n\ufb01rst (at the top). Thus, the representation of the 0  -9x state in Eq. (1.36) is\n \n0  -9x \u0003\n1\n22\n \u00a2 1\n-1\u2264 d 0  +9\nd 0  -9, \n \n(1.48)\n1\nP\nSz\n\u0003\u0002\n2\n\u0002\u03a8in\u0003\u0005\u0006\u0005\u0005\u0005\u0005\u0005\u0002\u0002\u0003\u0005\u0002\u0005\u0005\u0005\u0005\u0005\u0002\u0003\u0003\n3\n5\n4\n5\n\u0002\n2\nP\u0003\nP\u0002\nFIGURE 1.13 Histogram of Sz spin component measurements.\n\n1.3 Matrix Notation \n23\nwhere we have explicitly labeled the rows according to their corresponding basis kets. Using this con-\nvention, it should be clear that the basis kets themselves are written as\n \n0  +9 \u0003 a1\n0b  \n \n0  -9 \u0003 a0\n1b. \n \n(1.49)\nThis demonstrate",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 43
  },
  {
    "child_id": "6027723d-0121-44eb-8997-1f6e2f637d3b",
    "parent_id": "859c269a-b39a-4813-8f96-2ae79d4b373b",
    "text": "the top). Thus, the representation of the 0  -9x state in Eq. (1.36) is\n \n0  -9x \u0003\n1\n22\n \u00a2 1\n-1\u2264 d 0  +9\nd 0  -9, \n \n(1.48)\n1\nP\nSz\n\u0003\u0002\n2\n\u0002\u03a8in\u0003\u0005\u0006\u0005\u0005\u0005\u0005\u0005\u0002\u0002\u0003\u0005\u0002\u0005\u0005\u0005\u0005\u0005\u0002\u0003\u0003\n3\n5\n4\n5\n\u0002\n2\nP\u0003\nP\u0002\nFIGURE 1.13 Histogram of Sz spin component measurements.\n\n1.3 Matrix Notation \n23\nwhere we have explicitly labeled the rows according to their corresponding basis kets. Using this con-\nvention, it should be clear that the basis kets themselves are written as\n \n0  +9 \u0003 a1\n0b  \n \n0  -9 \u0003 a0\n1b. \n \n(1.49)\nThis demonstrates the important feature that basis kets are unit vectors when written in their own basis.\nThis new way of expressing a ket simply as the collection of coef\ufb01cients that multiply the basis \nkets is referred to as a representation. Because we have assumed the Sz kets as the basis kets, this is \ncalled the Sz representation. It is always true that basis kets have the simple form shown in Eq. (1.49) \nwhen written in their own representation. A general ket 0  c9 is written as\n \n0  c9 \u0003 \u00a2 8+  0  c9\n8- 0  c9 \u2264. \n(1.50)\nThis use of matrix notation simpli\ufb01es the mathematics of bras and kets. The advantage is not so evident for \nthe simple two-dimensional state space of spin-1/2 systems, but it is very evident for larger dimensional \nproblems. This notation is indispensable when using computers to calculate quantum mechanical results. \nFor example, the SPINS program employs matrix calculations coded in the Java computer language to \nsimulate the Stern-Gerlach experiments using the same probability rules you are learning here.\nWe saw earlier [Eq. (1.11)] that the coef\ufb01cients of a bra are the complex conjugates of the coef-\n\ufb01cients of the corresponding ket. We also know that an inner product of a bra and a ket yields a single \ncomplex number. In order for the matrix rules of multiplication to be used, a bra must be represented \nby a row vector, with the entries being the coef\ufb01cients ordered in the same sense as for the ket. For \nexample, if we use the general ket\n \n0  c9 = a0  +9 + b0  -9, \n(1.51)\nwhich is represented as\n \n0  c9 \u0003 aa\nbb, \n(1.52)\nthen the corresponding bra\n \n8c 0 = a*8 +  0 + b*8  - 0  \n(1.53)\nis represented by a row vector as\n \n8c 0 \u0003 1a* b*2. \n(1.54)\nThe rules of matrix algebra can then be applied to \ufb01nd an inner product. For example,\n \n 8c 0  c9 = 1a* b*2aa\nbb \n \n = 0 a0\n2 + 0 b0\n2.  \n \n(1.55)\nSo a bra is represented by a row vector that is the complex conjugate and transpose of the column vec-\ntor representing the corresponding ket.\n\n24 \nStern-Gerlach Experiments\nExample 1.3 To get some practice using this new matrix notation, and to learn some more about \nthe spin-1/2 system, use the results of Experiment 2 to determine the Sy basis kets using the matrix \napproach instead of the Dirac bra-ket approach.\nConsider Experiment 2 in the case where the second Stern-Gerlach analyzer is aligned along \nthe y-axis. We said before that the results are the same as in the case shown in Fig. 1.4. Thus, we \nhave\n \n P1,+y = @ y8+  @  +9@\n2 = 1\n2  \n \n P1,-y = @ y8- ",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 43
  },
  {
    "child_id": "c8af32d4-a262-4bed-b4fb-0aa08d23660f",
    "parent_id": "859c269a-b39a-4813-8f96-2ae79d4b373b",
    "text": "ents\nExample 1.3 To get some practice using this new matrix notation, and to learn some more about \nthe spin-1/2 system, use the results of Experiment 2 to determine the Sy basis kets using the matrix \napproach instead of the Dirac bra-ket approach.\nConsider Experiment 2 in the case where the second Stern-Gerlach analyzer is aligned along \nthe y-axis. We said before that the results are the same as in the case shown in Fig. 1.4. Thus, we \nhave\n \n P1,+y = @ y8+  @  +9@\n2 = 1\n2  \n \n P1,-y = @ y8-  @  +9@\n2 = 1\n2  \n \n P2,+y = @ y8+  @  -9@\n2 = 1\n2  \n(1.56)\n \n P2,-y = @ y8-  @  -9@\n2 = 1\n2, \nas depicted in the histograms of Fig. 1.14.\nThese results allow us to determine the kets 0 {9y corresponding to the spin component up and \ndown along the y-axis. The argument and calculation proceeds exactly as it did earlier for the 0 {9x \nstates up until the point [Eq. (1.35)] where we arbitrarily chose the phase a to be zero. Having done \nthat for the 0 {9x states, we are no longer free to make that same choice for the 0 {9y states. Thus \nwe use Eq. (1.35) to write the 0 {9y states as\n \n 0  +9y =\n1\n22\n 3 0  +9 + eia0  -94 \u0003\n1\n22\n a 1\neiab\n \n \n 0  -9y =\n1\n22\n 3 0  +9 - eia0  -94 \u0003\n1\n22\n a 1\n-eiab. \n(1.57)\nTo determine the phase a, we use some more information at our disposal. Experiment 2 could be \nperformed with the \ufb01rst Stern-Gerlach analyzer aligned along the x-axis and the second analyzer \nalong the y-axis. Again the results would be identical (50% at each output port), yielding\n \nP+y = @ y8+  @  +9x@\n2 = 1\n2 \n(1.58)\n(a)\nP\u0002y\nP\u0003y\n1\nP\nSy\n\u0003\u0002\n2\n\u0002\n2\n(b)\nP\u0002y\nP\u0003y\n1\nP\nSy\n\u0003\u0002\n2\n\u0002\n2\n\u0002\u03a8in\u0003\u0005\u0006\u0005\u0002\u0003\u0003\n\u0002\u03a8in\u0003\u0005\u0006\u0005\u0002\u0002\u0003\nFIGURE 1.14 Histograms of Sy spin component measurements for input states (a) 0 cin9 = 0  +9 \nand (b) 0 cin9 = 0  -9.",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 43
  },
  {
    "child_id": "852a1777-0ff6-4f9b-8a3d-46ebac88ad5a",
    "parent_id": "389e4712-9beb-495e-b47b-4cee6cf7ea8e",
    "text": "1.4 General Quantum Systems \n25\nas one of the measured quantities. Now use matrix algebra to calculate this:\n \n  y8 + 0  +9x =\n1\n12 11 e-ia2 1\n12 a1\n1b\n \n \n = 1\n2 11 + e-ia2\n \n \n @ y8 + 0  +9x@\n2 = 1\n2 11 + e-ia21\n2 11 + eia2 \n(1.59)\n \n = 1\n4 11 + eia + e-ia + 12 \n \n \n = 1\n2 11 + cos a2 = 1\n2.\n \nThis result requires that cos a = 0, or that a = {p>2. The two choices for the phase correspond \nto the two possibilities for the direction of the y-axis relative to the already determined x- and z-axes. \nThe choice a = +p>2 can be shown to correspond to a right-handed coordinate system, which is the \nstandard convention, so we choose that phase. We thus represent the 0 {9y kets as\n \n 0  +9y \u0003\n1\n22\n a1\ni b\n \n \n 0  -9y \u0003\n1\n22\n a 1\n-ib. \n(1.60)\nNote that the imaginary components of these kets are required. They are not merely a mathemati-\ncal convenience as one sees in classical mechanics. In general, quantum mechanical state vectors \nhave complex coef\ufb01cients. But this does not mean that the results of physical measurements are \ncomplex. On the contrary, we always calculate a measurement probability using a complex square, \nso all quantum mechanics predictions of probabilities are real.\n 1.4 \u0002 GENERAL QUANTUM SYSTEMS\nThe machinery we have developed for spin-1/2 systems can be generalized to other quantum systems. \nFor example, if an observable A yields quantized measurement results an for some \ufb01nite range of n, \nthen we generalize the schematic depiction of a Stern-Gerlach measurement to a measurement of the \nA\n\u0002a1\u0003\n\u0002a2\u0003\n\u0002a3\u0003\n\u0002\u03a8in\u0003\na2\na1\na3\nFIGURE 1.15 Generic depiction of the quantum mechanical measurement of observable A.\n\n26 \nStern-Gerlach Experiments\nobservable A, as shown in Fig. 1.15. The observable A labels the measurement device and the possible \nresults a1, a2, a3, etc. label the output ports. The basis kets corresponding to the results an are then 0 an9. \nThe mathematical rules about kets in this general case are\n \n 8ai@ aj9 = dij         orthonormality \n \n 0  c9 = a\ni\n8ai0  c9 0 ai9\n completeness,  \n \n(1.61)\nwhere we use the Kronecker delta\n \ndij = e0\n1 i \u0002 j\ni = j \n(1.62)\nto express the orthonormality condition compactly. In this case, the generalization of postulate 4 says \nthat the probability of a measurement of one of the possible results an is\n \nPan = 08an0 cin9 0\n2.  \n(1.63)\nExample 1.4 Imagine a quantum system with an observable A that has three possible measure-\nment results: a1, a2, and a3. The three kets 0 a19, 0 a29, and 0 a39 corresponding to these possible \nresults form a complete orthonormal basis. The system is prepared in the state\n \n0  c9 = 20 a19 - 30 a29 + 4i0 a39. \n(1.64)\nCalculate the probabilities of all possible measurement results of the observable A.\nThe state vector in Eq. (1.64) is not normalized, so we must normalize it before calculating \nprobabilities. Introducing a complex normalization constant C, we \ufb01nd\n \n 1 = 8c 0  c9\n \n \n = C*128a10 - 38a20 - 4i8a302C120 a19 - 30 a29 + 4i0 a392 \n \n = 0 C0\n2548a10 a19 - 68a10 a2",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 49
  },
  {
    "child_id": "d926c767-1750-4594-b76e-6a224c7a0f66",
    "parent_id": "389e4712-9beb-495e-b47b-4cee6cf7ea8e",
    "text": "these possible \nresults form a complete orthonormal basis. The system is prepared in the state\n \n0  c9 = 20 a19 - 30 a29 + 4i0 a39. \n(1.64)\nCalculate the probabilities of all possible measurement results of the observable A.\nThe state vector in Eq. (1.64) is not normalized, so we must normalize it before calculating \nprobabilities. Introducing a complex normalization constant C, we \ufb01nd\n \n 1 = 8c 0  c9\n \n \n = C*128a10 - 38a20 - 4i8a302C120 a19 - 30 a29 + 4i0 a392 \n \n = 0 C0\n2548a10 a19 - 68a10 a29 + 8i8a10 a39\n \n \n- 68a20 a19 + 98a20 a29 - 12i8a20 a39\n \n(1.65)\n \n \n- 8i8a30 a19 + 12i8a30 a29 + 168a30 a396\n \n \n = 0 C0\n254 + 9 + 166 = 0 C0\n2 29\n \n \n 1 C =\n1\n129.\n \nThe normalized state is\n \n0  c9 =\n1\n129 120 a19 - 30 a29 + 4i0 a392. \n(1.66)\n\n1.5 Postulates \n27\nThe probabilities of measuring the results a1, a2, and a3 are\n \n Pa1 = 08a10  c9 0\n2 \n \n = @8a10\n1\n129520 a19 - 30 a29 + 4i0 a396@\n2\n \n \n =\n1\n29 0 28a10 a19 - 38a10 a29 + 4i8a10 a39 0\n2 =\n4\n29 \n(1.67)\n \n Pa2 = 0 a20  c9 0\n2 = @8a2@\n1\n12952@ a19 - 3@ a29 + 4i@ a396@\n2\n=\n9\n29 \n \nPa3 = 08a30  c9 @\n2 = @8a3@\n1\n12952@ a19 - 3@ a29 + 4i@ a396@\n2\n= 16\n29 . \nA schematic of this experiment is shown in Fig. 1.16(a) and a histogram of the predicted probabili-\nties is shown in Fig. 1.16(b).\n 1.5 \u0002 POSTULATES\nWe have introduced two of the postulates of quantum mechanics in this chapter. The postulates \nof quantum mechanics dictate how to treat a quantum mechanical system mathematically and \nhow to interpret the mathematics to learn about the physical system in question. These postulates \ncannot be proven, but they have been successfully tested by many experiments, and so we accept \nthem as an accurate way to describe quantum mechanical systems. New results could force us \nto reevaluate these postulates at some later time. All six postulates are listed below to give you \nan idea where we are headed and a framework into which you can place the new concepts as we \nconfront them.\n \nPostulates of Quantum Mechanics\n \n1. The state of a quantum mechanical system, including all the information you can know \nabout it, is represented mathematically by a normalized ket 0 c9.\n \n2. A physical observable is represented mathematically by an operator A that acts on kets.\n \n3. The only possible result of a measurement of an observable is one of the eigenvalues an of \nthe corresponding operator A. \nA a2\na1\na3\n(a)\n(b)\nPa2 \u0006\nPa1\nPa1\nPa2\nPa3\n\u0006\nPa3 \u0006\nA\n1\nP\n4\n29\n9\n29\n16\n29\na3\na2\na1\n\u0002\u03a8in\u0003\nFIGURE 1.16 (a) Schematic diagram of the measurement of observable A and (b) histogram of the \npredicted measurement probabilities.\n\n28 \nStern-Gerlach Experiments\n \n4. The probability of obtaining the eigenvalue an in a measurement of the observable A on the \nsystem in the state 0  c9 is\n \nPan = 08an0  c9 0\n2, \n \n where 0 an9 is the normalized eigenvector of A corresponding to the eigenvalue an.\n \n5. After a measurement of A that yields the result an, the quantum system is in a new state that \nis the normalized projection of the original system ket",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 49
  },
  {
    "child_id": "15ef7169-0620-415a-8ffd-d7979608377d",
    "parent_id": "389e4712-9beb-495e-b47b-4cee6cf7ea8e",
    "text": "f observable A and (b) histogram of the \npredicted measurement probabilities.\n\n28 \nStern-Gerlach Experiments\n \n4. The probability of obtaining the eigenvalue an in a measurement of the observable A on the \nsystem in the state 0  c9 is\n \nPan = 08an0  c9 0\n2, \n \n where 0 an9 is the normalized eigenvector of A corresponding to the eigenvalue an.\n \n5. After a measurement of A that yields the result an, the quantum system is in a new state that \nis the normalized projection of the original system ket onto the ket (or kets) corresponding \nto the result of the measurement:\n \n0  c\u00049 =\nPn0  c9\n28c 0 Pn0  c9\n. \n \n6. The time evolution of a quantum system is determined by the Hamiltonian or total energy \noperator H(t) through the Schr\u00f6dinger equation\n \niU d\ndt\n 0  c 1t29 = H 1t2 0  c 1t29. \nAs you read these postulates for the \ufb01rst time, you will undoubtedly encounter new terms and \nconcepts. Rather than explain them all here, the plan of this text is to continue to explain them through \ntheir manifestation in the Stern-Gerlach spin-1/2 experiment. We have chosen this example because it \nis inherently quantum mechanical and forces us to break away from reliance on classical intuition or \nconcepts. Moreover, this simple example is a paradigm for many other quantum mechanical systems. \nBy studying it in detail, we can appreciate much of the richness of quantum mechanics.\nSUMMARY\nThrough the Stern-Gerlach experiment we have learned several key concepts about quantum mechan-\nics in this chapter.\n\u2022 Quantum mechanics is probabilistic. \n \nWe cannot predict the results of experiments precisely. We can predict only the probability \nthat a certain result is obtained in a measurement.\n\u2022 Spin measurements are quantized. \n \nThe possible results of a spin component measurement are quantized. Only these discrete \nvalues are measured.\n\u2022 Quantum measurements disturb the system. \n \nMeasuring one physical observable can \u201cdestroy\u201d information about other observables.\nWe have learned how to describe the state of a quantum mechanical system mathematically using \na ket, which represents all the information we can know about that state. The kets 0  +9 and 0  -9 result \nwhen the spin component Sz along the z-axis is measured to be up or down, respectively. These kets \nform an orthonormal basis, which we denote by the inner products\n \n 8+  0  +9 = 1  \n \n 8- 0  -9 = 1  \n(1.68)\n \n 8+  0  -9 = 0.\n\nProblems \n29\nThe basis is also complete, which means that it can be used to express all possible kets as superposi-\ntion states\n \n0  c9 = a0  +9 + b0  -9. \n(1.69)\nFor spin component measurements, the kets corresponding to spin up or down along the three \nCartesian axes are\n \n 0  +9   0  +9x =\n1\n12 3 0  +9 + 0  -94   0  +9y =\n1\n12 3 0  +9 + i0  -94\n \n 0  -9   0  -9x =\n1\n12 3 0  +9 - 0  -94   0  -9y =\n1\n12 3 0  +9 - i0  -94. \n(1.70)\nWe also found it useful to introduce a matrix notation for calculations. In this matrix language the kets \nin Eq. (1.70) are represented by\n \n0  +9 \u0003 \u00a21\n0\u2264 \n0  +9x ",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 49
  },
  {
    "child_id": "639adbdc-1524-4dc0-b2ce-669178e6240d",
    "parent_id": "389e4712-9beb-495e-b47b-4cee6cf7ea8e",
    "text": "ts as superposi-\ntion states\n \n0  c9 = a0  +9 + b0  -9. \n(1.69)\nFor spin component measurements, the kets corresponding to spin up or down along the three \nCartesian axes are\n \n 0  +9   0  +9x =\n1\n12 3 0  +9 + 0  -94   0  +9y =\n1\n12 3 0  +9 + i0  -94\n \n 0  -9   0  -9x =\n1\n12 3 0  +9 - 0  -94   0  -9y =\n1\n12 3 0  +9 - i0  -94. \n(1.70)\nWe also found it useful to introduce a matrix notation for calculations. In this matrix language the kets \nin Eq. (1.70) are represented by\n \n0  +9 \u0003 \u00a21\n0\u2264 \n0  +9x \u0003\n1\n22\n \u00a21\n1\u2264 \n0  +9y \u0003\n1\n22\n \u00a21\ni \u2264 \n \n0  -9 \u0003 \u00a20\n1\u2264 \n0  -9x \u0003\n1\n22\n \u00a2 1\n-1\u2264 \n0  -9y \u0003\n1\n22\n \u00a2 1\n-i\u2264. \n(1.71)\nThe most important tool we have learned so far is the probability postulate (postulate 4). To \ncalculate the probability that a measurement on an input state 0 cin9 will yield a particular result, for \nexample Sz = U>2, we complex square the inner product of the input state with the ket corresponding \nto the measured result, 0  +9 in this case:\n \nP+ = 08 + 0 cin9 0\n2. \n(1.72)\nThis is generalized to other systems where a measurement yields a particular result an corresponding \nto the ket 0 an9 as:\n \nPan = 08an0 cin9 0\n2.  \n(1.73)\nPROBLEMS\n 1.1 Consider the following state vectors:\n \n 0 c19 = 30  +9 + 40  -9\n \n \n 0 c29 = 0  +9 + 2i0  -9\n \n \n 0 c39 = 30  +9 - eip>30  -9. \na) Normalize each state vector.\nb) For each state vector, calculate the probability that the spin component is up or down \nalong each of the three Cartesian axes. Use bra-ket notation for the entire calculation.\nc) Write each normalized state in matrix notation.\nd) Repeat part (b) using matrix notation for the entire calculation.\n\n30 \nStern-Gerlach Experiments\n 1.2 Consider the three quantum states:\n \n 0 c19 =\n1\n13 0  +9 + i 12\n13 0  -9\n \n \n 0 c29 =\n1\n15 0  +9 -\n2\n15 0  -9\n \n \n 0 c39 =\n1\n12 0  +9 + eip>4 1\n12 0  -9. \n \n Use bra-ket notation (not matrix notation) to solve the following problems. Note  \nthat 8+  0  +9 = 1, 8- 0  -9 = 1, and 8+  0  -9 = 0.\na) For each of the 0 ci9 above, \ufb01nd the normalized vector 0 fi9 that is orthogonal to it.\nb) Calculate the inner products 8ci0 cj9 for i and j = 1, 2, 3.\n 1.3 Show that a change in the overall phase of a quantum state vector does not change \nthe probability of obtaining a particular result in a measurement. To do this, consider  \nhow the probability is affected by changing the state 0  c9 to the state eid0  c9.\n 1.4 Show by explicit bra-ket calculations using the states in Eq. (1.29) that the four \nexperimental results in Eq. (1.28) lead to the results 0 b0\n2 = 0 c0\n2 = 0 d0\n2 = 1\n2.\n 1.5 A beam of spin-1/2 particles is prepared in the state\n0  c9 =\n2\n113 0  +9 + i 3\n113 0  -9.\na) What are the possible results of a measurement of the spin component Sz, and with \nwhat probabilities would they occur?\nb) What are the possible results of a measurement of the spin component Sx, and with \nwhat probabilities would they occur?\nc) Plot histograms of the predicted measurement results from parts (a) and (b).\n 1.6 A beam of spin-1/2 particles is",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 49
  },
  {
    "child_id": "b782849c-4e7d-4ef5-a607-02ec9ee9c0d4",
    "parent_id": "389e4712-9beb-495e-b47b-4cee6cf7ea8e",
    "text": "e results 0 b0\n2 = 0 c0\n2 = 0 d0\n2 = 1\n2.\n 1.5 A beam of spin-1/2 particles is prepared in the state\n0  c9 =\n2\n113 0  +9 + i 3\n113 0  -9.\na) What are the possible results of a measurement of the spin component Sz, and with \nwhat probabilities would they occur?\nb) What are the possible results of a measurement of the spin component Sx, and with \nwhat probabilities would they occur?\nc) Plot histograms of the predicted measurement results from parts (a) and (b).\n 1.6 A beam of spin-1/2 particles is prepared in the state\n0  c9 =\n2\n113 0  +9x + i 3\n113 0  -9x.\na) What are the possible results of a measurement of the spin component Sz, and with \nwhat probabilities would they occur?\nb) What are the possible results of a measurement of the spin component Sx, and with \nwhat probabilities would they occur?\nc) Plot histograms of the predicted measurement results from parts (a) and (b).\n 1.7 A classical coin is thrown in the air and lands on the ground, where a measurement is \nmade of its state.\na) What are the possible results of this measurement?\nb) What are the predicted probabilities for these possible outcomes?\nc) Plot a histogram of the predicted measurement results.\n 1.8 A classical cubical die is thrown onto a table and comes to rest, where a measurement \nis made of its state.\na) What are the possible results of this measurement?\nb) What are the predicted probabilities for these possible outcomes?\nc) Plot a histogram of the predicted measurement results.",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 49
  },
  {
    "child_id": "8a636098-a611-43ca-9a3a-1423b1196abf",
    "parent_id": "88ffef8c-5d94-4e37-894f-4144a356460d",
    "text": "Problems \n31\n 1.9 A pair of dice (classical cubes) are thrown onto a table and come to rest, where a \nmeasurement is made of the state of the system (i.e., the sum of the two dice).\na) What are the possible results of this measurement?\nb) What are the predicted probabilities for these possible outcomes?\nc) Plot a histogram of the predicted measurement results.\n 1.10 Consider the three quantum states:\n \n 0 c19 = 4\n5 0  +9 + i 3\n5 0  -9\n \n \n 0 c29 = 4\n5 0  +9 - i 3\n5 0  -9\n \n \n 0 c39 = -  4\n5 0  +9 + i 3\n5 0  -9. \na) For each of the 0 ci9 above, calculate the probabilities of spin component measurements \nalong the x-, y-, and z-axes.\nb) Use your results from (a) to comment on the importance of the overall phase and of the \nrelative phases of the quantum state vector.\n 1.11  A beam of spin-1/2 particles is prepared in the state\n0  c9 =\n3\n134 0  +9 + i 5\n134 0  -9.\na) What are the possible results of a measurement of the spin component Sz, and with what \nprobabilities would they occur?\nb) Suppose that the Sz measurement yields the result Sz = -U>2. Subsequent to that result \na second measurement is performed to measure the spin component Sx. What are the \npossible results of that measurement, and with what probabilities would they occur?\nc) Draw a schematic diagram depicting the successive measurements in parts (a) and (b).\n 1.12  Consider a quantum system with an observable A that has three possible measurement \nresults: a1, a2, and a3. Write down the orthogonality, normalization, and completeness \nrelations for the three kets comprising the basis corresponding to the possible results of the  \nA measurement.\n 1.13  Consider a quantum system with an observable A that has three possible measurement \nresults: a1, a2, and a3.\na) Write down the three kets 0 a19, 0 a29, and 0 a39 corresponding to these possible results \nusing matrix notation.\nb) The system is prepared in the state\n0  c9 = 10 a19 - 20 a29 + 50 a39.\n \nWrite this state in matrix notation and calculate the probabilities of all possible measurement \nresults of the observable A. Plot a histogram of the predicted measurement results.\nc) In a different experiment, the system is prepared in the state\n0  c9 = 20 a19 + 3i0 a29.\n \nWrite this state in matrix notation and calculate the probabilities of all possible measurement \nresults of the observable A. Plot a histogram of the predicted measurement results.\n\n32 \nStern-Gerlach Experiments\n 1.14  Consider a quantum system in which the energy E is measured and there are four possible \nmeasurement results: 2 eV, 4 eV, 7 eV, and 9 eV. The system is prepared in the state\n0  c9 =\n1\n139 530 2 eV9 - i0 4 eV9 + 2eip>70 7 eV9 + 50 9 eV96.\n \n Calculate the probabilities of all possible measurement results of the energy E. Plot a \nhistogram of the predicted measurement results.\n 1.15  Consider a quantum system described by a basis 0 a19, 0 a29, and 0 a39. The system is initially \nin a state\n0\n ci9 =\ni\n13 0 a19 + 4\n2\n3 0 a29.\n \n Find the probability that the syst",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 55
  },
  {
    "child_id": "c6656975-79a3-4357-b6be-25be204c0214",
    "parent_id": "88ffef8c-5d94-4e37-894f-4144a356460d",
    "text": "here are four possible \nmeasurement results: 2 eV, 4 eV, 7 eV, and 9 eV. The system is prepared in the state\n0  c9 =\n1\n139 530 2 eV9 - i0 4 eV9 + 2eip>70 7 eV9 + 50 9 eV96.\n \n Calculate the probabilities of all possible measurement results of the energy E. Plot a \nhistogram of the predicted measurement results.\n 1.15  Consider a quantum system described by a basis 0 a19, 0 a29, and 0 a39. The system is initially \nin a state\n0\n ci9 =\ni\n13 0 a19 + 4\n2\n3 0 a29.\n \n Find the probability that the system is measured to be in the \ufb01nal state\n@\n cf9 = 1+i\n13 0 a19 +\n1\n16 0 a29 +\n1\n16 0 a39.\n 1.16  The spin components of a beam of atoms prepared in the state 0 cin9 are measured and the fol-\nlowing experimental probabilities are obtained:\n \nP+ = 1\n2 \nP+x = 3\n4 \nP+y = 0.067\n \nP- = 1\n2 \nP-x = 1\n4 \nP-y = 0.933. \n \n From the experimental data, determine the input state.\n 1.17  In part (1) of SPINS Lab #2, you measured the probabilities of all the possible spin compo-\nnents for each of the unknown initial states 0 ci9 (i = 1, 2, 3, 4). Using your data from that \nlab, \ufb01nd the unknown states 0 c19, 0 c29, 0 c39, and 0 c49. Express each of the unknown states \nas a linear superposition of the Sz basis states 0  +9 and 0  -9. For each state, use your result \nto calculate the theoretical values of the probabilities for each component measurement and \ncompare these theoretical predictions with your experimental results.\nRESOURCES\nActivities \nSPINS: A software program to simulate Stern-Gerlach spin experiments. The Java software runs on \nall platforms and can be downloaded in two forms:\nOpen Source Physics framework\nwww.physics.oregonstate.edu/~mcintyre/ph425/spins/index_SPINS_OSP.html\nor\nStandalone Java\nwww.physics.oregonstate.edu/~mcintyre/ph425/spins\nThe bulleted activities are available at\nwww.physics.oregonstate.edu/qmactivities\n\nResources \n33\n\u2022 SPINS Lab 1: An introduction to successive Stern-Gerlach spin-1/2 measurements. The random-\nness of measurements is demonstrated and students use statistical analysis to deduce probabilities \nfrom measurements.\n\u2022 SPINS Lab 2: Students deduce unknown quantum state vectors from measurements of spin projec-\ntions (part 3 requires material from Chapter 2 to do the calculations).\nStern-Gerlach simulation: A different simulation of the Stern-Gerlach experiment from the PHET \ngroup at the University of Colorado (somewhat Flashier version):\nhttp://phet.colorado.edu/en/simulation/stern-gerlach\nFurther Reading\nThe history of the Stern-Gerlach experiment and how a bad cigar helped are chronicled in  \na Physics Today article:\nB. Friedrich and D. Herschbach, \u201cStern and Gerlach: How a Bad Cigar Helped Reorient  \nAtomic Physics,\u201d Phys. Today 56(12), 53\u201359 (2003). \n \nhttp://dx.doi.org/10.1063/1.1650229\nA different spin on the quantum mechanics of socks is discussed by John S. Bell in this article:\nJ. S. Bell, \u201cBertlmann\u2019s socks and the nature of reality, \u201d J. Phys. Colloq. 42, C22 \nC2.41-C2.62 (1981).  \n \nhttp://cdsweb.cern.ch/record/142461",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 55
  },
  {
    "child_id": "386c2943-9f2a-4050-96f6-74a772d269b1",
    "parent_id": "88ffef8c-5d94-4e37-894f-4144a356460d",
    "text": "xperiment and how a bad cigar helped are chronicled in  \na Physics Today article:\nB. Friedrich and D. Herschbach, \u201cStern and Gerlach: How a Bad Cigar Helped Reorient  \nAtomic Physics,\u201d Phys. Today 56(12), 53\u201359 (2003). \n \nhttp://dx.doi.org/10.1063/1.1650229\nA different spin on the quantum mechanics of socks is discussed by John S. Bell in this article:\nJ. S. Bell, \u201cBertlmann\u2019s socks and the nature of reality, \u201d J. Phys. Colloq. 42, C22 \nC2.41-C2.62 (1981).  \n \nhttp://cdsweb.cern.ch/record/142461\nNature has published a supplement on the milestones in spin physics. An extensive timeline \nof historical events, review articles, and links to original articles are included.\nNature Phys. 4, S1\u2013S43 (2008). \n \nwww.nature.com/milestones/spin\nThe SPINS lab software is described in this pedagogical article:\nD. V. Schroeder and T. A. Moore, \u201cA computer-simulated Stern-Gerlach laboratory,\u201d  \nAm. J. Phys. 61, 798\u2013805 (1993). \n \nhttp://dx.doi.org/10.1119/1.17172\nSome other textbooks that take a spins-\ufb01rst approach or have an extensive treatment  \nof Stern-Gerlach experiments:\nR. P. Feynman, R. B. Leighton, and M. Sands, The Feynman Lectures on Physics, \nVolume 3, Quantum Mechanics, Reading, MA: Addison-Wesley Publishing Company, \nInc., 1965.\nJ. J. Sakurai, Modern Quantum Mechanics, Redwood City, CA: Addison-Wesley \nPublishing Company, Inc., 1985.\nJ. S. Townsend, A Modern Approach to Quantum Mechanics, New York: McGraw \nHill, Inc., 1992.\nC. Cohen-Tannoudji, B. Diu, and F. Lalo\u00eb, Quantum Mechanics, New York: John Wiley & \nSons, 1977.\nD. F. Styer, The Strange World of Quantum Mechanics, Cambridge: Cambridge University \nPress, 2000.\n\nC H A P T E R \n2\nOperators and Measurement\nIn Chapter 1 we used the results of experiments to deduce a mathematical description of the spin-1/2 \nsystem. The Stern-Gerlach experiments demonstrated that spin component measurements along the \nx-, y-, or z-axes yield only {U>2 as possible results. We learned how to predict the probabilities of \nthese measurements using the basis kets of the spin component observables Sx, Sy, and Sz, and these \npredictions agreed with the experiments. However, the real power of a theory is its ability to predict \nresults of experiments that you haven\u2019t yet done. For example, what are the possible results of a mea-\nsurement of the spin component Sn along an arbitrary direction nn and what are the predicted probabili-\nties? To make these predictions, we need to learn about the operators of quantum mechanics.\n2.1 \u0002 OPERATORS, EIGENVALUES, AND EIGENVECTORS\nThe mathematical theory we developed in Chapter 1 used only quantum state vectors. We said that \nthe state vector represents all the information we can know about the system and we used the state \nvectors to calculate probabilities. With each observable Sx, Sy, and Sz we associated a pair of kets \n corresponding to the possible measurement results of that observable. The observables themselves are \nnot yet included in our mathematical theory, but the distinct ",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 55
  },
  {
    "child_id": "83d903c1-1547-435c-86f6-349b7175e594",
    "parent_id": "88ffef8c-5d94-4e37-894f-4144a356460d",
    "text": "TORS, EIGENVALUES, AND EIGENVECTORS\nThe mathematical theory we developed in Chapter 1 used only quantum state vectors. We said that \nthe state vector represents all the information we can know about the system and we used the state \nvectors to calculate probabilities. With each observable Sx, Sy, and Sz we associated a pair of kets \n corresponding to the possible measurement results of that observable. The observables themselves are \nnot yet included in our mathematical theory, but the distinct association between an observable and its \nmeasurable kets provides the means to do so.\nThe role of physical observables in the mathematics of quantum theory is described by the two \npostulates listed below. Postulate 2 states that physical observables are represented by mathematical \noperators, in the same sense that physical states are represented by mathematical vectors or kets (postu-\nlate 1). An operator is a mathematical object that acts or operates on a ket and transforms it into a new \nket, for example A0 c9 = 0 f9. However, there are special kets that are not changed by the operation \nof a particular operator, except for a possible multiplicative constant, which we know does not change \nanything measurable about the state. An example of a ket that is not changed by an operator would be \nA0 c9 = a0 c9. Such kets are known as eigenvectors of the operator A and the multiplicative constants \nare known as the eigenvalues of the operator. These are important because postulate 3 states that the only \npossible result of a measurement of a physical observable is one of the eigenvalues of the corresponding \noperator.\nPostulate 2\nA physical observable is represented mathematically by an operator A \nthat acts on kets.\n\n2.1 Operators, Eigenvalues, and Eigenvectors \n35\nWe now have a mathematical description of that special relationship we saw in Chapter 1 between \na physical observable, Sz say, the possible results {U>2, and the kets 0{9 corresponding to those \nresults. This relationship is known as the eigenvalue equation and is depicted in Fig. 2.1 for the case \nof the spin up state in the z-direction. In the eigenvalue equation, the observable is represented by an \noperator, the eigenvalue is one of the possible measurement results of the observable, and the eigen-\nvector is the ket corresponding to the chosen eigenvalue of the operator. The eigenvector appears on \nboth sides of the equation because it is unchanged by the operator.\nThe eigenvalue equations for the Sz operator in a spin-1/2 system are:\n \n Sz0  +9 = +  U\n2 0  +9  \n \n Sz0  -9 = -  U\n2 0  -9. \n \n(2.1)\nThese equations tell us that +U>2 is the eigenvalue of Sz corresponding to the eigenvector 0  +9 and \n-U>2 is the eigenvalue of Sz corresponding to the eigenvector 0  -9. Equations (2.1) are suf\ufb01cient to \nde\ufb01ne how the Sz operator acts mathematically on kets. However, it is useful to use matrix notation \nto represent operators in the same sense that we used column vectors and row vectors in Chapter",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 55
  },
  {
    "child_id": "f7493586-b5e1-4c37-ad70-84c9f6030481",
    "parent_id": "88ffef8c-5d94-4e37-894f-4144a356460d",
    "text": "operator in a spin-1/2 system are:\n \n Sz0  +9 = +  U\n2 0  +9  \n \n Sz0  -9 = -  U\n2 0  -9. \n \n(2.1)\nThese equations tell us that +U>2 is the eigenvalue of Sz corresponding to the eigenvector 0  +9 and \n-U>2 is the eigenvalue of Sz corresponding to the eigenvector 0  -9. Equations (2.1) are suf\ufb01cient to \nde\ufb01ne how the Sz operator acts mathematically on kets. However, it is useful to use matrix notation \nto represent operators in the same sense that we used column vectors and row vectors in Chapter 1 to \nrepresent bras and kets, respectively. For Eqs. (2.1) to be satis\ufb01ed using matrix algebra with the kets \nrepresented as column vectors of size 1*  2, the operator Sz must be represented by a 2 *  2 matrix. The \neigenvalue equations (2.1) provide suf\ufb01cient information to determine this matrix.\nTo determine the matrix representing the operator Sz, assume the most general form for a 2 *  2 matrix\n \nSz \u0003 aa\nb\nc\ndb, \n(2.2)\nwhere we are again using the \u0003 symbol to mean \u201cis represented by.\u201d Now write the eigenvalue equa-\ntions in matrix form:\n \n aa\nb\nc\ndb a1\n0b = +  U\n2\n a1\n0b  \n \n aa\nb\nc\ndb a0\n1b = -  U\n2\n a0\n1b. \n \n(2.3)\nPostulate 3\nThe only possible result of a measurement of an observable is one of the \neigenvalues an of the corresponding operator A.\neigenvalue\neigenvector\noperator\n\u0002\n2\nSz \u0002\u0002\u0003\u0005\u0006\u0005\u0005\u0005\u0005\u0005\u0005\u0002\u0002\u0003\u0005\nFIGURE 2.1 Eigenvalue equation for the spin up state.",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 55
  },
  {
    "child_id": "9d5dc6d1-108f-4e74-9789-de0e4b4b20b5",
    "parent_id": "e4fe2b44-7296-4455-bd34-182542ca39f3",
    "text": "36 \nOperators and Measurement\nNote that we are still using the convention that the 0{9 kets are used as the basis for the representation. \nIt is crucial that the rows and columns of the operator matrix are ordered in the same manner as used \nfor the ket column vectors; anything else would amount to nonsense. An explicit labeling of the rows \nand columns of the operator and the basis kets makes this clear:\n \nSz\n0  +9\n0  -9\n8+ 0\na\nb\n8- 0\nc\nd\n \n0  +9\n8+ 0\n1\n8- 0\n0\n \n0  -9\n8+ 0\n0\n8- 0\n1\n . \n(2.4)\nCarrying through the multiplication in Eqs. (2.3) yields\n \n aa\ncb = +  U\n2\n  a1\n0b  \n \n ab\ndb = -  U\n2\n a0\n1b, \n \n(2.5)\nwhich results in\n \na = + U\n2 \nb = 0 \n \nc = 0 \nd = -  U\n2. \n \n(2.6)\nThus the matrix representation of the operator Sz is\n \n Sz \u0003 aU>2\n0\n0\n-U>2b \n \n \u0003 U\n2\n a1\n0\n0\n-1b.\n \n \n(2.7)\nNote two important features of this matrix: (1) it is a diagonal matrix\u2014it has only diagonal elements\u2014\nand (2) the diagonal elements are the eigenvalues of the operator, ordered in the same manner as the \ncorresponding eigenvectors. In this example, the basis used for the matrix representation is that formed \nby the eigenvectors 0{9 of the operator Sz. That the matrix representation of the operator in this case \nis a diagonal matrix is a necessary and general result of linear algebra that will prove valuable as we \nstudy quantum mechanics. In simple terms, we say that an operator is always diagonal in its own \nbasis. This special form of the matrix representing the operator is similar to the special form that the \neigenvectors 0{9 take in this same representation\u2014the eigenvectors are unit vectors in their own \nbasis. These ideas cannot be overemphasized, so we repeat them:\nAn operator is always diagonal in its own basis.  \nEigenvectors are unit vectors in their own basis.\nLet\u2019s also summarize the matrix representations of the Sz operator and its eigenvectors:\n \nSz \u0003 U\n2\n a1\n0\n0\n-1b \n0  +9 \u0003 a1\n0b \n0  -9 \u0003 a0\n1b. \n(2.8)\n\n2.1 Operators, Eigenvalues, and Eigenvectors \n37\n2.1.1 \u0002 Matrix Representation of Operators\nNow consider how matrix representation works in general. Consider a general operator A describ-\ning a physical observable (still in the two-dimensional spin-1/2 system), which we represent by the \ngeneral matrix\n \nA \u0003 aa\nb\nc\ndb \n(2.9)\nin the Sz basis. The operation of A on the basis ket 0  +9 yields\n \nA0  +9 \u0003 aa\nb\nc\ndba1\n0b = aa\ncb. \n(2.10)\nThe inner product of this new ket A0  +9 with the ket 0  +9 (converted to a bra following the rules) results in\n \n8+ 0 A0  +9 = 11\n02aa\ncb = a , \n(2.11)\nwhich serves to isolate one of the elements of the matrix. Hence an individual element such as \n8+ 0 A0  +9 or 8+ 0 A0  -9 is generally referred to as a matrix element. This \u201csandwich\u201d of a bra, an \noperator, and a ket\n \n8bra0 OPERATOR0 ket9 \n(2.12)\nplays an important role in many quantum mechanical calculations. Even in cases where the bra and ket \nare not basis kets, such as in 8c0 A0 f9, we still refer to this as a matrix element. A schematic diagram \nof a generic matrix ",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 60
  },
  {
    "child_id": "95ef22fd-4841-40df-8b98-39f25ff9540f",
    "parent_id": "e4fe2b44-7296-4455-bd34-182542ca39f3",
    "text": "2aa\ncb = a , \n(2.11)\nwhich serves to isolate one of the elements of the matrix. Hence an individual element such as \n8+ 0 A0  +9 or 8+ 0 A0  -9 is generally referred to as a matrix element. This \u201csandwich\u201d of a bra, an \noperator, and a ket\n \n8bra0 OPERATOR0 ket9 \n(2.12)\nplays an important role in many quantum mechanical calculations. Even in cases where the bra and ket \nare not basis kets, such as in 8c0 A0 f9, we still refer to this as a matrix element. A schematic diagram \nof a generic matrix element is depicted in Fig. 2.2(a).\nAll four elements of the matrix representation of A can be determined in the same manner as \nEq. (2.11), with the \ufb01nal result\n \nA \u0003 \u00a28+ 0 A0  +9\n8+ 0 A0  -9\n8- 0 A0  +9\n8- 0 A0  -9\u2264. \n(2.13)\nTo emphasize the structure of the matrix, let\u2019s write it with explicit labeling of the rows and columns:\n \nA\n0  +9\n0  -9\n8+ 0\n8+ 0 A0 +9\n8+ 0 A0  -9\n8- 0\n8- 0 A0 +9\n8- 0 A0  -9\n . \n(2.14)\n(a) bra\nket\noperator\n\u0004bra\u0002OPERATOR\u0002ket\u0003\n(b) row\ncolumn\noperator\n\u0004n\u0002A\u0002m\u0003\n\u0004\u03a6\u0002A\u0002\u03a8\u0003\nFIGURE 2.2 (a) Schematic diagram of a generic matrix element. (b) Schematic diagram \nof the row and column labeling convention for matrix elements.\n\n38 \nOperators and Measurement\nIn a more general problem with more than two dimensions in the complex vector space, the matrix \nrepresentation of an operator is\n \nA \u0003 \u2022\nA11\nA12\nA13\ng\nA21\nA22\nA23\ng\nA31\nA32\nA33\ng\nf\nf\nf\nf\n\u03bc, \n(2.15)\nwhere the matrix elements are\n \nAij = 8i0\n A0  j9 \n(2.16)\nand the basis is assumed to be the states labeled 0 i9, with the subscripts i and j labeling the rows and \ncolumns respectively, as depicted in Fig. 2.2(b). Using this matrix representation, the action of this\noperator on a general ket 0 c9 = a\ni\nci0 i9 is\n \nA0 c9 \u0003 \u2022\nA11\nA12\nA13\ng\nA21\nA22\nA23\ng\nA31\nA32\nA33\ng\nf\nf\nf\nf\n\u03bc\u2022\nc1\nc2\nc3\nf\n\u03bc = \u2022\nA11c1 + A12c2 + A13c3 + g\nA21c1 + A22c2 + A23c3 + g\nA31c1 + A32c2 + A33c3 + g\nf\n\u03bc. \n(2.17)\nIf we write the new ket 0  f9 = A0 c9 as 0 f9 = a\ni\nbi0 i9, then from Eq. (2.17) the coef\ufb01cients bi are\n \nbi = a\nj\nAij\n cj \n(2.18)\nin summation notation.\n 2.1.2 \u0002 Diagonalization of Operators\nIn the case of the operator Sz above, we used the experimental results and the eigenvalue equations to \n\ufb01nd the matrix representation of the operator in Eq. (2.7). It is more common to work the other way. \nThat is, one is given the matrix representation of an operator and is asked to \ufb01nd the possible results of \na measurement of the corresponding observable. According to the third postulate, the possible results \nare the eigenvalues of the operator, and the eigenvectors are the quantum states representing them. In \nthe case of a general operator A in a two-state system, the eigenvalue equation is\n \nA0 an9 = an0 an9, \n(2.19)\nwhere we have labeled the eigenvalues an and we have labeled the eigenvectors with the correspond-\ning eigenvalues. In matrix notation, the eigenvalue equation is\n \n\u00a2A11\nA12\nA21\nA22\n\u2264\u00a2cn1\ncn2\n\u2264= an \u00a2cn1\ncn2\n\u2264, \n(2.20)\nwhere cn1 and cn2 are the unknown coef\ufb01cients of the eigenvector 0 an9 corresponding to the eigen",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 60
  },
  {
    "child_id": "b6f00552-5c04-48c4-ad88-089f7c8d5097",
    "parent_id": "e4fe2b44-7296-4455-bd34-182542ca39f3",
    "text": "rator, and the eigenvectors are the quantum states representing them. In \nthe case of a general operator A in a two-state system, the eigenvalue equation is\n \nA0 an9 = an0 an9, \n(2.19)\nwhere we have labeled the eigenvalues an and we have labeled the eigenvectors with the correspond-\ning eigenvalues. In matrix notation, the eigenvalue equation is\n \n\u00a2A11\nA12\nA21\nA22\n\u2264\u00a2cn1\ncn2\n\u2264= an \u00a2cn1\ncn2\n\u2264, \n(2.20)\nwhere cn1 and cn2 are the unknown coef\ufb01cients of the eigenvector 0 an9 corresponding to the eigen-\nvalue an. This matrix equation yields the set of homogeneous equations\n \n 1A11 - an2cn1 + A12\n cn2 = 0  \n \n A21cn1 + 1A22 - an2cn2 = 0. \n \n(2.21)\n\n2.1 Operators, Eigenvalues, and Eigenvectors \n39\nThe rules of linear algebra dictate that a set of homogeneous equations has solutions for the unknowns \ncn1 and cn2 only if the determinant of the coef\ufb01cients vanishes:\n \n` A11 - an\nA12\nA21\nA22 - an\n` = 0. \n(2.22)\nIt is common notation to use the symbol l for the eigenvalues, in which case this equation is\n \ndet 1A - lI 2 = 0, \n(2.23)\nwhere I is the identity matrix\n \nI = a1\n0\n0\n1b. \n(2.24)\nEquation (2.23) is known as the secular or characteristic equation. It is a second order equation in the \nparameter l and the two roots are identi\ufb01ed as the two eigenvalues a1 and a2 that we are trying to \ufb01nd. \nOnce these eigenvalues are found, they are then individually substituted back into Eqs. (2.21), which \nare solved to \ufb01nd the coef\ufb01cients of the corresponding eigenvector.\nExample 2.1 Assume that we know (e.g., from Problem 2.1) that the matrix representation for \nthe operator Sy is\n \nSy \u0003 U\n2\n a0\n-i\ni\n0 b . \n(2.25)\nFind the eigenvalues and eigenvectors of the operator Sy.\nThe general eigenvalue equation is\n \nSy0 l9 = l0 l9, \n(2.26)\nand the possible eigenvalues l are found using the secular equation\n \ndet0 Sy - lI0 = 0. \n(2.27)\nThe secular equation is\n \n\u221e\n-l\n-i U\n2\ni U\n2\n-l\n\u221e= 0, \n(2.28)\nand solving yields the eigenvalues\n \n l2 + i 2 a U\n2b\n2\n= 0 \n \n l2 - a U\n2b\n2\n= 0\n \n \n l2 = a U\n2b\n2\n \n \n l = { U\n2,\n \n(2.29)\n\n40 \nOperators and Measurement\nwhich was to be expected, because we know that the only possible results of a measurement of any \nspin component are {U>2.\nAs before, we label the eigenvectors 0{9y. The eigenvalue equation for the positive eigenvalue is\n \nSy0  +9y = +  U\n2 0  +9y, \n(2.30)\nor in matrix notation\n \nU\n2\n a0\n-i\ni\n0 b aa\nbb = + U\n2\n aa\nbb, \n(2.31)\nwhere we must solve for a and b to determine the eigenvector. Multiplying through and canceling \nthe common factor yields\n \na-ib\nia b = aa\nbb. \n(2.32)\nThis results in two equations, but they are not linearly independent, so we need some more infor-\nmation. The normalization condition provides what we need. Thus we have two equations that \ndetermine the eigenvector coef\ufb01cients:\n \n b = ia\n \n \n 0 a0\n2 + 0 b0\n2 = 1. \n(2.33)\nSolving these yields\n \n 0 a0\n2 + 0 ia0\n2 = 1 \n \n 0 a0\n2 = 1\n2.\n \n(2.34)\nAgain we follow the convention of choosing the \ufb01rst coef\ufb01cient to be real and positive, resulting in\n \n a =\n1\n12  \n \n b = i",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 60
  },
  {
    "child_id": "8bbe9bc7-ed5f-4ade-a112-db4698c3f2b3",
    "parent_id": "e4fe2b44-7296-4455-bd34-182542ca39f3",
    "text": "ds\n \na-ib\nia b = aa\nbb. \n(2.32)\nThis results in two equations, but they are not linearly independent, so we need some more infor-\nmation. The normalization condition provides what we need. Thus we have two equations that \ndetermine the eigenvector coef\ufb01cients:\n \n b = ia\n \n \n 0 a0\n2 + 0 b0\n2 = 1. \n(2.33)\nSolving these yields\n \n 0 a0\n2 + 0 ia0\n2 = 1 \n \n 0 a0\n2 = 1\n2.\n \n(2.34)\nAgain we follow the convention of choosing the \ufb01rst coef\ufb01cient to be real and positive, resulting in\n \n a =\n1\n12  \n \n b = i 1\n12. \n(2.35)\nThus the eigenvector corresponding to the positive eigenvalue is\n \n0  +9y \u0003\n1\n12\n a1\ni b. \n(2.36)\nLikewise, one can \ufb01nd the eigenvector for the negative eigenvalue to be\n \n0  -9y \u0003\n1\n12\n a 1\n-ib . \n(2.37)\nThese are, of course, the same states we found in Chapter 1 (Eq. 1.60).\nThis procedure of \ufb01nding the eigenvalues and eigenvectors of a matrix is known as diagonaliza-\ntion of the matrix and is the key step in many quantum mechanics problems. Generally, if we \ufb01nd a \nnew operator, the \ufb01rst thing we do is diagonalize it to \ufb01nd its eigenvalues and eigenvectors. However, \nwe stop short of the mathematical exercise of \ufb01nding the matrix that transforms the original matrix to \nits new diagonal form. This would amount to a change of basis from the original basis to a new basis \nof the eigenvectors we have just found, much like a rotation in three dimensions changes from one \ncoordinate system to another. We don\u2019t want to make this change of basis. In the example above, the \nSy matrix is not diagonal, whereas the Sz matrix is diagonal, because we are using the Sz basis. It is\n\n2.2 New Operators \n41\ncommon practice to use the Sz basis as the default basis, so you can assume that is the case unless you \nare told otherwise.\nIn summary, we now know three operators and their eigenvalues and eigenvectors. The spin com-\nponent operators Sx, Sy, and Sz all have eigenvalues {U>2. The matrix representations of the opera-\ntors and eigenvectors are (see Problem 2.1)\n \nSx \u0003 U\n2\n a0\n1\n1\n0b \n0  +9x \u0003\n1\n12\n a1\n1b \n0  -9x \u0003\n1\n12\n a 1\n-1b \n \nSy \u0003 U\n2\n a0\n-i\ni\n0 b \n0  +9y \u0003\n1\n12\n a1\ni b \n0  -9y \u0003\n1\n12\n a 1\n-ib    \n.\n \n \nSz \u0003 U\n2\n a1\n0\n0\n-1b \n0  +9 \u0003 a1\n0b \n0  -9 \u0003 a0\n1b \n(2.38)\n 2.2 \u0002 NEW OPERATORS\n 2.2.1 \u0002 Spin Component in a General Direction\nNow that we know the three operators corresponding to the spin components along the three Cartesian \naxes, we can use them to \ufb01nd the operator Sn for the spin component along a general direction nn. This \nnew operator will allow us to predict results of experiments we have not yet performed. The direction \nnn is speci\ufb01ed by the polar and azimuthal angles u and f as shown in Fig. 2.3. The unit vector nn is\n \nn = in sin u cos f + jn sin u sin f + kn cos u. \n(2.39)\nThe spin component along this direction is obtained by projecting the spin vector S onto this new unit \nvector\n \n Sn = S~nn\n \n \n = Sx sin u cos f + Sy sin u sin f + Sz cos u. \n \n(2.40)\nThe matrix representations we found for Sx, Sy, and Sz lead to the matrix representati",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 60
  },
  {
    "child_id": "3b99933f-55a4-4a13-9940-c0ce6b0c0572",
    "parent_id": "e4fe2b44-7296-4455-bd34-182542ca39f3",
    "text": "dict results of experiments we have not yet performed. The direction \nnn is speci\ufb01ed by the polar and azimuthal angles u and f as shown in Fig. 2.3. The unit vector nn is\n \nn = in sin u cos f + jn sin u sin f + kn cos u. \n(2.39)\nThe spin component along this direction is obtained by projecting the spin vector S onto this new unit \nvector\n \n Sn = S~nn\n \n \n = Sx sin u cos f + Sy sin u sin f + Sz cos u. \n \n(2.40)\nThe matrix representations we found for Sx, Sy, and Sz lead to the matrix representation of the spin \ncomponent operator Sn (Problem 2.6):\n \nSn \u0003 U\n2\n acos u\nsin u  e-if\nsin u  eif\n-cos u\nb. \n(2.41)\nn\nz\nx\ny\n\u03a6\n\u0398\n\u0006\nFIGURE 2.3 General direction along which to measure the spin component.",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 60
  },
  {
    "child_id": "3dbc2125-ff40-4fcc-8202-86c10b6b32ef",
    "parent_id": "e2fca869-9c17-462e-ae29-4bdab58ef23a",
    "text": "42 \nOperators and Measurement\nWe have found a new operator, so to learn about its properties, we diagonalize it. Following \nthe diagonalization procedure outlined in Section 2.1.2, we \ufb01nd that the eigenvalues of Sn are {U>2 \n(Problem 2.7). So if we measure the spin component along any direction, we get only two possible \nresults. This is to be expected from the experiments in Chapter 1. The eigenvectors for these two pos-\nsible measurements are (Problem 2.7):\n \n0  +9n = cos u\n2 0  +9 + sin u\n2\n eif0  -9  \n \n0  -9n = sin u\n2 0  +9 - cos u\n2\n eif0  -9, \n \n(2.42)\nwhere we again use the convention of choosing the \ufb01rst coef\ufb01cient to be real and positive. It is important \nto point out that the 0  +9n eigenstate (or equivalently the 0  -9n eigenstate) can be used to represent any \npossible ket in a spin-1/2 system, if one allows for all possible angles 0 \u2026 u 6 p and 0 \u2026 f 6 2p.\nWe generally write the most general state as 0 c9 = a0  +9 + b0  -9, where a and b are complex. Requir-\ning that the state be normalized and using the freedom to choose the \ufb01rst coef\ufb01cient real and positive \nreduces this to\n \n0 c9 = 0 a0 0  +9 + 41 - 0 a0\n2\n eif0  -9. \n(2.43)\nIf we change the parametrization of 0 a0  to cos 1u>22, we see that 0  +9n is equivalent to the most general \nstate 0 c9. This correspondence between the 0  +9n eigenstate and the most general state is only valid in a \ntwo-state system such as spin 1/2. In systems with more dimensionality, it does not hold because more \nparameters are needed to specify the most general state than are afforded by the two angles u and f.\nExample 2.2 Find the probabilities of the measurements shown in Fig. 2.4, assuming that the \n\ufb01rst Stern-Gerlach analyzer is aligned along the direction nn de\ufb01ned by the angles u = 2p>3 and \nf = p>4.\nThe measurement by the \ufb01rst Stern-Gerlach analyzer prepares the system in the spin up state \n0  +9n along the direction nn. This state is then the input state to the second Stern-Gerlach analyzer. \nThe input state is\n \n 0 cin9 = 0  +9n = cos u\n2 0  +9 + sin u\n2\n eif0  -9 \n \n = cos p\n3 0  +9 + sin p\n3\n eip/40  -9\n \n \n = 1\n2 0  +9 + 23\n2\n eip/40  -9.\n \n(2.44)\nX\n?\n?\n^n\nP x\n2\nP x\nx\nn\n2\nx\nn\nFIGURE 2.4  Measurement of the spin component after state preparation in a new direction.\n\n2.2 New Operators \n43\nThe second analyzer is aligned along the x-axis, so the probabilities are\n \n P+x = 0 x8+ 0 cin9 0\n2 = 0 x8+ 0  +9n0\n2  \n \n P-x = 0 x8- 0 cin9 0\n2 = 0 x8- 0  +9n0\n2. \n(2.45)\nLet\u2019s calculate the \ufb01rst probability using bra-ket notation, recalling that 0  +9x =\n1\n12 30  +9 + 0  -94:\n \n P+x = 0 x8+ 0  +9n0\n2\n \n \n = @ 1\n12 38+ 0   +  8- 0 4 1\n2 3 0  +9 + 13eip/40  -94@\n2\n \n \n = @\n1\n212 31 + 13eip/44@\n2\n \n \n = 1\n8 31 + 13eip/4431 + 13e-ip/44\n \n \n = 1\n8 31 + 131eip/4 + e-ip/42 + 34\n \n \n = 1\n8 34 + 213 cos 1p>424\n \n \n = 1\n8 34 + 213> 124 \u0002 0.806.\n \n(2.46)\nLet\u2019s calculate the second probability using matrix notation, recalling that 0  -9x =\n1\n12 30  +9 - 0  -94:\n \n P-x = 0 x8- 0  +9n0\n2\n \n \n = ` 1\n12 11\n-12 1\n2 a\n1\n",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 66
  },
  {
    "child_id": "b3a82eb4-702a-4058-9660-c135d8327fb6",
    "parent_id": "e2fca869-9c17-462e-ae29-4bdab58ef23a",
    "text": " bra-ket notation, recalling that 0  +9x =\n1\n12 30  +9 + 0  -94:\n \n P+x = 0 x8+ 0  +9n0\n2\n \n \n = @ 1\n12 38+ 0   +  8- 0 4 1\n2 3 0  +9 + 13eip/40  -94@\n2\n \n \n = @\n1\n212 31 + 13eip/44@\n2\n \n \n = 1\n8 31 + 13eip/4431 + 13e-ip/44\n \n \n = 1\n8 31 + 131eip/4 + e-ip/42 + 34\n \n \n = 1\n8 34 + 213 cos 1p>424\n \n \n = 1\n8 34 + 213> 124 \u0002 0.806.\n \n(2.46)\nLet\u2019s calculate the second probability using matrix notation, recalling that 0  -9x =\n1\n12 30  +9 - 0  -94:\n \n P-x = 0 x8- 0  +9n0\n2\n \n \n = ` 1\n12 11\n-12 1\n2 a\n1\n13eip>4b `\n2\n \n \n = @\n1\n212 31 - 13eip/44@\n2\n \n \n = 1\n8 34 - 213 cos 1p>424\n \n \n = 1\n8 34 - 213> 124 \u0002 0.194. \n(2.47)\nThe two results sum to unity as they must. A histogram of the measured results is shown in Fig. 2.5.\n1\nP\nP\u0003x\nP\u0002x\n\u0002\u03a8in\u0003 \u0006\u0005\u0002\u0002\u0003n\nSx\n\u0003\u0002\n2\n\u0002\n2\nFIGURE 2.5 Histogram of spin component Sx measurement.\n\n44 \nOperators and Measurement\n2.2.2 \u0002 Hermitian Operators\nSo far we have de\ufb01ned how operators act upon kets. For example, an operator A acts on a ket 0 c9 to \nproduce a new ket 0 f9 = A0 c9. The operator acts on the ket from the left; if the operator is on the \nright of the ket, the result is not de\ufb01ned, which is clear if you try to use matrix representation. Simi-\nlarly, an operator acting on a bra must be on the right side of the bra\n \n8j0 = 8c0 A \n(2.48)\nand the result is another bra. However, the bra 8j0 = 8c0 A is not the bra 8f0  that corresponds to the \nket 0 f9 = A0 c9. Rather the bra 8f0  is found by de\ufb01ning a new operator A\u2020 that obeys\n \n8f0 = 8c0 A\u2020. \n(2.49)\nThis new operator A\u2020 is called the Hermitian adjoint of the operator A. We can learn something about the \nHermitian adjoint by taking the inner product of the state 0 f9 = A0 c9 with another (unspeci\ufb01ed) state 0 b9\n \n 8f0 b9 = 8b0 f9*\n \n \n 38c0 A+4 0 b9 = 58b03A0 c946* \n \n 8c0 A+ 0 b9 = 8b0 A0 c9*,\n \n(2.50)\nwhich relates the matrix elements of A and A\u2020. Equation (2.50) tells us that the matrix representing the \nHermitian adjoint A\u2020 is found by transposing and complex conjugating the matrix representing A. This \nis consistent with the de\ufb01nition of Hermitian adjoint used in matrix algebra.\nAn operator A is said to be Hermitian if it is equal to its Hermitian adjoint A\u2020. If an operator is \nHermitian, then the bra 8c0 A is equal to the bra 8f0  that corresponds to the ket 0 f9 = A0 c9. That is, a \nHermitian operator can act to the right on a ket or to the left on a bra with the same result. In quantum \nmechanics, all operators that correspond to physical observables are Hermitian. This includes the spin \noperators we have already encountered as well as the energy, position, and momentum operators that \nwe will introduce in later chapters. The Hermiticity of physical observables is important in light of two \nfeatures of Hermitian matrices: (1) Hermitian matrices have real eigenvalues, which ensures that results \nof measurements are always real; and (2) the eigenvectors of a Hermitian matrix comprise a complete \nset of basis states, which ensures that we can use the eigenvectors of any obser",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 66
  },
  {
    "child_id": "754b88b1-1731-4034-a49f-416f9e93b415",
    "parent_id": "e2fca869-9c17-462e-ae29-4bdab58ef23a",
    "text": "spin \noperators we have already encountered as well as the energy, position, and momentum operators that \nwe will introduce in later chapters. The Hermiticity of physical observables is important in light of two \nfeatures of Hermitian matrices: (1) Hermitian matrices have real eigenvalues, which ensures that results \nof measurements are always real; and (2) the eigenvectors of a Hermitian matrix comprise a complete \nset of basis states, which ensures that we can use the eigenvectors of any observable as a valid basis.\n 2.2.3 \u0002 Projection Operators\nFor the spin-1/2 system, we now know four operators: Sx, Sy, Sz, and Sn. Let\u2019s look for some other \noperators. Consider the ket 0 c9 written in terms of its coef\ufb01cients in the Sz basis\n \n 0 c9 = a0  +9 + b0  -9\n \n \n = 18+ 0 c92 0  +9 + 18- 0 c92 0  -9. \n \n(2.51)\nLooking for the moment only at the \ufb01rst term, we can write it as a number times a ket, or as a ket times \na number:\n \n18+ 0 c92 0  +9 = 0  +918+ 0 c92 \n(2.52)\nwithout changing its meaning. Using the second form, we can separate the bra and ket that form the \ninner product and obtain\n \n0  +918+ 0 c92 = 10  +98+ 02 0 c9. \n(2.53)\n\n2.2 New Operators \n45\nThe new term in parentheses is a product of a ket and a bra but in the opposite order compared to the \ninner product de\ufb01ned earlier. This new object must be an operator because it acts on the ket 0 c9 and\nproduces another ket: 18+ 0 c92 0  +9. This new type of operator is known as an outer product.\nReturning now to Eq. (2.51), we write 0 c9 using these new operators:\n \n 0 c9 = 8+ 0 c9 0  +9 + 8- 0 c9 0  -9  \n \n = 0  +98+ 0 c9 + 0  -98- 0 c9  \n \n = 10  +98+ 0 + 0  -98- 02 0 c9. \n \n(2.54)\nThe term in parentheses is a sum of two outer products and is clearly an operator because it acts on a \nket to produce another ket. In this special case, the result is the same as the original ket, so the operator \nmust be the identity operator 1. This relationship is often written as\n \n0  +98+ 0 + 0  -98- 0 = 1 \n(2.55)\nand is known as the completeness relation or closure. It expresses the fact that the basis states 0 {9 \ncomprise a complete set of states, meaning any arbitrary ket can be written in terms of them. To make \nit obvious that outer products are operators, it is useful to express Eq. (2.55) in matrix notation using \nthe standard rules of matrix multiplication:\n \n 0  +98+ 0 + 0  -98- 0 \u0003 a1\n0b11\n02 + a0\n1b10\n12 \n \n \u0003 a1\n0\n0\n0b + a0\n0\n0\n1b\n \n \n \n \u0003 a1\n0\n0\n1b.\n \n \n(2.56)\nEach outer product is represented by a matrix, as we expect for operators, and the sum of these two \nouter products is represented by the identity matrix, which we expected from Eq. (2.54).\nNow consider the individual operators 0  +98+ 0  and 0  -98- 0 . These operators are called projec-\ntion operators, and for spin 1/2 they are given by\n \n P+ = 0  +98+ 0 \u0003 a1\n0\n0\n0b  \n \n P- = 0  -98- 0 \u0003 a0\n0\n0\n1b. \n \n(2.57)\nIn terms of these new operators the completeness relation can also be written as\n \nP+ + P- = 1. \n(2.58)\nWhen a projection operator for",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 66
  },
  {
    "child_id": "482f7880-62e7-4515-ad48-9d807f661bb1",
    "parent_id": "e2fca869-9c17-462e-ae29-4bdab58ef23a",
    "text": "s we expect for operators, and the sum of these two \nouter products is represented by the identity matrix, which we expected from Eq. (2.54).\nNow consider the individual operators 0  +98+ 0  and 0  -98- 0 . These operators are called projec-\ntion operators, and for spin 1/2 they are given by\n \n P+ = 0  +98+ 0 \u0003 a1\n0\n0\n0b  \n \n P- = 0  -98- 0 \u0003 a0\n0\n0\n1b. \n \n(2.57)\nIn terms of these new operators the completeness relation can also be written as\n \nP+ + P- = 1. \n(2.58)\nWhen a projection operator for a particular eigenstate acts on a state 0 c9, it produces a new ket that is \naligned along the eigenstate and has a magnitude equal to the amplitude (including the phase) for the \nstate 0 c9 to be in that eigenstate. For example,\n \nP+ 0 c9 = 0  +98+ 0 c9 = 18+ 0 c92 0  +9  \n \nP- 0 c9 = 0  -98- 0 c9 = 18- 0 c92 0  -9. \n \n(2.59)\n\n46 \nOperators and Measurement\nNote also that a projector acting on its corresponding eigenstate results in that eigenstate, and a projec-\ntor acting on an orthogonal state results in zero:\n \n P+ 0  +9 = 0  +98+ 0  +9 = 0  +9 \n \n P- 0  +9 = 0  -98- 0  +9 = 0.  \n \n(2.60)\nBecause the projection operator produces the probability amplitude, we expect that it must be inti-\nmately tied to measurement in quantum mechanics.\nWe found in Chapter 1 that the probability of a measurement is given by the square of the inner \nproduct of initial and \ufb01nal states (postulate 4). Using the new projection operators, we rewrite the \nprobability as\n \n P+ = 08+ 0 c9 0\n2\n \n \n = 8+ 0 c9*8+ 0 c9 \n \n = 8c0  +98+ 0 c9  \n \n = 8c0 P+ 0 c9.\n \n \n(2.61)\nThus we say that the probability of the measurement Sz = U>2 can be calculated as a matrix element \nof the projection operator, using the input state 0 c9 and the projector P+ corresponding to the result.\nThe other important aspect of quantum measurement that we learned in Chapter 1 is that a mea-\nsurement disturbs the system. That is, if an input state 0 c9 is measured to have Sz = +U>2, then the \noutput state is no longer 0 c9 but is changed to 0  +9. We saw above that the projection operator does this \noperation for us, with a multiplicative constant of the probability amplitude. Thus, if we divide by this \namplitude, which is the square root of the probability, then we can describe the abrupt change of the \ninput state as\n \n0 c\u00049 =\nP+ 0 c9\n2\n 8c0 P+ 0 c9\n= 0  +9, \n(2.62)\nwhere 0 c\u00049 is the output state. This effect is described by the \ufb01fth postulate, which is presented below \nand is often referred to as the projection postulate.\nPostulate 5\nAfter a measurement of A that yields the result an, the quantum system is in a \nnew state that is the normalized projection of the original system ket onto the \nket (or kets) corresponding to the result of the measurement:\n0 c\u00049 =\nPn0 c9\n2\n 8c0 Pn0 c9\n.\nThe projection postulate is at the heart of quantum measurement. This effect is often referred to as the \ncollapse (or reduction or projection) of the quantum state vector. The projection postulate clearly states \nthat quantum ",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 66
  },
  {
    "child_id": "6096ccc8-018b-48f5-8ab9-31344e1293aa",
    "parent_id": "e2fca869-9c17-462e-ae29-4bdab58ef23a",
    "text": "ulate.\nPostulate 5\nAfter a measurement of A that yields the result an, the quantum system is in a \nnew state that is the normalized projection of the original system ket onto the \nket (or kets) corresponding to the result of the measurement:\n0 c\u00049 =\nPn0 c9\n2\n 8c0 Pn0 c9\n.\nThe projection postulate is at the heart of quantum measurement. This effect is often referred to as the \ncollapse (or reduction or projection) of the quantum state vector. The projection postulate clearly states \nthat quantum measurements cannot be made without disturbing the system (except in the case where the \ninput state is the same as the output state), in sharp contrast to classical measurements. The collapse of \n the quantum state makes quantum mechanics irreversible, again in contrast to classical mechanics.",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 66
  },
  {
    "child_id": "6b2e3718-95c0-47e3-a010-da7f44a50ecb",
    "parent_id": "d6868aea-6dae-4530-baa8-b589124d329c",
    "text": "2.2 New Operators \n47\nWe can use the projection postulate to make a model of quantum measurement, as shown in the \nrevised depiction of a Stern-Gerlach measurement system in Fig. 2.6. The projection operators act on \nthe input state to produce output states with probabilities given by the squares of the amplitudes that \nthe projection operations yield. For example, the input state 0 cin9 is acted on the projection operator \nP+ = 0  +98+ 0 , producing an output ket 0 cout9 = 0  +918+ 0 cin92 with probability P+ = 08+ 0 cin9 0 2. \nThe output ket 0 cout9 = 0  +918+ 0 cin92 is really just a 0  +9 ket that is not properly normalized, so we \nnormalize it for use in any further calculations. We do not really know what is going on in the mea-\nsurement process, so we cannot explain the mechanism of the collapse of the quantum state vector. \nThis lack of understanding makes some people uncomfortable with this aspect of quantum mechan-\nics and has been the source of much controversy surrounding quantum mechanics. Trying to better \nunderstand the measurement process in quantum mechanics is an ongoing research problem. How-\never, despite our lack of understanding, the theory for predicting the results of experiments has been \nproven with very high accuracy.\n 2.2.4 \u0002 Analysis of Experiments 3 and 4\nWe can now return to Experiments 3 and 4 from Chapter 1 and analyze them with these new tools. \nRecall that Experiment 3 is the same as Experiment 4a, and Experiments 4a and 4b are similar in that \nthey each use only one of the output ports of the second Stern-Gerlach analyzer as input to the third \nanalyzer. Figure 2.7 depicts these experiments again, with Fig. 2.7(a) showing a hybrid experiment \nthat is essentially Experiment 4a in its upper half and Experiment 4b in its lower half, and Fig. 2.7(b) \nshowing Experiment 4c. In this problem, we discuss the probability that an atom leaving the \ufb01rst \nanalyzer in the 0  +9 state is detected in one of the counters connected to the output ports of the third \nanalyzer. Such a probability involves two measurements at the second and third analyzers. The total \nprobability is the product of the individual probabilities of each measurement.\nFor the hybrid experiment shown in Fig. 2.7(a), the probability of measuring an atom at the top-\nmost counter is the probability of measuring Sx = +U>2 at the second analyzer, 0 x8+ 0  +9 0\n2, times the \nprobability of measuring Sz = +U>2 at the third analyzer, 08+ 0  +9x0\n2, giving\n \nPupper, + = 08+ 0  +9x0\n2\n 0 x8+ 0  +9 0\n2. \n(2.63)\nLikewise the probability of measuring the atom to have Sx = +U>2 and then Sz = -U>2 is\n \nPupper, - = 08- 0  +9x0\n2\n 0 x8+ 0  +9 0\n2, \n(2.64)\nZ\n\u0002\u0002\u0003 \u0004\u0002\u0002\n\u0002\u0003\u0003 \u0004\u0003\u0002\n\u0002\u0002\u0003\n\u0002\u0003\u0003\nProject\nNormalize\n\u0002\u03a8\u0003\n\u0002\u0002\u0003\u0004\u0002\u0002\u03a8\u0003\n\u0002\u0003\u0003\u0004\u0003\u0002\u03a8\u0003\nFIGURE 2.6 Schematic diagram of the role of the projection operator in a Stern-Gerlach spin measurement.\n\n48 \nOperators and Measurement\nwhere we have written the product so as to be read from right to left as is the usual practice with \nquantum mechanical ",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 71
  },
  {
    "child_id": "7840629b-aca6-4470-bc04-422f373527f2",
    "parent_id": "d6868aea-6dae-4530-baa8-b589124d329c",
    "text": " 0  +9x0\n2\n 0 x8+ 0  +9 0\n2. \n(2.63)\nLikewise the probability of measuring the atom to have Sx = +U>2 and then Sz = -U>2 is\n \nPupper, - = 08- 0  +9x0\n2\n 0 x8+ 0  +9 0\n2, \n(2.64)\nZ\n\u0002\u0002\u0003 \u0004\u0002\u0002\n\u0002\u0003\u0003 \u0004\u0003\u0002\n\u0002\u0002\u0003\n\u0002\u0003\u0003\nProject\nNormalize\n\u0002\u03a8\u0003\n\u0002\u0002\u0003\u0004\u0002\u0002\u03a8\u0003\n\u0002\u0003\u0003\u0004\u0003\u0002\u03a8\u0003\nFIGURE 2.6 Schematic diagram of the role of the projection operator in a Stern-Gerlach spin measurement.\n\n48 \nOperators and Measurement\nwhere we have written the product so as to be read from right to left as is the usual practice with \nquantum mechanical amplitudes and probabilities. For atoms that take the lower path from the second \nanalyzer, the \ufb01nal probabilities are\n \nPlower, + = 08+ 0  -9x0\n2\n 0 x8- 0  +9 0\n2  \n \nPlower, - = 08- 0  -9x0\n2\n 0 x8- 0  +9 0\n2. \n \n(2.65)\nFor Experiment 4c, shown in Fig. 2.7(b), we have a new situation at the second analyzer. Both \noutput ports are connected to the third analyzer, which means that the probability of an atom from \nthe \ufb01rst analyzer being input to the third analyzer is 100%. So we need only calculate the probability \nof passage through the third analyzer. The crucial step is determining the input state, for which we \nuse the projection postulate. Because both states are used, the relevant projection operator is the sum \nof the two projection operators for each port, P+x + P-x, where P+x = 0  +9x x8+ 0  and P-x = 0  -9x x8- 0 .\nThus the state after the second analyzer is\n \n 0 c29 =\n1P+x + P-x2 0 c19\n2\n 8c101P+x + P-x2 0 c19\n \n \n =\n1P+x + P-x2 0  +9\n2\n 8+ 01P+x + P-x2 0  +9\n . \n \n(2.66)\n100\n0\nX\nZ\nZ\n100\n100\n25\n25\nZ\nX\nZ\n100\n(a)\n(b)\n50\n25\n25\nZ\n50\nFIGURE 2.7 (a) Hybrid Experiment 4a and 4b, and (b) Experiment 4c.\n\n2.2 New Operators \n49\nIn this simple example, the projector P+x + P-x is equal to the identity operator because the two states \nform a complete basis. This clearly simpli\ufb01es the calculation, giving 0 c29 = 0  +9, but to illustrate our \npoint, let\u2019s simplify only the denominator (which equals one), giving\n \n 0 c29 = 10  +9x x8+ 0 + 0  -9x x8- 02 0  +9  \n \n = 0  +9x x8+ 0  +9 + 0  -9x x8- 0  +9. \n \n(2.67)\nThus the beam entering the third analyzer can be viewed as a coherent superposition of the eigenstates \nof the second analyzer. Now calculate the probability of measuring spin up at the third analyzer:\n \n P+ = 08+ 0 c29 0\n2\n \n \n = 08+ 0  +9x x8+ 0  +9 + 8+ 0  -9x x8- 0  +9 0\n2. \n \n(2.68)\nThe probability of measuring spin down at the third analyzer is similarly\n \nP - = 08- 0 c29 0\n2\n \n \n = 08- 0  +9x x8+ 0  +9 + 8- 0  -9x x8- 0  +9 0\n2. \n \n(2.69)\nIn each case, the probability is a square of a sum of amplitudes, each amplitude being the amplitude \nfor a successive pair of measurements. For example, in P- the amplitude 8- 0  +9x x8+ 0  +9 refers to the \nupper path that the initial 0  +9 state takes as it is \ufb01rst measured to be in the 0  +9x state and then mea-\nsured to be in the 0  -9 state (read from right to left). This amplitude is added to the amplitude for the \nlower path because the beams of the second analyzer are combined, in the proper fashion, to c",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 71
  },
  {
    "child_id": "7244fdfb-8071-447d-b268-479e5cd9f294",
    "parent_id": "d6868aea-6dae-4530-baa8-b589124d329c",
    "text": "robability is a square of a sum of amplitudes, each amplitude being the amplitude \nfor a successive pair of measurements. For example, in P- the amplitude 8- 0  +9x x8+ 0  +9 refers to the \nupper path that the initial 0  +9 state takes as it is \ufb01rst measured to be in the 0  +9x state and then mea-\nsured to be in the 0  -9 state (read from right to left). This amplitude is added to the amplitude for the \nlower path because the beams of the second analyzer are combined, in the proper fashion, to create the \ninput beam to the third analyzer. When the sum of amplitudes is squared, four terms are obtained, two \nsquares and two cross terms, giving\n \n P- = 08- 0  +9x x8+ 0  +9 0\n2 + 08- 0  -9x x8- 0  +9 0\n2 \n \n +8- 0  +9*\nx x8+ 0  +9*8- 0  -9x x8- 0  +9\n \n \n +8- 0  +9x x8+ 0  +98- 0  -9*\nx x8- 0  +9*\n \n \n = Pupper, - + Plower, - + interference terms. \n \n(2.70)\nThis tells us that the probability of detecting an atom to have spin down when both paths are used is the \nsum of the probabilities for detecting a spin down atom when either the upper path or the lower path is \nused alone plus additional cross terms involving both amplitudes, which are commonly called interference \nterms. It is these additional terms, which are not complex squares and so could be positive or negative, that \nallow the total probability to become zero in this case, illustrating the phenomenon of interference.\nThis interference arises from the nature of the superposition of states that enters the third analyzer. \nTo illustrate, consider what happens if we change the superposition state to a mixed state, as we dis-\ncussed previously in Section 1.2.3. Recall that a superposition state implies a beam with each atom in \nthe same state, which is a combination of states, while a mixed state implies that the beam consists of \natoms in separate states. As we have described it so far, Experiment 4c involves a superposition state \nas the input to the third analyzer. We can change this to a mixed state by \u201cwatching\u201d to see which of \nthe two output ports of the second analyzer each atom travels through. There are a variety of ways to \nimagine doing this experimentally. The usual idea proposed is to illuminate the paths with light and \nwatch for the scattered light from the atoms. With proper design of the optics, the light can be localized\n\n50 \nOperators and Measurement\nsuf\ufb01ciently to determine which path the atom takes. Hence, such experiments are generally referred to \nas \u201cWhich Path\u201d or \u201cWelcher Weg\u201d experiments. Such experiments can be performed in the SPINS \nprogram by selecting the \u201cWatch\u201d feature. Once we know which path the atom takes, the state is not \nthe superposition 0 c29 described above, but is either 0  +9x or 0  -9x, depending on which path produces \nthe light signal. To \ufb01nd the probability that atoms are detected at the spin down counter of the third \nanalyzer, we add the probabilities for atoms to follow the path 0  +9 S 0  +9x S 0  -9 to the probability \nfor other atoms to fo",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 71
  },
  {
    "child_id": "51418751-a2fc-4416-b05b-832362623e00",
    "parent_id": "d6868aea-6dae-4530-baa8-b589124d329c",
    "text": "experiments. Such experiments can be performed in the SPINS \nprogram by selecting the \u201cWatch\u201d feature. Once we know which path the atom takes, the state is not \nthe superposition 0 c29 described above, but is either 0  +9x or 0  -9x, depending on which path produces \nthe light signal. To \ufb01nd the probability that atoms are detected at the spin down counter of the third \nanalyzer, we add the probabilities for atoms to follow the path 0  +9 S 0  +9x S 0  -9 to the probability \nfor other atoms to follow the path 0  +9 S 0  -9x S 0  -9 because these are independent events, giving\n \n Pwatch,  - = 08- 0  +9x x8+ 0  +9 0\n2 + 08- 0  -9x x8- 0  +9 0\n2 \n \n = Pupper, - + Plower, - ,\n \n \n(2.71)\nin which no interference terms are present.\nThis interference example illustrates again the important distinction between a coherent superpo-\nsition state and a statistical mixed state. In a coherent superposition, there is a de\ufb01nite relative phase \nbetween the different states, which gives rise to interference effects that are dependent on that phase. In a \nstatistical mixed state, the phase relationship between the states has been destroyed and the interference \nis washed out. Now we can understand what it takes to have the beams \u201cproperly\u201d combined after the \nsecond analyzer of Experiment 4c. The relative phases of the two paths must be preserved. Anything that \nrandomizes the phase is equivalent to destroying the superposition and leaving only a statistical mixture. \nIf the beams are properly combined to leave the superposition intact, the results of Experiment 4c are \nthe same as if no measurement were made at the second analyzer. So even though we have used a mea-\nsuring device in the middle of Experiment 4c, we generally say that no measurement was made there. \nWe can summarize our conclusions by saying that if no measurement is made on the intermediate state, \nthen we add amplitudes and then square to \ufb01nd the probability, while if an intermediate measurement is \n performed (i.e., watching), then we square the amplitudes \ufb01rst and then add to \ufb01nd the probability. One \nis the square of a sum and the other is the sum of squares, and only the former exhibits interference.\n 2.3 \u0002 MEASUREMENT\nLet\u2019s discuss how the probabilistic nature of quantum mechanics affects the way experiments are \nperformed and compared with theory. In classical physics, a theoretical prediction can be reliably \ncompared to a single experimental result. For example, a prediction of the range of a projectile can be \ntested by doing an experiment. The experiment may be repeated several times in order to understand \nand possibly reduce any systematic errors (e.g., wind) and measurement errors (e.g., misreading the \ntape measure). In quantum mechanics, a single measurement is meaningless. If we measure an atom to \nhave spin up in a Stern-Gerlach analyzer, we cannot discern whether the original state was 0  +9 or 0  -9x \nor any arbitrary state 0 c9 1except 0  -92. Moreover, we cannot repeat the meas",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 71
  },
  {
    "child_id": "50a9ce2c-da2f-43a5-9584-1fef73a92cab",
    "parent_id": "d6868aea-6dae-4530-baa8-b589124d329c",
    "text": "ile can be \ntested by doing an experiment. The experiment may be repeated several times in order to understand \nand possibly reduce any systematic errors (e.g., wind) and measurement errors (e.g., misreading the \ntape measure). In quantum mechanics, a single measurement is meaningless. If we measure an atom to \nhave spin up in a Stern-Gerlach analyzer, we cannot discern whether the original state was 0  +9 or 0  -9x \nor any arbitrary state 0 c9 1except 0  -92. Moreover, we cannot repeat the measurement on the same \natom, because the original measurement changed the state, per the projection postulate.\nThus, one must, by necessity, perform identical measurements on identically prepared systems. \nIn the spin-1/2 example, an initial Stern-Gerlach analyzer is used to prepare atoms in a particular state \n0 c9. Then a second Stern-Gerlach analyzer is used to perform the same experiment on each identically \n prepared atom. Consider performing a measurement of Sz on N identically prepared atoms. Let N+ be the \nnumber of times the result +U>2 is recorded and N\u2212 be the number of times the result -U>2 is recorded. \nBecause there are only two possible results for each measurement, we must have N = N+ + N-. The \nprobability postulate (postulate 4) predicts that the probability of measuring +U>2 is\n \nP+ = 08+ 0 c9 0\n2. \n(2.72)",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 71
  },
  {
    "child_id": "e758e0b4-1a2c-489b-acaa-2fb0d0c7f8b1",
    "parent_id": "59103437-2f5a-49fb-a911-8837e38604f3",
    "text": "2.3 Measurement \n51\nFor a \ufb01nite number N of atoms, we expect that N+ is only approximately equal to P+ N due to the statis-\ntical \ufb02uctuations inherent in a random process. Only in the limit of an in\ufb01nite number N do we expect \nexact agreement:\n \nlim\nNS \u0005\nN+\nN = P+ = 08+ 0 c9 0\n2. \n(2.73)\nIt is useful to characterize a data set in terms of the mean and standard deviation (see Appendix \nA for further information on probability). The mean value of a data set is the average of all the mea-\nsurements. The expected or predicted mean value of a measurement is the sum of the products of each \npossible result and its probability, which for this spin-1/2 measurement is\n \n8Sz9 = a+  U\n2b P+ + a-  U\n2b P-   , \n(2.74)\nwhere the angle brackets signify average or mean value. Using the rules of quantum mechanics we \nrewrite this mean value as\n \n 8Sz9 = +  U\n2\n 08+ 0 c9 0\n2 + a-  U\n2b 08- 0 c9 0\n2\n \n \n = +  U\n2\n 8c0  +98+ 0 c9 + a-  U\n2b8c0  -98- 0 c9 \n \n = 8c0 J\n +  U\n2 0  +98+ 0 c9 + a-  U\n2b 0  -98- 0 c9\n R \n \n = 8c03Sz0  +98+ 0 c9 + Sz0  -98- 0 c94\n \n \n = 8c0 Sz30  +98+ 0 + 0  -98- 04 0 c9.\n \n \n(2.75)\nAccording to the completeness relation, the term in square brackets in the last line is unity, so \nwe obtain\n \n8Sz9 = 8c0 Sz0 c9  . \n(2.76)\nWe now have two ways to calculate the predicted mean value, Eq. (2.74) and Eq. (2.76). Which you \nuse generally depends on what quantities you have readily available. The matrix element version in \nEq. (2.76) is more common and is especially useful in systems that are more complicated than the \n2-level spin-1/2 system. This predicted mean value is commonly called the expectation value, but \nit is not the expected value of any single experiment. Rather it is the expected mean value of a large \nnumber of experiments. It is not a time average, but an average over many identical experiments. For a \ngeneral quantum mechanical observable, the expectation value is\n \n8A9 = 8c0 A0 c9 = a\nn\nanPan   , \n(2.77)\nwhere an are the eigenvalues of the operator A.\nTo see how the concept of expectation values applies to our study of spin-1/2 systems, consider \ntwo examples. First consider a system prepared in the state 0  +9. The expectation value of Sz is\n \n8Sz9 = 8+ 0 Sz0  +9, \n(2.78)\n\n52 \nOperators and Measurement\nwhich we calculate with bra-ket notation\n \n 8Sz9 = 8+ 0 Sz0  +9 \n \n = 8+ 0 U\n2 0  +9  \n \n = U\n2\n 8+ 0  +9  \n \n = U\n2.\n \n \n(2.79)\nThis result should seem obvious because +U>2 is the only possible result of a measurement of Sz for \nthe 0  +9 state, so it must be the expectation value.\nNext consider a system prepared in the state 0  +9x. In this case, the expectation value of Sz is\n \n8Sz9 = x8+ 0 Sz0 +9x. \n(2.80)\nUsing matrix notation, we obtain\n \n 8Sz9 =\n1\n12  11\n12 U\n2\n a1\n0\n0\n-1b 1\n12 a1\n1b \n \n = U\n4\n  11\n12a 1\n-1b = 0 U.\n \n \n(2.81)\nAgain this is what you expect, because the two possible measurement results {U>2 each have 50% \nprobability, so the average value is zero. Note that the value of zero is never measured, so it is not the",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 75
  },
  {
    "child_id": "c8332e4b-94bd-4e8f-a75c-14ffee215669",
    "parent_id": "59103437-2f5a-49fb-a911-8837e38604f3",
    "text": "tate, so it must be the expectation value.\nNext consider a system prepared in the state 0  +9x. In this case, the expectation value of Sz is\n \n8Sz9 = x8+ 0 Sz0 +9x. \n(2.80)\nUsing matrix notation, we obtain\n \n 8Sz9 =\n1\n12  11\n12 U\n2\n a1\n0\n0\n-1b 1\n12 a1\n1b \n \n = U\n4\n  11\n12a 1\n-1b = 0 U.\n \n \n(2.81)\nAgain this is what you expect, because the two possible measurement results {U>2 each have 50% \nprobability, so the average value is zero. Note that the value of zero is never measured, so it is not the \nvalue \u201cexpected\u201d for any given measurement, but rather the expected mean value of an ensemble of \nmeasurements.\nIn addition to the mean value, it is common to characterize a measurement by the standard devia-\ntion, which quanti\ufb01es the spread of measurements about the mean or expectation value. The standard \ndeviation is de\ufb01ned as the square root of the mean of the square of the deviations from the mean, and \nfor an observable A is given by\n \n\u0006A = 481A - 8A9229, \n(2.82)\nwhere the angle brackets signify average value as used in the de\ufb01nition of an expectation value. This \nresult is also often called the root-mean-square deviation, or r.m.s. deviation. We need to square the \ndeviations, because the deviations from the mean are equally distributed above and below the mean in \nsuch a way that the average of the deviations themselves is zero. This expression can be simpli\ufb01ed by \nexpanding the square and performing the averages, resulting in\n \n \u0006A = 481A2 - 2A8A9 + 8A9229 \n \n = 48A29 - 28A98A9 + 8A92 \n \n = 48A29 - 8A92,\n \n \n(2.83)\n\n2.3 Measurement \n53\nwhere one must be clear to distinguish between the square of the mean 8A9\n2 and the mean of the \nsquare 8A29. While the mean of the square of an observable may not be a common experimental quan-\ntity, it can be calculated using the de\ufb01nition of the expectation value\n \n8A29 = 8c0 A20 c9. \n(2.84)\nThe square of an operator means that the operator acts twice in succession:\n \nA20 c9 = AA0 c9 = A1A0 c92. \n(2.85)\nTo gain experience with the standard deviation, return to the two examples used above. To calcu-\nlate the standard deviation, we need to \ufb01nd the mean of the square of the operator S z. In the \ufb01rst case \nA 0  +9 initial stateB, we get\n \n 8S\n 2\nz 9 = 8+ @S\n 2\nz @  +9 = 8+ @Sz Sz@  +9 = 8+ @Sz U\n2\n @  +9\n \n = 8+ 0 a U\n2b\n2\n0  +9\n \n = a U\n2b\n2\n.\n \n(2.86)\nWe already have the mean of the operator Sz in Eq. (2.79) so the standard deviation is\n \n \u0006Sz = 48S\n 2\nz 9 - 8Sz9\n2  \n \n = Ca U\n2b\n2\n- a U\n2b\n2\n \n \n = 0 U,\n \n \n(2.87)\nwhich is to be expected because there is only one possible result, and hence no spread in the results of \nthe measurement, as shown in the histogram in Fig. 2.8(a).\n(a)\n1\nP\nP\u2212\nP+\nSz\n\u0003\u0002\n2\n\u0002\n2\n1\nP\nP\u2212\nP+\nSz\n\u0003\u0002\n2\n\u0002\n2\n\u000bSz \u0006 \u0002\n2\n\u000bSz \u0006\u00050\n\u0004Sz\u0003 \u0006\u0005\n\u0004Sz\u0003 \u0006\u00050\u0005\n\u0002\n2\n\u0002\u03a8in\u0003\u0005\u0006\u0005\u0002\u0002\u0003\n\u0002\u03a8in\u0003\u0005\u0006\u0005\u0002\u0002\u0003x\nFIGURE 2.8 Idealized measurements of Sz with (a) a 0  +9 input state and (b) with a 0  +9x input state.\n\n54 \nOperators and Measurement\nIn the second case 1 0  +9x initial state2, the mean of the square of the operator Sz is\n \n 8S",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 75
  },
  {
    "child_id": "435c67ae-b164-4813-9346-1f568e3c1dcd",
    "parent_id": "59103437-2f5a-49fb-a911-8837e38604f3",
    "text": "s to be expected because there is only one possible result, and hence no spread in the results of \nthe measurement, as shown in the histogram in Fig. 2.8(a).\n(a)\n1\nP\nP\u2212\nP+\nSz\n\u0003\u0002\n2\n\u0002\n2\n1\nP\nP\u2212\nP+\nSz\n\u0003\u0002\n2\n\u0002\n2\n\u000bSz \u0006 \u0002\n2\n\u000bSz \u0006\u00050\n\u0004Sz\u0003 \u0006\u0005\n\u0004Sz\u0003 \u0006\u00050\u0005\n\u0002\n2\n\u0002\u03a8in\u0003\u0005\u0006\u0005\u0002\u0002\u0003\n\u0002\u03a8in\u0003\u0005\u0006\u0005\u0002\u0002\u0003x\nFIGURE 2.8 Idealized measurements of Sz with (a) a 0  +9 input state and (b) with a 0  +9x input state.\n\n54 \nOperators and Measurement\nIn the second case 1 0  +9x initial state2, the mean of the square of the operator Sz is\n \n 8S\n 2\nz 9 = x8+ @ S\n 2\nz @  +9x\n \n \n =\n1\n12\n 11\n12  U\n2\n a1\n0\n0\n-1b U\n2\n a1\n0\n0\n-1b 1\n12\n a1\n1b \n \n = 1\n2\n a U\n2b\n2\n11\n12a1\n0\n0\n-1ba 1\n-1b\n \n \n = 1\n2\n a U\n2b\n2\n11\n12a1\n1b\n \n \n = a U\n2b\n2\n.\n \n \n(2.88)\nThe mean of the operator Sz is in Eq. (2.81), giving a standard deviation of \n \n \u0006Sz = 48S\n 2\nz 9 - 8Sz9\n2 \n \n = Ca U\n2b\n2\n- 0 U2 \n(2.89)\n \n = U\n2.\nAgain this makes sense because each measurement deviates from the mean (0 U) by the same value of \nU>2, as shown in the histogram in Fig. 2.8(b).\nThe standard deviation \u0006A represents the uncertainty in the results of an experiment. In quan-\ntum mechanics, this uncertainty is inherent and fundamental, meaning that you cannot design the \nexperiment any better to improve the result. What we have calculated then is the minimum uncertainty \nallowed by quantum mechanics. Any actual uncertainty may be larger due to experimental error. \nThis is another rami\ufb01cation of the probabilistic nature of quantum mechanics and will lead us to the \nHeisenberg uncertainty relation in Section 2.5.\n 2.4 \u0002 COMMUTING OBSERVABLES\nWe found in Experiment 3 that two incompatible observables could not be known or measured simul-\ntaneously, because measurement of one somehow erased knowledge of the other. Let us now explore \nfurther what it means for two observables to be incompatible and how incompatibility affects the results \nof measurements. First we need to de\ufb01ne a new object called a commutator. The commutator of two \noperators is de\ufb01ned as the difference between the products of the two operators taken in alternate orders:\n \n3A, B4 = AB - BA. \n(2.90)\nIf the commutator is equal to zero, we say that the operators or observables commute; if it is not zero, we \nsay they don\u2019t commute. Whether or not two operators commute has important rami\ufb01cations in analyzing \na quantum system and in making measurements of the two observables represented by those operators.\n\n2.4 Commuting Observables \n55\nConsider what happens when two operators A and B do commute:\n \n 3A, B4 = 0\n \n \n AB - BA = 0\n \n \n AB = BA. \n(2.91)\nThus, for commuting operators the order of operation does not matter, whereas it does for noncom-\nmuting operators. Now let 0 a9 be an eigenstate of the operator A with eigenvalue a:\n \nA0 a9 = a0 a9. \n(2.92)\nOperate on both sides of this equation with the operator B and use the fact that A and B commute:\n \n BA0 a9 = Ba0 a9\n \n \n AB0 a9 = aB0 a9\n \n \n A1B0 a92 = a1B0 a92. \n(2.93)\nThe last equation says that the state B0 a9 is also an eigenstate of the ",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 75
  },
  {
    "child_id": "f569e495-df43-4819-9940-e931658e0cc7",
    "parent_id": "59103437-2f5a-49fb-a911-8837e38604f3",
    "text": " B4 = 0\n \n \n AB - BA = 0\n \n \n AB = BA. \n(2.91)\nThus, for commuting operators the order of operation does not matter, whereas it does for noncom-\nmuting operators. Now let 0 a9 be an eigenstate of the operator A with eigenvalue a:\n \nA0 a9 = a0 a9. \n(2.92)\nOperate on both sides of this equation with the operator B and use the fact that A and B commute:\n \n BA0 a9 = Ba0 a9\n \n \n AB0 a9 = aB0 a9\n \n \n A1B0 a92 = a1B0 a92. \n(2.93)\nThe last equation says that the state B0 a9 is also an eigenstate of the operator A with the same eigen-\nvalue a. Assuming that each eigenvalue has a unique eigenstate (which is true if there is no degen-\neracy, but we haven\u2019t discussed degeneracy yet), the state B0 a9 must be some scalar multiple of the \nstate 0 a9. If we call this multiple b, then we can write\n \nB0 a9 = b0 a9, \n(2.94)\nwhich is just an eigenvalue equation for the operator B. Thus, we must conclude that the state 0 a9 is \nalso an eigenstate of the operator B, with the eigenvalue b. The assumption that the operators A and B \ncommute has led us to the result that A and B have common or simultaneous sets of eigenstates. This \nresult bears repeating:\nCommuting operators share common eigenstates.\nThe rami\ufb01cations of this result for experiments are very important. Recall that a measurement of \nthe observable A projects the initial state 0 c9 onto an eigenstate of A: 0 a9. A subsequent measurement \nof the observable B then projects the input state 0 a9 onto an eigenstate of B. But the eigenstates of \nthe commuting operators A and B are the same, so the second measurement does not change the state \n0 a9. Thus, another measurement of A following the measurement of B yields the same result as the \n initial measurement of A, as illustrated in Fig. 2.9. Thus we say that we can know the eigenvalues of \nthese two observables simultaneously. It is common to extend this language and say that these two \nobservables can be measured simultaneously, although, as illustrated in Fig. 2.9, we do not really measure \nthem simultaneously. What we mean is that we can measure one observable without erasing our knowl-\nedge of the previous results of the other observable. Observables A and B are said to be compatible.\n100\n0\n0\nA\nB\nA\na1\na1\na1\na2\na3\na1\na2\na3\na1\na2\na3\nb1\nb2\nb3\nFIGURE 2.9 Successive measurements of commuting observables.\n\n56 \nOperators and Measurement\nConversely, if two operators do not commute, then they are incompatible observables and cannot \nbe measured or known simultaneously. This is what we saw in Experiment 3 in Chapter 1. In that case, the \ntwo observables were Sx and Sz. Let\u2019s take a look at their commutator to show that they are not compatible:\n \n3Sz, Sx4 \u0003 U\n2\n a1\n0\n0\n-1b U\n2\n a0\n1\n1\n0b - U\n2\n a0\n1\n1\n0b U\n2\n a1\n0\n0\n-1b \n \n\u0003 a U\n2b\n2\n c a 0\n1\n-1\n0b - a0\n-1\n1\n0 bd\n \n \n\u0003 a U\n2b\n2\na 0\n2\n-2\n0b\n \n \n= i USy. \n(2.95)\nAs expected, these two operators do not commute. In fact, none of the spin component operators com-\nmute with each other. The complete commutation relations are",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 75
  },
  {
    "child_id": "16166d7f-69d9-4cf8-b7ee-b2a3f59ea557",
    "parent_id": "59103437-2f5a-49fb-a911-8837e38604f3",
    "text": "s what we saw in Experiment 3 in Chapter 1. In that case, the \ntwo observables were Sx and Sz. Let\u2019s take a look at their commutator to show that they are not compatible:\n \n3Sz, Sx4 \u0003 U\n2\n a1\n0\n0\n-1b U\n2\n a0\n1\n1\n0b - U\n2\n a0\n1\n1\n0b U\n2\n a1\n0\n0\n-1b \n \n\u0003 a U\n2b\n2\n c a 0\n1\n-1\n0b - a0\n-1\n1\n0 bd\n \n \n\u0003 a U\n2b\n2\na 0\n2\n-2\n0b\n \n \n= i USy. \n(2.95)\nAs expected, these two operators do not commute. In fact, none of the spin component operators com-\nmute with each other. The complete commutation relations are\n \n3Sx, Sy4 = i USz\n \n \n3Sy, Sz4 = i USx \n \n3Sz, Sx4 = i USy   , \n(2.96)\nso written to make the cyclic relations clear.\nWhen we represent operators as matrices, we can often decide whether two operators commute \nby inspection of the matrices. Recall the important statement: An operator is always diagonal in its \nown basis. If you are presented with two matrices that are both diagonal, they must share a common \nbasis, and so they commute with each other. To be explicit, the product of two diagonal matrices\n \nAB \u0003 \u00a7\na1\n0\n0\ng\n0\na2\n0\ng\n0\n0\na3\ng\nf\nf\nf\nf\n\u00a5  \u00a7\nb1\n0\n0\ng\n0\nb2\n0\ng\n0\n0\nb3\ng\nf\nf\nf\nf\n\u00a5 \n \n\u0003 \u00a7\na1b1\n0\n0\ng\n0\na2b2\n0\ng\n0\n0\na3b3\ng\nf\nf\nf\nf\n\u00a5 , \n(2.97)\nis clearly independent of the order of the product. Note, however, that you may not conclude that two \noperators do not commute if one is diagonal and one is not, nor if both are not diagonal.\n 2.5 \u0002 UNCERTAINTY PRINCIPLE\nThe intimate connection between the commutator of two observables and the possible precision of \nmeasurements of the two corresponding observables is re\ufb02ected in an important relation that we sim-\nply state here (see more advanced texts for a derivation). The product of the uncertainties or standard \ndeviations of two observables is related to the commutator of the two observables:\n \n\u0006A\u0006B \u00da 1\n2 083A, B49 0   . \n(2.98)",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 75
  },
  {
    "child_id": "974f87d7-3d52-4975-8e6a-298e1f92fa0e",
    "parent_id": "ece3fc14-a785-4dc3-8ca5-e238e4db211f",
    "text": "2.6 S2 Operator \n57\nThis is the uncertainty principle of quantum mechanics. Consider what it says about a simple Stern-\nGerlach experiment. The uncertainty principle for the Sx and Sy spin components is\n \n \u0006Sx\u0006Sy \u00da 1\n2 083Sx, Sy49 0  \n \n \u00da 1\n2 08i USz9 0\n \n \n \u00da U\n2 08Sz9 0 .\n \n(2.99)\nThese uncertainties are the minimal quantum mechanical uncertainties that would arise in any experi-\nment. Any experimental uncertainties due to experimenter error, apparatus errors, and statistical limi-\ntations would be additional.\nLet\u2019s now apply the uncertainty principle to Experiment 3 where we \ufb01rst learned of the impact of \nmeasurements in quantum mechanics. If the initial state is 0  +9, then a measurement of Sz results in an \nexpectation value 8Sz9 = U>2 with an uncertainty \u0006Sz = 0, as illustrated in Fig. 2.8(a). Thus the uncer-\ntainty principle dictates that the product of the other uncertainties for measurements of the 0  +9 state is\n \n\u0006Sx\u0006Sy \u00da a U\n2b\n2\n, \n(2.100)\nor simply\n \n\u0006Sx\u0006Sy \u0002 0. \n(2.101)\nThis implies that\n \n  \u0006Sx \u0002 0  \n \n \u0006Sy \u0002 0. \n(2.102)\nThe conclusion to draw from this is that while we can know one spin component absolutely (\u0006Sz = 0), \nwe can never know all three, nor even two, simultaneously. This is in agreement with our results from \nExperiment 3. This lack of ability to measure all spin components simultaneously implies that the spin \ndoes not really point in a given direction, as a classical spin or angular momentum does. So when we \nsay that we have measured \u201cspin up,\u201d we really mean only that the spin component along that axis is up, \nas opposed to down, and not that the complete spin angular momentum vector points up along that axis.\n 2.6 \u0002 S2 OPERATOR\nAnother indication that the spin does not point along the axis along which you measure the spin com-\nponent is obtained by considering a new operator that represents the magnitude of the spin vector but \nhas no information about the direction. It is common to use the square of the spin vector for this task. \nThis new operator is\n \nS2 = S2\nx + S2\ny + S2\nz , \n(2.103)\nand it is calculated in the Sz representation as\n \nS2 \u0003 a U\n2b\n2\n c a0\n1\n1\n0b a0\n1\n1\n0b + a0\n-i\ni\n0\n ba0\n-i\ni\n0\n b + a1\n0\n0\n-1ba1\n0\n0\n-1bd  \n \n\u0003 a U\n2b\n2\n c a1\n0\n0\n1b + a1\n0\n0\n1b + a1\n0\n0\n1bd  \n(2.104)\n \n\u0003 3\n4 U2 a1\n0\n0\n1b.\n\n58 \nOperators and Measurement\nThus the S2 operator is proportional to the identity operator, which means it must commute with all \nthe other operators Sx, Sy, and Sz. It also means that all states are eigenstates of the S2 operator. Thus, \nwe can write \n \nS20 c9 = 3\n4 U20 c9 \n(2.105)\nfor any state 0 c9 in the spin-1/2 system.\nFor the case of spin 1/2, note that the expectation value of the operator S2 is\n \n8S29 = 3\n4 U2, \n(2.106)\nwhich would imply that the \u201clength\u201d of the spin vector is\n \n0 S0 = 48S29 = 23 U\n2. \n(2.107)\nThis is appreciably longer than the measured component of U>2, implying that the spin vector can \nnever be fully aligned along any axis. A useful mental model of the spin vector and its compo",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 81
  },
  {
    "child_id": "c9794f78-e8af-4351-938e-141d20e7827c",
    "parent_id": "ece3fc14-a785-4dc3-8ca5-e238e4db211f",
    "text": "he S2 operator. Thus, \nwe can write \n \nS20 c9 = 3\n4 U20 c9 \n(2.105)\nfor any state 0 c9 in the spin-1/2 system.\nFor the case of spin 1/2, note that the expectation value of the operator S2 is\n \n8S29 = 3\n4 U2, \n(2.106)\nwhich would imply that the \u201clength\u201d of the spin vector is\n \n0 S0 = 48S29 = 23 U\n2. \n(2.107)\nThis is appreciably longer than the measured component of U>2, implying that the spin vector can \nnever be fully aligned along any axis. A useful mental model of the spin vector and its component is \nshown in Fig. 2.10. In this vector model, one can imagine the total spin vector S precessing around the \nz-axis at a constant angle to form a cone, with a constant spin component Sz. For a spin-1/2 system in \nthe \u201cspin up\u201d state 0  +9, this classical model yields the same expectation values and uncertainties as the \nquantum model (Problem 2.9)\n \n 8Sz9 = U\n2   \u0006Sz = 0  \n \n 8Sx9 = 0   \u0006Sx \u0002 0  \n \n 8Sy9 = 0   \u0006Sy \u0002 0. \n(2.108)\nS\nz\ny\nx\n(a)\nS\n(b)\nz\n\u0002\n2\n\u221a3\u0002\n2\n\u0002\u0002\n2\n\u0002\n2\n\u221a3\u0002\n2\n\u0002\u0002\n2\nFIGURE 2.10 (a) Vector model illustrating the classical precision of a spin vector and the allowed \nquantum mechanical components. (b) Two-dimensional version of the vector model with constant spin \nvector length and two possible components.\n\n2.7 Spin-1 System \n59\n?\n?\n?\n0\n1\n0\n1\nZ\nFIGURE 2.11 Spin-1 Stern-Gerlach experiment.\nHowever, a quantum mechanical experiment on a spin component eigenstate does not yield the time \ndependence of the precession implied by the picture in Fig. 2.10(a). Rather, the quantum mechanical \nspin vector is more accurately thought of as smeared out over the whole cone in a uniform random sense. \nThis randomness is often termed quantum fuzziness and will be evident in other systems we will study \nlater. To avoid the inaccurate precession part of the vector model, it is often illustrated as in Fig. 2.10(b).\n 2.7 \u0002 SPIN-1 SYSTEM\nThe Stern-Gerlach experiment depicted in Fig. 1.1 can be performed on a variety of atoms or par-\nticles. Such experiments always result in a \ufb01nite number of discrete beams exiting the analyzer. For \nspin-1/2 particles, there are two output beams. For the case of three output beams, the de\ufb02ections are \nconsistent with magnetic moments arising from spin angular momentum components of 1U, 0 U, and \n-1U. For an analyzer aligned along the z-axis, the three output states are labeled 0 19, 0 09, and 0  -19, \nas shown in Fig. 2.11. This is what we call a spin-1 system. (Note that the SPINS software and our \nStern-Gerlach schematics use arrows for the 0 19 and 0  -19 output beams, but these outputs are not the \nsame as the spin-1/2 states that are also denoted with arrows.)\nThe three eigenvalue equations for the spin component operator Sz of a spin-1 system are\n \n Sz0 19 = U0 19\n \n \n Sz0 09 = 0 U0 09\n \n \n Sz0  -19 = -U0  -19. \n(2.109)\nAs we did in the spin-1/2 case, we choose the Sz basis as the standard basis in which to express kets \nand operators using matrix representation. In Section 2.1, we found that eigenvectors are unit vectors \nin",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 81
  },
  {
    "child_id": "c5435a61-3f59-4565-b332-9ea250e8ea5f",
    "parent_id": "ece3fc14-a785-4dc3-8ca5-e238e4db211f",
    "text": "e 0 19 and 0  -19 output beams, but these outputs are not the \nsame as the spin-1/2 states that are also denoted with arrows.)\nThe three eigenvalue equations for the spin component operator Sz of a spin-1 system are\n \n Sz0 19 = U0 19\n \n \n Sz0 09 = 0 U0 09\n \n \n Sz0  -19 = -U0  -19. \n(2.109)\nAs we did in the spin-1/2 case, we choose the Sz basis as the standard basis in which to express kets \nand operators using matrix representation. In Section 2.1, we found that eigenvectors are unit vectors \nin their own basis and an operator is always diagonal in its own basis. Using the \ufb01rst rule, we can \nimmediately write down the eigenvectors of the Sz operator:\n \n0 19 \u0003 \u00b0\n1\n0\n0\n\u00a2  0 09 \u0003 \u00b0\n0\n1\n0\n\u00a2  0  -19 \u0003 \u00b0\n0\n0\n1\n\u00a2 , \n(2.110)\nwhere we again use the convention that the ordering of the rows follows the eigenvalues in descending \norder. Using the second rule, we write down the Sz operator\n \nSz \u0003 \u00b0\n1U\n0\n0\n0\n0 U\n0\n0\n0\n-1U\n\u00a2 = U \u00b0\n1\n0\n0\n0\n0\n0\n0\n0\n-1\n\u00a2 \n(2.111)\nwith the eigenvalues 1U, 0 U, and -1U ordered along the diagonal. The value zero is a perfectly valid \neigenvalue in some systems.\n\n60 \nOperators and Measurement\nThe same four experiments performed on the spin-1/2 system can be performed on a spin-1 sys-\ntem. Conceptually the results are the same. One important difference occurs in Experiment 2, where a \nmeasurement of Sz is \ufb01rst performed to prepare a particular state, and then a subsequent measurement \nof Sx (or Sy) is performed. Based upon the results of the spin-1/2 experiment, one might expect each of \nthe possible components to have one-third probability. Such is not the case. Rather, one set of results is\n \n P1x = 0 x810 19 0\n2 = 1\n4\n \n \n P0x = 0 x800 19 0\n2 = 1\n2\n \n \n P-1x = 0 x8-10 19 0\n2 = 1\n4, \n(2.112)\nas illustrated in Fig. 2.12. These experimental results can be used to determine the Sx eigenstates in \nterms of the Sz basis\n \n 0 19x = 1\n2@ 19 +\n1\n12@ 09 + 1\n2 @ -19\n \n \n 0 09x =\n1\n12@ 19 -\n1\n12@  -19\n \n \n 0  -19x = 1\n2@ 19 -\n1\n12@ 09 + 1\n2@  -19. \n(2.113)\nLikewise, we can \ufb01nd the Sy eigenstates:\n \n 0 19y = 1\n2@ 19 + i 1\n12@ 09 - 1\n2@  -19\n \n \n 0 09y =\n1\n12@ 19 +\n1\n12@  -19\n \n \n 0  -19y = 1\n2@ 19 - i 1\n12@ 09 - 1\n2@  -19. \n(2.114)\nThe matrix representations of the Sx and Sy operators are\n \nSx \u0003\nU\n12\n \u00b0\n0\n1\n0\n1\n0\n1\n0\n1\n0\n\u00a2  Sy \u0003\nU\n12\n \u00b0\n0\n-i\n0\ni\n0\n-i\n0\ni\n0\n\u00a2 . \n(2.115)\n25\n25\nX\n0\n50\nZ\n0\n1\n1 x\n0 x\n1 x\nFIGURE 2.12 Experiment 2 in the spin-1 case.\n\n2.7 Spin-1 System \n61\n0\nP\nP\u22121\nP1\nP0\n1\nSz\n\u03a8in\n(2 1\ni 0\ni\n1 )\n\u221a6\n1\nFIGURE 2.13 Histogram of measurements of z-component of spin for spin-1 particle.\nExample 2.3 A spin-1 system is prepared in the state\n \n0 cin9 =\n2\n16 0 19 -\ni\n16 0 09 +\ni\n16 0  -19. \n(2.116)\nFind the probabilities of measuring each of the possible spin components along the z-axis.\nThe probability of measuring Sz = +1U is\n \n P1 = 0810 cin90\n2\n \n \n = @810C 2\n16 0 19 -\ni\n16 0 09 +\ni\n16 0  -19D@\n2\n \n \n = @ 2\n16 810 19 -\ni\n16810 09 +\ni\n16 810  -19@\n2\n \n \n = @ 2\n16\n @\n2\n= 2\n3.\n \n(2.117)\nThe probability of measuring Sz = 0 U is\n \n P0 = 0800 cin90\n",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 81
  },
  {
    "child_id": "41c29e02-cd17-41a6-b26e-3a37d0467979",
    "parent_id": "ece3fc14-a785-4dc3-8ca5-e238e4db211f",
    "text": "onent of spin for spin-1 particle.\nExample 2.3 A spin-1 system is prepared in the state\n \n0 cin9 =\n2\n16 0 19 -\ni\n16 0 09 +\ni\n16 0  -19. \n(2.116)\nFind the probabilities of measuring each of the possible spin components along the z-axis.\nThe probability of measuring Sz = +1U is\n \n P1 = 0810 cin90\n2\n \n \n = @810C 2\n16 0 19 -\ni\n16 0 09 +\ni\n16 0  -19D@\n2\n \n \n = @ 2\n16 810 19 -\ni\n16810 09 +\ni\n16 810  -19@\n2\n \n \n = @ 2\n16\n @\n2\n= 2\n3.\n \n(2.117)\nThe probability of measuring Sz = 0 U is\n \n P0 = 0800 cin90\n2\n \n \n = @800C 2\n16 0 19 -\ni\n16 0 09 +\ni\n16 0  -19D@\n2\n \n \n = @ -i\n16\n @\n2\n= 1\n6.\n \n(2.118)\nThe probability of measuring Sz = -1U is\n \n P-1 = 08-10 cin90\n2\n \n \n = @8-10C 2\n16 0 19 -\ni\n16 0 09 +\ni\n16 0  -19D@\n2\n \n \n = @ i\n16\n @\n2\n= 1\n6.\n \n(2.119)\nThe three probabilities add to unity, as they must. A histogram of the predicted measurement results \nis shown in Fig. 2.13.\n\n62 \nOperators and Measurement\nTo generalize to other possible spin systems, we need to introduce new labels. We use the label \ns to denote the spin of the system, such as spin 1/2, spin 1, spin 3/2. The number of beams exiting a \nStern-Gerlach analyzer is 2s + 1. In each of these cases, a measurement of a spin component along \nany axis yields results ranging from a maximum value of s U to a minimum value of -s U, in unit steps \nof the value U. We denote the possible values of the spin component along the z-axis by the label m, \nthe integer or half-integer multiplying U. A quantum state with speci\ufb01c values of s and m is denoted as \n0 sm9, yielding the eigenvalue equations\n \n S20 sm9 = s(s + 1) U20 sm9 \n \n Sz0 sm9 = m U0 sm9.\n \n \n(2.120)\nThe label s is referred to as the spin angular momentum quantum number or the spin quantum \nnumber for short. The label m is referred to as the spin component quantum number or the mag-\nnetic quantum number because of its role in magnetic \ufb01eld experiments like the Stern-Gerlach \nexperiment. The connection between this new 0 sm9 notation and the spin-1/2 0{9 notation is\n \n @ 1\n2 1\n29 = 0  +9  \n \n @ 1\n2, -1\n29 = 0  -9. \n(2.121)\nFor the spin-1 case, the connection to this new notation is\n \n 0 119 = 0 19\n \n \n 0 109 = 0 09\n \n \n 0 1, -19 = 0  -19. \n(2.122)\nWe will continue to use the 0{9 notation, but we will \ufb01nd the new notation useful later (Chapter 7).\n 2.8 \u0002 GENERAL QUANTUM SYSTEMS\nLet\u2019s extend the important results of this chapter to general quantum mechanical systems. For a gen-\neral observable A with quantized measurement results an, the eigenvalue equation is\n \nA0 an9 = an0 an9. \n(2.123)\nIn the basis formed by the eigenstates 0 an9, the operator A is represented by a matrix with the eigen-\nvalues along the diagonal\n \nA \u0003 \u00a7\na1\n0\n0\ng\n0\na2\n0\ng\n0\n0\na3\ng\nf\nf\nf\nf\n\u00a5 , \n(2.124)\nwhose size depends on the dimensionality of the system. In this same basis, the eigenstates are repre-\nsented by the column vectors\n \n0 a19 \u0003 \u00a7\n1\n0\n0\nf\n\u00a5 , 0 a29 \u0003 \u00a7\n0\n1\n0\nf\n\u00a5 , 0 a39 \u0003 \u00a7\n0\n0\n1\nf\n\u00a5 , ... . \n(2.125)",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 81
  },
  {
    "child_id": "eb3528c7-5472-44b6-aab0-f42a1e23a7ed",
    "parent_id": "bc15bbb5-6be8-4fcb-8c2a-9e782489449f",
    "text": "Summary \n63\nThe projection operators corresponding to measurement of the eigenvalues an are \n \nPan = 0 an98an0 . \n(2.126)\nThe completeness of the basis states is expressed by saying that the sum of the projection operators is \nthe identity operator\n \na\nn\nPan = a\nn\n0 an98an0 = 1. \n(2.127)\nSUMMARY\nIn this chapter we have extended the mathematical description of quantum mechanics by using \noperators to represent physical observables. The only possible results of measurements are the \neigenvalues of operators. The eigenvectors of the operator are the basis states corresponding to each \npossible eigenvalue. We \ufb01nd the eigenvalues and eigenvectors by diagonalizing the matrix representing \nthe operator, which allows us to predict the results of measurements. The eigenvalue equations for the \nspin-1/2 component operator Sz are\n \n Sz0  +9 = +  U\n2 0  +9 \n \n Sz0  -9 = -  U\n2 0  -9. \n(2.128)\nThe matrices representing the spin-1/2 operators are\n \n Sx \u0003 U\n2\n a0\n1\n1\n0b\n \n Sy \u0003 U\n2\n a0\n-i\ni\n0 b  \n \n Sz \u0003 U\n2\n a1\n0\n0\n-1b  \n S2 \u0003 3U2\n4\n a1\n0\n0\n1b. \n(2.129)\nWe characterized quantum mechanical measurements of an observable A by the expectation value\n \n8A9 = 8c0 A0 c9 = a\nn\nanPan \n(2.130)\nand the uncertainty\n \n\u0006A = 48A29 - 8A92. \n(2.131)\nWe made a connection between the commutator [A, B] = AB - BA of two operators and the \nability to measure the two observables. If two operators commute, then we can measure both observ-\nables simultaneously, but if they do not commute, then we cannot measure them simultaneously. \nWe quanti\ufb01ed this disturbance that measurement in\ufb02icts on quantum systems through the quantum \nmechanical uncertainty principle\n \n\u0006A\u0006B \u00da 1\n2@83A, B49@ . \n(2.132)\nWe also introduced the projection postulate, which states how the quantum state vector is changed \nafter a measurement.\n\n64 \nOperators and Measurement\nPROBLEMS\n 2.1 Given the following information:\n \n Sx0{9x = { U\n2 0{9x\n \n Sy0{9y = { U\n2 0{9y\n \n 0{9x =\n1\n12 30  +9 { 0  -94  \n 0{9y =\n1\n12 30  +9 { i0  -94\n \n \ufb01nd the matrix representations of Sx and Sy in the Sz basis.\n 2.2 From the previous problem we know that the matrix representation of Sx in the Sz basis is\nSx \u0003 U\n2\n a0\n1\n1\n0b.\n \n Diagonalize this matrix to \ufb01nd the eigenvalues and the eigenvectors of Sx.\n 2.3 Find the matrix representation of Sz in the Sx basis for spin 1/2. Diagonalize this matrix to \ufb01nd \nthe eigenvalues and the eigenvectors in this basis. Show that the eigenvalue equations for Sz are \nsatis\ufb01ed in this new representation.\n 2.4 Show by explicit matrix calculation that the matrix elements of a general operator A (within a \nspin-1/2 system) are as shown in Eq. (2.13).\n 2.5 Calculate the commutators of the spin-1/2 operators Sx, Sy, and Sz, thus verifying Eqs. (2.96).\n 2.6 Verify that the spin component operator Sn along the direction nn has the matrix representation \nshown in Eq. (2.41).\n 2.7 Diagonalize the spin component operator Sn along the direction nn to \ufb01nd its eigenvalues and \nthe eigenvectors.\n 2.8 Find the probabilities",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 87
  },
  {
    "child_id": "1dbfe749-3e81-4bcf-aef5-09be4e0e9ea7",
    "parent_id": "bc15bbb5-6be8-4fcb-8c2a-9e782489449f",
    "text": "xplicit matrix calculation that the matrix elements of a general operator A (within a \nspin-1/2 system) are as shown in Eq. (2.13).\n 2.5 Calculate the commutators of the spin-1/2 operators Sx, Sy, and Sz, thus verifying Eqs. (2.96).\n 2.6 Verify that the spin component operator Sn along the direction nn has the matrix representation \nshown in Eq. (2.41).\n 2.7 Diagonalize the spin component operator Sn along the direction nn to \ufb01nd its eigenvalues and \nthe eigenvectors.\n 2.8 Find the probabilities of the measurements shown below in Fig. 2.14. The \ufb01rst Stern-Gerlach \nanalyzer is aligned along the direction nn de\ufb01ned by the angles u = p>4 and f = 5p>3.\n 2.9 For the state 0 +9, calculate the expectation values and uncertainties for measurements of Sx, Sy, \nand Sz in order to verify Eq. (2.108).\n 2.10 For the state 0 +9y, calculate the expectation values and uncertainties for measurements of Sx, \nSy, and Sz. Draw a diagram of the vector model applied to this state and reconcile your quan-\ntum mechanical calculations with the classical results.\n 2.11 Show that the S2 operator commutes with each of the spin component operators of Sx, Sy, and \nSz. Do this once with matrix notation for a spin-1/2 system and a second time using only the \ncomponent commutation relations in Eqs. (2.96) and the de\ufb01nition of S2 in Eq. (2.103).\nY\n?\n?\nP\u0002y\nP\u0003y\n^n\nFIGURE 2.14 Measurement of spin components (Prob. 2.8).\n\n2.12 Diagonalize the Sx and Sy operators in the spin-1 case to \ufb01nd the eigenvalues and the eigenvec-\ntors of both operators.\n 2.13 For a spin-1 system, show by explicit matrix calculation that the spin component operators \nobey the commutation relations in Eqs. (2.96).\n 2.14 Find the matrix representation of the S2 operator for a spin-1 system. Do this once by explicit \nmatrix calculation and a second time by inspection of the S2 eigenvalue equation (2.120).\n 2.15 A beam of spin-1 particles is prepared in the state\n0 c9 =\n2\n129 0 19 + i 3\n129 0 09 -\n4\n129 0  -19.\na) What are the possible results of a measurement of the spin component Sz, and with what \nprobabilities would they occur?\nb) What are the possible results of a measurement of the spin component Sx, and with what \nprobabilities would they occur?\nc) Plot histograms of the predicted measurement results from parts (a) and (b), and calculate \nthe expectation values for both measurements.\n 2.16 A beam of spin-1 particles is prepared in the state\n0 c9 =\n2\n129 0 19y + i 3\n129 0 09y -\n4\n129 0  -19y.\na) What are the possible results of a measurement of the spin component Sz, and with what \nprobabilities would they occur?\nb) What are the possible results of a measurement of the spin component Sy, and with what \nprobabilities would they occur?\nc) Plot histograms of the predicted measurement results from parts (a) and (b), and calculate \nthe expectation values for both measurements.\n 2.17 A spin-1 particle is in the state\n0 c9 \u0003\n1\n130\n \u00b0\n1\n2\n5i\n\u00a2 .\na) What are the possible results of a measurement of the spin component",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 87
  },
  {
    "child_id": "809908ce-8caa-4f9f-8f04-5496251f9f38",
    "parent_id": "bc15bbb5-6be8-4fcb-8c2a-9e782489449f",
    "text": "results of a measurement of the spin component Sz, and with what \nprobabilities would they occur?\nb) What are the possible results of a measurement of the spin component Sy, and with what \nprobabilities would they occur?\nc) Plot histograms of the predicted measurement results from parts (a) and (b), and calculate \nthe expectation values for both measurements.\n 2.17 A spin-1 particle is in the state\n0 c9 \u0003\n1\n130\n \u00b0\n1\n2\n5i\n\u00a2 .\na) What are the possible results of a measurement of the spin component Sz, and with what \nprobabilities would they occur? Calculate the expectation value of the spin component Sz.\nb) Calculate the expectation value of the spin component Sx. Suggestion: Use matrix mechan-\nics to evaluate the expectation value.\n 2.18 A spin-1 particle is prepared in the state\n0 c9 =\n1\n114 0 19 -\n3\n114 0 09 + i 2\n114 0  -19.\na) What are the possible results of a measurement of the spin component Sz, and with what \nprobabilities would they occur?\nb) Suppose that the Sz measurement on the particle yields the result Sz = -U. Subsequent to \nthat result a second measurement is performed to measure the spin component Sx. What are \nthe possible results of that measurement, and with what probabilities would they occur?\nc) Draw a schematic diagram depicting the successive measurements in parts (a) and (b).\nProblems \n65\n\n66 \nOperators and Measurement\n 2.19 A spin-1 particle is prepared in the state\n0 ci9 = 4\n1\n6 0 19 - 4\n2\n6 0 09 + i 4\n3\n6 0  -19.\n \n Find the probability that the system is measured to be in the \ufb01nal state\n0 cf9 = 1+i\n17 0 19y +\n2\n17 0 09y - i 1\n17 0  -19y.\n 2.20 In part (2) of SPINS Lab #3, you measured the spin components of the unknown (spin 1) ini-\ntial states 0 ci9 (i \u0003 1, 2, 3, 4) along the three axes. Using your measured values, deduce the \nunknown initial states.\n 2.21 In part (3) of SPINS Lab #3, you built a spin-1 interferometer and measured the relative prob-\nabilities after the \ufb01nal Stern-Gerlach analyzer for the seven possible cases where one beam, \na pair of beams, or all three beams from the second Stern-Gerlach analyzer were used. Show \nhow you used the projection postulate to calculate the theoretical probabilities.\n 2.22 A beam of spin-1/2 particles is sent through a series of three Stern-Gerlach analyzers, as shown \nin Fig. 2.15. The second Stern-Gerlach analyzer is aligned along the nn direction, which makes \nan angle \u0007 in the x-z plane with respect to the z-axis.\na) Find the probability that particles transmitted through the \ufb01rst Stern-Gerlach analyzer are \nmeasured to have spin down at the third Stern-Gerlach analyzer?\nb) How must the angle \u0007 of the second Stern-Gerlach analyzer be oriented so as to maximize \nthe probability that particles are measured to have spin down at the third Stern-Gerlach \nanalyzer? What is this maximum fraction?\nc) What is the probability that particles have spin down at the third Stern-Gerlach analyzer if \nthe second Stern-Gerlach analyzer is removed from the experiment?\n 2.23 Consider a th",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 87
  },
  {
    "child_id": "ae2f8b76-059a-4ba0-9ba2-f407c5a219e6",
    "parent_id": "bc15bbb5-6be8-4fcb-8c2a-9e782489449f",
    "text": "st Stern-Gerlach analyzer are \nmeasured to have spin down at the third Stern-Gerlach analyzer?\nb) How must the angle \u0007 of the second Stern-Gerlach analyzer be oriented so as to maximize \nthe probability that particles are measured to have spin down at the third Stern-Gerlach \nanalyzer? What is this maximum fraction?\nc) What is the probability that particles have spin down at the third Stern-Gerlach analyzer if \nthe second Stern-Gerlach analyzer is removed from the experiment?\n 2.23 Consider a three-dimensional ket space. In the basis de\ufb01ned by three orthogonal kets 0 19, 0 29, \nand 0 39, the operators A and B are represented by\n \nA \u0003 \u00b0\na1\n0\n0\n0\na2\n0\n0\n0\na3\n \u00a2  B \u0003 \u00b0\nb1\n0\n0\n0\n0\nb2\n0\nb2\n0\n\u00a2 ,\n \n where all the quantities are real.\na) Do the operators A and B commute?\nb) Find the eigenvalues and normalized eigenvectors of both operators.\nZ\n?\n?\n^n\nZ\nFIGURE 2.15 Measurement of spin components (Prob. 2.22).\n\nResources \n67\nc) Assume the system is initially in the state 0 29. Then the observable corresponding to the oper-\nator B is measured. What are the possible results of this measurement and the probabilities of \neach result? After this measurement, the observable corresponding to the operator A is mea-\nsured. What are the possible results of this measurement and the probabilities of each result?\nd) How are questions (a) and (c) above related?\n 2.24 If a beam of spin-3/2 particles is input to a Stern-Gerlach analyzer, there are four output beams \nwhose de\ufb02ections are consistent with magnetic moments arising from spin angular momentum \ncomponents of 3\n2 U, 1\n2 U, -  1\n2 U, and -  3\n2 U. For a spin-3/2 system:\na) Write down the eigenvalue equations for the Sz operator.\nb) Write down the matrix representation of the Sz eigenstates.\nc) Write down the matrix representation of the Sz operator.\nd) Write down the eigenvalue equations for the S2 operator.\ne) Write down the matrix representation of the S2 operator.\n 2.25 Are the projection operators P+ and P- Hermitian? Explain.\nRESOURCES\nActivities\nThis activity is available at\nwww.physics.oregonstate.edu/qmactivities\nSpins Lab 3: Stern-Gerlach measurements of a spin-1 system.\n\nC H A P T E R \n3\nSchr\u00f6dinger Time Evolution\nThis chapter marks our \ufb01nal step in developing the mathematical basis of a quantum theory. In \n Chapter 1, we learned how to use kets to describe quantum states and how to predict the probabili-\nties of results of measurements. In Chapter 2, we learned how to use operators to represent physical \nobservables and how to determine the possible measurement results. The key missing aspect is the \nability to predict the future. Physics theories are judged on their predictive power. Classical mechan-\nics relies on Newton\u2019s second law F = ma to predict the future of a particle\u2019s motion. The ability to \npredict the quantum future started with Erwin Schr\u00f6dinger and bears his name.\n3.1 \u0002 SCHR\u00d6DINGER EQUATION\nThe sixth postulate of quantum mechanics says that the time evolution of a quantum system is \n gov",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 87
  },
  {
    "child_id": "86b3f815-b29b-47cc-8c4f-5a201e0285b3",
    "parent_id": "bc15bbb5-6be8-4fcb-8c2a-9e782489449f",
    "text": "les and how to determine the possible measurement results. The key missing aspect is the \nability to predict the future. Physics theories are judged on their predictive power. Classical mechan-\nics relies on Newton\u2019s second law F = ma to predict the future of a particle\u2019s motion. The ability to \npredict the quantum future started with Erwin Schr\u00f6dinger and bears his name.\n3.1 \u0002 SCHR\u00d6DINGER EQUATION\nThe sixth postulate of quantum mechanics says that the time evolution of a quantum system is \n governed by the differential equation\n \niU d\ndt\n 0  c 1t29 = H 1t2 0  c 1t29, \n(3.1)\nwhere the operator H corresponds to the total energy of the system and is called the Hamiltonian \noperator of the system because it is derived from the classical Hamiltonian. This equation is known as \nthe Schr\u00f6dinger equation.\nPostulate 6\nThe time evolution of a quantum system is determined by the  Hamiltonian \nor total energy operator H1t2 through the Schr\u00f6dinger equation\niU d\ndt\n 0  c 1t29 = H 1t2 0  c 1t29.\nThe Hamiltonian is a new operator, but we can use the same ideas we developed in Chapter 2 to \nunderstand its basic properties. The Hamiltonian H is an observable, so it is a Hermitian operator. The \neigenvalues of the Hamiltonian are the allowed energies of the quantum system, and the eigenstates \nof H are the energy eigenstates of the system. If we label the allowed energies as En, then the energy \neigenvalue equation is\n \nH 0 En9 = En0 En9 . \n(3.2)",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 87
  },
  {
    "child_id": "cde5ac91-4cd7-4543-a9b0-da743a8b2e16",
    "parent_id": "be2003dc-de63-4f4e-9c71-3540860515c2",
    "text": "3.1 Schr\u00f6dinger Equation \n69\nIf we have the Hamiltonian H in a matrix representation, then we diagonalize the matrix to \ufb01nd the \neigenvalues En and the eigenvectors 0 En9 just as we did with the spin operators in Chapter 2. For the \nmoment, let\u2019s assume that we have already diagonalized the Hamiltonian [i.e., solved Eq. (3.2)] so that \nwe know the eigenvalues En and the eigenvectors 0 En9, and let\u2019s see what we can learn about quantum \ntime evolution in general by solving the Schr\u00f6dinger equation.\nThe eigenvectors of the Hamiltonian form a complete basis because the Hamiltonian is an observ-\nable, and therefore a Hermitian operator. Because H is the only operator appearing in the Schr\u00f6dinger \nequation, it would seem reasonable (and will prove invaluable) to consider the energy eigenstates as \nthe basis of choice for expanding general state vectors:\n \n0 c 1t29 = a\nn\ncn1t2 0 En9. \n(3.3)\nThe basis of eigenvectors of the Hamiltonian is also orthonormal, so\n \n8Ek\u0004 En9 = dkn. \n(3.4)\nWe refer to this basis as the energy basis.\nFor now, we assume that the Hamiltonian is time independent (we will do the time-dependent case \nH(t) in Section 3.4). The eigenvectors of a time-independent Hamiltonian come from the diagonaliza-\ntion procedure we used in Chapter 2, so there is no reason to expect the eigenvectors themselves to \ncarry any time dependence. Thus if a general state 0 c9 is to be time dependent, as the Schr\u00f6dinger equa-\ntion implies, then the time dependence must reside in the expansion coef\ufb01cients cn1t2, as expressed in \nEq. (3.3). Substitute this general state into the Schr\u00f6dinger equation (3.1)\n \niU d\ndt a\nn\ncn1t2 0 En9 = Ha\nn\ncn1t2 0 En9 \n(3.5)\nand use the energy eigenvalue equation (3.2) to obtain\n \niUa\nn\ndcn1t2\ndt\n0 En9 = a\nn\ncn1t2En0 En9. \n(3.6)\nEach side of this equation is a sum over all the energy states of the system. To simplify this equation, \nwe isolate single terms in these two sums by taking the inner product of the ket on each side with one \nparticular ket 0 Ek9 (this ket can have any label k, but must not have the label n that is already used in \nthe summation). The orthonormality condition 8Ek\u0004En9 = dkn then collapses the sums:\n \n 8Ek0 iUa\nn\ndcn1t2\ndt\n0 En9 = 8Ek0 a\nn\ncn1t2En0 En9 \n \n iUa\nn\ndcn1t2\ndt\n 8Ek0 En9 = a\nn\ncn1t2En8Ek0 En9  \n \n iUa\nn\ndcn1t2\ndt\n  dkn = a\nn\ncn1t2Endkn\n \n \n iU \ndck1t2\ndt\n= ck1t2Ek.\n \n(3.7)\nWe are left with a single differential equation for each of the possible energy states of the systems \nk = 1, 2, 3, ... . This \ufb01rst-order differential equation can be rewritten as\n \ndck1t2\ndt\n= -i Ek\nU\n ck1t2. \n(3.8)\n\n70 \nSchr\u00f6dinger Time Evolution\nThe solution to Eq. (3.8) is a complex exponential\n \nck1t2 = ck102e-iEkt>U. \n(3.9)\nIn Eq. (3.9), we have denoted the initial condition as ck102, but we denote it simply as ck hereafter. \nEach coef\ufb01cient in the energy basis expansion of the state obeys the same form of the time dependence \nin Eq. (3.9), but with a different exponent due to the different energies. The time-dependen",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 93
  },
  {
    "child_id": "124b0820-d58d-4939-b2fe-4f5e6bfa3b7f",
    "parent_id": "be2003dc-de63-4f4e-9c71-3540860515c2",
    "text": "-order differential equation can be rewritten as\n \ndck1t2\ndt\n= -i Ek\nU\n ck1t2. \n(3.8)\n\n70 \nSchr\u00f6dinger Time Evolution\nThe solution to Eq. (3.8) is a complex exponential\n \nck1t2 = ck102e-iEkt>U. \n(3.9)\nIn Eq. (3.9), we have denoted the initial condition as ck102, but we denote it simply as ck hereafter. \nEach coef\ufb01cient in the energy basis expansion of the state obeys the same form of the time dependence \nin Eq. (3.9), but with a different exponent due to the different energies. The time-dependent solution \nfor the full state vector is summarized by saying that if the initial state of the system at time t \u0003 0 is\n \n0 c1029 = a\nn\ncn0 En9, \n(3.10)\nthen the time evolution of this state under the action of the time-independent Hamiltonian H is\n \n0 c1t29 = a\nn\ncne-iEnt>U0 En9  . \n(3.11)\nSo the time dependence of the original state vector is found by multiplying each energy eigenstate \ncoef\ufb01cient by its own phase factor e-iEnt>U that depends on the energy of that eigenstate. Note that the \nfactor E>U is an angular frequency, so that the time dependence is of the form e-ivt, a form commonly \nfound in many areas of physics. It is important to remember that one must use the energy eigenstates for \nthe expansion in Eq. (3.10) in order to use the simple phase factor multiplication in Eq. (3.11) to account \nfor the Schr\u00f6dinger time evolution of the state. This key role of the energy basis accounts for the impor-\ntance of the Hamiltonian operator and for the common practice of \ufb01nding the energy eigenstates to use \nas the preferred basis.\nA few examples help to illustrate some of the important consequences of this time evolution of \nthe quantum mechanical state vector. First, consider the simplest possible situation where the system \nis initially in one particular energy eigenstate:\n \n0 c1029 = 0 E19, \n(3.12)\nfor example. The prescription for time evolution tells us that after some time t the system is in the state\n \n0 c1t29 = e-iE1t>U0 E19. \n(3.13)\nBut this state differs from the original state only by an overall phase factor, which we have said before \ndoes not affect any measurements (Problem 1.3). For example, if we measure an observable A, then \nthe probability of measuring an eigenvalue aj is given by\n \n Paj = 08aj0 c1t290\n2\n \n \n = 08aj0 e-iE1t>U0 E190\n2 \n \n = 08aj0 E190\n2.\n \n(3.14)\nThis probability is time independent and is equal to the probability at the initial time. Thus, we \n conclude that there is no measureable time evolution for this state. Hence, the energy eigenstates are \ncalled stationary states. If a system begins in an energy eigenstate, then it remains in that state.\nNow consider an initial state that is a superposition of two energy eigenstates:\n \n0 c1029 = c10 E19 + c20 E29. \n(3.15)\nIn this case, time evolution takes the initial state to the later state\n \n0 c1t29 = c1e-iE1t>U0 E19 + c2e-iE2t>U0 E29. \n(3.16)\n\n3.1 Schr\u00f6dinger Equation \n71\nA measurement of the system energy at the time t would yield the value E1 with a probability\n \n PE1 = 0",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 93
  },
  {
    "child_id": "096a357c-ef98-4993-b39b-1938b9e04ccc",
    "parent_id": "be2003dc-de63-4f4e-9c71-3540860515c2",
    "text": "y eigenstates are \ncalled stationary states. If a system begins in an energy eigenstate, then it remains in that state.\nNow consider an initial state that is a superposition of two energy eigenstates:\n \n0 c1029 = c10 E19 + c20 E29. \n(3.15)\nIn this case, time evolution takes the initial state to the later state\n \n0 c1t29 = c1e-iE1t>U0 E19 + c2e-iE2t>U0 E29. \n(3.16)\n\n3.1 Schr\u00f6dinger Equation \n71\nA measurement of the system energy at the time t would yield the value E1 with a probability\n \n PE1 = 08E10 c1t290\n2\n \n \n = 08E103c1e-iE1t>U0 E19 + c2e-iE2t>U0 E294 0\n2 \n \n = 0 c10\n2,\n \n(3.17)\nwhich is independent of time. The same is true for the probability of measuring the energy E2. Thus, \nthe probabilities of measuring the energies are stationary, as they were in the \ufb01rst example.\nHowever, now consider what happens if another observable is measured on this system in this \nsuperposition state. There are two distinct situations: (1) If the other observable A commutes with the \nHamiltonian H, then A and H have common eigenstates. In this case, measuring A is equivalent to mea-\nsuring H because the inner products used to calculate the probabilities use the same eigenstates. Hence, \nthe probability of measuring any particular eigenvalue of A is time independent, as in Eq. (3.17). (2) If \nA and H do not commute, then they do not share common eigenstates. In this case, the eigenstates of A \nin general consist of superpositions of energy eigenstates. For example, suppose that the eigenstate of \nA corresponding to the eigenvalue a1 were\n \n0 a19 = a10 E19 + a20 E29. \n(3.18)\nThen the probability of measuring the eigenvalue a1 would be\n \n Pa1 = 08a10 c1t290\n2\n \n \n = 03a*\n18E10 + a*\n28E2043c1e-iE1t>U0 E19 + c2e-iE2t>U0 E294 0\n2 \n \n = @ a*\n1c1e-iE1t>U + a*\n2c2e-iE2t>U@\n2.\n \n(3.19)\nFactoring out the common phase gives\n \n Pa1 = @ e-iE1t>U@\n2\n @ a*\n1c1 + a*\n2c2e-i1E2-E12t>U@\n2\n \n \n = 0 a10\n20 c10\n2 + 0 a20\n20 c20\n2 + 2Re1a1c*\n1a*\n2c2e-i1E2-E12t>U2. \n(3.20)\nThe different time-evolution phases of the two components of 0 c1t29 lead to a time dependence in the \nprobability. The overall phase in Eq. (3.20) drops out, and only the relative phase remains in the prob-\nability calculation. Hence, the time dependence is determined by the difference of the energies of the \ntwo states involved in the superposition. The corresponding angular frequency of the time evolution\n \nv 21 = E2 - E1\nU\n \n(3.21)\nis called the Bohr frequency.\nTo summarize, we list below a recipe for solving a standard time-dependent quantum mechanics \nproblem with a time-independent Hamiltonian.\nGiven a Hamiltonian H and an initial state 0 c1029, what is the probability that \nthe eigenvalue aj of the observable A is measured at time t?\n 1. Diagonalize H (\ufb01nd the eigenvalues En and eigenvectors 0 En92.\n 2. Write 0 c1029 in terms of the energy eigenstates 0 En9.\n 3. Multiply each eigenstate coef\ufb01cient by e-iEnt>U to get 0 c1t29.\n 4. Calculate the probability Paj = 08aj0 c1t290\n2.\n\n72 \nSchr\u00f6dinger Time Evolution\n3",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 93
  },
  {
    "child_id": "406d31f8-00e8-4fda-ba97-ffe6f2ab852f",
    "parent_id": "be2003dc-de63-4f4e-9c71-3540860515c2",
    "text": "me-dependent quantum mechanics \nproblem with a time-independent Hamiltonian.\nGiven a Hamiltonian H and an initial state 0 c1029, what is the probability that \nthe eigenvalue aj of the observable A is measured at time t?\n 1. Diagonalize H (\ufb01nd the eigenvalues En and eigenvectors 0 En92.\n 2. Write 0 c1029 in terms of the energy eigenstates 0 En9.\n 3. Multiply each eigenstate coef\ufb01cient by e-iEnt>U to get 0 c1t29.\n 4. Calculate the probability Paj = 08aj0 c1t290\n2.\n\n72 \nSchr\u00f6dinger Time Evolution\n3.2 \u0002 SPIN PRECESSION\nNow apply this new concept of Schr\u00f6dinger time evolution to the case of a spin-1/2 system. The Ham-\niltonian operator represents the total energy of the system, but because only energy differences are \nimportant in time-dependent solutions (and because we can de\ufb01ne the zero of potential energy as \nwe wish), we need consider only energy terms that differentiate between the two possible spin states \nin the system. Our experience with the Stern-Gerlach apparatus tells us that the magnetic potential \nenergy of the magnetic dipole differs for the two possible spin-component states. So to begin, we \nconsider the potential energy of a single magnetic dipole (e.g., in a silver atom) in a uniform magnetic \n\ufb01eld as the sole term in the Hamiltonian. Recalling that the magnetic dipole is given by\n \nM = g q\n2me\n S, \n(3.22)\nthe Hamiltonian is\n \n H = -M~B\n \n \n = -g q\n2me\n S~B \n \n = e\nme\n S~B,\n \n(3.23)\nwhere q = -e and g = 2 have been used in the last line. The gyromagnetic ratio, g, is slightly differ-\nent from 2, but we ignore that detail.\n3.2.1 \u0002 Magnetic Field in the z-Direction\nFor our \ufb01rst example, we assume that the magnetic \ufb01eld is uniform and directed along the z-axis. \n Writing the magnetic \ufb01eld as\n \nB = B0\n zn \n(3.24)\nallows the Hamiltonian to be simpli\ufb01ed to\n \n H = eB0\nme\n Sz \n \n = v0 Sz,  \n(3.25)\nwhere we have introduced the de\ufb01nition\n \nv0 K eB0\nme\n. \n(3.26)\nThis de\ufb01nition of an angular frequency simpli\ufb01es the notation now and will have an obvious \n interpretation at the end of the problem.\nThe Hamiltonian in Eq. (3.25) is proportional to the Sz operator, so H and Sz commute and \n therefore share common eigenstates. This is clear if we write the Hamiltonian as a matrix in the \nSz  representation:\n \nH \u0003 U v0\n2\n a1\n0\n0\n-1b. \n(3.27)\n\n3.2 Spin Precession \n73\nBecause H is diagonal, we have already completed step 1 of the Schr\u00f6dinger time-evolution recipe. \nThe eigenstates of H are the basis states of the representation, while the eigenvalues are the diagonal \nelements of the matrix in Eq. (3.27). The eigenvalue equations for the Hamiltonian are thus\n \n H 0  +9 = v0Sz0  +9 = U v0\n2\n 0  +9 = E+ 0  +9\n \n \n H 0  -9 = v0Sz0  -9 = -  U v0\n2\n 0  +9 = E - 0  -9, \n(3.28)\nwith eigenvalues and eigenvectors given by\n \n E + = U v 0\n2\n \n E - = -  U v 0\n2  \n \n 0\n E +9 = 0  +9\n \n 0\n E -9 = 0  -9.  \n(3.29)\nThe information regarding the energy eigenvalues and eigenvectors is commonly presented in a \ngraphical diagram, which is shown in Fig. 3.1 for this case. T",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 93
  },
  {
    "child_id": "463e6b05-fee3-40e7-a00a-b1123d2e0f1a",
    "parent_id": "be2003dc-de63-4f4e-9c71-3540860515c2",
    "text": "gonal \nelements of the matrix in Eq. (3.27). The eigenvalue equations for the Hamiltonian are thus\n \n H 0  +9 = v0Sz0  +9 = U v0\n2\n 0  +9 = E+ 0  +9\n \n \n H 0  -9 = v0Sz0  -9 = -  U v0\n2\n 0  +9 = E - 0  -9, \n(3.28)\nwith eigenvalues and eigenvectors given by\n \n E + = U v 0\n2\n \n E - = -  U v 0\n2  \n \n 0\n E +9 = 0  +9\n \n 0\n E -9 = 0  -9.  \n(3.29)\nThe information regarding the energy eigenvalues and eigenvectors is commonly presented in a \ngraphical diagram, which is shown in Fig. 3.1 for this case. The two energy states are separated \nby the energy E+ - E- = U v0, so the angular frequency v0 characterizes the energy scale of this \nsystem. The spin-up state 0  +9 has a higher energy because the magnetic moment is aligned against \nthe \ufb01eld in that state; the negative charge in Eq. (3.22) causes the spin and magnetic moment to be \nantiparallel.\nNow we look at a few examples to illustrate the key features of the behavior of a spin-1/2 system \nin a uniform magnetic \ufb01eld. First, consider the case where the initial state is spin up along the z-axis:\n \n0\n c1029 = 0  +9. \n(3.30)\nThis initial state is already expressed in the energy basis (step 2 of the Schr\u00f6dinger recipe), so the \nSchr\u00f6dinger equation time evolution takes this initial state to the state\n \n 0\n c1t29 = e-iE +\n t>U0  +9 \n \n = e-iv 0\n t>20  +9 \n(3.31)\n\u00030.5\n\u00030.25\n0.0\n0.25\n0.5\nE/\u0002\u03a90\n\u0002\u0002\u0003\n\u0002\u03a90\nE\u0002\u0005 \u0002\u03a90\n2\n\u0003\nE\u0003\u0005\n\u0002\u03a90\n2\n\u0002\u0003\u0003\nFIGURE 3.1 Energy level diagram of a spin-1/2 particle in a uniform magnetic \ufb01eld.",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 93
  },
  {
    "child_id": "a2a21c76-70b5-4507-b580-868d58765281",
    "parent_id": "6e1a4db9-7c08-4544-ae15-05eb08111e58",
    "text": "74 \nSchr\u00f6dinger Time Evolution\naccording to step 3 of the Schr\u00f6dinger recipe. As we saw before [(Eq. (3.13)], because the initial state is \nan energy eigenstate, the time-evolved state acquires an overall phase factor, which does not represent \na physical change of the state. The probability for measuring the spin to be up along the z-axis is (step 4 \nof the Schr\u00f6dinger recipe)\n \n P+ = 08+ 0 c1t290\n2\n \n \n = @8+ 0 e-iv0t>20  +9@\n2 \n \n(3.32)\n \n = 1.\n \n \nAs expected, this probability is not time dependent, and we therefore refer to 0  +9 as a stationary state \nfor this system. A schematic diagram of this experiment is shown in Fig. 3.2, where we have intro-\nduced a new element to represent the applied \ufb01eld. This new depiction is the same as the depictions in \nthe SPINS software, where the number in the applied magnetic \ufb01eld box (42 in Fig. 3.2) is a measure \nof the magnetic \ufb01eld strength. In this experiment, the results shown are independent of the applied \n\ufb01eld strength, as indicated by Eq. (3.32), and as you can verify with the software.\nNext, consider the most general initial state, which we saw in Chapter 2 corresponds to spin \nup along an arbitrary direction de\ufb01ned by the polar angle u and the azimuthal angle f. The initial \nstate is\n \n0 c1029 = 0  +9n = cos u\n2 0  +9 + sin u\n2\n eif0  -9, \n(3.33)\nor using matrix notation:\n \n0 c1029 \u0003 a cos1u>22\neif sin1u>22b. \n(3.34)\nSchr\u00f6dinger time evolution introduces a time-dependent phase term for each component, giving\n \n 0 c1t29 \u0003 a e-iE+t>U cos1u>22\ne-iE-t>Ueif sin1u>22b\n \n \n \u0003 a e-iv0t>2 cos1u>22\neiv0t>2eif sin1u>22b\n \n \n(3.35)\n \n \u0003 e-iv0t>2 a\ncos1u>22\nei1f+v0t2 sin1u>22b. \nZ\nZ\n100\n0\n42\nZ\nFIGURE 3.2 Schematic diagram of a Stern-Gerlach measurement with an applied uniform magnetic \ufb01eld \nrepresented by the box in the middle, with the number 42 representing the strength of the magnetic \ufb01eld.\n\n3.2 Spin Precession \n75\nNote again that an overall phase does not have a measurable effect, so the evolved state is a spin up \neigenstate along a direction that has the same polar angle u as the initial state and a new azimuthal \nangle f + v0t. The state appears to have simply rotated around the z-axis, the axis of the magnetic \n\ufb01eld, by the angle v0t. Of course, we have to limit our discussion to results of measurements, so let\u2019s \n\ufb01rst calculate the probability for measuring the spin component along the z-axis:\n \n P+ = 08+  0 c1t290\n2\n \n \n = 2 11 02e-iv0t>2 a\ncos1u>22\nei1f+v0t2 sin1u>22b 2\n2\n \n \n = 0 e-iv0t>2 cos1u>22 0\n2\n \n \n = cos21u>22.\n \n \n(3.36)\nThis probability is time independent because the Sz eigenstates are also energy eigenstates for this \nproblem (i.e., H and Sz commute). The probability in Eq. (3.36) is consistent with the interpretation \nthat the angle u that the spin vector makes with the z-axis does not change.\nThe probability for measuring spin up along the x-axis is\n \n P+x = 0 x8+  0 c1t290\n2\n \n \n = 2 1\n12 11  12e-iv0t>2a\ncos1u>22\nei(f +v0t) sin1u>22b 2\n2\n \n \n = 1\n2 @ cos1u>22 + ei1f+v0t2 sin1u>22 ",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 98
  },
  {
    "child_id": "f8ef2b39-97df-4922-9c56-3b877cef5be9",
    "parent_id": "6e1a4db9-7c08-4544-ae15-05eb08111e58",
    "text": "\n = cos21u>22.\n \n \n(3.36)\nThis probability is time independent because the Sz eigenstates are also energy eigenstates for this \nproblem (i.e., H and Sz commute). The probability in Eq. (3.36) is consistent with the interpretation \nthat the angle u that the spin vector makes with the z-axis does not change.\nThe probability for measuring spin up along the x-axis is\n \n P+x = 0 x8+  0 c1t290\n2\n \n \n = 2 1\n12 11  12e-iv0t>2a\ncos1u>22\nei(f +v0t) sin1u>22b 2\n2\n \n \n = 1\n2 @ cos1u>22 + ei1f+v0t2 sin1u>22 @\n2\n \n(3.37)\n \n = 1\n2 3cos21u>22 + cos1u>22sin1u>221ei1f+v0t2 + e-i1f +v0t22 + sin21u>224 \n \n = 1\n2 31 + sin u cos1f + v0t24.\n \nThis probability is time dependent because the Sx eigenstates are not stationary states (i.e., H and Sx \ndo not commute). The time dependence in Eq. (3.37) is consistent with the spin precessing around \nthe z-axis.\nTo illustrate this spin precession further, it is useful to calculate the expectation values for each of \nthe spin components. For Sz, we have\n \n 8Sz9 = 8c1t2 0 Sz0 c1t29\n \n \n = eiv0t>2 a\n cos a u\n2b  e-i1f +v0t2 sin a u\n2b b  U\n2\n a1\n0\n0\n-1b e-iv0t>2 a\ncos1u>22\nei1f+v0t2 sin1u>22b \n \n = U\n2\n 3cos21u>22 - sin21u>224\n \n \n = U\n2\n cos u,\n \n(3.38)\n\n76 \nSchr\u00f6dinger Time Evolution\nwhile the other components are\n \n 8Sy9 = 8c1t2 0 Sy0 c1t29\n \n \n = eiv0t>2 a\n cos a u\n2b  e-i1f+v0t2 sin a u\n2b b U\n2\n a0\n-i\ni\n0 be-iv0t>2 a\ncos1u>22\nei1f +v0t2 sin1u>22b (3.39)\n \n = U\n2\n sin u sin1f + v0t2 \nand\n \n 8Sx9 = 8c1t2 0 Sx0 c1t29\n \n \n = U\n2\n sin u cos1f + v0t2. \n \n(3.40)\nThe expectation value of the total spin vector 8S9 is shown in Fig. 3.3, where it is seen to precess \naround the magnetic \ufb01eld direction with an angular frequency v0. The precession of the spin vector is \nknown as Larmor precession and the frequency of precession is known as the Larmor frequency.\nThe quantum mechanical Larmor precession is analogous to the classical behavior of a magnetic \nmoment in a uniform magnetic \ufb01eld. A classical magnetic moment M experiences a torque M * B \nwhen placed in a magnetic \ufb01eld. If the magnetic moment is associated with an angular momentum L, \nthen we can write\n \nM =\nq\n2m\n L, \n(3.41)\nwhere q and m are the charge and mass, respectively, of the system. The equation of motion for the \nangular momentum\n \nd L\ndt = M * B \n(3.42)\nthen results in\n \ndM\ndt =\nq\n2m\n M * B. \n(3.43)\ny\nx\nz\n\u0004S(t)\u0003\n\u0004S(0)\u0003\nB\n\u03a90t\nFIGURE 3.3 The expectation value of the spin vector precesses in a uniform magnetic \ufb01eld.\n\n3.2 Spin Precession \n77\nBecause the torque M * B is perpendicular to the angular momentum L = 2mM>q, it causes the \nmagnetic moment to precess about the \ufb01eld with the classical Larmor frequency vcl = qB>2m.\nIn the quantum mechanical example we are considering, the charge q is negative (meaning the \nspin and magnetic moment are antiparallel), so the precession is counterclockwise around the \ufb01eld. A \npositive charge would result in clockwise precession. This precession of the spin vector makes it clear \nthat the system has angular momentum, as opposed to simply h",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 98
  },
  {
    "child_id": "bbf59270-313e-4ddd-9c4d-fb9308859e70",
    "parent_id": "6e1a4db9-7c08-4544-ae15-05eb08111e58",
    "text": "o the angular momentum L = 2mM>q, it causes the \nmagnetic moment to precess about the \ufb01eld with the classical Larmor frequency vcl = qB>2m.\nIn the quantum mechanical example we are considering, the charge q is negative (meaning the \nspin and magnetic moment are antiparallel), so the precession is counterclockwise around the \ufb01eld. A \npositive charge would result in clockwise precession. This precession of the spin vector makes it clear \nthat the system has angular momentum, as opposed to simply having a magnetic dipole moment. The \nequivalence of the classical Larmor precession and the expectation value of the quantum mechanical \nspin vector is one example of Ehrenfest\u2019s theorem, which states that quantum mechanical expecta-\ntion values obey classical laws.\nPrecession experiments like the one discussed here are of great practical value. For example, if \nwe measure the magnetic \ufb01eld strength and the precession frequency, then the gyromagnetic ratio can \nbe determined. This spin precession problem is also of considerable theoretical utility because it is \nmathematically equivalent to many other quantum systems that can be modeled as two-state systems. \nThis utility is broader than you might guess at \ufb01rst glance, because many multistate quantum systems \ncan be reduced to two-state systems if the experiment is designed to interact only with two of the many \nlevels of the system.\nExample 3.1 A spin-1/2 particle with a magnetic moment is prepared in the state 0  -9x and is \nsubject to a uniform applied magnetic \ufb01eld B = B0\n zn. Find the probability of measuring spin up in \nthe x-direction after a time t. This experiment is depicted in Fig. 3.4.\nWe solve this problem using the four steps of the Schr\u00f6dinger time-evolution recipe from \nSection 3.1. The initial state is\n \n0 c1029 = 0  -9x. \n(3.44)\nThe applied magnetic \ufb01eld is in the z-direction, so the Hamiltonian is H = v0Sz and the energy \neigenstates are 0{9 with energies E{ = {U v0>2 (step 1). The Larmor precession frequency is \nv0 = eB0>me. We must express the initial state in the energy basis (step 2):\n \n0 c1029 = 0  -9x =\n1\n12 0  +9 -\n1\n12 0  -9. \n(3.45)\nThe time-evolved state is obtained by multiplying each energy eigenstate coef\ufb01cient by the appro-\npriate phase factor (step 3):\n \n 0 c1t29 =\n1\n12 e-iE +t>U0  +9 -\n1\n12 e-iE -t>U0  -9 \n(3.46)\n \n =\n1\n12 e-iv0t>20  +9 -\n1\n12 e+iv0t>2 0 -9.\nX\n?\n?\n42\nZ\nX\nFIGURE 3.4 Spin precession experiment.\n\n78 \nSchr\u00f6dinger Time Evolution\nThe measurement probability is found by projecting 0 c1t29 onto the measured state and complex \nsquaring (step 4):\n \n P+x = 0 x8+ 0\n c1t29 0\n2\n \n \n = @x8+ 0A 1\n12 e-iv0t>20  +9 -\n1\n12 e+iv0t>20  -9B @\n2\n \n \n = @ A 1\n128+ 0 +\n1\n128- 0 BA 1\n12 e-iv0t>20  +9 -\n1\n12 e+iv0t>20  -9B @\n2\n \n(3.47)\n \n = 1\n4 @e-iv0t>2 - e+iv0t>2@\n2\n \n \n = sin2 1v0t>22.\n \nThe probability that the system has spin up in the x-direction oscillates between zero and unity \nas time evolves, as shown in Fig. 3.5(a), which is consistent with the model of the spin vector ",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 98
  },
  {
    "child_id": "1bf4e04d-b1ae-4c5b-9630-e507800e4a95",
    "parent_id": "6e1a4db9-7c08-4544-ae15-05eb08111e58",
    "text": "rojecting 0 c1t29 onto the measured state and complex \nsquaring (step 4):\n \n P+x = 0 x8+ 0\n c1t29 0\n2\n \n \n = @x8+ 0A 1\n12 e-iv0t>20  +9 -\n1\n12 e+iv0t>20  -9B @\n2\n \n \n = @ A 1\n128+ 0 +\n1\n128- 0 BA 1\n12 e-iv0t>20  +9 -\n1\n12 e+iv0t>20  -9B @\n2\n \n(3.47)\n \n = 1\n4 @e-iv0t>2 - e+iv0t>2@\n2\n \n \n = sin2 1v0t>22.\n \nThe probability that the system has spin up in the x-direction oscillates between zero and unity \nas time evolves, as shown in Fig. 3.5(a), which is consistent with the model of the spin vector \nprecessing around the applied \ufb01eld, as shown in Fig. 3.5(b).\n3.2.2 \u0002 Magnetic Field in a General Direction\nFor our second example, consider a more general direction for the magnetic \ufb01eld by adding a magnetic \n\ufb01eld component along the x-axis to the already existing \ufb01eld along the z-axis. The simplest approach \nto solving this new problem would be to rede\ufb01ne the coordinate system so the z-axis pointed along the \ndirection of the new total magnetic \ufb01eld. Then the solution would be the same as was obtained above, \nwith a new value for the magnitude of the magnetic \ufb01eld being the only change. This approach would \nbe considered astute in many circumstances, but we will not take it because we want to get practice \nsolving this new type of problem and because we want to address some issues that are best posed in the \noriginal coordinate system. Thus, we de\ufb01ne a new magnetic \ufb01eld as\n \nB = B0zn + B1xn . \n(3.48)\nt\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nP\u0002x\ny\nx\nz\n(a)\n(b)\n\u03a90t\nB\n\u0004S(0)\u0003\n\u0004S(t)\u0003\n2\u03a0\n\u03a90\n4\u03a0\n\u03a90\n6\u03a0\n\u03a90\nFIGURE 3.5 (a) Probability of a spin component measurement and (b) the corresponding \nprecession of the expectation value of the spin.\n\n3.2 Spin Precession \n79\nThis \ufb01eld is oriented in the xz-plane at an angle u with respect to the z-axis, as shown in Fig. 3.6. In \nlight of the solution above, it is useful to de\ufb01ne Larmor frequencies associated with each of the \ufb01eld \ncomponents:\n \nv0 K eB0\nme\n, \nv1 K eB1\nme\n. \n(3.49)\nUsing these de\ufb01nitions, the Hamiltonian becomes\n \n H = - M~B\n \n \n = v0 Sz + v1Sx, \n(3.50)\nor in matrix representation\n \nH \u0003 U\n2\n av0\nv1\nv1\n-v0\nb. \n(3.51)\nThis Hamiltonian is not diagonal, so its eigenstates are not the same as the eigenstates of Sz. Rather we \nmust use the diagonalization procedure to \ufb01nd the new eigenvalues and eigenvectors. The characteristic \nequation determining the energy eigenvalues is\n \n \u221e \nU\n2\n  v0 - l\nU\n2\n  v1\nU\n2\n  v1\n-  U\n2\n  v0 - l\n\u221e= 0  \n \n - a U\n2\n v0b\n2\n+ l2 - a U\n2\n v1b\n2\n= 0, \n \n(3.52)\nwith solutions\n \nl = { U\n2\n 4v2\n0 + v2\n1. \n(3.53)\nNote that the energy eigenvalues are {1U v0>22 when v1 = 0, which they must be given our previ-\nous solution. Rather than solve directly for the eigenvectors, let\u2019s make them obvious by rewriting the \nHamiltonian. From Fig. 3.6 it is clear that the angle is determined by the equation\n \ntan u = B1\nB0\n= v1\nv0\n. \n(3.54)\nB0\nB1\nB\n\u03b8\nFIGURE 3.6 A uniform magnetic \ufb01eld in a general direction.",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 98
  },
  {
    "child_id": "0a95dfc7-4a94-4faf-b13d-16d73ce16b1d",
    "parent_id": "3a1e7dfb-4ac7-444c-81a8-ae482c556ea7",
    "text": "80 \nSchr\u00f6dinger Time Evolution\nUsing this, the Hamiltonian can be written as\n \nH \u0003 U\n2\n 4v2\n0 + v2\n1 acos u\nsin u\nsin u\n-cos ub. \n(3.55)\nIf we let nn be the unit vector in the direction of the total magnetic \ufb01eld, then the Hamiltonian is propor-\ntional to the spin component Sn along the direction nn:\n \nH = 4v2\n0 + v2\n1 Sn. \n(3.56)\nThis is what we expected at the beginning: that the problem could be solved by using the \ufb01eld direc-\ntion to de\ufb01ne a coordinate system. Thus, the eigenvalues are as we found in Section 2.2.1 and the \neigenstates are the spin up and down states along the direction nn, which are\n \n0  +9n = cos u\n2\n 0  +9 + sin u\n2\n 0  -9 \n \n0  -9n = sin u\n2\n 0  +9 - cos u\n2\n 0  -9 \n \n(3.57)\nfor this case, because the azimuthal angle f is zero. These are the same states you would \ufb01nd by \ndirectly solving for the eigenstates of the Hamiltonian. Because we have already done that for the Sn \ncase, we do not repeat it here.\nNow consider performing the following experiment: begin with the system in the spin-up state \nalong the z-axis, and measure the spin component along the z-axis after the system has evolved in \nthis magnetic \ufb01eld for some time, as depicted in Fig. 3.7. Let\u2019s speci\ufb01cally calculate the probabil-\nity that the initial 0  +9 is later found to have evolved to the 0  -9 state. This is commonly known as a \nspin \ufb02ip. According to our time-evolution prescription, we must \ufb01rst write the initial state in terms \nof the energy eigenstates of the system. In the previous examples, this was trivial because the energy \neigenstates were the 0{9 states that we used to express all general states. But now this new problem is \nmore involved, so we proceed more slowly. The initial state\n \n0\n c1029 = 0  +9 \n(3.58)\nmust be written in the 0{9n basis. Because the 0{9n basis is complete, we can use the completeness \nrelation [Eq. (2.55)] to decompose the initial state\n \n 0\n c1029 = 10  +9n n8+ 0 + 0  -9n n8- 02 0  +9 \n \n = 0  +9n n8+ 0  +9 + 0  -9n n8- 0  +9 \n \n = n8+ 0  +9 0  +9n + n8- 0  +9 0  -9n  \n \n = cos u\n2\n 0  +9n + sin u\n2\n 0  -9n.\n \n \n(3.59)\nZ\n?\n?\n42\n^n\nZ\nFIGURE 3.7 A spin precession experiment with a uniform magnetic \ufb01eld aligned in a general direction nn.\n\n3.2 Spin Precession \n81\nNow that the initial state is expressed in the energy basis, the time-evolved state is obtained by multi-\nplying each coef\ufb01cient by a phase factor dependent on the energy of that eigenstate:\n \n0\n c1t29 = e-iE+t>U cos u\n2\n 0  +9n + e-iE-t>U sin u\n2\n 0  -9n. \n(3.60)\nWe leave it in this form and substitute the energy eigenvalues\n \nE{ = { U\n2 4v2\n0 + v2\n1 \n(3.61)\nat the end of the example.\nThe probability of a spin \ufb02ip is\n \nP+ S  - = 08-  0\n c1t290\n2 \n \n= 2 8- 0 Je-iE+t>U cos u\n2 0  +9n + e-iE-t>U sin u\n2 0  -9n R 2\n2\n \n \n= 2 e-iE+t>U cos u\n2\n 8- 0  +9n + e-iE-t>U sin u\n2\n 8- 0  -9n 2\n2\n \n \n= 2 e-iE+t>U cos u\n2 sin u\n2\n + e-iE-t>U sin u\n2\n a-cos u\n2b 2\n2\n \n(3.62)\n \n= cos2 u\n2 sin2\n  u\n2\n @ 1 - ei1E+-E-2t>U@\n2 \n \n= sin2 u\n  sin2 a1E+ - E-2t\n2U\nb. \nThe probability oscilla",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 104
  },
  {
    "child_id": "769532a0-574a-4be6-aab9-a53c32530c41",
    "parent_id": "3a1e7dfb-4ac7-444c-81a8-ae482c556ea7",
    "text": " in this form and substitute the energy eigenvalues\n \nE{ = { U\n2 4v2\n0 + v2\n1 \n(3.61)\nat the end of the example.\nThe probability of a spin \ufb02ip is\n \nP+ S  - = 08-  0\n c1t290\n2 \n \n= 2 8- 0 Je-iE+t>U cos u\n2 0  +9n + e-iE-t>U sin u\n2 0  -9n R 2\n2\n \n \n= 2 e-iE+t>U cos u\n2\n 8- 0  +9n + e-iE-t>U sin u\n2\n 8- 0  -9n 2\n2\n \n \n= 2 e-iE+t>U cos u\n2 sin u\n2\n + e-iE-t>U sin u\n2\n a-cos u\n2b 2\n2\n \n(3.62)\n \n= cos2 u\n2 sin2\n  u\n2\n @ 1 - ei1E+-E-2t>U@\n2 \n \n= sin2 u\n  sin2 a1E+ - E-2t\n2U\nb. \nThe probability oscillates at the frequency determined by the difference in energies of the eigen-\nstates. This time dependence results because the initial state was a superposition state, as we saw in \nEq. (3.20). In terms of the Larmor frequencies used to de\ufb01ne the Hamiltonian in Eq. (3.51), the prob-\nability of a spin \ufb02ip is\n \nP+ S - =\nv2\n1\nv2\n0 + v2\n1\n sin2\n a 2v2\n0 + v2\n1\n2\n tb  . \n(3.63)\nEq. (3.63) is often called Rabi\u2019s formula, and it has important applications in many problems as we \nshall see.\nTo gain insight into Rabi\u2019s formula, consider two simple cases. First, if there is no added \ufb01eld in \nthe x-direction, then v1 \u0003 0 and P+ S - = 0 because the initial state is a stationary state. Second, if \nthere is no \ufb01eld component in the z-direction, then v0 \u0003 0 and P+ S - oscillates between 0 and 1 at the \nfrequency v1, as shown in Fig. 3.8(a). The second situation corresponds to spin precession around the \napplied magnetic \ufb01eld in the x-direction, as shown in Fig. 3.8(b), with a complete spin \ufb02ip from 0  +9 to \n0  -9 and back again occurring at the precession frequency v1. In the general case where both magnetic \n\ufb01eld components are present, the probability does not reach unity and so there is no time at which the \nspin is certain to \ufb02ip over. If the x-component of the \ufb01eld is small compared to the z-component, then \nv1 << v0 and P+ S - oscillates between 0 and a value much less than 1 at a frequency approximately \nequal to v0, as shown in Fig. 3.9.\n\n82 \nSchr\u00f6dinger Time Evolution\nExample 3.2 A spin-1/2 particle with a magnetic moment is prepared in the state 0  -9 and is sub-\nject to a uniform applied magnetic \ufb01eld B = B0yn. Find the probability of measuring spin up in the \nz-direction after a time t.\nThe initial state is\n \n0\n c1029 = 0  -9. \n(3.64)\nThe applied magnetic \ufb01eld is in the y-direction, so the Hamiltonian is H = v0Sy and the energy \neigenstates are 0{9y with energies E{ = {U v0>2 (step 1). The Larmor precession frequency is \nt\n0\n0.2\n0.4\n0.6\n0.8\n1.0\n)\nb\n(\n)\na\n(\ny\nx\nz\nB\n\u3008S(0)\u3009\n\u3008S(t)\u3009\n2\u0002\n\u00030\n4\u0002\n\u00030\n6\u0002\n\u00030\nP+\u2192\u2212\nFIGURE 3.9 (a) Spin-\ufb02ip probability for a uniform magnetic \ufb01eld with x- and z-components and \n(b) the corresponding precession of the expectation value of the spin.\nt\n)\nb\n(\n)\na\n(\ny\nx\nz\nB\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nP+\u2192\u2212\nS(0)\nS(t)\n2\u03a0\n\u03a91\n4\u03a0\n\u03a91\n6\u03a0\n\u03a91\nFIGURE 3.8 (a) Spin-flip probability for a uniform magnetic \ufb01eld in the x-direction and (b) the \ncorresponding precession of the expectation value of the spin.\nP+\u2192\u2212\n\n3.2 Spin Precession \n83\nv0 = eB0>me. We must express the i",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 104
  },
  {
    "child_id": "b04b02ee-8b2b-490b-b45d-0de4f89ffa5c",
    "parent_id": "3a1e7dfb-4ac7-444c-81a8-ae482c556ea7",
    "text": "\u3009\n\u3008S(t)\u3009\n2\u0002\n\u00030\n4\u0002\n\u00030\n6\u0002\n\u00030\nP+\u2192\u2212\nFIGURE 3.9 (a) Spin-\ufb02ip probability for a uniform magnetic \ufb01eld with x- and z-components and \n(b) the corresponding precession of the expectation value of the spin.\nt\n)\nb\n(\n)\na\n(\ny\nx\nz\nB\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nP+\u2192\u2212\nS(0)\nS(t)\n2\u03a0\n\u03a91\n4\u03a0\n\u03a91\n6\u03a0\n\u03a91\nFIGURE 3.8 (a) Spin-flip probability for a uniform magnetic \ufb01eld in the x-direction and (b) the \ncorresponding precession of the expectation value of the spin.\nP+\u2192\u2212\n\n3.2 Spin Precession \n83\nv0 = eB0>me. We must express the initial state in the energy basis (step 2), which in this case is \nthe Sy basis:\n \n 0\n c1029 = 0  -9 = 10  +9y y0  + 0 + 0  -9y y8- 02 0  -9 \n \n = 0  +9y y8+ 0  -9 + 0  -9y y8- 0  -9\n \n \n = y8+ 0  -9 0  +9y + y8- 0  -9 0  -9y\n \n(3.65)\n \n =\n-i\n12 0  +9y +\ni\n12 0  -9y.\n \nThe time evolved state is obtained by multiplying each energy eigenstate coef\ufb01cient by a phase \nfactor (step 3):\n \n 0\n c1t29 =\n-i\n12\n e-iE +t>U0  +9y +\ni\n12\n e-iE -t>U0  -9y \n \n =\n-i\n12\n e-iv0t>20  +9y +\ni\n12\n e+iv0t>20  -9y. \n(3.66)\nThe measurement probability is found by projecting onto the measured state and squaring (step 4):\n \n P+ = 08+ 0\n c1t290\n2\n \n \n = @8+ 0A -i\n12 e-iv0t>20  +9y +\ni\n12 e+iv0t>20  -9y2@\n2\n \n \n = @ A -i\n12 e-iv0t>28+ 0  +9y +\ni\n12 e+iv0t>28+ 0  -9yB @\n2\n \n \n(3.67)\n \n = @ A -i\n12 e-iv0t>2 A 1\n12B +\ni\n12 e+iv0t>2 A 1\n12B B @\n2\n \n \n = 1\n4 @-ie-iv0t>2 + ie+iv0t>2@\n2\n= 1\n4 @-2sin1v0t>22 @\n2\n \n \n = sin2\n 1v0t>22.\n \n \nThe probability oscillates between zero and unity as time evolves, as shown in Fig. 3.10(a), which \nis consistent with the model of the spin vector precessing around the applied \ufb01eld, as shown in \nFig. 3.10(b).\nt\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\ny\nx\nz\n\u03a90t\nB\n(a)\n(b)\nP+\u2192\u2212\n\u0004S(t)\u0003\n\u0004S(0)\u0003\n2\u03a0\n\u03a90\n4\u03a0\n\u03a90\n6\u03a0\n\u03a90\nFIGURE 3.10 (a) Spin measurement probability and (b) the corresponding precession \nof the expectation value of the spin.\n\n84 \nSchr\u00f6dinger Time Evolution\nThough we have derived Rabi\u2019s formula [Eq. (3.63)] in the context of a spin-1/2 particle in a \nuniform magnetic \ufb01eld, its applicability is much more general. If we can express the Hamiltonian \nof any two-state system in the matrix form of Eq. (3.51) with the parameters v0 and v1, then we can \nuse Rabi\u2019s formula to \ufb01nd the probability that the system starts in the \u201cspin-up\u201d state 0  +9 and is then \nmeasured to be in the \u201cspin-down\u201d state 0  -9 after some time t. In the general case, the 0  +9 and 0  -9 \nstates are whatever states of the system are used to represent the Hamiltonian operator in the form of \nEq. (3.51). In the next section, we\u2019ll look at the example of neutrino oscillations to see how this exam-\nple can be applied more generally.\n3.3 \u0002 NEUTRINO OSCILLATIONS\nNeutrinos have enjoyed an almost mystical history in particle physics because they are very hard to \ndetect and yet play an important role in many fundamental processes. In 1930, the neutrino was pos-\ntulated by Wolfgang Pauli as a solution to the beta decay problem. A free neutron decays to a proton \nand an electron with a lifetime of about 10 minutes in th",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 104
  },
  {
    "child_id": "0d0c4d1d-9b40-4b5d-83e8-f9615d137236",
    "parent_id": "3a1e7dfb-4ac7-444c-81a8-ae482c556ea7",
    "text": "on, we\u2019ll look at the example of neutrino oscillations to see how this exam-\nple can be applied more generally.\n3.3 \u0002 NEUTRINO OSCILLATIONS\nNeutrinos have enjoyed an almost mystical history in particle physics because they are very hard to \ndetect and yet play an important role in many fundamental processes. In 1930, the neutrino was pos-\ntulated by Wolfgang Pauli as a solution to the beta decay problem. A free neutron decays to a proton \nand an electron with a lifetime of about 10 minutes in the most basic beta decay process. However, the \ndecay scheme n S p + e- violates conservation of angular momentum, and experimental data sug-\ngest that conservation of energy is also violated. That\u2019s not good. Rather than reject these two basic \nconservation laws, as some suggested, Pauli proposed that a third particle is involved in the decay \nprocess. Enrico Fermi named this new particle the \u201cneutrino.\u201d Fermi developed a theory that used the \nneutrino to properly explain beta decay, but it was 25 more years before a neutrino was detected.\nNeutrinos are uncharged, relativistic particles. In nuclear beta decay, neutrinos are produced in \nprocesses such as\n \nn S p + e- + ne  \n \np S n + e+ + ne, \n \n(3.68)\nwhere the subscript labels the neutrino ne as an electron neutrino and the bar labels ne as an antineu-\ntrino. In the standard model of particle physics, neutrinos are massless, like photons. Neutrinos are so \nelusive because they interact via the weak force or weak interaction, which is the weakest of the four \nfundamental forces\u2014the strong nuclear force, electromagnetism, and gravity being the other three.\nThe reaction p S n + e+ + ne is part of the thermonuclear reaction chain in the sun and other \nstars, so we earthlings are constantly bombarded with neutrinos along with the essential photons we \nreceive from the sun. In the 1960s and 70s, landmark experiments indicated that there are only about \nhalf as many solar neutrinos arriving on earth as we would expect, given reliable models of stellar ther-\nmonuclear reactions. This solar neutrino problem has recently been solved by experiments detecting \nneutrinos from the sun and from nuclear reactors that demonstrate that neutrinos have nonzero mass. \nThese results are counter to the standard model and so have profound implications for particle physics \nand cosmology. Understanding how these experiments provide information on the neutrino mass is a \npowerful illustration of the applicability of Rabi\u2019s formula to other two-state systems.\nIn addition to the electron neutrinos in Eq. (3.68), there are other types of neutrinos associated \nwith other reactions, such as\n \n p+ S m+ + nm\n \n \n m- S e- + nm + ne, \n \n(3.69)\nwhich represent the decay of a pion (p) to a muon (m) and the decay of a muon to an electron, respectively. \nA muon behaves exactly like an electron but has a larger mass. Electrons, muons, and a third particle \n(tau) and their associated neutrinos are collectively called leptons. In reactions invol",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 104
  },
  {
    "child_id": "f2c4e65e-5ace-4178-b79f-bdc4bbdb2d33",
    "parent_id": "3a1e7dfb-4ac7-444c-81a8-ae482c556ea7",
    "text": " two-state systems.\nIn addition to the electron neutrinos in Eq. (3.68), there are other types of neutrinos associated \nwith other reactions, such as\n \n p+ S m+ + nm\n \n \n m- S e- + nm + ne, \n \n(3.69)\nwhich represent the decay of a pion (p) to a muon (m) and the decay of a muon to an electron, respectively. \nA muon behaves exactly like an electron but has a larger mass. Electrons, muons, and a third particle \n(tau) and their associated neutrinos are collectively called leptons. In reactions involving these particles",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 104
  },
  {
    "child_id": "2c134b17-0bf4-4f0d-b985-767368bb94df",
    "parent_id": "28032c31-bfd7-4b6b-b1df-fd0a83248b1e",
    "text": "3.3 Neutrino Oscillations \n85\nit is convenient to define a lepton \u201c\ufb02avor\u201d quantum number L, with the assigned values Le = 1 for the \nelectron e\u2212 and its associated neutrino ne, Le = -1 for the positron e+ and the antineutrino ne, Lm = 1\nfor the muon \u03bc\u2212 and its associated neutrino nm, and Lm = -1 for the \u03bc+ and nm. With these assignments, \nthe individual electron and muon \ufb02avor numbers are conserved in the processes shown above. However, \nthere is no theoretical basis for this conservation, and so we allow for the possibility that these quantum \nnumbers are only approximately conserved. This possibility then allows for reactions of the type\n \nne 4 nm, \n(3.70)\nwhere an electron neutrino changes its \ufb02avor and becomes a muon neutrino, or the reverse. Such \nchanges are called neutrino mixing or neutrino oscillations.\nThe labeling of neutrinos according to their association with electrons or muons arises from their behavior \nin the weak interaction processes described above. In other words, the quantum states 0 ne9 and 0 nm9 are \neigenstates of the Hamiltonian describing the weak interaction. However, when neutrinos propagate in \nfree space, the weak interaction is not relevant and the only Hamiltonian of relevance is that due to the \nrelativistic energy of the particles, which includes their rest masses and momenta. The eigenstates of this \nHamiltonian are generally referred to as the mass eigenstates. If the masses of the two types of neutrinos \n(electron and muon) are different, then, in general, the mass eigenstates do not coincide with the weak \ninteraction eigenstates. This distinction between sets of eigenstates allows for \ufb02avor-changing processes.\nTo see why this is so, let the mass eigenstates be labeled 0 n19 and 0 n29. Either one of the two bases \n(mass or weak eigenstates) can be used as a complete basis upon which to expand any general state in \nthis system. Let\u2019s assume that the relation between the bases is\n \n 0 ne9 = cos u\n2\n 0 n19 + sin u\n2\n 0 n29  \n \n 0 nm9 = sin u\n2\n 0 n19 - cos u\n2\n 0 n29. \n \n(3.71)\nThe angle u>2 is generally referred to as the mixing angle (some treatments drop the factor 1/2, but \nwe retain it to be consistent with the previous spin-1/2 discussion). If the mixing angle is small, then \nthe relations become\n \n 0 ne9 \u0003 0 n19  \n \n 0 nm9 \u0003 0 n29. \n \n(3.72)\nAssume that an electron neutrino is created in some weak interaction process and then propagates \nthrough free space to a detector. We wish to know the probability that a muon neutrino is detected, \nwhich is the signature of neutrino \ufb02avor mixing. The initial state vector is\n \n 0 c1029 = 0 ne9\n \n \n = cos u\n2\n 0 n19 + sin u\n2\n 0 n29. \n \n(3.73)\nDuring the free-space propagation, the energy eigenstates of the system are the mass eigenstates \nbecause there is no weak interaction present. Thus the Schr\u00f6dinger time evolution for this state is\n \n0 c1t29 = cos u\n2\n e-iE1t>U0 n19 + sin u\n2\n e-iE2t>U0 n29. \n(3.74)\nThe energy eigenvalues are simply the relativistic energies, wh",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 109
  },
  {
    "child_id": "2b221188-edb9-4a29-bdfd-bd98973fc8fd",
    "parent_id": "28032c31-bfd7-4b6b-b1df-fd0a83248b1e",
    "text": " neutrino is detected, \nwhich is the signature of neutrino \ufb02avor mixing. The initial state vector is\n \n 0 c1029 = 0 ne9\n \n \n = cos u\n2\n 0 n19 + sin u\n2\n 0 n29. \n \n(3.73)\nDuring the free-space propagation, the energy eigenstates of the system are the mass eigenstates \nbecause there is no weak interaction present. Thus the Schr\u00f6dinger time evolution for this state is\n \n0 c1t29 = cos u\n2\n e-iE1t>U0 n19 + sin u\n2\n e-iE2t>U0 n29. \n(3.74)\nThe energy eigenvalues are simply the relativistic energies, which are determined by the rest masses \nand the momenta:\n \nEi = 41pc22 + 1mi c222,  i = 1, 2. \n(3.75)\n\n86 \nSchr\u00f6dinger Time Evolution\nAssuming that the neutrinos are highly relativistic 1mc2 V pc2, we \ufb01nd\n \n Ei = pc c1 + ami c2\npc b\n2\nd\n1>2\n \n \n \u0002 pc c1 + 1\n2\n amic2\npc b\n2\nd  \n \n(3.76)\n \n \u0002 pc + 1mi c222\n2pc\n.\n \nThe beauty of studying two-level systems such as spin-1/2 particles and neutrino oscillations is \nthat they are formally identical. In the spin-1/2 case, we phrased the problem in terms of \ufb01nding the \nprobability of a spin \ufb02ip, whereas here we are looking for a change in the \ufb02avor of the neutrino. In \nboth cases, the initial and \ufb01nal states are not energy eigenstates, but rather orthogonal states in a dif-\nferent basis. The problems are mathematically identical, so the probability of a transition between the \northogonal states takes the same form. The probability of a neutrino oscillation is thus given by the \nsame equation as the spin-\ufb02ip probability, Eq. (3.62),\n \n PneSnm = 08nm0 c1t290\n2\n \n \n = sin2 u\n  sin2 a1E1 - E22t\n2U\nb, \n \n(3.77)\nwhere the parameter u has been de\ufb01ned the same in both problems and the energy difference E+ - E- \nhas been changed to the energy difference E1 - E2. This energy difference is\n \n E1 - E2 = 1m1c22\n2\n2pc\n- 1m2c22\n2\n2pc\n \n \n = c3\n2p\n 1m2\n1 - m2\n22.\n \n \n(3.78)\nNeutrinos move at nearly the speed of light c, so we approximate the time from the creation of the \nelectron neutrino to the detection of the muon neutrino as t \u0002 L>c, where L is the distance from the \nsource to the detector. We also approximate the relativistic momentum as p = E>c. This gives a prob-\nability for neutrino \ufb02avor change of\n \n PneSnm = sin2 u sin2 a1m2\n1 - m2\n22Lc3\n4E U\nb . \n(3.79)\nAs a function of the distance L, the probability oscillates from 0 to a maximum value of sin2 u\u2014hence \nthe term neutrino oscillation. By measuring the fractions of different neutrino \ufb02avors at a distance \nfrom a neutrino source (e.g., the sun or a reactor) and comparing to a model for the expected fractions, \nexperimenters have been able to infer the masses of the different neutrinos, or at least the differences \nof the squares of the masses. Recent results from solar neutrino and reactor neutrino experiments \nindicate a squared mass difference of approximately\n \nm2\n1 - m2\n2 \u0005 8 * 10-5 eV 2>c4. \n(3.80)\nThese experiments also provide information on the mixing angle u, with recent results indicating\n \nu \u0005 69\b. \n(3.81)\nNeutrino experiments such as these continue to provide i",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 109
  },
  {
    "child_id": "e109f275-d1f7-4858-853b-6467b0d0182a",
    "parent_id": "28032c31-bfd7-4b6b-b1df-fd0a83248b1e",
    "text": "for the expected fractions, \nexperimenters have been able to infer the masses of the different neutrinos, or at least the differences \nof the squares of the masses. Recent results from solar neutrino and reactor neutrino experiments \nindicate a squared mass difference of approximately\n \nm2\n1 - m2\n2 \u0005 8 * 10-5 eV 2>c4. \n(3.80)\nThese experiments also provide information on the mixing angle u, with recent results indicating\n \nu \u0005 69\b. \n(3.81)\nNeutrino experiments such as these continue to provide information about the fundamental physics of \nthe universe.\n\n3.4 Time-Dependent Hamiltonians \n87\n3.4 \u0002 TIME-DEPENDENT HAMILTONIANS\nUp to now, we have studied the time evolution of quantum mechanical systems where the Hamiltonian \nis time independent. We solved the Schr\u00f6dinger equation once for the general case and developed \na recipe for the time evolution of the system that we can apply to all cases with time-independent \nHamiltonians. However, if the Hamiltonian is time dependent, then we cannot use that simple recipe. \nWe must know the form of the Hamiltonian time dependence in order to solve the Schr\u00f6dinger equa-\ntion. Fortunately, there are common forms of time dependence that we can solve in general and then \napply in many cases. The most common form of time dependence is sinusoidal time dependence at one \nfrequency. We will solve this problem in the context of a spin-1/2 particle in a magnetic \ufb01eld and then \nalso apply it to atom-light interactions.\n3.4.1 \u0002 Magnetic Resonance\nIn the spin precession example in Section 3.2.2, we concluded that a complete spin \ufb02ip required a large \nmagnetic \ufb01eld in the x-direction, which represents a large change or perturbation compared to the \ninitial situation of a magnetic \ufb01eld in the z-direction. Now consider whether we can induce a complete \nspin \ufb02ip without such a large perturbation. That is, what small magnetic \ufb01eld can we add to the system \nthat will cause a 0  +9 state to \ufb02ip to a 0  -9 state? The answer is that we must apply a time-dependent \nmagnetic \ufb01eld that oscillates at a frequency close to the Larmor precession frequency v0 that charac-\nterizes the energy difference between the spin-up and spin-down states, as shown in Fig. 3.1. By mak-\ning the oscillating magnetic \ufb01eld resonant with the Larmor frequency, we induce transitions between \nthe energy states shown in Fig. 3.1. This effect is known as magnetic resonance. I. I. Rabi won the \nNobel Prize in physics in 1944 for his work in developing the magnetic resonance technique and using \nit to measure the magnetic moments of nuclei. Following Rabi\u2019s work, nuclear magnetic resonance \n(NMR) became a widely used tool for studying the properties of materials. The Larmor frequency \ndepends on the magnetic \ufb01eld magnitude at the location of the particular nucleus being studied. This \nmagnetic \ufb01eld includes the applied external \ufb01eld and any internal \ufb01elds created by the local environ-\nment, such that measuring the resonance frequency provides valuable information ",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 109
  },
  {
    "child_id": "8e7b3516-9d52-46b7-be13-fc5d3586697b",
    "parent_id": "28032c31-bfd7-4b6b-b1df-fd0a83248b1e",
    "text": "e technique and using \nit to measure the magnetic moments of nuclei. Following Rabi\u2019s work, nuclear magnetic resonance \n(NMR) became a widely used tool for studying the properties of materials. The Larmor frequency \ndepends on the magnetic \ufb01eld magnitude at the location of the particular nucleus being studied. This \nmagnetic \ufb01eld includes the applied external \ufb01eld and any internal \ufb01elds created by the local environ-\nment, such that measuring the resonance frequency provides valuable information about the environ-\nment of the nucleus. In biology and chemistry, NMR has been used extensively to distinguish different \ntypes of bonds and identify structures. More recently, magnetic resonance imaging (MRI) has been \ndeveloped for medical diagnosis.\nTo understand how magnetic resonance works, it is instructive to consider the classical problem \n\ufb01rst. A classical magnetic moment aligned with an angular momentum precesses around the direc-\ntion of an applied magnetic \ufb01eld. Now imagine going to a reference frame that rotates about the \ufb01eld \n(assumed to be in the z-direction) with the same frequency as the precession. An observer in the rotat-\ning frame would see the magnetic moment stationary and so would conclude that there is no magnetic \n\ufb01eld in that frame. If that rotating observer were asked to \ufb02ip the magnetic moment from up to down \nalong the z-axis, she would answer, \u201cSimple, just impose a small magnetic \ufb01eld perpendicular to the \nz-axis, which will cause the spin to precess around that direction.\u201d Because that \ufb01eld is the only \ufb01eld \nacting in the rotating frame, it can be as small as one likes. The magnitude simply determines the time \nfor the spin to \ufb02ip.\nIn this situation, the transverse applied \ufb01eld is stationary in the rotating frame, so it will appear to \nbe rotating at the precessional frequency in the original frame. Thus, we could write it as\n \nB = B1 cos1vt2xn + B1 sin1vt2yn, \n(3.82)\nwhere we allow the frequency v to differ from the precessional frequency v0 in order to solve the \nproblem more generally. In that case, there would be some residual precession in the rotating frame, \nand so the rotating observer would conclude that there is some residual \ufb01eld in the z-direction. Hence,\n\n88 \nSchr\u00f6dinger Time Evolution\nwe expect that the added transverse \ufb01eld would not cause a complete \ufb02ipping of the magnetic moment \nfrom up to down in this general case.\nLet\u2019s now apply this reasoning to the quantum mechanical case. Assume a magnetic \ufb01eld of the form\n \nB = B0zn + B13cos1vt2xn + sin1vt2yn4, \n(3.83)\nwhere the role of B0 is to split the energies of the spin-up and spin-down states and the role of B1 is to \n\ufb02ip the spin between the the up and down states. The Hamiltonian is\n \n H = -M~B\n \n \n = v0 Sz + v13cos1vt2Sx + sin1vt2Sy4, \n \n(3.84)\nwhere we again de\ufb01ne the Larmor frequencies corresponding to the two magnetic \ufb01eld components,\n \nv0 K eB0\nme\n,   v1 K eB1\nme\n. \n(3.85)\nThe matrix representation of the Hamiltonian is\n \nH \u0003 U\n2\n \u00a2 v0\nv1e-ivt\nv1eivt\n",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 109
  },
  {
    "child_id": "06f5bd1a-a5ae-4695-b187-7114e7e5e73c",
    "parent_id": "28032c31-bfd7-4b6b-b1df-fd0a83248b1e",
    "text": "B = B0zn + B13cos1vt2xn + sin1vt2yn4, \n(3.83)\nwhere the role of B0 is to split the energies of the spin-up and spin-down states and the role of B1 is to \n\ufb02ip the spin between the the up and down states. The Hamiltonian is\n \n H = -M~B\n \n \n = v0 Sz + v13cos1vt2Sx + sin1vt2Sy4, \n \n(3.84)\nwhere we again de\ufb01ne the Larmor frequencies corresponding to the two magnetic \ufb01eld components,\n \nv0 K eB0\nme\n,   v1 K eB1\nme\n. \n(3.85)\nThe matrix representation of the Hamiltonian is\n \nH \u0003 U\n2\n \u00a2 v0\nv1e-ivt\nv1eivt\n-v0\n\u2264. \n(3.86)\nThis Hamiltonian is time dependent, so we can no longer use our simple recipe for Schr\u00f6dinger \ntime evolution. Rather, we must return to the Schr\u00f6dinger equation and solve it with these new time-\ndependent terms. Because we are not using our recipe for Schr\u00f6dinger time evolution, we are not \nbound to use the energy basis as the preferred basis. The obvious choice would be to use the basis we \nhave used for representing the Hamiltonian as a matrix, which becomes the basis of energy states if the \ntransverse part B1 of the magnetic \ufb01eld vanishes. Using this basis, we write the state vector as\n \n0 c1t29 = c+1t2 0  +9 + c-1t2 0  -9 \u0003  \u00a2c+1t2\nc-1t2\u2264. \n(3.87)\nSchr\u00f6dinger\u2019s equation\n \niU d\ndt\n 0\n c1t29 = H1t2 0\n c1t29 \n(3.88)\nin matrix form is\n \niU d\ndt\n \u00a2c+1t2\nc-1t2\u2264= U\n2\n \u00a2 v0\nv1e-ivt\nv1eivt\n-v0\n\u2264\u00a2c+1t2\nc-1t2\u2264 \n(3.89)\nand leads to the differential equations\n \niUc#\n+ 1t2 = U v0\n2  c+1t2 + U v1\n2  e-ivtc-1t2 \n \niUc#\n- 1t2 = U v1\n2  eivt c+1t2 - U v0\n2  c-1t2, \n \n(3.90)\nwhere c#\n+1t2 denotes a time derivative. To solve these time-dependent coupled differential equations, \nit is useful to follow the lead of the classical discussion and consider the problem from the rotating",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 109
  },
  {
    "child_id": "098cb54b-4ea1-4a31-a83f-db69d39a35d9",
    "parent_id": "bf80c9f3-b2fc-4583-b433-6b972a1d32c7",
    "text": "3.4 Time-Dependent Hamiltonians \n89\nframe. Though we don\u2019t yet have the complete tools to know how to effect this transformation, we take \nit on faith that after a frame transformation the state vector is\n \n0 c\u00031t29 = c+1t2eivt>2 0  +9 + c-1t2e-ivt>2 0  -9 \u0003 \u00a2 c+1t2eivt>2\nc-1t2e-ivt>2\u2264, \n(3.91)\nwhere 0 c\u00031t29 is the state vector as viewed from the rotating frame. If we call the coef\ufb01cients of this \nvector a{1t2, then we can write\n \n0 c\u00031t29 = a+1t2 0  +9 + a-1t2 0  -9 \u0003 \u00a2a+1t2\na-1t2\u2264, \n(3.92)\nwhere the relations between the sets of coef\ufb01cients are\n \n c+1t2 = e-ivt>2a+1t2 \n \n c-1t2 = eivt>2a-1t2. \n \n(3.93)\nThe state vector in the nonrotating frame can thus be written as\n \n0 c1t29 = a+1t2e-ivt>2 0  +9 + a-1t2eivt>2 0  -9 \u0003 \u00a2a+1t2e-ivt>2\na-1t2eivt>2 \u2264. \n(3.94)\nAnother way of viewing this transformation is to say that based upon earlier solutions of similar \nproblems [Eq. (3.35)], we expect the coef\ufb01cients c{1t2 to have time dependence of the form e|ivt>2, \nand so we have extracted that part of the solution and now need to solve for the remaining time depen-\ndence in the coef\ufb01cients a{1t2. In this view, we have simply performed a mathematical trick to make \nthe solution easier.\nIf we now substitute the expressions for c{1t2 in terms of a{1t2 into the differential \nequations (3.90), then we obtain\n \n iUa#\n+1t2 = -  U\u0006v\n2\n a+1t2 + U v1\n2\n a-1t2 \n \n iUa#\n-1t2 = U v1\n2\n a+1t2 + U\u0006v\n2\n a-1t2,  \n \n(3.95)\nwhere we have de\ufb01ned a new term\n \n\u0006v K v - v0, \n(3.96)\nwhich is the difference between the angular frequencies of the rotating \ufb01eld and the Larmor preces-\nsion due to the z-component of the magnetic \ufb01eld. Because a{1t2 are the coef\ufb01cients of the trans-\nformed state vector 0 c\u00031t29, these differential equations can be considered as comprising a transformed \nSchr\u00f6dinger equation\n \niU d\ndt\n 0\n c\u00031t29 = H\u0003\n 0\n c\u00031t29, \n(3.97)\nwhere the new Hamiltonian H\u0003 has the matrix representation\n \nH\u0003 \u0003 U\n2\n a-\u0006v\nv1\nv1\n\u0006vb. \n(3.98)\n\n90 \nSchr\u00f6dinger Time Evolution\nThus, we have transformed (by rotation or mathematical sleight of hand) the original problem \ninto a new problem that has a time-independent Hamiltonian. Once we solve the new problem, we can \nuse the transformation equations to \ufb01nd the solution to the original problem. However, because the \nnew Hamiltonian H\u0003 is time independent, we already know the solution. That is, this new problem has \nthe same form of the Hamiltonian as the spin precession problem in Section 3.2.2. Comparing the spin \nprecession Hamiltonian in Eq. (3.51) with the transformed Hamiltonian in Eq. (3.98), we note that the \nterm v0 is replaced by the new term -\u0006v. We are interested in \ufb01nding the same probability P+ S - that \nan initial 0  +9 state is later found to have evolved to the 0  -9 state. The rotational transformation does \nnot alter the 0{9 basis states so if\n \n0 c1029 = 0  +9, \n(3.99)\nthen\n \n0 c\u00031029 = 0  +9. \n(3.100)\nThe probability for a spin flip is given by\n \n P+ S - = 08- 0\n c1t290\n2 \n \n = 0 c-1t20\n2.\n \n \n(3.101)\nFrom Eq. (3.93) r",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 113
  },
  {
    "child_id": "d83fa3f4-2350-4988-840f-420ff71581dd",
    "parent_id": "bf80c9f3-b2fc-4583-b433-6b972a1d32c7",
    "text": "51) with the transformed Hamiltonian in Eq. (3.98), we note that the \nterm v0 is replaced by the new term -\u0006v. We are interested in \ufb01nding the same probability P+ S - that \nan initial 0  +9 state is later found to have evolved to the 0  -9 state. The rotational transformation does \nnot alter the 0{9 basis states so if\n \n0 c1029 = 0  +9, \n(3.99)\nthen\n \n0 c\u00031029 = 0  +9. \n(3.100)\nThe probability for a spin flip is given by\n \n P+ S - = 08- 0\n c1t290\n2 \n \n = 0 c-1t20\n2.\n \n \n(3.101)\nFrom Eq. (3.93) relating the coef\ufb01cients, we have\n \n 0 c-1t20\n2 = 0 e-ivt>2a-1t20\n2 \n \n = 0 a-1t20\n2\n \n \n(3.102)\n \n = 08- 0 c\u00031t290\n2,  \nwhich means that the probability we desire is\n \nP+ S - = 08- 0 c\u00031t290\n2. \n(3.103)\nWe obtain this spin-\ufb02ip probability using Rabi\u2019s formula in Eq. (3.63), with the change v0 S -\u0006v, \nresulting in\n \n P+ S - =\nv2\n1\n\u0006v2 + v2\n1\n  sin2 \u00a2 4\u0006v2 + v2\n1\n2\n t\u2264 \n \n =\nv2\n1\n1v - v022 + v2\n1\n  sin2 \u00a241v - v022 + v2\n1\n2\n t\u2264. \n \n(3.104)\nThis spin-\ufb02ip probability is a generalization of Rabi\u2019s formula. Note that Eq. (3.104) reduces to \nEq. (3.63) for the case v = 0, which is expected because the applied \ufb01eld in Eq. (3.83) is static and \naligned the same as the static \ufb01eld in Eq. (3.48) for the case v = 0. The static magnetic \ufb01eld case is \ngenerally referred to as spin precession, while the rotating \ufb01eld case is referred to as Rabi \ufb02opping. \nThough we have used their similarities to help us derive Eq. (3.104), it is important to clarify their dif-\nferences. In the static applied magnetic \ufb01eld case, the resulting spin precession is a manifestation of \nthe natural Bohr oscillation of a quantum system that starts in a superposition of energy eigenstates. \nThe initial superposition remains intact and there is no exchange of energy between the system and \nthe applied \ufb01eld. In the rotating applied magnetic \ufb01eld case, the Rabi \ufb02opping represents transitions \nbetween energy eigenstates, and there is exchange of energy between the system and the applied \ufb01eld. \nThe energy exchange occurs because the Hamiltonian is time dependent.\n\n3.4 Time-Dependent Hamiltonians \n91\nThe probability of a Rabi spin \ufb02ip oscillates with an angular frequency given by\n \n\t = 41v - v022 + v2\n1, \n(3.105)\nthat is typically referred to as the generalized Rabi frequency. The term Rabi frequency generally \nrefers to the frequency v1, which is the value of the generalized Rabi frequency when the frequency v \nof the rotating \ufb01eld is on resonance (i.e., v is set equal to the Larmor precession frequency v0 of the \nsystem in the presence of the magnetic \ufb01eld B0 alone). For this choice of v = v0, the probability of a \nspin \ufb02ip becomes\n \nP+ S - = sin2 av1\n2\n tb, \n(3.106)\nwhich implies that the spin is \ufb02ipped with 100% probability at an angular frequency v1. For other off-\nresonance choices of the frequency v, the probability of a spin \ufb02ip oscillates with an amplitude smaller \nthan one. The amplitude of the spin-\ufb02ip oscillation, as a function of the frequency v of the rotating \n\ufb01eld, is plotted in Fig. 3.",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 113
  },
  {
    "child_id": "9b529cca-92f6-402e-8689-02da94944c15",
    "parent_id": "bf80c9f3-b2fc-4583-b433-6b972a1d32c7",
    "text": "he \nsystem in the presence of the magnetic \ufb01eld B0 alone). For this choice of v = v0, the probability of a \nspin \ufb02ip becomes\n \nP+ S - = sin2 av1\n2\n tb, \n(3.106)\nwhich implies that the spin is \ufb02ipped with 100% probability at an angular frequency v1. For other off-\nresonance choices of the frequency v, the probability of a spin \ufb02ip oscillates with an amplitude smaller \nthan one. The amplitude of the spin-\ufb02ip oscillation, as a function of the frequency v of the rotating \n\ufb01eld, is plotted in Fig. 3.11. This curve has the form of a Lorentzian curve and clearly exhibits the \nimportant resonant behavior of the spin-\ufb02ip probability. The full width at half maximum (FWHM) of \nthe resonance curve is 2v1.\nFor the resonance condition v = v0, the probability of a spin \ufb02ip as a function of time is plotted \nin Fig. 3.12. Because the frequency v1 is proportional to the applied \ufb01eld B1, the rate of spin \ufb02ipping \nincreases with increasing rotating magnetic \ufb01eld strength. However, it is important to note that there \nis still 100% probability of a spin \ufb02ip for very small \ufb01elds. This is the property we were looking for at \nthe beginning of the problem\u2014a way to \ufb02ip the spin without perturbing the system appreciably. After \na time t given by v1t = p, the probability for a spin \ufb02ip is 100%. We have assumed that the applied \n\ufb01eld is on continuously, but this spin \ufb02ip can also be produced by a pulsed \ufb01eld with a magnitude and \nduration that satisfy v1t = p. Such a pulse is often called a P-pulse and is used to \ufb02ip a spin, or more \ngenerally to make a transition from one energy state to another with 100% certainty. The diagram on \nthe right of Fig. 3.12 illustrates the energy levels of the spin in the magnetic \ufb01eld and how the spin-\ufb02ip \noscillations are associated with transitions between the two energy levels. A transition from the upper \nlevel to the lower level takes energy from the atom and gives it to the magnetic \ufb01eld and is known as \nemission, while the opposite process takes energy from the \ufb01eld and is known as absorption.\n0\n0.5\n1.0\n2\u03a91\n\u03a90\n\u03a9\nP+\u2192\u2212,max\nFIGURE 3.11 Magnetic resonance curve showing the probability \nof a spin \ufb02ip as a function of the applied  frequency.\n\n92 \nSchr\u00f6dinger Time Evolution\n3.4.2 \u0002 Light-Matter Interactions\nThis same model of the interaction between a two-level system and an applied time-dependent \ufb01eld is \nused to explain how atoms absorb and emit light. In the magnetic resonance example above, the oscil-\nlating magnetic \ufb01eld interacts with the magnetic dipole and energy is exchanged between the \ufb01eld and \nthe dipole. In the interaction of atoms with light, the oscillating electric \ufb01eld of the light wave interacts \nwith the electric dipole of the atom, and energy exchange between the \ufb01eld and the atom corresponds to \nabsorption and emission of photons. We can use the Rabi \ufb02opping formula of Eq. (3.104) to model the \natom-light interaction as long as we express the Hamiltonian of the system in the form of Eq. (3.86). \nThough atoms have more than",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 113
  },
  {
    "child_id": "85aba7dc-b496-4cb9-b85c-e418432c539f",
    "parent_id": "bf80c9f3-b2fc-4583-b433-6b972a1d32c7",
    "text": " dipole and energy is exchanged between the \ufb01eld and \nthe dipole. In the interaction of atoms with light, the oscillating electric \ufb01eld of the light wave interacts \nwith the electric dipole of the atom, and energy exchange between the \ufb01eld and the atom corresponds to \nabsorption and emission of photons. We can use the Rabi \ufb02opping formula of Eq. (3.104) to model the \natom-light interaction as long as we express the Hamiltonian of the system in the form of Eq. (3.86). \nThough atoms have more than two energy levels, we can reduce the problem to a two-level system if \nthe frequency v of the applied light \ufb01eld is close to just one of the Bohr frequencies of the atom.\nConsider two levels of an atom, as shown in Fig. 3.13. Following the convention used in this com-\nmon problem, we label the lower state 0 g9 (for ground state) and the upper state 0 e9 (for excited state). \nThe energy difference between the two levels is de\ufb01ned to be\n \nEe - Eg = U v0 \n(3.107)\nto connect to the spin notation. The applied light \ufb01eld (e.g., laser beam) has a frequency v that is close \nto, but not necessarily equal to, the atomic Bohr frequency v0. Using the same notation as the spin \nproblem [Eq. (3.86)], we express the Hamiltonian for this atom-light system in two parts\n \nH \u0003 U\n2\n a v0\nv1e-ivt\nv1eivt\n-v0\nb = U\n2\n av0\n0\n0\n-v0\nb + U\n2\n a\n0\nv1e-ivt\nv1eivt\n0\nb \n(3.108)\nEe\nEg\n\u0002\u03a90\n\u0002\u03a9\n\u0002e\u0003\n\u0002g\u0003\nFIGURE 3.13 Energy level diagram of a two-level atom interacting with \nan applied light \ufb01eld of frequency v.\nt\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nemission\nabsorption\nemission\nabsorption\nemission\nabsorption\nP+\u2192\u2212\n\u03a0\n\u03a91\n2\u03a0\n\u03a91\n3\u03a0\n\u03a91\n4\u03a0\n\u03a91\n\u0002\u0004\u0003\n\u0002\u0005\u0003\nFIGURE 3.12 Rabi oscillations of the spin-\ufb02ip probability for the resonance condition.",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 113
  },
  {
    "child_id": "8fb2f828-e2b2-447f-94f9-7f8a74864209",
    "parent_id": "33d7064e-1e86-42cd-bbc8-60ea5f699ead",
    "text": "Summary \n93\nand identify the \ufb01rst term as the atomic Hamiltonian and the second term as the interaction Hamilto-\nnian. In this way, we see that the parameter v1 is really an off-diagonal matrix element of the interac-\ntion Hamiltonian that connects the two states:\n \nv1 = 2\nU\n 8e0 Hint0 g9. \n(3.109)\nThe Rabi formula in Eq. (3.104) then gives the probability for the light \ufb01eld to cause transitions \nbetween the two atomic energy states. Transitions between the atomic states correspond to absorption \n10 g9 S 0 e92 and emission 10 e9 S 0 g92 of photons in the light \ufb01eld. Total energy is conserved as it is \nexchanged between the atom and the light \ufb01eld.\nStudying these induced transitions is the most powerful tool we have for discovering what the \nenergy levels of a system are and ultimately for determining the Hamiltonian of the system. This \ntool is known as spectroscopy and has played a pivotal role in relating experiments and theory in \nquantum mechanics. As we encounter new quantum mechanical systems in this text, we will point \nout the spectroscopic aspects of these systems. For now, we can make a few general comments. If the \nmatrix element of the interaction Hamiltonian in Eq. (3.109) happens to be zero, then the transition \nprobability between the two levels is zero and we say that this is a forbidden transition. By studying \nthe general properties of the matrix elements 8e0 Hint0 g9 for a system and an interaction, we can dis-\ncover a set of basic rules governing whether transitions are allowed or forbidden. These are known as \nselection rules and are often representative of some underlying symmetry in the system. We will discuss \nselection rules brie\ufb02y as we encounter new systems and then will study them more fully in Chapter 14.\nSUMMARY\nIn this chapter we have learned the key aspect of quantum mechanics\u2014how to predict the future. \nSchr\u00f6dinger\u2019s equation\n \niU d\ndt\n 0\n c1t29 = H1t20\n c1t29 \n(3.110)\ntells us how quantum state vectors evolve with time. In the common case where the Hamiltonian \nis time independent, the solution to Schr\u00f6dinger\u2019s equation has the same form no matter the problem. The \ntime-evolved state includes energy-dependent phase factors for each component of the superposition \nthat the system starts in:\n \n0 c1t29 = a\nn\ncne-iEnt>U0 En9. \n(3.111)\nThe general recipe for solving time-dependent problems is\nGiven a Hamiltonian H and an initial state 0 c1029, what is the probability that \nthe eigenvalue aj of the observable A is measured at time t?\n 1. Diagonalize H (\ufb01nd the eigenvalues En and eigenvectors 0 En92.\n 2. Write 0 c1029 in terms of the energy eigenstates 0 En9.\n 3. Multiply each eigenstate coef\ufb01cient by e-iEnt>U to get 0 c1t29.\n 4. Calculate the probability Paj = 08aj0 c1t290\n2.\nWe will use this recipe throughout the rest of the book to study the time evolution of quantum mechan-\nical systems where the Hamiltonian is time independent.\n\n94 \nSchr\u00f6dinger Time Evolution\nPROBLEMS\n 3.1 Write out the Schr\u00f6dinger equation as expr",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 117
  },
  {
    "child_id": "326aa2b5-1e94-4217-a29b-fe18db46aefb",
    "parent_id": "33d7064e-1e86-42cd-bbc8-60ea5f699ead",
    "text": "me t?\n 1. Diagonalize H (\ufb01nd the eigenvalues En and eigenvectors 0 En92.\n 2. Write 0 c1029 in terms of the energy eigenstates 0 En9.\n 3. Multiply each eigenstate coef\ufb01cient by e-iEnt>U to get 0 c1t29.\n 4. Calculate the probability Paj = 08aj0 c1t290\n2.\nWe will use this recipe throughout the rest of the book to study the time evolution of quantum mechan-\nical systems where the Hamiltonian is time independent.\n\n94 \nSchr\u00f6dinger Time Evolution\nPROBLEMS\n 3.1 Write out the Schr\u00f6dinger equation as expressed in Eq. (3.5) in matrix form for the two-state \nsystem and verify the result in Eq. (3.8).\n 3.2 Show that the probability of a measurement of the energy is time independent for a general state \n \n 0 c1t29 = a\nn\ncn1t2 0 En9 that evolves due to a time-independent Hamiltonian. Show that the \n \n probability of measurements of other observables are also time independent if those observables \ncommute with the Hamiltonian.\n 3.3 Show that the Hamiltonian in Eq. (3.51) can be written in the simple form of Eq. (3.56). \nDiagonalize the Hamiltonian in Eq. (3.55) and con\ufb01rm the results in Eq. (3.57).\n 3.4 Consider a spin-1/2 particle with a magnetic moment placed in a uniform magnetic \ufb01eld \naligned with the z-axis. Verify by explicit matrix calculations that the Hamiltonian commutes \nwith the spin component operator in the z-direction but not with spin component operators in \nthe x- and y-directions. Comment on the relevance of these results to spin precession.\n 3.5 Consider a spin-1/2 particle with a magnetic moment. At time t = 0, the state of the particle is \n0 c1t = 029 = 0  +9.\na) If the observable Sx is measured at time t = 0, what are the possible results and the \nprobabilities of those results?\nb) Instead of performing the above measurement, the system is allowed to evolve in a uniform \nmagnetic \ufb01eld B = B0yn. Calculate the state of the system (in the Sz basis) after a time t.\nc) At time t, the observable Sx is measured. What is the probability that a value U>2 will be \nfound?\nd) Draw a schematic diagram of the experiment in parts (b) and (c), similar to Fig. 3.2.\n 3.6 Consider a spin-1/2 particle with a magnetic moment.\na) At time t = 0, the observable Sx is measured, with the result U>2. What is the state vector \n0 c1t = 029 immediately after the measurement?\nb) Immediately after the measurement, a magnetic \ufb01eld B = B0zn is applied and the particle is \nallowed to evolve for a time T. What is the state of the system at time t \u0003 T?\nc) At t = T, the magnetic \ufb01eld is very rapidly changed to B = B0yn. After another time inter-\nval T, a measurement of Sx is carried out once more. What is the probability that a value U>2 \nis found?\n 3.7 A beam of identical neutral particles with spin 1/2 travels along the y-axis. The beam passes \nthrough a series of two Stern-Gerlach spin-analyzing magnets, each of which is designed to \nanalyze the spin component along the z-axis. The \ufb01rst Stern-Gerlach analyzer allows only \nparticles with spin up (along the z-axis) to pass thr",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 117
  },
  {
    "child_id": "7fac2bdf-9894-452f-aa89-7c2aa00a51d4",
    "parent_id": "33d7064e-1e86-42cd-bbc8-60ea5f699ead",
    "text": "very rapidly changed to B = B0yn. After another time inter-\nval T, a measurement of Sx is carried out once more. What is the probability that a value U>2 \nis found?\n 3.7 A beam of identical neutral particles with spin 1/2 travels along the y-axis. The beam passes \nthrough a series of two Stern-Gerlach spin-analyzing magnets, each of which is designed to \nanalyze the spin component along the z-axis. The \ufb01rst Stern-Gerlach analyzer allows only \nparticles with spin up (along the z-axis) to pass through. The second Stern-Gerlach analyzer \nallows only particles with spin down (along the z-axis) to pass through. The particles travel at \nspeed v between the two analyzers, which are separated by a region of length d in which there \nis a uniform magnetic \ufb01eld B0 pointing in the x-direction. Determine the smallest value of d \nsuch that 25% of the particles transmitted by the \ufb01rst analyzer are transmitted by the second \nanalyzer.\n 3.8 A beam of identical neutral particles with spin 1/2 is prepared in the 0  +9 state. The beam enters \na uniform magnetic \ufb01eld B0, which is in the xz-plane and makes an angle u with the z-axis. \nAfter a time T in the \ufb01eld, the beam enters a Stern-Gerlach analyzer oriented along the y-axis. \nWhat is the probability that particles will be measured to have spin up in the y-direction? Check \nyour result by evaluating the special cases u = 0 and u = p>2.\n\n3.9 Consider a spin-1/2 particle with a magnetic moment. At time t = 0, the state of the particle is \n0 c1t = 029 = 0  +9n with the direction n = 1xn + yn2> 12. The system is allowed to evolve in \na uniform magnetic \ufb01eld B = B0zn. What is the probability that the particle will be measured to \nhave spin up in the y-direction after a time t?\n 3.10 Consider a spin-1/2 particle with a magnetic moment. At time t = 0, the state of the \nparticle is 0 c1t = 029 = 0  +9. The system is allowed to evolve in a uniform magnetic \ufb01eld \nB = B01xn + zn2> 12. What is the probability that the particle will be measured to have spin \ndown in the z-direction after a time t?\n 3.11 Consider a spin-1/2 particle with a magnetic moment. At time t = 0, the state of the particle is \n0 c1t = 029 = 0  +9n with the direction n = 1xn + yn2> 12. The system is allowed to evolve in \na uniform magnetic \ufb01eld B = B01xn + zn2> 12. What is the probability that the particle will be \nmeasured to have spin up in the y-direction after a time t?\n 3.12 Consider a two-state quantum system with a Hamiltonian\nH \u0003 aE1\n0\n0\nE2\nb .\n \n Another physical observable A is described by the operator\nA \u0003 a0\na\na\n0b,\n \n where a is real and positive. Let the initial state of the system be 0 c1029 = 0 a19, where 0 a19 is \nthe eigenstate corresponding to the larger of the two possible eigenvalues of A. What is the \nfrequency of oscillation (i.e., the Bohr frequency) of the expectation value of A?\n 3.13 Let the matrix representation of the Hamiltonian of a three-state system be\nH \u0003 \u00b0\nE0\n0\nA\n0\nE1\n0\nA\n0\nE0\n \u00a2\n \n using the basis states 0 19, 0 29, and ",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 117
  },
  {
    "child_id": "ba17c43a-badd-4601-9f09-f1c1b6f9a42a",
    "parent_id": "33d7064e-1e86-42cd-bbc8-60ea5f699ead",
    "text": "ysical observable A is described by the operator\nA \u0003 a0\na\na\n0b,\n \n where a is real and positive. Let the initial state of the system be 0 c1029 = 0 a19, where 0 a19 is \nthe eigenstate corresponding to the larger of the two possible eigenvalues of A. What is the \nfrequency of oscillation (i.e., the Bohr frequency) of the expectation value of A?\n 3.13 Let the matrix representation of the Hamiltonian of a three-state system be\nH \u0003 \u00b0\nE0\n0\nA\n0\nE1\n0\nA\n0\nE0\n \u00a2\n \n using the basis states 0 19, 0 29, and 0 39.\na) If the state of the system at time t = 0 is 0 c1029 = 0 29, what is the probability that the \nsystem is in state 0 29 at time t?\nb) If, instead, the state of the system at time t = 0 is 0 c1029 = 0 39, what is the probability that \nthe system is in state 0 39 at time t?\n 3.14 A quantum mechanical system starts out in the state\n0 c1029 = C130 a19 + 40 a292,\n \n where 0 ai9 are the normalized eigenstates of the operator A corresponding to the eigenvalues ai. \nIn this 0 ai9 basis, the Hamiltonian of this system is represented by the matrix\nH \u0003 E0 a2\n1\n1\n2b.\na) If you measure the energy of this system, what values are possible, and what are the \nprobabilities of measuring those values?\nb) Calculate the expectation value 8A9 of the observable A as a function of time.\nProblems \n95\n\n96 \nSchr\u00f6dinger Time Evolution\n 3.15 Show that the general energy state superposition 0 c1t29 = a\nn\ncne-iEnt>U0 En9 satis\ufb01es the \n \n Schr\u00f6dinger equation, but not the energy eigenvalue equation.\n 3.16 For a spin-1/2 system undergoing Rabi oscillations, assume that the resonance condition \nv = v0 holds.\na) Solve the differential equations for the coef\ufb01cients a{1t2. Use your results to \ufb01nd the \ntransformed state vector 0 c\u00031t29 and the state vector 0 c1t29, assuming the most general \ninitial state of the system.\nb) Verify that a p-pulse (v1t = p) produces a complete spin \ufb02ip. Calculate both the \ntransformed state vector 0 c\u00031t29 and the state vector 0 c1t29.\nc) Assume that the interaction time is such that v1t = p>2. Find the effect on the system \nif the initial state is 0  +9.\nd) Discuss the differences between the original reference frame and the rotating reference \nframe in light of your results.\n 3.17 Consider an electron neutrino with an energy of 8 MeV. How far must this neutrino travel \nbefore it oscillates to a muon neutrino? Assume the neutrino mixing parameters given in the \ntext. How many complete oscillations (ne S nm S ne) will take place if this neutrino travels \nfrom the sun to the earth? Through the earth?\n 3.18 Many weak decay processes produce neutrinos with a spectrum of energies. Assume electron \nneutrinos are produced with a uniform distribution from 4 MeV to 8 MeV. By averaging the \nprobability over the energy spectrum, calculate and plot, as a function of the travel distance L, \nthe probability that electron neutrinos are measured at the detector. Compare the result with the \nprobability for monoenergetic neutrinos at 8 MeV. The integral required for the a",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 117
  },
  {
    "child_id": "fe5fd5ef-cde7-4653-bc28-fc5546f0ea18",
    "parent_id": "33d7064e-1e86-42cd-bbc8-60ea5f699ead",
    "text": "n to the earth? Through the earth?\n 3.18 Many weak decay processes produce neutrinos with a spectrum of energies. Assume electron \nneutrinos are produced with a uniform distribution from 4 MeV to 8 MeV. By averaging the \nprobability over the energy spectrum, calculate and plot, as a function of the travel distance L, \nthe probability that electron neutrinos are measured at the detector. Compare the result with the \nprobability for monoenergetic neutrinos at 8 MeV. The integral required for the averaging does \nnot yield an elementary expression, so a computer is advisable. Assume the neutrino mixing \nparameters given in the text.\nRESOURCES\nActivities\nThis activity is available at\nwww.physics.oregonstate.edu/qmactivities\nSpins Lab 4: Students design experiments to study spin precession in a magnetic \ufb01eld.\nFurther Reading\nPedagogical articles on neutrino oscillations:\nW. C. Haxton and B. R. Holstein, \u201cNeutrino physics,\u201d Am. J. Phys. 68, 15\u201332 (2000).\nW. C. Haxton and B. R. Holstein, \u201cNeutrino physics: An update,\u201d Am. J. Phys. 72, 18\u201324 (2004).\nE. Sassaroli, \u201cNeutrino oscillations: A relativistic example of a two-level system,\u201d Am. J. Phys. \n67, 869\u2013875 (1999).\nC. Waltham, \u201cTeaching neutrino oscillations,\u201d Am. J. Phys. 72, 742\u2013752 (2004).\nThe application of Rabi oscillations to atomic physics is the main focus of this book:\nL. Allen and J. H. Eberly, Optical Resonance and Two-Level Atoms, New York: Dover \nPublications, Inc., 1987.",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 117
  },
  {
    "child_id": "698ba317-bb11-4a1b-8624-b3f0398cfb0f",
    "parent_id": "2f37d376-3ff6-4c85-bab8-d3eb23a233f6",
    "text": "97\nC H A P T E R \n4\nQuantum Spookiness\nAs we have seen in the previous chapters, many aspects of quantum mechanics run counter to our \nphysical intuition, which is formed from our experience living in the classical world. The probabilistic \nnature of quantum mechanics does not agree with the certainty of the classical world\u2014we have no \ndoubt that the sun will rise tomorrow. Moreover, the disturbance of a quantum mechanical system \nthrough the action of measurement makes us part of the system, rather than an independent observer. \nThese issues and others make us wonder what is really going on in the quantum world. As quantum \nmechanics was being developed in the early twentieth century, many of the world\u2019s greatest physicists \ndebated the \u201ctrue meaning\u201d of quantum mechanics. They often developed gedanken experiments or \nthought experiments to illustrate their ideas. Some of these gedanken experiments have now actually \nbeen performed and some are still being pursued.\nIn this chapter, we present a few of the gedanken and real experiments that demonstrate the \nspookiness of quantum mechanics. We present enough details to give a \ufb02avor of the spookiness and \nprovide references for further readings on these topics at the end of the chapter.\n4.1 \u0002  EINSTEIN-PODOLSKY-ROSEN PARADOX\nAlbert Einstein was never comfortable with quantum mechanics. He is famously quoted as saying \n\u201cGott w\u00fcrfelt nicht\u201d or \u201cGod does not play dice,\u201d to express his displeasure with the probabilistic \nnature of quantum mechanics. But his opposition to quantum mechanics ran deeper than that. He felt \nthat properties of physical objects have an objective reality independent of their measurement, much \nas Erwin felt that his socks were black or white, or long or short, independent of his pulling them out \nof the drawer. In quantum mechanics, we cannot say that a particle whose spin is measured to be up \nhad that property before the measurement. It may well have been in a superposition state. Moreover, \nwe can only know one spin component of a particle, because measurement of one component disturbs \nour knowledge of the other components. Because of these apparent de\ufb01ciencies, Einstein believed that \nquantum mechanics was an incomplete description of reality.\nIn 1935, Einstein, Boris Podolsky, and Nathan Rosen published a paper presenting a gedan-\nken experiment designed to expose the shortcomings of quantum mechanics. The EPR Paradox \n(Einstein-Podolsky-Rosen) tries to paint quantum mechanics into a corner and expose the \u201cabsurd\u201d \nbehavior of the theory. The essence of the argument is that if you believe that measurements on two \nwidely separated particles cannot in\ufb02uence each other, then the quantum mechanics of an ingeniously \nprepared two-particle system leads you to conclude that the physical properties of each particle are \nreally there\u2014they are elements of reality in the authors\u2019 words.\n\n98 \nQuantum Spookiness\nThe experimental situation is depicted in Fig. 4.1 (this version of the",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 121
  },
  {
    "child_id": "d7570463-60d5-4cd6-beb1-03cf4a18033b",
    "parent_id": "2f37d376-3ff6-4c85-bab8-d3eb23a233f6",
    "text": "o a corner and expose the \u201cabsurd\u201d \nbehavior of the theory. The essence of the argument is that if you believe that measurements on two \nwidely separated particles cannot in\ufb02uence each other, then the quantum mechanics of an ingeniously \nprepared two-particle system leads you to conclude that the physical properties of each particle are \nreally there\u2014they are elements of reality in the authors\u2019 words.\n\n98 \nQuantum Spookiness\nThe experimental situation is depicted in Fig. 4.1 (this version of the EPR experiment is due to \nDavid Bohm and has been updated by N. David Mermin). An unstable particle with spin 0 decays into \ntwo spin-1/2 particles, which by conservation of angular momentum must have opposite spin compo-\nnents and by conservation of linear momentum must travel in opposite directions. For example, a neu-\ntral pi meson decays into an electron and a positron: p0 S e- + e+. Observers A and B are on opposite \nsides of the decaying particle and each has a Stern-Gerlach apparatus to measure the spin component \nof the particle headed in its direction. Whenever one observer measures spin up along a given direc-\ntion, then the other observer measures spin down along that same direction. The quantum state of this \ntwo-particle system is\n \n0\n c9 =\n1\n12 10  +91 0  -92 - 0  -91 0  +922 , \n(4.1)\nwhere the subscripts label the particles and the relative minus sign ensures that this is a spin-0 state \n(as we\u2019ll discover in Chapter 11). The use of a product of kets 1e.g., 0  +91 0  -922 is required here to \ndescribe the two-particle system (Problem 4.1). The kets and operators for the two particles are inde-\npendent, so, for example, operators act only on their own kets\n \nS1z0  +91 0  -92 = 1S1z0  +912 0  -92 = + U\n2\n 0  +91 0  -92, \n(4.2)\nand inner products behave as\n \n118+ 0 2 8-  0210  +91 0  -922 = 118+\n 0  +912128-  0  -922 = 1. \n(4.3)\nAs shown in Fig. 4.1, observer A measures the spin component of particle 1 and observer B mea-\nsures the spin component of particle 2. The probability that observer A measures particle 1 to be spin \nup is 50% and the probability for spin down is 50%. The 50-50 split is the same for observer B. For a \nlarge ensemble of decays, each observer records a random sequence of spin up and spin down results, \nwith a 50>50 ratio. But, because of the correlation between the spin components of the two particles, \nif observer A measures spin up (i.e., S1z = +U>2), then we can predict with 100% certainty that the \nresult of observer B\u2019s measurement will be spin down (S2z = -U>2). The result is that even though \neach observer records a random sequence of ups and downs, the two sets of results are perfectly anticor-\nrelated. The state 0\n c9 in Eq. (4.1) that produces this strange mixture of random and correlated measure-\nment results is known as an entangled state. The spins of the two particles are entangled with each \nother and produce this perfect correlation between the measurements of observer A and observer B.\nImagine that the tw",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 121
  },
  {
    "child_id": "6b866a1a-602d-49e9-9fef-41d47594b6e8",
    "parent_id": "2f37d376-3ff6-4c85-bab8-d3eb23a233f6",
    "text": "ement will be spin down (S2z = -U>2). The result is that even though \neach observer records a random sequence of ups and downs, the two sets of results are perfectly anticor-\nrelated. The state 0\n c9 in Eq. (4.1) that produces this strange mixture of random and correlated measure-\nment results is known as an entangled state. The spins of the two particles are entangled with each \nother and produce this perfect correlation between the measurements of observer A and observer B.\nImagine that the two observers are separated by a large distance, with observer B slightly farther \nfrom the decay source than observer A. Once observer A has made the measurement S1z = +U>2, we \nknow that the measurement by observer B in the next instant will be spin down 1S2 z = -U>22. We con-\nclude that the state 0\n c9 in Eq. (4.1) instantaneously collapses onto the state 0  +91 0  -92 , and the measure-\nment by observer A has somehow determined the measurement result of observer B. Einstein referred \nto this as \u201cspooky action at a distance\u201d (spukhafte Fernwirkungen). The result that observer B records is \nstill random, it is just that its randomness is perfectly anticorrelated with observer A\u2019s random result. \nA\nB\nParticle 1 \nParticle 2 \nSpin 0\nSource \nS2z\nS1z\nFIGURE 4.1 Einstein-Podolsky-Rosen gedanken experiment.\n\n4.1 Einstein-Podolsky-Rosen Paradox \n99\nHence, there is no problem with faster-than-light communication here because there is no information \ntransmitted between the two observers.\nThe EPR argument contends that because we can predict a measurement result with 100% cer-\ntainty 1e.g., S2z = -U>22, then that result must be a \u201creal\u201d property of the particle\u2014it must be an ele-\nment of reality. Because the particles are widely separated, this element of reality must be independent \nof what observer A does, and hence, must have existed all along. The independence of the elements of \nreality of the two  particles is called Einstein\u2019s locality principle, and is a fundamental assumption of \nthe EPR argument.\nThe correlation of spin measurements of the two observers is independent of the choice of mea-\nsurement direction, assuming the same direction for both observers. That is, if observer A measures \nthe x-component of spin and records S1x = +U>2, then we know with 100% certainty that observer B \nwill measure S2x = -U>2. Observer A is free to choose to measure S1x, S1y, or S1z, so EPR argue that \nS2x, S2y, and S2z must all be elements of reality for particle 2. However, quantum mechanics maintains \nthat we can know only one spin component at a time for a single particle. EPR conclude that quantum \nmechanics is an incomplete description of physical reality because it does not describe all the elements \nof reality of the particle.\nIf the EPR argument is correct, then the elements of reality, which are also called hidden vari-\nables or instruction sets, are really there, but for some reason we cannot know all of them at once. \nThus, one can imagine constructing a local h",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 121
  },
  {
    "child_id": "2158ec49-3e74-456e-bb09-c401b438684a",
    "parent_id": "2f37d376-3ff6-4c85-bab8-d3eb23a233f6",
    "text": " mechanics maintains \nthat we can know only one spin component at a time for a single particle. EPR conclude that quantum \nmechanics is an incomplete description of physical reality because it does not describe all the elements \nof reality of the particle.\nIf the EPR argument is correct, then the elements of reality, which are also called hidden vari-\nables or instruction sets, are really there, but for some reason we cannot know all of them at once. \nThus, one can imagine constructing a local hidden variable theory wherein there are different types of \nparticles with different instruction sets that determine the results of measurements. The theory is local \nbecause the instruction sets are local to each particle so that measurements by the two observers are \nindependent. The populations or probabilities of the different instruction sets can be properly adjusted \nin a local hidden variable theory to produce results consistent with quantum mechanics. Because quan-\ntum mechanics and a local hidden variable theory cannot be distinguished by experiment, the question \nof which is correct is then left to the realm of metaphysics. For many years, this was what many physi-\ncists believed. After all, it doesn\u2019t seem unreasonable to believe that there are things we cannot know!\nHowever, in 1964, John Bell showed that the hidden variables that we cannot know cannot even \nbe there! Bell showed that there are speci\ufb01c measurements that can be made to distinguish between a \nlocal hidden variable theory and quantum mechanics. The results of these quantum mechanics experi-\nments are not compatible with any local hidden variable theory. Bell derived a very general relation, \nbut we present a speci\ufb01c one here for simplicity.\nBell\u2019s argument relies on observers A and B making measurements along a set of different direc-\ntions. Consider three directions an, bn, cn in a plane as shown in Fig. 4.2, each 120\u00b0 from any of the other \ntwo. Each observer makes measurements of the spin projection along one of these three directions, \nchosen randomly. Any single observer\u2019s result can be only spin up or spin down along that direction, \nbut we record the results independent of the direction of the Stern-Gerlach analyzers, so we denote \none observer\u2019s result simply as  + or  -, without noting the axis of measurement. The results of the pair \nParticle 1 \nParticle 2 \na\u2227\nb\n\u2227\nc\u2227\nA\nB\nSpin 0\nSource \na\u2227\nb\n\u2227\nc\u2227\nFIGURE 4.2 Measurement of spin components along three directions as proposed by Bell.",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 121
  },
  {
    "child_id": "311eee56-8ab0-4e65-98ca-8c7cbb3b5317",
    "parent_id": "84381b89-8aa6-4af7-8808-d4736015c7e5",
    "text": "100 \nQuantum Spookiness\nof measurements from one correlated pair of particles (i.e., one decay from the source) are denoted \n+ -, for example, which means observer A recorded a + and observer B recorded a -. There are only \nfour possible system results: + +,  + -,  - +, or  - -. Even more simply, we classify the results as \neither the same, + + or  - -, or opposite, + - or  - +.\nA local hidden variable theory needs a set of instructions for each particle that speci\ufb01es ahead \nof time what the results of measurements along the three directions an, bn, cn will be. For example, the \ninstruction set 1an  +, bn  +, cn +2 means that a measurement along any one of the three directions will \nproduce a spin up result. For the entangled state of the system given by Eq. (4.1), measurements by the \ntwo observers along the same direction can yield only the results + - or  - +. To reproduce this aspect \nof the data, a local hidden variable theory would need the eight instruction sets shown in Table 4.1. For \nexample, the instruction set 1an  +, bn  -, cn +2 for particle 1 must be paired with the set 1an  -, bn  +, cn -2 for \nparticle 2 in order to produce the proper correlations of the entangled state. Beyond that requirement, \nwe allow the proponent of the local hidden variable theory freedom to adjust the populations Ni (or \nprobabilities) of the different instruction sets as needed to make sure that the hidden variable theory \nagrees with the quantum mechanical results.\nNow use the instruction sets (i.e., the local hidden variable theory) to calculate the prob-\nability that the results of the spin component measurements are the same 1Psame = P+ + + P- -2 \nand the probability that the results are opposite 1Popp = P+ - + P+ -2, considering all possible \norientations of the spin measurement devices. There are nine different combinations of measure-\nment directions for the pair of observers: anan, anbn, ancn, bnan, bnbn, bncn, cnan, cnbn, cncn. If we consider particles \nof type 1 (i.e., instruction set 1), then for each of these nine possibilities, the results are opposite \n(+ -). The results are never the same for particles of type 1. The same argument holds for type \n8 particles. For type 2 particles, the instruction sets 1an  +, bn  +, cn -2 and 1an  -, bn  -, cn +2 yield the\nnine possible results + -,  + -,  + +,  + -,  + -,  + +,  - -,  - -,  - + with four possibilities of \nrecording the same results and \ufb01ve possibilities for recording opposite results. Thus, we arrive at the \nfollowing probabilities for the different particle types:\n \nPopp = 1\nPsame = 0 r types 1 & 8 \n \nPopp = 5\n9\nPsame = 4\n9\nt types 2 S 7 . \n \n(4.4)\nTable 4.1 Instruction Sets (Hidden Variables)\nPopulation\nParticle 1\nParticle 2\nN1\nN2\nN3\nN4\nN5\nN6\nN7\nN8\n1an\n  +, bn\n +, cn\n +2\n1an\n  +, bn\n +, cn\n -2\n1an\n  +, bn\n -, cn\n +2\n1an\n  +, bn\n -, cn\n -2\n1an\n  -, bn\n +, cn\n +2\n1an\n  -, bn\n +, cn\n -2\n1an\n  -, bn\n -, cn\n +2\n1an\n  -, bn\n -, cn\n -2\n1an\n  -, bn\n -, cn\n -2\n1an\n  -, bn\n -, cn\n +2\n1an\n  -, bn\n",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 124
  },
  {
    "child_id": "5728bc2c-85e6-4300-958c-10548caeeb51",
    "parent_id": "84381b89-8aa6-4af7-8808-d4736015c7e5",
    "text": "ve at the \nfollowing probabilities for the different particle types:\n \nPopp = 1\nPsame = 0 r types 1 & 8 \n \nPopp = 5\n9\nPsame = 4\n9\nt types 2 S 7 . \n \n(4.4)\nTable 4.1 Instruction Sets (Hidden Variables)\nPopulation\nParticle 1\nParticle 2\nN1\nN2\nN3\nN4\nN5\nN6\nN7\nN8\n1an\n  +, bn\n +, cn\n +2\n1an\n  +, bn\n +, cn\n -2\n1an\n  +, bn\n -, cn\n +2\n1an\n  +, bn\n -, cn\n -2\n1an\n  -, bn\n +, cn\n +2\n1an\n  -, bn\n +, cn\n -2\n1an\n  -, bn\n -, cn\n +2\n1an\n  -, bn\n -, cn\n -2\n1an\n  -, bn\n -, cn\n -2\n1an\n  -, bn\n -, cn\n +2\n1an\n  -, bn\n +, cn\n -2\n1an\n  -, bn\n +, cn\n +2\n1an\n  +, bn\n -, cn\n -2\n1an\n  +, bn\n -, cn\n +2\n1an\n  +, bn\n +, cn\n -2\n1an\n  +, bn\n +, cn\n +2\n\n4.1 Einstein-Podolsky-Rosen Paradox \n101\nTo \ufb01nd the probabilities of recording the same or opposite results in all the measurements, we \nperform a weighted average over all the possible particle types. The weight of any particular particle \ntype, for example type 1, is simply N1  \u0006aNi (recall we will adjust the actual values later as needed). \nThus, the averaged probabilities are:\n \n Psame =\n1\na\ni\nNi\n 4\n9\n 1N2 + N3 + N4 + N5 + N6 + N72 \u2026 4\n9\n \n \n Popp =\n1\na\ni\nNi\n aN1 + N8 + 5\n9\n 1N2 + N3 + N4 + N5 + N6 + N72b \u00da 5\n9\n ,  \n(4.5)\nwhere the inequalities follow because the sum of all the weights for the different particle types must \nbe unity. In summary, we can adjust the populations all we want, but that will always produce prob-\nabilities of the same or opposite measurements that are bound by the above inequalities. That is what \nis meant by a Bell inequality.\nWhat does quantum mechanics predict for these probabilities? For this system of two spin-1/2 \nparticles, we can calculate the probabilities using the concepts from the previous chapters. Assume \nthat observer A records a \u201c+\u201d along some direction (of the three). De\ufb01ne that direction as the z-axis \n(no law against that). Observer B measures along a direction nn at some angle u with respect to the \nz-axis. The probability that observer A records a \u201c+\u201d along the z-axis and observer B records a \u201c+\u201d \nalong the nn direction is\n \nP+ + = 0118+ 0   n   \n2n 8+ 02 0\n c9 0\n2 . \n(4.6)\nSubstituting the entangled state 0\n c9 and the direction eigenstate 0  +9nn  gives\n \nP+ + = 2 18+ 0 \u00a2cos u\n2  28+ 0 + e-if sin u\n2  28- 0 \u2264 1\n12 10  +91 0  -92 - 0  -91 0  +922 2\n2\n \n \n= 2 1\n12 \u00a2cos u\n2  28+ 0 + e-if sin u\n2  28- 0 \u226410  -922 2\n2\n \n \n= 1\n2\n sin2  u\n2\n . \n \n(4.7)\nThe same result is obtained for the probability that observer A records a \u201c-\u201d along the z-axis and \nobserver B records a \u201c-\u201d along the nn direction. Hence, the result for the same measurements is\n \nPsame = P+ + + P- - = sin2 u\n2\n . \n(4.8)\nThe probability that observer B records a \u201c-\u201d along the direction nn, when A records a \u201c+\u201d is\n \nP+ - = 0118+ 0     n \n2n 8- 02 0\n c9 0\n2 \n \n= 2 18+ 0 \u00a2sin u\n2  28+ 0 - e-if cos u\n2  28- 0 \u2264 1\n12 10  +91 0  -92 - 0  -91 0  +922 2\n2\n \n \n= 2 1\n12 \u00a2sin u\n2  28+ 0 - e-if cos u\n2  28- 0 \u2264 1 0  -922 2\n2\n \n \n= 1\n2\n  cos2  u\n2\n , \n \n(4.9)\n\n102 \nQuantum Spookiness\nand the probability for opposite results is\n \nPopp",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 124
  },
  {
    "child_id": "dc839ddc-dbf6-4f3b-b907-a900a8217d49",
    "parent_id": "84381b89-8aa6-4af7-8808-d4736015c7e5",
    "text": "n. Hence, the result for the same measurements is\n \nPsame = P+ + + P- - = sin2 u\n2\n . \n(4.8)\nThe probability that observer B records a \u201c-\u201d along the direction nn, when A records a \u201c+\u201d is\n \nP+ - = 0118+ 0     n \n2n 8- 02 0\n c9 0\n2 \n \n= 2 18+ 0 \u00a2sin u\n2  28+ 0 - e-if cos u\n2  28- 0 \u2264 1\n12 10  +91 0  -92 - 0  -91 0  +922 2\n2\n \n \n= 2 1\n12 \u00a2sin u\n2  28+ 0 - e-if cos u\n2  28- 0 \u2264 1 0  -922 2\n2\n \n \n= 1\n2\n  cos2  u\n2\n , \n \n(4.9)\n\n102 \nQuantum Spookiness\nand the probability for opposite results is\n \nPopp = P+  - + P-  + = cos2 u\n2\n . \n(4.10)\nThe angle u between the measurement directions of observers A and B is 0\u00b0 in 1>3 of the mea-\nsurements and 120\u00b0 in 2>3 of the measurements, so the average probabilities are\n \nPsame = 1\n3 ~ sin2 0\b\n2 + 2\n3 ~ sin2 120\b\n2\n= 1\n3 ~ 0 + 2\n3 ~ 3\n4 = 1\n2  \n \nPopp = 1\n3 ~ cos2 0\b\n2 + 2\n3 ~ cos2 120\b\n2\n= 1\n3 ~ 1 + 2\n3 ~ 1\n4 = 1\n2\n . \n \n(4.11)\nThese predictions of quantum mechanics are inconsistent with the range of possibilities that we \nderived for local hidden variable theories in Eq. (4.5). Because these probabilities can be measured, \nwe can do experiments to test whether local hidden variable theories are possible. The results of exper-\niments performed on systems that produce entangled quantum states have consistently agreed with \nquantum mechanics and hence, exclude the possibility of local hidden variable theories. We are forced \nto conclude that quantum mechanics is an inherently nonlocal theory.\nThe EPR paradox also raises issues regarding the collapse of the quantum state and how a mea-\nsurement by A can instantaneously alter the quantum state at B. However, there is no information \ntransmitted instantaneously and so there is no violation of relativity. What observer B measures is not \naffected by any measurements that A makes. The two observers notice only when they get together \nand compare results that some of the measurements (along the same axes) are correlated.\nThe entangled states of the EPR paradox have truly nonclassical behavior and so appear spooky \nto our classically trained minds. But when you are given lemons, make lemonade. Modern quantum \nresearchers are now using the spookiness of the entangled states to enable new technologies that take \nadvantage of the way that quantum mechanics stores information in these correlated systems. Quan-\ntum computers, quantum communication, and quantum information processing in general are active \nareas of research and promise to enable a new revolution in information technology.\n 4.2 \u0002 SCHR\u00d6DINGER CAT PARADOX\nThe Schr\u00f6dinger cat paradox is a gedanken experiment designed by Schr\u00f6dinger to illustrate some of \nthe problems of quantum measurement, particularly in the extension of quantum mechanics to classi-\ncal systems. The apparatus of Schr\u00f6dinger\u2019s gedanken experiment consists of a radioactive nucleus, a \nGeiger counter, a hammer, a bottle of cyanide gas, a cat, and a box, as shown in Fig. 4.3. The nucleus \nhas a 50% probability of decaying in one hour. The components ",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 124
  },
  {
    "child_id": "70596a19-bf92-456e-bf0a-ebc740af2b54",
    "parent_id": "84381b89-8aa6-4af7-8808-d4736015c7e5",
    "text": ".\n 4.2 \u0002 SCHR\u00d6DINGER CAT PARADOX\nThe Schr\u00f6dinger cat paradox is a gedanken experiment designed by Schr\u00f6dinger to illustrate some of \nthe problems of quantum measurement, particularly in the extension of quantum mechanics to classi-\ncal systems. The apparatus of Schr\u00f6dinger\u2019s gedanken experiment consists of a radioactive nucleus, a \nGeiger counter, a hammer, a bottle of cyanide gas, a cat, and a box, as shown in Fig. 4.3. The nucleus \nhas a 50% probability of decaying in one hour. The components are assembled such that when the \nnucleus decays, it triggers the Geiger counter, which causes the hammer to break the bottle and release \nthe poisonous gas, killing the cat. Thus, after one hour there is a 50% probability that the cat is dead.\nAfter the one hour, the nucleus is in an equal superposition of undecayed and decayed states:\n \n0 cnucleus9 =\n1\n12 10 cundecayed9 + 0\n cdecayed92. \n(4.12)\nThe apparatus is designed such that there is a one-to-one correspondence between the undecayed \nnuclear state and the live-cat state and a one-to-one correspondence between the decayed nuclear state \nand the dead-cat state. Though the cat is macroscopic, it is made up of microscopic particles and so \nshould be describable by a quantum state, albeit a complicated one. Thus, we expect that the quantum \nstate of the cat after one hour is\n \n0 ccat9 =\n1\n12 10 calive9 + 0 cdead92. \n(4.13)\n\n4.2 Schr\u00f6dinger Cat Paradox \n103\nBoth quantum calculations and classical reasoning would predict 50>50 probabilities of observ-\ning an alive or a dead cat when we open the box. However, quantum mechanics would lead us to \nbelieve that the cat was neither dead nor alive before we opened the box, but rather was in a super-\nposition of states, and the quantum state collapses to the alive state 0 calive9 or dead state 0 cdead9 only \nwhen we open the box and make the measurement by observing the cat. But our classical experiences \nclearly run counter to this. We would say that the cat really was dead or alive, we just did not know \nit yet. (Imagine that the cat is wearing a cyanide sensitive watch\u2014the time will tell us when the cat \nwas killed, if it is dead!)\nWhy are we so troubled by a cat in a superposition state? After all, we have just \ufb01nished three \nchapters of electrons in superposition states! What is so inherently different about cats and electrons? \nExperiment 4 that we studied in Chapters 1 and 2 provides a clue. The superposition state in that \nexperiment exhibits a clear interference effect that relies on the coherent phase relationship between \nthe two parts of the superposition state vector for the spin-1/2 particle. No one has ever observed such \nan interference effect with cats, so our gut feeling that cats and electrons are different appears justi\ufb01ed.\nThe main issues raised by the Schr\u00f6dinger cat gedanken experiment are (1) Can we describe mac-\nroscopic states quantum mechanically? and (2) What causes the collapse of the wave function?\nThe Copenhagen interpretation of qua",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 124
  },
  {
    "child_id": "ca4b5639-45ac-492c-a5dd-827214d442e9",
    "parent_id": "84381b89-8aa6-4af7-8808-d4736015c7e5",
    "text": "fect that relies on the coherent phase relationship between \nthe two parts of the superposition state vector for the spin-1/2 particle. No one has ever observed such \nan interference effect with cats, so our gut feeling that cats and electrons are different appears justi\ufb01ed.\nThe main issues raised by the Schr\u00f6dinger cat gedanken experiment are (1) Can we describe mac-\nroscopic states quantum mechanically? and (2) What causes the collapse of the wave function?\nThe Copenhagen interpretation of quantum mechanics championed by Bohr and Heisenberg \nmaintains that there is a boundary between the classical and quantum worlds. We describe micro-\nscopic systems (the nucleus) with quantum states and macroscopic systems (the cat, or even the Gei-\nger counter) with classical rules. The measurement apparatus causes the quantum state to collapse and \nto produce the single classical or meter result. The actual mechanism for the collapse of the wave func-\ntion is not speci\ufb01ed in the Copenhagen interpretation, and where to draw the line between the classical \nand the quantum world is not clear. Others have argued that the human consciousness is responsible \nfor collapsing the wave function, while some have argued that there is no collapse, just bifurcation into \nalternate, independent universes. Many of these different points of view are untestable experimentally \nand thus raise more metaphysical than physical questions.\nThese debates about the interpretation of quantum mechanics arise when we use words, which \nare based on our classical experiences, to describe the quantum world. The mathematics of quantum \nNucleus\nCyanide\nGeiger Counter\nCat\nFIGURE 4.3 Schr\u00f6dinger cat gedanken experiment.",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 124
  },
  {
    "child_id": "abce5264-bd74-4eec-b212-520d0be25a33",
    "parent_id": "237782b9-282b-4f6b-9066-0b1842a2908a",
    "text": "104 \nQuantum Spookiness\nmechanics is clear and allows us to calculate precisely. No one is disagreeing about the probability \nthat the cat will live or die. The disagreement is all about \u201cwhat it really means!\u201d To steer us toward \nthe clear mathematics, Richard Feynman admonished us to \u201cShut up and calculate!\u201d Two physicists \nwho disagree on the words they use to describe a quantum mechanical experiment generally agree on \nthe mathematical description of the results.\nRecent advances in experimental techniques have allowed experiments to probe the boundary \nbetween the classical and quantum worlds and address the quantum measurement issues raised by \nthe Schr\u00f6dinger cat paradox. The coupling between the microscopic nucleus and the macroscopic \ncat is representative of a quantum measurement whereby a classical meter (the cat) provides a clear \nand unambiguous measurement of the state of the quantum system (the nucleus). In this case, the two \npossible states of the nucleus (undecayed or decayed) are measured by the two possible positions on \nthe meter (cat alive or cat dead). The quantum mechanical description of this complete system is the \nentangled state\n \n0 csystem9 =\n1\n12 10 cundecayed9 0 calive9 + 0 cdecayed9 0 cdead92. \n(4.14)\nThe main issue to be addressed by experiment is whether Eq. (4.14) is the proper quantum mechanical \ndescription of the system. That is, is the system in a coherent quantum mechanical superposition, as \ndescribed by Eq. (4.14), or is the system in a 50>50 statistical mixed state of the two possibilities? As \ndiscussed above, we can distinguish these two cases by looking for interference between the two states \nof the system.\nTo build a Schr\u00f6dinger cat experiment, researchers use a two-state atom as the quantum system \nand an electromagnetic \ufb01eld in a cavity as the classical meter (or cat). The atom can either be in the \nground 0\n g9 or excited 0\n e9 state. The cavity is engineered to be in a coherent state 0\n a9 described \nby the complex number a, whose magnitude is equal to the square root of the average number of \nphotons in the cavity. For large a, the coherent state is equivalent to a classical electromagnetic \n\ufb01eld, but for small a, the \ufb01eld appears more quantum mechanical. The beauty of this experiment is \nthat the experimenters can tune the value of a between these limits to study the region between the \nmicroscopic and macroscopic descriptions of the meter (cat). In this intermediate range, the meter is \na mesoscopic system.\nAtoms travel through the cavity and disturb the electromagnetic \ufb01eld in the cavity. Each atom is \nmodeled as having an index of refraction that alters the phase of the electromagnetic \ufb01eld. The sys-\ntem is engineered such that the ground and excited atomic states produce opposite phase shifts {f. \nBefore the atom enters the cavity, it undergoes a p-pulse that places it in an equal superposition of \nground and excited states\n \n0 catom9 =\n1\n12 10\n e9 + 0\n g92, \n(4.15)\nas shown in Fig. 4.4. Ea",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 128
  },
  {
    "child_id": "4457c15a-2afd-4381-8b4a-3404493ad78d",
    "parent_id": "237782b9-282b-4f6b-9066-0b1842a2908a",
    "text": "tem.\nAtoms travel through the cavity and disturb the electromagnetic \ufb01eld in the cavity. Each atom is \nmodeled as having an index of refraction that alters the phase of the electromagnetic \ufb01eld. The sys-\ntem is engineered such that the ground and excited atomic states produce opposite phase shifts {f. \nBefore the atom enters the cavity, it undergoes a p-pulse that places it in an equal superposition of \nground and excited states\n \n0 catom9 =\n1\n12 10\n e9 + 0\n g92, \n(4.15)\nas shown in Fig. 4.4. Each component of this superposition produces a different phase shift in the \ncavity \ufb01eld such that after the atom passes through the cavity, the atom-cavity system is in the entan-\ngled state\n \n0 catom +cavity9 =\n1\n12 10\n e9 0 ae if9 + 0\n g9 0 ae -if92 \n(4.16)\nthat mirrors the Schr\u00f6dinger cat state in Eq. (4.14). The state of the cavity \ufb01eld is probed by sending \na second atom into the cavity and looking for interference effects in the atom that are produced by the \ntwo components of the \ufb01eld. In this experiment, the two \ufb01eld states are classically distinguishable, \nakin to the alive and dead cat states. For small values of the phase difference 2f between the two \ufb01eld \ncomponents, the interference effect is evident. However, for large values of the phase difference 2f\n\nProblems \n105\nbetween the two \ufb01eld components, the interference effect vanishes, indicating that the superposition \nstate in Eq. (4.16) has lost the \ufb01xed phase relationship between the two parts of the entangled state and \ncan no longer produce interference effects. The system has undergone decoherence due to its interac-\ntion with the random aspects of the environment. The decoherence effect also increases as the number \nof photons in the cavity \ufb01eld increases, which makes the cavity \ufb01eld more like a classical state. Hence, \nthe experiment demonstrates that the quantum coherence of a superposition state is rapidly lost when \nthe state becomes complex enough to be considered classical. Further details on this recent experiment \nare available in the references below (Brune et al.).\nPROBLEMS\n 4.1 Show that the quantum state vector of a two-particle system must be a product 0\n c910\n f92 of \ntwo single-particle state vectors rather than a sum 0\n c91 + 0\n f92. Hint: consider the action of a \nsingle-particle state operator on the two-particle state vector.\n 4.2 Consider the two-particle entangled state\n0 c9 =\n1\n12 10  +91 0  -92 - 0  -91 0  +922.\na) Show that 0\n c9 is not an eigenstate of the spin component operator S1z for particle 1.\nb) Show that 0\n c9 is properly normalized.\n 4.3 Consider the two-particle entangled state\n0 c9 =\n1\n12 10  +91 0  -92 - 0  -91 0  +922.\n \n Show that the probability of observer A measuring particle 1 to have spin up is 50% for any \norientation of the Stern-Gerlach detector used by observer A. To \ufb01nd this probability, sum over \nall the joint probabilities for observer A to measure spin up and observer B to measure anything.\n 4.4 Show that the state\n0 ca9 =\n1\n12 10  +91",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 128
  },
  {
    "child_id": "b81428dc-caaf-4865-8db1-020c7ef9891f",
    "parent_id": "237782b9-282b-4f6b-9066-0b1842a2908a",
    "text": "operator S1z for particle 1.\nb) Show that 0\n c9 is properly normalized.\n 4.3 Consider the two-particle entangled state\n0 c9 =\n1\n12 10  +91 0  -92 - 0  -91 0  +922.\n \n Show that the probability of observer A measuring particle 1 to have spin up is 50% for any \norientation of the Stern-Gerlach detector used by observer A. To \ufb01nd this probability, sum over \nall the joint probabilities for observer A to measure spin up and observer B to measure anything.\n 4.4 Show that the state\n0 ca9 =\n1\n12 10  +91 0  -92 - 0  -91 0  +922\n \n is equivalent to the state\n0 cb9 =\n1\n12 10  +91x 0  -92  x - 0  -91x 0  +92  x2.\n \n That is, the two observers record perfect anticorrelations independent of the orientation of their \ndetectors, as long as both are aligned along the same direction.\nAtom Source\n\u03a0\u00062 Pulse\nCavity\n1\n2 \u0002g\u0003+\u0002e\u0003\n\u0002g\u0003\nFIGURE 4.4 Schr\u00f6dinger cat experiment with atoms in a cavity.\n\n106 \nQuantum Spookiness\n 4.5 Calculate the quantum mechanical probabilities in Eqs. (4.7) and (4.9) without assuming that \nobserver A\u2019s Stern-Gerlach device is aligned with the z-axis. Let the direction of observer A\u2019s \nmeasurements be described by the angle u1 and the direction of observer B\u2019s measurements be \ndescribed by the angle u2. Show that the averaged results in Eq. (4.11) are still obtained.\nRESOURCES\nFurther Reading\nThe EPR Paradox and Bell\u2019s theorem are discussed in these articles:\nF. Laloe, \u201cDo we really understand quantum mechanics? Strange correlations, paradoxes, \nand  theorems,\u201d Am. J. Phys. 69, 655\u2013701 (2001); \u201cErratum: Do we really understand \nquantum mechanics? Strange correlations, paradoxes, and theorems,\u201d Am. J. Phys. 70, \n556 (2002).\nN. D. Mermin, \u201cBringing home the atomic world: Quantum mysteries for anybody,\u201d Am. J. \nPhys. 49, 940\u2013943 (1981).\nN. D. Mermin, \u201cIs the moon there when nobody looks? Reality and the quantum theory,\u201d \nPhys. Today 38(5), 38\u201347 (1985).\nN. D. Mermin, \u201cQuantum mysteries revisited,\u201d Am. J. Phys. 58, 731\u2013734 (1990).\nN. D. Mermin, \u201cNot quite so simply no hidden variables,\u201d Am. J. Phys. 60, 25\u201327 (1992).\nN. D. Mermin, \u201cQuantum mysteries re\ufb01ned,\u201d Am. J. Phys. 62, 880\u2013887 (1994).\nN. D. Mermin, \u201cNonlocal character of quantum theory?\u201d Am. J. Phys. 66, 920\u2013924 (1998).\nN. D. Mermin, \u201cWhat is quantum mechanics trying to tell us?\u201d Am. J. Phys. 66, 753\u2013767 \n(1998).\nSchr\u00f6dinger\u2019s cat is discussed in these references:\nT. J. Axon, \u201cIntroducing Schrodinger\u2019s cat in the laboratory,\u201d Am. J. Phys. 57, 317\u2013321 (1989).\nM. Brune, E. Hagley, J. Dreyer, X. Ma\u00d3tre, A. Maali, C. Wunderlich, J. M. Raimond, and  \nS. Haroche, \u201cObserving the progressive decoherence of the \u2018meter\u2019 in a quantum \nmeasurement,\u201d Phys. Rev. Lett. 77, 4887\u20134890 (1996).\nB. S. DeWitt, \u201cQuantum mechanics and reality,\u201d Phys. Today 23(9), 30\u201335 (1970).\nA. J. Legett, \u201cSchrodinger\u2019s cat and her laboratory cousins,\u201d Contemp. Phys. 25, 583\u2013598 \n(1984). \nJ. G. Loeser, \u201cThree perspectives on Schrodinger\u2019s cat,\u201d Am. J. Phys. 52, 1089\u20131093 (1984).\nW. H. Zurek, \u201cDecoherence and the transition from q",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 128
  },
  {
    "child_id": "b2555e42-db64-46cb-9148-dc9fa094ad33",
    "parent_id": "237782b9-282b-4f6b-9066-0b1842a2908a",
    "text": ". Maali, C. Wunderlich, J. M. Raimond, and  \nS. Haroche, \u201cObserving the progressive decoherence of the \u2018meter\u2019 in a quantum \nmeasurement,\u201d Phys. Rev. Lett. 77, 4887\u20134890 (1996).\nB. S. DeWitt, \u201cQuantum mechanics and reality,\u201d Phys. Today 23(9), 30\u201335 (1970).\nA. J. Legett, \u201cSchrodinger\u2019s cat and her laboratory cousins,\u201d Contemp. Phys. 25, 583\u2013598 \n(1984). \nJ. G. Loeser, \u201cThree perspectives on Schrodinger\u2019s cat,\u201d Am. J. Phys. 52, 1089\u20131093 (1984).\nW. H. Zurek, \u201cDecoherence and the transition from quantum to classical,\u201d Phys. Today \n44(10), 36\u201344 (1991).\nRichard Feynman\u2019s directive to \u201cShut up and calculate!\u201d is discussed in: \nN. D. Mermin, \u201cWhat\u2019s wrong with this pillow?\u201d Phys. Today 42(4), 9\u201311 (1989).\nN. D. Mermin, \u201cCould Feynman have said this?\u201d Phys. Today 57(5), 10\u201311 (2004).\n\n107\nC H A P T E R \n5\nQuantized Energies:  \nParticle in a Box\nIn the \ufb01rst part of this book we used the spin system to illustrate the basic concepts and tools of quan-\ntum mechanics. With a \ufb01rm foundation in how quantum mechanics works, we are ready to address the \ncentral question that quantum mechanics was designed to answer: How do we explain the structure of \nthe microscopic world? All around us are nuclei, atoms, molecules, and solids with unique properties \nthat cannot be explained with classical physics but require quantum mechanics. For example, quantum \nmechanics can tell us why sodium lamps are yellow, why laser diodes have a unique color, and why \nuranium is radioactive.\nThe key to understanding the structure of microscopic systems lies in the energy states that the \nsystems are allowed to have. Each microscopic system has a unique set of energy levels that gives that \nsystem a \u201c\ufb01ngerprint\u201d that sets it apart from other systems. With the tools of quantum mechanics, we \ncan build a theoretical model for the system, predict that \ufb01ngerprint, and compare it to the experimen-\ntal measurement. Our goal in this chapter and the ones that follow is to learn how to predict this energy \n\ufb01ngerprint. In this chapter we will study a particularly simple model system that exhibits most of the \nimportant features that are shared by all microscopic systems.\n5.1 \u0002 SPECTROSCOPY\nThe energy \ufb01ngerprint of a system not only identi\ufb01es that system uniquely, but the allowed energies \ndetermine the time evolution of the system through the Schr\u00f6dinger equation, as we learned in Chapter 3. \nOne of the primary experimental techniques for measuring the energy \ufb01ngerprint of a system is spectros-\ncopy. We saw a hint of this in the magnetic resonance example of Section 3.4: absorption and emission of \nphotons causes transitions between quantized energy levels of the system only when the photon energy \nmatches the spacing between the energy eigenstates. Historically, the spectrum of hydrogen was a key \ningredient in the development of quantum mechanics, and spectroscopy continues to play an important \nrole in characterizing new quantum systems and in verifying the rules of quantum mechanics.\nIn th",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 128
  },
  {
    "child_id": "0fbecab8-f053-4c4c-a87e-9dbeb57c273d",
    "parent_id": "237782b9-282b-4f6b-9066-0b1842a2908a",
    "text": " saw a hint of this in the magnetic resonance example of Section 3.4: absorption and emission of \nphotons causes transitions between quantized energy levels of the system only when the photon energy \nmatches the spacing between the energy eigenstates. Historically, the spectrum of hydrogen was a key \ningredient in the development of quantum mechanics, and spectroscopy continues to play an important \nrole in characterizing new quantum systems and in verifying the rules of quantum mechanics.\nIn the magnetic resonance example of Section 3.4, the two quantized energy levels arose from the \ntwo possible spin components (up or down) and their different interactions with an applied magnetic \n\ufb01eld. The more common situation that gives rise to quantized energy levels is where two or more \nparticles interact in a way that limits their spatial motion and binds them together into a compos-\nite system. Bound systems such as nuclei, atoms, molecules, and solids are everyday examples that \nare characterized by distinct spectral lines associated with quantized energy states, (i.e., eigenstates \nof the Hamiltonian with discrete energy eigenvalues). For example, the hydrogen atom energy levels",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 128
  },
  {
    "child_id": "0ab75a9b-c7f6-44fe-aef4-35ada8e62d38",
    "parent_id": "efaa2300-5f63-4b4f-a82b-d6b6b7f80df2",
    "text": "108 \nQuantized Energies: Particle in a Box\nand the corresponding optical spectrum are shown in Fig. 5.1. The spectral lines appear when elec-\ntrons make transitions between energy levels. Downward transitions emit photons and give rise to an \nemission spectrum, while upward transitions absorb photons and yield an absorption spectrum. For \nevery pair of energy eigenvalues Ei and Ej  , there is a possible spectral line with photon energy Ei - Ej\n , \nand photon frequency fij and wavelength \nij given by\n \nfij =\nvij\nU =\nEi - Ej\nh\n \n \nlij = c\nfij\n=\nhc\nEi - Ej\n , \n(5.1)\nassuming that Ei 7 Ej\n . The set of spectral lines of atomic hydrogen that share a common lower level \nforms a series that is named after its discoverer. The \ufb01rst three series in hydrogen are shown in Fig. 5.1 \nand listed in Table 5.1. The lowest energy state (n \u0003 1 for hydrogen) is called the ground state, and \nthe levels above that are called excited states. Though the word spectrum often refers to the observed \noptical lines, the set of quantized energy states is also commonly referred to as the energy spectrum \nof the system.\n1\n2\n3\n4\n5\nn\nLyman\nBalmer\nPaschen\n0\n\u00051\n\u00052\n\u00053\n\u00054\n\u00055\n\u00056\n\u00057\n\u00058\n\u00059\n\u000510\n\u000511\n\u000512\n\u000513\n\u000514\nE\nf\n\u039b\n\b\nEnergy (eV)\nFIGURE 5.1 Hydrogen energy levels and the corresponding optical spectrum as a function \nof energy,  frequency, and wavelength (the wavelength scale is not a linear scale).\n\n5.1 Spectroscopy \n109\nA spectroscopy experiment can be considered to be a measurement of the energy of a quantum \nstate. A spectroscopic energy measurement is depicted in Fig. 5.2(a) in a simpli\ufb01ed schematic that is \nanalogous to the Stern-Gerlach spin measurement we discussed earlier. A system is prepared in an \n initial state 0 c9, and we measure the probability that the state is measured to have a particular energy \nEi. If we write the energy eigenstates as 0\n Ei9, then the probability of a particular energy measurement is\n \nPEi = 08Ei0 c90\n2. \n(5.2)\nAs we did in the spins problem, we represent the collection of measurements on an ensemble of iden-\ntical states as a histogram, as shown in Fig. 5.2(b). In a real spectroscopy experiment, the measured \nenergies are really energy differences between levels, so it can be a bit of a puzzle to decode the energy \nlevels from the observed spectrum. We assume that this decoding process can be done and we assume \nthat the histogram in Fig. 5.2(b) faithfully represents the energy levels of the system. The energy levels \nEi and the eigenstates 0\n Ei9 are solutions to the energy eigenvalue equation\n \nHn  0 Ei9 = Ei0\n Ei9, \n(5.3)\nso the spectroscopic measurement is how the theoretical Hamiltonian is compared with experiment. \nOur task in this chapter is to learn how to predict the allowed energy eigenstates of a particular system \ngiven the Hamiltonian of the system.\n)\nb\n(\n)\na\n(\nPE1\nE1\n2\nPEi\nPE2\nPE3\nPE4\nPE5\nE5\n2\nE\nH\nE1\nE2\nE3\nE4\nE5\nE1\n2\nE4\n2\nE5\n2\nE1 E2\nE3\nE4\nE5\nE3\n2\nE2\n2\nE4\n2\nE2\n2\nE3\n2\nFIGURE 5.2 (a) Energy measurement and (b) histogram of results.\nTable ",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 132
  },
  {
    "child_id": "7ab3fb51-b80d-4f49-abb0-eb57e1f7faa3",
    "parent_id": "efaa2300-5f63-4b4f-a82b-d6b6b7f80df2",
    "text": "ns to the energy eigenvalue equation\n \nHn  0 Ei9 = Ei0\n Ei9, \n(5.3)\nso the spectroscopic measurement is how the theoretical Hamiltonian is compared with experiment. \nOur task in this chapter is to learn how to predict the allowed energy eigenstates of a particular system \ngiven the Hamiltonian of the system.\n)\nb\n(\n)\na\n(\nPE1\nE1\n2\nPEi\nPE2\nPE3\nPE4\nPE5\nE5\n2\nE\nH\nE1\nE2\nE3\nE4\nE5\nE1\n2\nE4\n2\nE5\n2\nE1 E2\nE3\nE4\nE5\nE3\n2\nE2\n2\nE4\n2\nE2\n2\nE3\n2\nFIGURE 5.2 (a) Energy measurement and (b) histogram of results.\nTable 5.1 Hydrogen Transition Wavelengths\nFinal state\nInitial state\nSeries\n2\n3\n4\n5\n1\n122 nm\n103 nm\n97 nm\n95 nm\nLyman\n2\n656 nm\n486 nm\n434 nm\nBalmer\n3\n1875 nm\n1282 nm\nPaschen\n\n110 \nQuantized Energies: Particle in a Box\n5.2 \u0002 ENERGY EIGENVALUE EQUATION\nIn classical mechanics, we often solve problems by using Newton\u2019s second law F = ma to predict the \nposition r1t2 of a particle subject to some known forces. Another common method is the energy method, \nwhereby we use conservation of energy and the relation E = T + V between the total energy (E ) \nand the kinetic (T ) and potential (V ) energies to predict the motion. Of course, the two methods are \nrelated because the force is related to the potential energy by\n \nFx = -  dV\ndx  \n(5.4)\nin one dimension. Hence the potential energy function V(x) is what determines the classical motion of \na particle.\nThe potential energy is also the key element in quantum mechanics, because of the important role \nit plays in the Hamiltonian of the system in question. The Hamiltonian determines the energy states \nthrough the energy eigenvalue equation\n \nHn 0\n Ei9 = Ei0\n Ei9. \n(5.5)\nNote that many other textbooks refer to Eq. (5.5) as the time-independent Schr\u00f6dinger equation \nbecause it can be derived from the Schr\u00f6dinger equation by separating the time and space parts; how-\never, we refer to it always as the energy eigenvalue equation. The prescription for \ufb01nding a quantum \nmechanical Hamiltonian operator is to \ufb01nd the classical form of the energy and replace the physical \nobservables with their quantum mechanical operators. For a moving particle, the classical mechanical \nenergy is the sum of the kinetic energy and the potential energy, which in one dimension is\n \nE =\np2\nx\n2m + V1x2. \n(5.6)\nWe use the position x and momentum p as the primary physical observables in quantum mechanics, \nfollowing the Hamiltonian approach to classical mechanics. Hence the quantum mechanical Hamilto-\nnian operator for a particle moving in one dimension is\n \nHn =\npn 2\nx\n2m + V1xn2. \n(5.7)\nWe use carets or hats on operators on occasion to distinguish them from the same symbol used as a \nvariable. If the distinction is clear from the context, then that notation may be dropped.\nSo now what? What are these new operators xn and pn for position and momentum? And how do \nwe use them to solve the energy eigenvalue equation? In the spins chapters, we learned much of the \nmachinery of quantum mechanics and would rightly expect to be able to use it in this new proble",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 132
  },
  {
    "child_id": "36b122c7-839c-4874-8b22-7eabf95ad0f0",
    "parent_id": "efaa2300-5f63-4b4f-a82b-d6b6b7f80df2",
    "text": " 2\nx\n2m + V1xn2. \n(5.7)\nWe use carets or hats on operators on occasion to distinguish them from the same symbol used as a \nvariable. If the distinction is clear from the context, then that notation may be dropped.\nSo now what? What are these new operators xn and pn for position and momentum? And how do \nwe use them to solve the energy eigenvalue equation? In the spins chapters, we learned much of the \nmachinery of quantum mechanics and would rightly expect to be able to use it in this new problem \non particle motion. However, position and momentum are different enough from spin that we need to \nredevelop some of the mathematical machinery we have already learned.\nWhen we discussed spin quantum states, we either used abstract kets, such as 0  +9 or 0  -9x, or we \nused column vectors to represent the abstract kets in a particular basis of eigenstates. For example, we \noften used the eigenstates of the Sz operator as the preferred basis, in which case the abstract kets 0  +9 \nand 0  -9x are expressed as\n \n0  +9 \u0003 a1\n0b \n(5.8)\n\n5.2 Energy Eigenvalue Equation \n111\nand\n \n0  -9x \u0003\n1\n12\n a 1\n-1b. \n(5.9)\nIn fact, there are very few quantum mechanical problems that can be solved using abstract kets. It is \ngenerally necessary to use a representation of the kets that is convenient for solving the problem. In \nthe problems that we wish to address now, it is most convenient to represent abstract quantum states as \nspatial functions, so we need to explain what that means.\nThe spatial functions we use to represent quantum states are called wave functions and are gener-\nally written using the Greek letter c as\n \nc 1x2. \n(5.10)\nThe wave function is a representation of the abstract quantum state, so we can use our representation \nnotation to write\n \n0\n c9 \u0003 c 1x2. \n(5.11)\nWe call this representation the position representation, which means that we are using the position \neigenstates as the preferred basis (more on these eigenstates later). For clarity, we will use the Greek \nletter c when referring to generic quantum states and other Greek letters to denote speci\ufb01c eigenstates. \nFor example, in the case of the energy eigenstates, we write the wave functions representing them as\n \n0\n Ei9 \u0003 wEi1x2 \n(5.12)\nto distinguish them as speci\ufb01c eigenstates.\nUsing this new wave function notation, the energy eigenvalue equation Eq. (5.5) becomes\n \nHnwEi1x2 = Ei\n wEi1x2. \n(5.13)\nTo solve this equation, we must know how to represent the operators in the Hamiltonian of Eq. (5.7) \nusing the position representation. It turns out that in the position representation, the action of the posi-\ntion operator xn is represented by multiplication by the position variable x, while the action of the \nmomentum operator pn is represented by application of a derivative with respect to position (see an \nadvanced text for justi\ufb01cation or take these as postulates). Using our representation notation, these two \nstatements are\n \n xn \u0003 x\n \n \n pn \u0003 -iU d\ndx  . \n \n(5.14)\nThe momentum operator has a fact",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 132
  },
  {
    "child_id": "d2ddb7c8-9790-401b-b2d9-3cee1108f370",
    "parent_id": "efaa2300-5f63-4b4f-a82b-d6b6b7f80df2",
    "text": " position representation. It turns out that in the position representation, the action of the posi-\ntion operator xn is represented by multiplication by the position variable x, while the action of the \nmomentum operator pn is represented by application of a derivative with respect to position (see an \nadvanced text for justi\ufb01cation or take these as postulates). Using our representation notation, these two \nstatements are\n \n xn \u0003 x\n \n \n pn \u0003 -iU d\ndx  . \n \n(5.14)\nThe momentum operator has a factor of -iU to get the dimensions correct and to ensure that the mea-\nsurable results are real (not imaginary).\nWith these representations of the position and momentum operators, we now begin to solve the \nenergy eigenvalue equation. Inserting Eq. (5.14) into the energy eigenvalue equation gives\n \n HnwEi1x2 = Ei\n wEi1x2  \n \n a pn 2\n2m + V 1xn2\n b wEi1x2 = Ei\n wEi1x2  \n(5.15)\n \n a 1\n2m a-iU d\ndxb\n2\n+ V 1x2\n b wEi1x2 = Ei\n wEi1x2.\n\n112 \nQuantized Energies: Particle in a Box\nThe result is that the energy eigenvalue equation becomes a differential equation\n \na-  U2\n2m\n d 2\ndx2 + V1x2\n b wE1x2 = EwE1x2  . \n(5.16)\nThis differential equation is a big change from the matrix eigenvalue equations we encountered in the \nspin problems. This result is a common occurrence when using the wave function approach: operator \nequations turn into differential equations. Hence, when we use the wave function approach to \ufb01nd \nthe allowed energy eigenstates of a system, we typically solve differential equations. We will solve \nthis differential equation for several different potential energy functions V1x2 in the remainder of this \nbook, but \ufb01rst we pause to examine the wave function idea more carefully.\n5.3 \u0002 THE WAVE FUNCTION\nTo better understand the new concept of a wave function c1x2, let\u2019s see how it relates to the quantum \nstate vector 0\n c9 we used in spins. In the spin case, we found that a useful way to represent a state vec-\ntor was as a column vector of numbers, with each number being the probability amplitude for the state \n0\n c9 to be measured in a particular spin eigenstate. For example, we could write the state 0\n c9 using the \nSz representation as\n \n0\n c9 \u0003 \u00a28+ 0\n c9\n8- 0\n c9\u2264 d Sz = +U>2\n d Sz = -U>2. \n(5.17)\nThe numbers 8{0\n c9 in the column vector are the projections of the state vector 0\n c9 onto the Sz \neigenstates 0{9, corresponding to the two possible eigenvalues. If we measure the spin projection, as \ndepicted in Fig. 5.3(a), then the amplitudes 8{0\n c9 are used to calculate the probabilities\n \nP{ = 08{ 0\n c90\n2 \n(5.18)\nshown in the histogram in Fig. 5.3(b).\nIf we now consider an energy measurement, such as depicted in Fig. 5.2(a), then the basis of \nenergy eigenstates is the appropriate basis for representing the state vector:\n \n0\n c9 \u0003 \u2022\n8E1@ c9\n8E2@ c9\n8E3@c9\nf\n\u03bc \nd E = E1\nd E = E2\nd E = E3.\nf\n  \n(5.19)\nP\n2\n2\n(a)\n(b)\n1\nP\nZ\n2\n2\nSz\nP\n2\n2\nFIGURE 5.3 (a) Spin measurement and (b) probability histogram.",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 132
  },
  {
    "child_id": "2a4c24ff-35e7-47a4-8fa6-74b9f8dc520f",
    "parent_id": "9beab8f7-d5de-40a5-a138-aade0844445c",
    "text": "In such an energy measurement, the probabilities shown in Fig. 5.2(b) are calculated using the pro-\njections 8Ei0\n c9 of the state 0\n c9 onto the energy eigenstates 0\n Ei9. The probabilities of measuring the \nquantized energies are\n \nPEi = 08Ei 0\n c90\n2\n . \n(5.20)\nIn analogy to these two examples, the wave function is a representation of a quantum state using \nthe eigenstates of the position operator xn as the basis states. If we call the position eigenstates 0\n xi9, \nthen the analog to Eqs. (5.17) and (5.19) would be\n \n0\n c9 \u0003 \u2022\n8x1@ c9\n8x2@ c9\n8x3@ c9\nf\n\u03bc \nd x1\nd x2\nd x3 ,\nf\n  \n(5.21)\nwhere the projection 8xi0 c9 is  the probability amplitude for the state 0 c9 to be measured in the posi-\ntion eigenstate 0\n xi9. However, experiment tells us that the physical observable x is not quantized. \nRather, all values of position x are allowed. This is in stark contrast to the case of the spin component \nSz, where only two results were possible. We say that the spectrum of eigenvalues of position is con-\ntinuous and the spectrum of eigenvalues of spin is discrete. Future experiments may shed new light on \nthis, but to date, space appears to be continuous. \u201cDiscrete vs. continuous\u201d is an important distinction \nthat affects how we use and interpret the quantum state vector, the probability amplitudes, and the \nprobabilities when position is the relevant quantum mechanical observable.\nFor a continuous variable like position, the column vector representation of Eq. (5.21) is not con-\nvenient because we cannot write down the in\ufb01nite number of components. Even if the number were \n\ufb01nite but large, say 100, then we would \ufb01nd a column vector cumbersome. Instead, we might choose to \nrepresent the 100 discrete numbers 8xi0 c9 as points in a graph, such as shown in Fig. 5.4(a). However, \nbecause the position spectrum is continuous, there is an in\ufb01nite continuum of the probability ampli-\ntudes 8x0 c9, and the natural way to represent such a continuous set of numbers is as a continuous func-\ntion, as shown in Fig. 5.4(b). This function is what we call the quantum mechanical wave  function c1x2. \nThe wave function is the collection of numbers that represents the quantum state vector in terms of the \nposition eigenstates, in the same way that the column vector used to represent a general spin state is a \ncollection of numbers that represents the quantum state vector in terms of the spin eigenstates. Whether \nyou write the wave function as c1x2 or as 8x0 c9 is ultimately a matter of taste. It is more common to \n(a)\n(b)\nx\nx\n\u0004x1\u0002\u03a8\u0003\n\u0004x2\u0002\u03a8\u0003\n\u0004x3\u0002\u03a8\u0003\n\u0004x\u0002\u03a8\u0003\n\u03a8(x)\n\u03a8(x)\n\u0004x4\u0002\u03a8\u0003\u0004x5\u0002\u03a8\u0003\n\u0004x6\u0002\u03a8\u0003\n\u0004x7\u0002\u03a8\u0003\n\u0004x8\u0002\u03a8\u0003\n\u0004x9\u0002\u03a8\u0003\n\u0004x10\u0002\u03a8\u0003\nx1 x2 x3 x4 x5 x6 x7 x8 x9 x10\nFIGURE 5.4 (a) Discrete basis representation and (b) continuous basis representation.\n5.3 The Wave Function \n113\n\n114 \nQuantized Energies: Particle in a Box\nsee the form c1x2 used as the wave function, and we will follow that convention mostly, using the \nDirac notation when convenient. But it is important to remember both forms, so we r",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 137
  },
  {
    "child_id": "730e6bba-ed01-43e6-9915-11fa11df9d11",
    "parent_id": "9beab8f7-d5de-40a5-a138-aade0844445c",
    "text": "of taste. It is more common to \n(a)\n(b)\nx\nx\n\u0004x1\u0002\u03a8\u0003\n\u0004x2\u0002\u03a8\u0003\n\u0004x3\u0002\u03a8\u0003\n\u0004x\u0002\u03a8\u0003\n\u03a8(x)\n\u03a8(x)\n\u0004x4\u0002\u03a8\u0003\u0004x5\u0002\u03a8\u0003\n\u0004x6\u0002\u03a8\u0003\n\u0004x7\u0002\u03a8\u0003\n\u0004x8\u0002\u03a8\u0003\n\u0004x9\u0002\u03a8\u0003\n\u0004x10\u0002\u03a8\u0003\nx1 x2 x3 x4 x5 x6 x7 x8 x9 x10\nFIGURE 5.4 (a) Discrete basis representation and (b) continuous basis representation.\n5.3 The Wave Function \n113\n\n114 \nQuantized Energies: Particle in a Box\nsee the form c1x2 used as the wave function, and we will follow that convention mostly, using the \nDirac notation when convenient. But it is important to remember both forms, so we repeat them here:\n \nc1x2 = 8x0 c9  . \n(5.22)\nIn words, we say that the wave function c1x2 is the probability amplitude for the quantum state 0 c9 to be \nmeasured in the position eigenstate 0 x9. We will say more about the position eigenstates in Chapter 6 and \nthen also make more connections between the wave function language and the Dirac bra-ket notation.\nContinuing with the analogy to the spin and energy examples above, we expect that the prob-\nability of measuring a particular value of position is obtained by taking the absolute square of the \nprojection 8x0 c9, as was done in Eqs. (5.18) and (5.20) for spin and energy representations. However, \nbecause the projection 8x0 c9 is the continuous wave function c1x2, the absolute square yields a con-\ntinuous probability function (actually a probability density, as we\u2019ll \ufb01nd in a moment), which we write \nas P1x2 so as to distinguish it from the discrete case Ae.g. PSz=+U>2B by making x an argument rather than \na subscript. In wave function notation, this new probability function is\n \nP1x2 = 0 c1x20\n2  . \n(5.23)\nThus, given a wave function c1x2, such as shown in Fig. 5.5(a), we use Eq. (5.23) to calculate the prob-\nability function P1x2, which is shown in Fig. 5.5(b). The probability function in Fig. 5.5(b) is analogous \nto the histograms of discrete probabilities in Figs. 5.2(b) and 5.3(b). We must stress that measuring the \nprobability function P1x2 does not allow us to infer the wave function c1x2. We saw in the spin measure-\nments of Chapters 1 and 2 that measurements of three different observables, Sx, Sy, and Sz, were required \nto deduce the state vector 0 c9 because the probability amplitudes are complex numbers. The relative \nphases between the probability amplitudes are not accessible from measurement of a single observable.\nHaving a continuous function for the probability rather than a set of discrete values raises some \nimportant issues. In quantum mechanics we require that the sum of all possible probabilities be equal \nto unity (i.e., the state vector must be normalized). In the discrete spins case this meant that:\n \na\n{\nP{ = a\n{\n08{0 c90\n2 = 1. \n(5.24)\nIf position were discrete instead of continuous, then the normalization condition would be:\n \na\nn\nPxn = a\nn\n08xn0 c90\n2 = 1. \n(5.25)\n(a)\n(b)\nx\nP(x)\n\u03a8(x)\nx\nFIGURE 5.5 (a) Wave function and (b) corresponding probability density.\n\n5.3 The Wave Function \n115\nHowever, because the spectrum of position eigenvalues is continuous rather than discrete, the s",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 137
  },
  {
    "child_id": "cb0dc181-3cc5-46c3-b3a0-050d5b81ad0c",
    "parent_id": "9beab8f7-d5de-40a5-a138-aade0844445c",
    "text": "es be equal \nto unity (i.e., the state vector must be normalized). In the discrete spins case this meant that:\n \na\n{\nP{ = a\n{\n08{0 c90\n2 = 1. \n(5.24)\nIf position were discrete instead of continuous, then the normalization condition would be:\n \na\nn\nPxn = a\nn\n08xn0 c90\n2 = 1. \n(5.25)\n(a)\n(b)\nx\nP(x)\n\u03a8(x)\nx\nFIGURE 5.5 (a) Wave function and (b) corresponding probability density.\n\n5.3 The Wave Function \n115\nHowever, because the spectrum of position eigenvalues is continuous rather than discrete, the sum \nover discrete probabilities must be changed to an integral over the continuous probability function \nP1x2, with the requisite differential term dx added. For now, we restrict the discussion to one spatial \ndimension. Thus the normalization condition is\n \nL\n\u0005\n- \u0005\nP1x2dx =\n \nL\n\u0005\n- \u0005\n0 c1x20\n2\n dx = 1. \n(5.26)\nThe differential dx has dimensions of length and the total integrated probability must be dimension-\nless, so the probability function P1x2 must have dimensions of inverse length. This means that P1x2 is \na probability density (in one dimension a probability per unit length) rather than a probability. Hence \nwe interpret the quantity\n \nP1x2dx \n(5.27)\nas the in\ufb01nitesimal probability of detecting a particle at position x within an in\ufb01nitesimal region of \nwidth dx [i.e., between x and x + dx, as shown in Fig. 5.6(a)]. To calculate the probability that a par-\nticle is measured to be in a \ufb01nite interval a 6 x 6 b, we add all the in\ufb01nitesimal probabilities in that \ninterval, which is the integral\n \nPa6x6b =\n \nL\nb\na\n0 c1x20\n2\n dx \n(5.28)\nas depicted in Fig. 5.6(b). Equation (5.28) is an incredibly important formula. We use it, for example, \nto \ufb01nd the probability that an electron is in a certain region of an atom (extended to three dimensions, \nof course).\nTo calculate other experimental quantities, such as expectation values, we must learn how to trans-\nlate bra-ket rules for discrete basis systems to wave function rules for continuous basis systems. We can \nlearn some rules for this translation by comparing the new wave function form of the normalization \ncondition in Eq. (5.26) to the bra-ket normalization condition. In Dirac notation, the requirement of \nprobability normalization is expressed in terms of the inner product of the state vector with itself:\n \n8c0 c9 = 1. \n(5.29)\nRewrite the wave function normalization condition Eq. (5.26) to make it look more like the bra-ket form:\n \nL\n\u0005\n- \u0005\nc*1x2c1x2dx = 1. \n(5.30)\n(a)\n(b)\nx x + dx\na\nb\nP(x)\nP(x)\nx\nx\nFIGURE 5.6 Probability for measuring a particle to be in the position range (a) x to x + dx, and (b) a to b.\n\n116 \nQuantized Energies: Particle in a Box\nComparing Eq. (5.29) and Eq. (5.30), we postulate the following rules for translating bra-ket formulae \nto wave function formulae:\n 1) Replace ket with wave function \n0 c9 S c1x2\n 2) Replace bra with wave function conjugate \n8c 0 S c*1x2\n 3) Replace bracket with integral over all space \n8 0 9 S\nL\n\u0005\n- \u0005\n dx\n 4) Replace operator with position representation An ",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 137
  },
  {
    "child_id": "b7dbd653-1e20-4db4-8a81-92213fe1dff4",
    "parent_id": "9beab8f7-d5de-40a5-a138-aade0844445c",
    "text": "bability for measuring a particle to be in the position range (a) x to x + dx, and (b) a to b.\n\n116 \nQuantized Energies: Particle in a Box\nComparing Eq. (5.29) and Eq. (5.30), we postulate the following rules for translating bra-ket formulae \nto wave function formulae:\n 1) Replace ket with wave function \n0 c9 S c1x2\n 2) Replace bra with wave function conjugate \n8c 0 S c*1x2\n 3) Replace bracket with integral over all space \n8 0 9 S\nL\n\u0005\n- \u0005\n dx\n 4) Replace operator with position representation An S A1x2\nwhere we have added a rule about operators that will become obvious in a moment.\nExample 5.1 Normalize the wave function\n \nc1x2 = Ce-a0 x -  20. \n(5.31)\nUse Eq. (5.26) for the normalization condition and integrate over all space\n \n 1 =\n \nL\n\u0005\n- \u0005\n0 c1x20\n2\n dx\n \n \n =\n \nL\n\u0005\n- \u0005\n@ Ce-a0 x -  2@ 0\n2\n dx\n \n \n =\n \nL\n\u0005\n- \u0005\n0 C0\n2 e-2a0 x -  20  dx. \n(5.32)\nBreak the integral into two pieces to remove the absolute value:\n \n 1 =\n \nL\n2\n- \u0005\n0 C0\n2 e2a1x -  22 dx +\n \nL\n\u0005\n2\n0 C0\n2 e-2a1x -  22 dx \n \n = J 0 C0 2\n2a\n e2a 1x -  22 R\n2\n- \u0005\n+ J 0 C0 2\n-2a\n e-2a 1x  -22 R\n\u0005\n2\n \n \n = 0 C0\n2\na\n .\n \n(5.33)\nOnce again, we have freedom to choose the overall phase, so we let C be real and positive:\n \nC = 1a \n(5.34)\ngiving the normalized wave function\n \nc1x2 = 1a e\n -  a0 x -  2 0 . \n(5.35)\nUsing the rules for translating bra-ket notation to wave function notation, a general state vector \nprojection or probability amplitude expressed in wave function language is\n \n8f0 c9 =\n \nL\n\u0005\n- \u0005\nf*1x2c1x2dx . \n(5.36)\n\n5.3 The Wave Function \n117\nThe square of this probability amplitude is the probability that the state c1x2 is measured to be in the \nstate f1x2\n \nPcSw = 08w0 c90\n2 = 2\nL\n\u0005\n- \u0005\nw*1x2cx1x2dx 2\n2   \n . \n(5.37)\nTechnically, we should say that this is the probability that the system prepared in state c1x2 is measured \nto have the physical observable for which f1x2 is the eigenstate, because we measure observables, not \nstates. But the looser language is common and does not create any ambiguity in the calculation. If we \nmeasure the energy, for example, then the probability of obtaining the result En is\n \nPEn = 08En0 c90\n2 = 2\nL\n\u0005\n- \u0005\nw*\nn1x2c1x2dx 2\n2\n, \n(5.38)\nwhere wn1x2 is the energy eigenstate with energy En. Note that Eq. (5.28) and Eq. (5.37) look simi-\nlar but have important differences. In Eq. (5.28) we integrate the probability density (wave function \ncomplex squared) over a \ufb01nite range of position in order to sum the probabilities of measuring many \ndifferent positions. In Eq. (5.37) we integrate the product of two wave functions over all space to deter-\nmine their mutual overlap, and then we complex square that result to get the probability of measuring \na single result.\nTo transform an expectation value to wave function language, we must consider the operator. The \nexpectation value of an observable A is the matrix element of the operator\n \n8An9 = 8c0 An 0 c9. \n(5.39)\nIf we rewrite the expectation value as\n \n8An9 = 8c 05An0 c96, \n(5.40)\nwe see that it is an inner pro",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 137
  },
  {
    "child_id": "1211a60e-3028-4e22-b130-29f8e6124334",
    "parent_id": "9beab8f7-d5de-40a5-a138-aade0844445c",
    "text": "5.37) we integrate the product of two wave functions over all space to deter-\nmine their mutual overlap, and then we complex square that result to get the probability of measuring \na single result.\nTo transform an expectation value to wave function language, we must consider the operator. The \nexpectation value of an observable A is the matrix element of the operator\n \n8An9 = 8c0 An 0 c9. \n(5.39)\nIf we rewrite the expectation value as\n \n8An9 = 8c 05An0 c96, \n(5.40)\nwe see that it is an inner product where one ket has been transformed by the operator An. To write this \nin terms of wave functions, we must make sure to use the position representation form of the operator. \nFor example, the position operator xn in the position representation is simply multiplication by the sca-\nlar position x. Using the translation rules to write the expectation value of the position in wave function \nnotation yields\n \n 8xn9 = 8c0 xn 0 c9\n \n \n =\n \nL\n\u0005\n- \u0005\nc*1x2x c1x2dx \n \n =\n \nL\n\u0005\n- \u0005\nx0 c1x20\n2 dx,\n \n \n(5.41)\nwhere we have used the fact that scalar multiplication is commutative. For the expectation value of the \nmomentum, we \ufb01nd\n \n 8pn9 = 8c0 pn 0 c9\n \n \n =\n \nL\n\u0005\n- \u0005\nc*1x2a-iU d\ndxb c1x2dx, \n \n(5.42)",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 137
  },
  {
    "child_id": "5d57f933-57c2-4951-b8c7-e86ce5b7f2a1",
    "parent_id": "e3e4cd3d-81d2-4602-b94a-2904c3c6cf93",
    "text": "118 \nQuantized Energies: Particle in a Box\nwhich cannot be simpli\ufb01ed more without knowing the wave function. In the next section, we will solve \nthe energy eigenvalue equation for a speci\ufb01c potential energy to allow us to calculate these expectation \nvalues explicitly.\nExample 5.2 Consider the wave function from Example 5.1:\n \nc1x2 = 1a e\n -  a0 x -  2 0 . \n(5.43)\nCalculate the expectation value of the position and the probability that the particle is measured to \nbe in the interval 4 6 x 6 6.\nThe expectation value of position is given by Eq. (5.41)\n \n 8xn9 =\n \nL\n\u0005\n- \u0005\nx0 c1x20\n2\n dx\n \n \n =\n \nL\n\u0005\n- \u0005\nx 11ae -a 0 x -  202\n2\n dx\n \n \n = a\nL\n\u0005\n- \u0005\nxe -2a 0 x-\n 20  dx\n \n \n = a\nL\n2\n- \u0005\nxe2a 1x-22 dx + a\nL\n\u0005\n2\nxe-2a 1x-22 dx\n \n(5.44)\n \n = a Je2a 1x-22 1-1 + 2ax2\n4a2\nR\n2\n- \u0005\n+ a Je-2a 1x-22 1-1 - 2ax2\n4a2\nR\n\u0005\n2\n \n \n = a J1-1 + 4a2\n4a2\n- 0 + 0 - 1-1 - 4a2\n4a2\nR\n \n \n = 2.\n \nThis is what you expect based upon the plot of wave function shown in Fig. 5.7(a) and the probabil-\nity density in Fig. 5.7(b), which are symmetric about the point x = 2.\n(a)\n(b)\n\u00022\n0\n2\n4\n6\n\u00022\n0\n2\n4\n6\nP(x)\n(x)\nx\nx\nFIGURE 5.7 (a) Wave function and (b) corresponding probability density. The hatched region \nin (b) represents the probability for the particle to be measured in the region 4 6 x 6 6.\n\n5.4 In\ufb01nite Square Well \n119\nTo calculate the probability of \ufb01nding the particle in the interval, use Eq. (5.28)\n \n P46x66 =\n \nL\n6\n4\n2 1a e -a 0 x -\n 20 2\n2\n dx \n \n =\n \nL\n6\n4\nae -2a1x-22 dx\n \n(5.45)\n \n = c a\n-2a\n e -2a 1x-22 d\n6\n4\n \n \n = e -4a\n2\n 31 - e -4a4 .\n \nThis probability is shown as the hatched region in Fig. 5.7(b). The actual value of the probability \ndepends on the value of the parameter a.\n5.4 \u0002 INFINITE SQUARE WELL\nOur task now is to solve the energy eigenvalue equation, which we found to be a differential equation\n \na-  U2\n2m d 2\ndx2 + V 1x2\n b wE 1x2 = E wE 1x2. \n(5.46)\nAs you might expect, the solutions to this differential equation depend critically on the functional \ndependence of the potential energy V1x2. A generic potential energy function is depicted in Fig. 5.8 \nin a potential energy diagram that illustrates some important aspects of the motion of the particle. \nMost of the interesting systems to which we will apply Eq. (5.46) resemble the potential energy func-\ntion depicted in Fig. 5.8 in that V1x2 has a minimum, so we refer to the potential energy function as a \nx\nE1\nX1\nX2\nEnergy\nT \u0002\u0003E \u0004\u0003V(x)\nV(x)\nClassical\nturning points\nClassically allowed region\nClassically\nforbidden region\nClassically\nforbidden region\nFIGURE 5.8 A generic potential energy well.\n\n120 \nQuantized Energies: Particle in a Box\npotential well. The particle energy is conserved, so the kinetic energy T1x2 = E - V1x2 is illustrated \nin the potential energy diagram by the vertical arrow between the \ufb01xed energy E1 and the potential \nenergy V1x2. For a classical particle, the kinetic energy cannot be negative, so a classical particle with \nthe energy E1 chosen in Fig. 5.8 has its motion constrained to the region ",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 142
  },
  {
    "child_id": "860fd3b7-8aae-40a1-ab1c-14d3e9ec566a",
    "parent_id": "e3e4cd3d-81d2-4602-b94a-2904c3c6cf93",
    "text": "ssically\nforbidden region\nFIGURE 5.8 A generic potential energy well.\n\n120 \nQuantized Energies: Particle in a Box\npotential well. The particle energy is conserved, so the kinetic energy T1x2 = E - V1x2 is illustrated \nin the potential energy diagram by the vertical arrow between the \ufb01xed energy E1 and the potential \nenergy V1x2. For a classical particle, the kinetic energy cannot be negative, so a classical particle with \nthe energy E1 chosen in Fig. 5.8 has its motion constrained to the region between x1 and x2. These \nextreme points of the classical motion are called classical turning points and the region within the \nturning points is called the classically allowed region, while the regions beyond are called classically \nforbidden regions. Particles that have their motion constrained by the potential well are said to be \nin bound states. Particles with energies above the top of the potential well do not have their motion \nconstrained and so are in unbound states. Note that the extent of the classically forbidden and allowed \nregions depends on the speci\ufb01c value of the energy, E1, for a particular bound state.\nSolving Eq. (5.46) for various important potential energy functions is the subject of this and later \nchapters. In this chapter, our goal is to study a simple potential energy system and learn the mathemat-\nics required for this new wave function approach.\nWe begin our journey to energy quantization with the simplest example of a particle that is con-\n\ufb01ned to a region of space. The classical picture is a super ball bouncing between two perfectly elastic \nwalls. We call this system a particle in a box. We observe three important characteristics of this \nclassical system: (1) the ball \ufb02ies freely between the walls, (2) the ball is re\ufb02ected perfectly at each \nbounce, and (3) the ball remains in the box no matter how large its energy. These three observations \nare consistent with (1) zero force on the ball when it is between the walls, (2) in\ufb01nite force on the ball \nat the walls, and (3) in\ufb01nite potential energy outside the box.\nThe mathematical model that is consistent with these three observations of the motion of a par-\nticle in a box is given by the potential energy function shown in Fig. 5.9. The potential energy is zero \nwithin the well (any constant would suf\ufb01ce, but we choose zero for simplicity), and it is in\ufb01nite out-\nside the well. The discontinuity at the sides of the well requires us to write the potential energy func-\ntion in a piecewise fashion\n \nV1x2 = \u2022\n\u0005,\n0 ,\n\u0005,   \nx 6 0\n0 6 x 6 L\nx 7 L.\n \n(5.47)\nBecause of the shape of the potential energy in Fig. 5.9, this system is also referred to as an in\ufb01nite \nsquare well. Though this model is too simple to accurately represent any real quantum mechanical \nsystem, it does illustrate most of the important features of a particle bound to a limited region of space.\n0\nL/2\nL\nx\nV(x)\n\u0005\nFIGURE 5.9 In\ufb01nite square potential energy well.\n\n5.4 In\ufb01nite Square Well \n121\nOur goal is to \ufb01nd the energy",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 142
  },
  {
    "child_id": "d5c39cc9-283c-48f3-9409-b39a5de2139a",
    "parent_id": "e3e4cd3d-81d2-4602-b94a-2904c3c6cf93",
    "text": "fashion\n \nV1x2 = \u2022\n\u0005,\n0 ,\n\u0005,   \nx 6 0\n0 6 x 6 L\nx 7 L.\n \n(5.47)\nBecause of the shape of the potential energy in Fig. 5.9, this system is also referred to as an in\ufb01nite \nsquare well. Though this model is too simple to accurately represent any real quantum mechanical \nsystem, it does illustrate most of the important features of a particle bound to a limited region of space.\n0\nL/2\nL\nx\nV(x)\n\u0005\nFIGURE 5.9 In\ufb01nite square potential energy well.\n\n5.4 In\ufb01nite Square Well \n121\nOur goal is to \ufb01nd the energy eigenstates and eigenvalues of the system by solving the energy \neigenvalue equation using the potential energy in Eq. (5.47). The potential energy is piecewise, so we \nmust solve the differential equation (5.46) separately inside and outside the box. Outside the box, the \npotential energy is in\ufb01nite and the energy eigenvalue equation is\n \na-  U2\n2m d 2\ndx2 + \u0005b wE 1x2 = E wE 1x2,   outside box. \n(5.48)\nWe are looking for solutions with \ufb01nite energy E, so Eq. (5.48) is satis\ufb01ed only if the energy eigenstate \nwave function wE1x2 is zero everywhere outside the box. This means that the quantum mechanical \nparticle is excluded from the classically forbidden regions in this example. This correspondence with \nthe classical situation holds only for the case of in\ufb01nite potential energy walls on the potential well.\nInside the box, the potential energy is zero and the energy eigenvalue equation is\n \na-  U2\n2m\n d 2\ndx2 + 0b wE1x2 = EwE1x2,   inside box. \n(5.49)\nThus our task reduces to solving the differential equation inside the box:\n \n-  U2\n2m\n d 2\ndx2 wE1x2 = EwE1x2. \n(5.50)\nIt is worth reminding ourselves at this point what is known and what is not. The particle has a mass \nm and is con\ufb01ned to a box of size L. These quantities are known, as is U, a fundamental constant. The \nunknowns that we need to \ufb01nd are the energy E and the wave function wE1x2, which is what it means to \nsolve an eigenvalue problem (now posing as a differential equation).\nIt is convenient to rewrite the differential equation (5.50) as\n \n d 2\ndx2 wE1x2 = -  2mE\nU2  wE1x2 \n \n = -k2wE1x2,\n \n(5.51)\nwhere we have de\ufb01ned a new parameter\n \nk2 = 2mE\nU2 , \n(5.52)\nwhich is positive because the energy E is positive in this problem. The parameter k is called the wave \nvector, and its physical interpretation will be evident in Eq. (5.67). Equation (5.51) says that the \nenergy eigenstate wE1x2 is a function whose second derivative is equal to that function itself times a \nnegative constant. We can write the solution either in terms of complex exponential functions\n \nwE1x2 = A\u0004e ikx + B\u0004e -ikx \n(5.53)\nor in terms of sine and cosine functions\n \nwE1x2 = A sin kx + B cos kx. \n(5.54)\nEither solution includes two as yet unknown constants, as you would expect for a second-order differ-\nential equation. It turns out that bound state energy eigenstates can always be written as real functions, \nso we choose to work with the sine and cosine form of the general solution (if you choose the complex\n\n122 \nQuantized Ener",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 142
  },
  {
    "child_id": "07ede576-a84a-400b-bb8c-d8adadead01b",
    "parent_id": "e3e4cd3d-81d2-4602-b94a-2904c3c6cf93",
    "text": "n either in terms of complex exponential functions\n \nwE1x2 = A\u0004e ikx + B\u0004e -ikx \n(5.53)\nor in terms of sine and cosine functions\n \nwE1x2 = A sin kx + B cos kx. \n(5.54)\nEither solution includes two as yet unknown constants, as you would expect for a second-order differ-\nential equation. It turns out that bound state energy eigenstates can always be written as real functions, \nso we choose to work with the sine and cosine form of the general solution (if you choose the complex\n\n122 \nQuantized Energies: Particle in a Box\nexponential form, you will arrive at the sine and cosine solutions at the end of the problem anyway: \nProblem 5.3). Hence the energy eigenstate wave function throughout space is\n \nwE 1x2 = \u2022\n0 ,\nA sin kx + B cos kx ,\n0 ,\n   \nx 6 0\n0 6 x 6 L\nx 7 L.\n \n(5.55)\nWe now need some more information to reach the \ufb01nal solution. There are three unknowns in \nthe problem: A, B, and k [which contains the energy E through Eq. (5.52)], so we expect to need three \npieces of information to solve for the three unknowns. We get two of these pieces of information from \nimposing boundary conditions on the wave function. To make sure that the mathematical solutions \nproperly represent real physical systems, we require that the wave function be continuous across each \nboundary between different regions of space where different solutions exist. Applying this require-\nment on the continuity of the wave function at the sides of the box x = 0 and L yields two boundary \ncondition equations:\n \n wE102: A sin102 + B cos102 = 0 \n \n wE1L2: A sin kL + B cos kL = 0.  \n(5.56)\nThe boundary condition at the left side of the box yields\n \nB = 0. \n(5.57)\nThis tells us that the cosine part of the general solution is not allowed because the cosine solution is not \nzero at the edge of the box and so does not match the wave function outside the box. The exclusion of \nthe cosine part of the solution arises because we chose to locate our box with one side at x \u0003 0; if the \nbox is located differently, then both sine and cosine solutions may be allowed. Given that the allowed \nwave functions must be sine functions, the boundary condition at the right side of the box yields\n \nA sin kL = 0. \n(5.58)\nThis equation is satis\ufb01ed if A \u0003 0, but that yields a wave function that is zero everywhere, so it is unin-\nteresting. The more interesting possibility is that\n \nsin kL = 0. \n(5.59)\nThis is a transcendental equation that places limitations on the allowed values of the wave vector k. We \nwill \ufb01nd other transcendental equations when we study other potentials. This transcendental equation \nhas solutions when the sinusoid function is zero. Hence the wave vectors that satisfy this equation are\n \n kL = np\n \n \n kn = n p\nL\n ,   n = 1, 2, 3, ... . \n(5.60)\nOnly discrete wave vectors are allowed, so this is termed the quantization condition. The index n is \nthe quantum number, which we use to label the quantized states and energies. The value n = 0 is \nexcluded because that would yield a wave function",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 142
  },
  {
    "child_id": "b67aecc4-3793-4abb-8d4e-4e6562dfe38f",
    "parent_id": "e3e4cd3d-81d2-4602-b94a-2904c3c6cf93",
    "text": "r transcendental equations when we study other potentials. This transcendental equation \nhas solutions when the sinusoid function is zero. Hence the wave vectors that satisfy this equation are\n \n kL = np\n \n \n kn = n p\nL\n ,   n = 1, 2, 3, ... . \n(5.60)\nOnly discrete wave vectors are allowed, so this is termed the quantization condition. The index n is \nthe quantum number, which we use to label the quantized states and energies. The value n = 0 is \nexcluded because that would yield a wave function equal to zero, which is uninteresting. The nega-\ntive values of n are excluded because they yield the same states as the corresponding positive n values,\n\n5.4 In\ufb01nite Square Well \n123\nrecalling that an overall phase A-1 = eip in this caseB does not change the physical state. Using the de\ufb01-\nnition of the wave vector in Eq. (5.52), we relate the quantized wave vectors to the quantized energies\n \nEn = U2k 2\nn\n2m . \n(5.61)\nHence, the wave vector quantization condition in Eq. (5.60) results directly in the energy quantization \nfor this system:\n \nEn = n2p2U2\n2mL2 ,   n = 1, 2, 3, ...  . \n(5.62)\nThese allowed energies scale with the square of the quantum number n and produce the set of energy \nlevels shown in Fig. 5.10. The ground state is the n \u0003 1 level.\nThe allowed energy eigenstate wave functions are:\n \nwn1x2 = A sin npx\nL ,   n = 1, 2, 3, ...  . \n(5.63)\nThe constant A was not determined by the boundary conditions. To determine A, we need the third \npiece of information, which is that the wave function is normalized to unity:\n \n1 = 8En 0\n En9 =\n \nL\n\u0005\n- \u0005\nw*\nn1x2wn1x2dx =\n \nL\n\u0005\n- \u0005\n0 wn1x20\n2\n dx. \n(5.64)\n0\n5\n10\n15\n20\n25\nE /E1\nn \u0002\u00031\nn \u0002\u00032\nn \u0002\u00033\nn \u0002\u00034\nn \u0002\u00035\nE1 \u0002 1E1\nE2 \u0002 4E1\nE3 \u0002 9E1\nE4 \u0002 16E1\nE5 \u0002 25 E1\nFIGURE 5.10 Energy spectrum of the in\ufb01nite square potential energy well.",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 142
  },
  {
    "child_id": "f282c5b2-01df-4643-bbb8-124dcd818130",
    "parent_id": "f1712e35-8508-43d5-927d-331e848209b9",
    "text": "124 \nQuantized Energies: Particle in a Box\nSubstitute the wave function from Eq. (5.63) and note that the wave function is zero for x 6 0 and \nx 6 L to limit the range of integration, resulting in\n \n1 =\n \nL\nL\n0\n0 A0\n2 sin2 kn\n x dx = 0 A0\n2 L\n2 . \n(5.65)\nWe are free to choose the normalization constant to be real and positive, because an overall phase is \nnot measurable. Thus the normalization constant is A = 12>L and the properly normalized energy \neigenstates are\n \nwn1x2 = A\n2\nL sin npx\nL ,   n = 1, 2, 3, ...  . \n(5.66)\nThe \ufb01rst few allowed energy states are shown in Fig. 5.11. From these plots, it is now clear why \nwe call c1x2 the wave function. These energy eigenstates have a \u201cwavy\u201d spatial dependence, much \nlike the modes on a guitar string. For the in\ufb01nite square well, the waves \u201c\ufb01t\u201d into the potential well \nsuch that there are an integer number of half wavelengths within the well. If we relate the wave vector \nk to a wavelength l through the relation\n \nk = 2p\nl , \n(5.67)\nthen we can rewrite the quantization condition in terms of the wavelength\n \n kn = n p\nL  \n \n 2p\nln\n= n p\nL  \n \n ln = 2L\nn\n \n(5.68)\n \n L = n ln\n2 . \nIn words, the well must contain an integer number of half wavelengths. This is the sense in which the \nwaves must \u201c\ufb01t\u201d into the well. This is the same as the classical result for the allowed standing waves \non a vibrating string, such as a guitar string. The distinction between the classical wave and the quan-\ntum wave is that the classical wave does not have a quantized energy. The energy of a vibrating guitar \nn \u0002\u00031\nL/2\nL\nx\n\u03a8(x)\n(a)\nn \u0002\u00032\nL/2\nL\nx\n\u03a8(x)\n(b)\nn \u0002\u00033\nL/2\nL\nx\n\u03a8(x)\n(c)\nFIGURE 5.11 Wave functions of the \ufb01rst three energy eigenstates of the in\ufb01nite \nsquare potential energy well.\n\n5.4 In\ufb01nite Square Well \n125\nstring depends on the amplitude of oscillation, not on the wavelength or wave vector, and so it can have \nany energy value. The amplitude of the quantum wave function is determined by the normalization \ncondition and is independent of the energy for the in\ufb01nite square well.\nThe wave properties of this quantum system are a new aspect that is not evident in the classical \ndescription of a particle. In classical mechanics, waves and particles are clearly distinct, whereas in \nquantum mechanics a system exhibits properties that remind us of classical particles but also exhibits \nproperties of classical waves. This is often referred to as wave-particle duality. We will see more of \nthis in the next chapter when we discuss free particles.\nExample 5.3 It is useful to put some numbers into these expressions to get a sense of scale. For \nexample, if we con\ufb01ne an electron 1me = 511 k eV>c22 in a box of size 0.2 nm (about the size of an \natom), the ground state (n \u0003 1) energy is\n \n E1 =\np2U2\n2me L2\n \n \n =\np216.58 * 10-16 eV s2\n2\n210.511 * 106 eV>c2210.2 * 10-9 m2\n2 \n(5.69)\n \n = 9.4 eV. \nThis is comparable to typical atomic binding energies.\nThe spectrum of this system will include the transition between the ground state and ",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 148
  },
  {
    "child_id": "243fff01-d918-4219-a5ad-5cfd3a46e42e",
    "parent_id": "f1712e35-8508-43d5-927d-331e848209b9",
    "text": "articles.\nExample 5.3 It is useful to put some numbers into these expressions to get a sense of scale. For \nexample, if we con\ufb01ne an electron 1me = 511 k eV>c22 in a box of size 0.2 nm (about the size of an \natom), the ground state (n \u0003 1) energy is\n \n E1 =\np2U2\n2me L2\n \n \n =\np216.58 * 10-16 eV s2\n2\n210.511 * 106 eV>c2210.2 * 10-9 m2\n2 \n(5.69)\n \n = 9.4 eV. \nThis is comparable to typical atomic binding energies.\nThe spectrum of this system will include the transition between the ground state and the \ufb01rst excited \nstate. The \ufb01rst excited state has energy E2 = 22E1 = 4E1, so the wavelength of light for this transition is\n \n l21 =\nhc\nE2 - E1\n= hc\n3E1\n \n \n = 1240 eV nm\n319.4 eV2\n= 44 nm . \n(5.70)\nNote that l21 is the wavelength of the photon emitted or absorbed in the transition, not the wave-\nlength of the bound particle that is associated with the wave vector of the wave function, which is \n0.4 nm for the ground state and 0.2 nm for the excited state, in agreement with Eq. (5.68).\nNow that we have found the energy eigenstates, we have what we need to calculate probabilities \nand expectation values to compare with experiments. The square of the wave function gives us the \nprobability density\n \n Pn1x2 = 0 wn1x2 0\n2\n \n \n = 2\nL sin2 npx\nL , \n(5.71)\nwhich is shown in Fig. 5.12 for the \ufb01rst three states. Note that the probability density is zero outside \nthe well, so the probability of \ufb01nding the particle anywhere outside the well is zero, just as in the clas-\nsical case. However, in the quantum system there are positions within the well where the probability \nof \ufb01nding the particle is zero, which does not happen in the classical case. These positions are at the \nnodes of the wave function and hence are characteristic of the wave nature of the particle.\n\n126 \nQuantized Energies: Particle in a Box\nExample 5.4 Find the expectation value of the position for a particle in the ground state of an \nin\ufb01nite square potential energy well.\nThe expectation value of position is given by Eq. (5.41)\n \n 8xn9 = 8E10\n xn  0 E19 =\n \nL\n\u0005\n- \u0005\nw*\n11x2xw11x2dx =\n \nL\n\u0005\n- \u0005\nx  0\n w11x20\n2\n dx \n \n = 2\nL L\nL\n0\nx sin2a px\nL b dx = 2\nL\n a L\npb\n2\nL\np\n0\ny sin21y2dy\n \n \n = 2\nL\n a L\npb\n2\n c y2\n4 - y sin 2y\n4\n-\n cos 2y\n8\nd\np\n0\n \n(5.72)\n \n = 2\nL\n a L\npb\n2\n c p2\n4 -\np sin12p2\n4\n-\n cos12p2\n8\n+ 1\n8 d\n \n \n = 2\nL\n a L\npb\n2\n c p2\n4 d\n \n \n = L\n2 .\n \nThis is what we would expect to get given the symmetry of the problem. There is no preference for \nthe left or right side of the well, so the average value of a set of position measurements must be the \nmidpoint of the well. We get the same result for any energy eigenstate of the system.\nTo summarize, we have solved the problem of a particle bound in an in\ufb01nitely deep square poten-\ntial energy well, which means we have found the energy eigenvalues and eigenstates. The well is \ndepicted in Fig. 5.13(a), the spectrum of allowed energies is depicted in Fig. 5.13(b), and the wave \nfunctions of the energy eigenstates are depicted in Fig. 5.13(c). It is com",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 148
  },
  {
    "child_id": "4446c0f5-7a53-4af5-9365-d330ca7b2186",
    "parent_id": "f1712e35-8508-43d5-927d-331e848209b9",
    "text": "a set of position measurements must be the \nmidpoint of the well. We get the same result for any energy eigenstate of the system.\nTo summarize, we have solved the problem of a particle bound in an in\ufb01nitely deep square poten-\ntial energy well, which means we have found the energy eigenvalues and eigenstates. The well is \ndepicted in Fig. 5.13(a), the spectrum of allowed energies is depicted in Fig. 5.13(b), and the wave \nfunctions of the energy eigenstates are depicted in Fig. 5.13(c). It is common practice to unify the three \ndiagrams of Fig. 5.13 in a single diagram, shown in Fig. 5.14, that represents the quantum mechani-\ncal potential energy well problem and its solution. The well, the energies, and the wave functions are \nsuperimposed on each other, such that different aspects of the diagram have different vertical axes. \nThe wave function for each energy eigenstate has its vertical coordinate origin located at the energy of \nthat state.\nn \u0002\u00033\n0\n(c)\nL/2\nL\nx\n\u0002\u03a8\u00022\nn \u0002\u00031\n0\n(a)\nL/2\nL\nx\n\u0002\u03a8\u00022\nn \u0002\u00032\n0\n(b)\nL/2\nL\nx\n\u0002\u03a8\u00022\nFIGURE 5.12 Probability densities of the \ufb01rst three energy eigenstates of the \nin\ufb01nite square potential energy well.\n\n5.4 In\ufb01nite Square Well \n127\n0\nL\nx\nV(x)\n(a)\n\u0005\n0\n5\n10\n15\n20\n25\n(b)\nE /E1\nn \u0002\u00031\nn \u0002\u00032\nn \u0002\u00033\nn \u0002\u00034\nn \u0002\u00035\nL\nx\nn \u0002\u00035\nL\nx\nn \u0002\u00034\nL\nx\nn \u0002\u00033\nL\nx\nn \u0002\u00032\nL\n(c)\nx\nn \u0002\u00031\n\u03a8(x)\nFIGURE 5.13 (a) In\ufb01nite square potential energy well, (b) spectrum of allowed energies, and \n(c) energy eigenstate wave functions.\n0\nL\nx\nn \u0002\u00031\nn \u0002\u00032\nn \u0002\u00033\nn \u0002\u00034\nn \u0002\u00035\nFIGURE 5.14 Uni\ufb01ed schematic diagram of in\ufb01nite square well problem and solution. \nNote that two vertical scales are implied. For the potential energy well and the energy  \nspectrum, the vertical scale is energy with the origin at the bottom of the well. For the  \nwave functions, the vertical scale is probability amplitude 11>length1>22 with the \nc = 0 origin for each state centered on the energy of that state.\n\n128 \nQuantized Energies: Particle in a Box\nThe take home message of this problem is that the imposition of boundary conditions on the \nwave function limits the possible states that can \u201c\ufb01t\u201d into the well and directly leads to the quantiza-\ntion of energy. This is a general result that we will return to time and again as we study other potential \nwell landscapes.\n5.5 \u0002 FINITE SQUARE WELL\nNow let\u2019s make the problem a little more realistic by having the potential energy outside the well be \ufb01nite \ninstead of in\ufb01nite. We still assume that the well is square, which still results in an in\ufb01nite force at the \nwalls. However, this new problem illustrates several important features of bound energy states that were \nnot evident in the in\ufb01nite well. A \ufb01nite well can be used to model many real systems, such as an electron \nin a thin semiconductor. In Section 5.8, we use this model to discuss quantum well semiconductor lasers.\nThe \ufb01nite square well potential energy is shown in Fig. 5.15 and is written as\n \nV1x2 = \u2022\nV0,\nx 6 -a\n  0,\n-a 6 x 6 a\nV0,  \nx 7 a,\n \n(5.73)\nwhere we have deliberately chosen a diffe",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 148
  },
  {
    "child_id": "49b8017f-5714-4ad6-a66c-534adb963c3a",
    "parent_id": "f1712e35-8508-43d5-927d-331e848209b9",
    "text": " \nwalls. However, this new problem illustrates several important features of bound energy states that were \nnot evident in the in\ufb01nite well. A \ufb01nite well can be used to model many real systems, such as an electron \nin a thin semiconductor. In Section 5.8, we use this model to discuss quantum well semiconductor lasers.\nThe \ufb01nite square well potential energy is shown in Fig. 5.15 and is written as\n \nV1x2 = \u2022\nV0,\nx 6 -a\n  0,\n-a 6 x 6 a\nV0,  \nx 7 a,\n \n(5.73)\nwhere we have deliberately chosen a different position origin from the in\ufb01nite well case in order to \ngive you practice and also for convenience. For now, we look for bound state solutions, that is, for \nenergies below the potential V0. Energies above V0 correspond to unbound states that we will discuss \nin the next chapter.\nWith this new potential energy function, the energy eigenvalue equation is\n \n a-  U2\n2m d 2\ndx 2 + 0b wE1x2 = EwE1x2,    inside box  \n \n a-  U2\n2m d 2\ndx 2 + V0b wE1x2 = EwE1x2,          outside box . \n(5.74)\n0\n\u0004a\na\nx\nV(x)\nV0\nFIGURE 5.15 Finite square potential energy well.\n\n5.5 Finite Square Well \n129\nIn the in\ufb01nite well problem, we found it useful to use the wave vector k\n \nk = A\n2mE\nU2 . \n(5.75)\nIn this case, it is also useful to de\ufb01ne a similar constant outside the well\n \nq = A\n2m\nU2 1V0 - E2. \n(5.76)\nFor bound states, 0 6 E 6 V0, and therefore both k and q are real. We use these two constants to \nrewrite the energy eigenvalue equation:\n \n \nd 2wE1x2\ndx2\n= -k2wE1x2,    inside box  \n \n \nd 2wE1x2\ndx 2\n= q 2wE1x2,       outside box . \n(5.77)\nThe energy eigenvalue equation inside the box is identical to the one we solved for the in\ufb01nite well poten-\ntial. The differential equation outside the box is similar except the constant is positive instead of negative, \ngiving real exponential solutions rather than complex exponentials. Thus the solution outside the box is\n \nwE1x2 = Aeqx + Be-qx. \n(5.78)\nThis solution in the classically forbidden region is exponentially decaying, or growing, with a decay \nlength, or growth length, of 1Nq.\nThe energy eigenstate must be constructed by connecting solutions in the three regions shown in \nFig. 5.15. We write the general solution as\n \nwE1x2 = \u2022\nAeqx + Be-qx,\nC sin kx + D cos kx,\nFeqx + Ge-qx,    x 6 -a\n -a 6 x 6 a\n x 7 a.\n \n(5.79)\nAs we discussed in the in\ufb01nite well problem, the solutions in the three regions must satisfy bound-\nary conditions where the regions connect. In constructing the in\ufb01nite well solutions, we used the \ncondition that the wave function must be continuous across a boundary. We now introduce a second \nrequirement that the slope of the wave function be continuous across a boundary. If the slope were \ndiscontinuous, that would imply an in\ufb01nite kinetic energy. However, this requirement has one excep-\ntion: it does not apply if the potential is in\ufb01nite (Problem 5.24), which is why we did not use it in the \nin\ufb01nite well problem. You can see in Fig. 5.14 that the in\ufb01nite well solutions have a change in slope \nat the edges of the",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 148
  },
  {
    "child_id": "3c1f723b-610a-452d-8e10-3bf0b6df8a18",
    "parent_id": "f1712e35-8508-43d5-927d-331e848209b9",
    "text": "ction must be continuous across a boundary. We now introduce a second \nrequirement that the slope of the wave function be continuous across a boundary. If the slope were \ndiscontinuous, that would imply an in\ufb01nite kinetic energy. However, this requirement has one excep-\ntion: it does not apply if the potential is in\ufb01nite (Problem 5.24), which is why we did not use it in the \nin\ufb01nite well problem. You can see in Fig. 5.14 that the in\ufb01nite well solutions have a change in slope \nat the edges of the box where the potential energy becomes in\ufb01nite. We now summarize these two \nboundary conditions:\n 1) wE1x2 is continuous\n 2) dwE1x2\ndx\n is continuous unless V = \u0005.\nBefore we impose the boundary conditions, we make two immediate simpli\ufb01cations to the gen-\neral solutions in Eq. (5.79). In the regions outside the well, the wave function must be a decaying",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 148
  },
  {
    "child_id": "8f958aa1-7a82-4f6b-beb4-4a40f4215b68",
    "parent_id": "711fa48f-1c6a-46c1-bbe0-acf86541bc95",
    "text": "130 \nQuantized Energies: Particle in a Box\nexponential because a growing exponential term all the way out to in\ufb01nity would not permit the wave \nfunction to be normalized. This normalization condition, which can also be termed a boundary condi-\ntion at in\ufb01nity, requires that B = F = 0 in Eq. (5.79). The second simpli\ufb01cation comes from recog-\nnizing that the potential energy is symmetric with respect to the origin 3V1x2 = V1-x24. This means \nthat the energy eigenstates will either be symmetric or antisymmetric (even or odd). This symmetry \nis evident in the in\ufb01nite well solutions shown in Fig. 5.14. (This can also be discussed in terms of the \ncommutation of the Hamiltonian and the parity operator, which we discuss in Section 7.6.4) We can \nthus solve for the two sets of solutions independently. If you don\u2019t impose this symmetry condition \nnow, it will come out naturally after some algebra on the general solutions anyway (Problem 5.14). \nWith these two simpli\ufb01cations, the even solutions reduce to\n \nweven1x2 = \u2022\nAeqx,\nD cos1kx2,\nAe-qx,\n   \nx 6 -a\n-a \u2026 x \u2026 a\nx 7 a.\n \n(5.80)\nThe odd solutions are\n \nwodd1x2 = \u2022\nAeqx,\nC sin1kx2,\n-Ae-qx,\n   \nx 6 -a\n-a \u2026 x \u2026 a\nx 7 a.\n \n(5.81)\nLet\u2019s \ufb01rst do the even solutions. The boundary conditions at the right side of the well 1x = a2 give\n \n weven1a2: D cos1ka2 = Ae-qa\n \n \n \ndweven1x2\ndx\n`\nx=a \n: -kD sin1ka2 = -qAe-qa. \n(5.82)\nThe boundary conditions at the left side of the well 1x = -a2 yield the same equations, which must be \ntrue because of the symmetry. The two equations above have three unknowns: the amplitudes A and D \nand the energy E, which is contained in the parameters k and q. The normalization condition provides \nthe third equation required to solve for all three unknowns. We \ufb01nd the energy condition rather simply \nby dividing the two equations, which eliminates the amplitudes and yields\n \nk tan1ka2 = q. \n(5.83)\nBecause both k and q are functions of the energy, this equation gives us a formula to \ufb01nd the allowed \nenergies. It is independent of the constants A and D, which are found by applying the normalization \ncondition and using Eq. (5.82) again. As usual with these types of problems, the eigenvalue condi-\ntion is obtained \ufb01rst, and then the eigenfunctions are obtained later. To make the energy dependence \nexplicit, we use Eqs. (5.75) and (5.76) to write Eq. (5.83) as\n \nA\n2m\nU2  E tana A\n2m\nU2  E ab = A\n2m\nU2  1V0 - E2. \n(5.84)\nThe next step is to solve this transcendental equation for the energy E.\nFor the odd solutions, a similar argument leads to the transcendental equation (Problem 5.15)\n \n-k cot1ka2 = q. \n(5.85)\n\n5.5 Finite Square Well \n131\nA graphical solution for the allowed energies using these two transcendental equations is most useful \nhere. There are many ways of doing this. One way involves de\ufb01ning some new dimensionless parameters:\n \n z = ka = B\n2mEa2\nU2\n \n \n z0 = B\n2mV0a2\nU2\n \n \n qa = B\n2m1V0 - E2a2\nU2\n, \n \n(5.86)\nwhere the variable z parameterizes the energy of the state and the constant ",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 154
  },
  {
    "child_id": "024eb7df-6ffa-4887-af22-1fbb7c2b068a",
    "parent_id": "711fa48f-1c6a-46c1-bbe0-acf86541bc95",
    "text": "lutions, a similar argument leads to the transcendental equation (Problem 5.15)\n \n-k cot1ka2 = q. \n(5.85)\n\n5.5 Finite Square Well \n131\nA graphical solution for the allowed energies using these two transcendental equations is most useful \nhere. There are many ways of doing this. One way involves de\ufb01ning some new dimensionless parameters:\n \n z = ka = B\n2mEa2\nU2\n \n \n z0 = B\n2mV0a2\nU2\n \n \n qa = B\n2m1V0 - E2a2\nU2\n, \n \n(5.86)\nwhere the variable z parameterizes the energy of the state and the constant z0 characterizes the strength \nof the potential energy well. These de\ufb01nitions lead to the convenient expressions\n \n 1ka2\n2 + 1qa2\n2 = z 2\n0\n \n \n 1qa2\n2 = z 2\n0 - 1ka2\n2 = z 2\n0 - z 2. \n \n(5.87)\nThis allows us to write the transcendental equations in this form:\n \n ka tan1ka2 = qa  S  z tan1z2 = 4z 2\n0 - z 2\n \n \n -ka cot1ka2 = qa  S  -z cot1z2 = 4z 2\n0 - z 2. \n \n(5.88)\nIn each of these new transcendental equations, the left side is a modi\ufb01ed trig function, while the right \nside is a circle with radius z 0. These functions are plotted in Fig. 5.16 as a function of the parameter \nz. The intersection points of these curves determine the allowed values of z and hence the allowed \nenergies En through Eq. (5.86). Because the constant z 0 is the radius of the circle, there are a limited \nnumber of allowed energies, and that number grows as z 0 gets larger. Wells that are deeper and wider \nhave more allowed bound energy states. \nThat\u2019s it for the energies. There is no simple formula\u2014the transcendental equations must be \nsolved graphically or numerically for each different well. For example, the curves in Fig. 5.16 corre-\nspond to a well with z 0 = 6, which results in four intersection points and hence four bound states. The \nintersection points and four allowed energies are\n \n z1 = 1.34 S E1 = 1.81 U2\n2ma2\n \n \n z2 = 2.68 S E2 = 7.18 U2\n2ma2\n \n \n z3 = 3.99 S E3 = 15.89 U2\n2ma2  \n \n z4 = 5.23 S E4 = 27.31 U2\n2ma2 . \n \n(5.89)\nThe energy eigenstate wave functions are characterized by the allowed values of the parameters \nk and q from Eq. (5.86). All that remains to do is normalize the wave function, which is straightfor-\nward but tedious (Problem 5.16). Once again, we use a uni\ufb01ed diagram to show the potential energy \nwell, the allowed energies, and the allowed eigenstate wave functions superimposed in Fig. 5.17.\n\n132 \nQuantized Energies: Particle in a Box\n0\n\u0004a\na\nx\nn \u0002\u00031\nn \u0002\u00032\nn \u0002\u00034\nn \u0002\u00033\nFIGURE 5.17 Uni\ufb01ed schematic diagram of the \ufb01nite potential energy well and the bound state \nsolutions, showing the well, the allowed energies, and the energy eigenstate wave functions.\n0\n\u000b\n2\n\u000b\n3\u000b\n2\nz\n\u000b\n2\n\u000b\n3\u000b\n2\n2\u000b\nf(z)\nz tanz\n_z cotz\nz02\u000b\nz0\nz2\n0 \n_ z 2\nFIGURE 5.16 Graphical solution of the transcendental equations for the allowed energies of a \ufb01nite \nsquare well 1z0 = 62.\n\n5.6 Compare and Contrast \n133\nNote that the \ufb01nite well eigenstates share many features with the in\ufb01nite well states, with one major \nexception\u2014they extend into the classically forbidden region. Quantum mechanical p",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 154
  },
  {
    "child_id": "37a4ef1a-a855-4191-91c2-394e77e35c0f",
    "parent_id": "711fa48f-1c6a-46c1-bbe0-acf86541bc95",
    "text": "\nsolutions, showing the well, the allowed energies, and the energy eigenstate wave functions.\n0\n\u000b\n2\n\u000b\n3\u000b\n2\nz\n\u000b\n2\n\u000b\n3\u000b\n2\n2\u000b\nf(z)\nz tanz\n_z cotz\nz02\u000b\nz0\nz2\n0 \n_ z 2\nFIGURE 5.16 Graphical solution of the transcendental equations for the allowed energies of a \ufb01nite \nsquare well 1z0 = 62.\n\n5.6 Compare and Contrast \n133\nNote that the \ufb01nite well eigenstates share many features with the in\ufb01nite well states, with one major \nexception\u2014they extend into the classically forbidden region. Quantum mechanical particles have a \n\ufb01nite probability of being found where classical particles may not exist! This is a purely quantum \nmechanical effect and is commonly referred to as barrier penetration. The ability of the particle \nto penetrate the potential energy barrier leads to the phenomenon of tunneling, an example of which \nis radioactive decay. We\u2019ll say more about these wave functions in a bit, but let\u2019s \ufb01rst check that our \nsolution is consistent with the solution we derived earlier for the in\ufb01nite energy well case.\nThe limit of an in\ufb01nitely deep well corresponds to the radius z0 in Fig. 5.16 going to in\ufb01nity, in \nwhich case the allowed values of z become the asymptotes of the modi\ufb01ed trig functions, shown by the \ndashed lines in Fig. 5.16. These limits are the same as for the simple trig functions and yield\n \n zn = n p\n2 1 kna = n p\n2 \n \n kn = np\n2a ,\n \n \n(5.90)\nfrom which we recover the in\ufb01nite well energy eigenvalues:\n \nEn =\nn2p2 U2\n2m12a2\n2 . \n(5.91)\nNote that the width of the well is 2a here, whereas we called the width L in the in\ufb01nite well case. The \nin\ufb01nite well eigenstate wave functions for this symmetric well position are\n \n wn1x2 = A\n2\n2a\n cos npx\n2a ,    n = 1, 3, 5, ...  \n \n wn1x2 = A\n2\n2a\n sin npx\n2a ,    n = 2, 4, 6, ... . \n \n(5.92)\nThere are two sets of solutions because we chose a different coordinate system to solve the problem. \nIn the limit z0 S \u0005, the decay length q becomes zero and the energy eigenstates are zero outside the \nwell, as expected. The in\ufb01nite well eigenstates are shown in Fig. 5.18(a) for this new choice of coor-\ndinates. Comparing the wave functions in Fig. 5.18(a) with those from Fig. 5.14, though, we see that \nthese are the same eigenstate wave functions that we found before. In Fig. 5.18(b) we show the \ufb01nite \nwell states for comparison.\n5.6 \u0002 COMPARE AND CONTRAST\nNow that we have solved two similar problems, the in\ufb01nite and \ufb01nite square wells, let\u2019s discuss some \nof the important features of these solutions and see which features are common to both problems and \nothers, and which are distinct.\n 5.6.1 \u0002 Wave Function Curvature\nThe \ufb01rst common feature is that the wave function is oscillatory 1sin kx or cos kx2 inside the well and \nexponentially decaying (e-qx or eqx) outside the well. This aspect is explained by examining the curvature \n(i.e., second derivative) of the wave function. To see this, we rewrite the energy eigenvalue equation\n \nd 2wE 1x2\ndx2\n= -  2m\nU2  3E - V 1x24wE 1x2, \n(5.93)\n\n134 \nQuantized Energies: Particl",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 154
  },
  {
    "child_id": "473de504-b80b-4107-a26c-33324832731c",
    "parent_id": "711fa48f-1c6a-46c1-bbe0-acf86541bc95",
    "text": "e common to both problems and \nothers, and which are distinct.\n 5.6.1 \u0002 Wave Function Curvature\nThe \ufb01rst common feature is that the wave function is oscillatory 1sin kx or cos kx2 inside the well and \nexponentially decaying (e-qx or eqx) outside the well. This aspect is explained by examining the curvature \n(i.e., second derivative) of the wave function. To see this, we rewrite the energy eigenvalue equation\n \nd 2wE 1x2\ndx2\n= -  2m\nU2  3E - V 1x24wE 1x2, \n(5.93)\n\n134 \nQuantized Energies: Particle in a Box\nwhich then directly relates the wave function curvature to the difference between the energy E and \nthe potential energy V(x). Thus, inside the well, in the classically allowed region, we have E 7 V1x2 \nand the differential equation admits only sinusoidal solutions characterized by the wave vector k or \nwavelength l = 2p>k. Outside the well, in the classically forbidden region, we have E 6 V1x2 and \nthe differential equation admits only real exponential solutions with a decay length of 1>q, which is \nzero for the in\ufb01nite square well. The growing exponential terms in these problems are excluded by the \nnormalization requirement (i.e., the boundary condition at in\ufb01nity).\nThese comments can be generalized as shown in Fig. 5.19. Equation (5.93) tells us that in a clas-\nsically allowed region where E 7 V, the curvature has the opposite sign to the wavefunction, and in \nthe classically forbidden region where E 6 V, the curvature has the same sign as the wavefunction. \nThis means that in the classically allowed region the wave function is concave toward the axis, while \nin the classically forbidden region the wave function is convex toward the axis, as shown in Fig. 5.19.\nWe can also make some general observations regarding the length scales of the wave functions. In \na general potential well, the wave vector is given by\n \nk =\n22m 1E - V2\nU\n. \n(5.94)\nHence, the oscillatory part of the wave function (inside the well) has a characteristic wavelength\n \nl = 2p\nk\n=\nh\n22m 1E - V2\n\f\n1\n2T\n. \n(5.95)\nSo the larger the energy difference between the eigenvalue and the potential energy (i.e., the larger \nthe kinetic energy), the smaller the wavelength. That relationship is evident in the eigenstates shown \nin Fig. 5.18; the higher the energy, the more \u201cwiggly\u201d the wave function. In the forbidden region, the \ndecay constant \n \nq =\n22m 1V - E2\nU\n \n(5.96)\n\u0004a\n0\na\nx\n0\n\u0004a\na\nx\n(a)\n(b)\nFIGURE 5.18 (a) In\ufb01nite and (b) \ufb01nite well energy eigenstates.",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 154
  },
  {
    "child_id": "7700565f-e2ee-452f-9ab6-85ad0e599880",
    "parent_id": "df3dc39a-d035-41f5-8bb8-be4cff004a0a",
    "text": "5.6 Compare and Contrast \n135\ndecreases as the energy increases toward V, which means that the decay length becomes larger. Hence, \nfor higher energy states the wave function penetrates further into the classically forbidden region \n(Problem 5.17). This increasing penetration with increasing energy is evident in the \ufb01nite well states \nof Fig. 5.17.\nIn comparing the \ufb01nite and in\ufb01nite well energies in Fig. 5.18, we also note that a given \ufb01nite well \nenergy eigenvalue En lies below the corresponding in\ufb01nite well energy eigenvalue. This is consistent \nwith the longer wavelength of the \ufb01nite well eigenstate compared to the corresponding in\ufb01nite well \nstate. For the \ufb01nite well eigenstate to \u201c\ufb01t\u201d in the well, the wavelength can be longer because part of the \nwave function is outside the well. The increasing penetration of the wave function into the classically \nforbidden region with increasing energy implies that the difference in energies between the \ufb01nite and \nin\ufb01nite wells is larger for higher energies, as is also evident in Fig. 5.18 (Problem 5.19).\n 5.6.2 \u0002 Nodes\nThe ground state has a single antinode in the wave function, with each subsequent higher state acquiring \nan extra antinode. Thus the nth energy level has n antinodes and 1n - 12 nodes. This is a general char-\nacteristic of the energy eigenstates of any potential energy well. In the in\ufb01nite well we found an in\ufb01nite \nnumber of states. In the \ufb01nite well we found a \ufb01nite number of states, but we looked only for bound \nstates. We will see later that there are an in\ufb01nite number of unbound states with E 7 V0, which means \nthat there are an in\ufb01nite number of total allowed energy states. The in\ufb01nite number of states is a common \nfeature of potential energy wells. In the \ufb01nite well, if the well is small enough (small V0 and/or small a), \nthen there might be only one bound state, but there is always at least one bound state. This is generally \ntrue for any well shape. The delta-function potential is an extreme case (Problem 5.25).\n 5.6.3 \u0002 Barrier Penetration\nIn the \ufb01nite potential well, the wave function is nonzero in the classically forbidden region. This \nimplies a \ufb01nite probability that the quantum mechanical particle can be found where the classical \nparticle cannot. As mentioned above, this penetration of the wave function into the potential energy \nx\nE0\nE, \u03a8\nExponential\nOscillatory\nAllowed\nForbidden\nV(x)\n\u03a8 > 0, \u03a8\" < 0\n\u03a8 < 0, \u03a8\" > 0\n\u03a8 > 0, \u03a8\" > 0\n\u03a8 < 0, \u03a8\" < 0\nFIGURE 5.19 Curvature of the energy eigenstate wave functions in the allowed and forbidden regions.\n\n136 \nQuantized Energies: Particle in a Box\nbarrier leads to the phenomenon of tunneling, which we explore in the next chapter. The wave function \nplots in Fig. 5.18 indicate that the barrier penetration is more pronounced for higher energy levels and \ncan become quite large for energies close to the top of the well. This aspect is clear quantitatively if we \nnote that the decay constant q in the forbidden region decreases as the energy in",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 159
  },
  {
    "child_id": "1330dccc-dc1e-4564-b912-90c87c623721",
    "parent_id": "df3dc39a-d035-41f5-8bb8-be4cff004a0a",
    "text": "ate wave functions in the allowed and forbidden regions.\n\n136 \nQuantized Energies: Particle in a Box\nbarrier leads to the phenomenon of tunneling, which we explore in the next chapter. The wave function \nplots in Fig. 5.18 indicate that the barrier penetration is more pronounced for higher energy levels and \ncan become quite large for energies close to the top of the well. This aspect is clear quantitatively if we \nnote that the decay constant q in the forbidden region decreases as the energy increases, which means \nthat the decay length becomes larger, so more of the wave function is outside the well.\n 5.6.4 \u0002 Inversion Symmetry and Parity\nIn both square well problems, the allowed wave functions are either symmetric (even) or antisym-\nmetric (odd) with respect to the center of the well. In both cases, the potential energy well, and hence \nthe Hamiltonian, is symmetric with respect to the well center. We say that the Hamiltonian is invariant \nunder the parity operation x S -x. Because the Hamiltonian is invariant under the parity operation, \nit must commute with the parity operator, and hence the energy eigenstates are also eigenstates of \nthe parity operator. The symmetric states satisfy wn1x2 = +wn1-x2, have a parity eigenvalue +1, \nand are called even parity states. The antisymmetric states satisfy wn1x2 = -wn1-x2, have a parity \neigenvalue -1, and are called odd parity states. Identifying the parity of an energy eigenstate is useful \nbecause the parity of the state often indicates whether a particular matrix element involving that state \nis zero or not. For example, the probability of a transition between two energy eigenstates caused by \nincident laser light is proportional to the matrix element of the electric dipole operator (-ex in one \ndimension) between the two states:\n \n8wm 0\n -ex 0\n wn9 = -\nL\n\u0005\n- \u0005\nwm1x2ex wm1x2d 3r. \n(5.97)\nThis integral is zero if the integrand has odd parity. The electric dipole operator has odd parity, so the \nenergy eigenstates must have different parity for the transition to be allowed. If the integral is zero, then \nthe transition is a forbidden transition. Many of the selection rules that determine which transitions \nare allowed and which are forbidden come from these types of parity arguments. More complete dis-\ncussion of electric dipole transitions must wait until we discuss time-dependent perturbation theory in \nChapter 14.\n 5.6.5 \u0002 Orthonormality\nThe energy eigenstates form an orthonormal set, as we have found for other sets of eigenstates, such \nas spin states. The normalization is not an intrinsic property of the solutions but rather something that \nwe impose so that the total probability of \ufb01nding the particle somewhere is unity. The orthogonality is \na fundamental trait of eigenstates of Hermitian operators. The orthonormality condition is expressed \nin Dirac notation as\n \n8En0 Em9 = dnm \n(5.98)\nand in wave function language as\n \nL\n\u0005\n- \u0005\nw*\nn 1x2wm1x2dx = dnm. \n(5.99)\nThis condition is straightforward",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 159
  },
  {
    "child_id": "e02ce250-7c79-4a8c-bc9d-0a3e1b54f0bf",
    "parent_id": "df3dc39a-d035-41f5-8bb8-be4cff004a0a",
    "text": "other sets of eigenstates, such \nas spin states. The normalization is not an intrinsic property of the solutions but rather something that \nwe impose so that the total probability of \ufb01nding the particle somewhere is unity. The orthogonality is \na fundamental trait of eigenstates of Hermitian operators. The orthonormality condition is expressed \nin Dirac notation as\n \n8En0 Em9 = dnm \n(5.98)\nand in wave function language as\n \nL\n\u0005\n- \u0005\nw*\nn 1x2wm1x2dx = dnm. \n(5.99)\nThis condition is straightforward to show for the in\ufb01nite well states (Problem 5.12) but is a little tedious \nfor the \ufb01nite well states because of the lack of a general expression for the allowed wave vectors.\n\n5.7 Superposition States and Time Dependence \n137\n 5.6.6 \u0002 Completeness\nThe energy eigenstates form a complete basis, as we have found for other sets of basis states. Com-\npleteness is also a fundamental trait of eigenstates of Hermitian operators. Completeness means \nthat we can use these basis functions to construct all possible solutions to the Schr\u00f6dinger equation \nH0 c9 = iU d 0 c9>dt for this problem. The wave function of a general superposition state is\n \nc1x2 = a\nn\ncn\n wn1x2. \n(5.100)\nNote that the energy eigenvalue equation Hwn1x2 = En\n wn1x2 is satis\ufb01ed by each particular energy \neigenstate in turn but is not satis\ufb01ed by general superposition states. For the in\ufb01nite well, Eq. (5.100) \nis exact, while for the \ufb01nite well we must also include unbound energy states above the well in the sum \nover basis states. Obviously, for a well that is so small that there is only one bound state, we would \nexpect to need more states to form a complete basis. The completeness relation is also called the clo-\nsure relation and, as we saw in the spins problem, is expressed as a sum of all the projection operators\n \na\nn\n0 En98En0 = 1, \n(5.101)\nwhere the right-hand side is understood to be the identity operator\n 5.7 \u0002 SUPERPOSITION STATES AND TIME DEPENDENCE\nSolving for the energy eigenvalues and eigenstates is an important aspect of any problem, but it is not \nthe only goal. As physicists, our aim is to predict the future of a physical system. In quantum mechan-\nics, we do this through the Schr\u00f6dinger equation\n \nH0 c9 = iU d\ndt\n 0 c9 \n(5.102)\nthat governs the time evolution of any quantum system. Though different systems clearly have differ-\nent Hamiltonians, we need not solve the Schr\u00f6dinger equation for the time evolution separately for \neach system. We have already solved it in Chapter 3 for a time-independent Hamiltonian, where we \nfound that the most general time-dependent solution to the Schr\u00f6dinger equation is\n \n0 c1t29 = a\nn\ncn\n e-iEnt>U0 En9. \n(5.103)\nThat is, the energy eigenstates form the preferred basis in which to expand a general quantum state \nvector, with the time evolution determined by phase factors dependent on the energy of each compo-\nnent state. In a general superposition, each energy eigenstate acquires a different phase. It is critical \nto remember that one must use t",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 159
  },
  {
    "child_id": "00f0740e-37ed-4275-ac8c-5bf71ebe3910",
    "parent_id": "df3dc39a-d035-41f5-8bb8-be4cff004a0a",
    "text": "independent Hamiltonian, where we \nfound that the most general time-dependent solution to the Schr\u00f6dinger equation is\n \n0 c1t29 = a\nn\ncn\n e-iEnt>U0 En9. \n(5.103)\nThat is, the energy eigenstates form the preferred basis in which to expand a general quantum state \nvector, with the time evolution determined by phase factors dependent on the energy of each compo-\nnent state. In a general superposition, each energy eigenstate acquires a different phase. It is critical \nto remember that one must use the energy basis in order to use this simple recipe for time evolu-\ntion. This is why we spend much of our time \ufb01nding energy eigenstates.\nTo use Eq. (5.103) we need to know the expansion coef\ufb01cients cn for the particular state in ques-\ntion. The quantum state at time t = 0 is\n \n0 c 1029 = a\nn\ncn0 En9, \n(5.104)\n\n138 \nQuantized Energies: Particle in a Box\nso the expansion coef\ufb01cients cn are determined by the initial state of the system. The coef\ufb01cients cn are \nthe probability amplitudes for the state 0 c1029 to be in the energy eigenstates 0 En9\n \ncn = 8En0 c1029. \n(5.105)\nTo show this again, we perform a manipulation with the closure relation in Eq. (5.101). The identity \noperator does not change the state vector, so we act on the state vector to obtain\n \n 0 c1029 = 10 c1029\n \n \n = e a\nn\n0 En98En0f 0 c1029 \n \n = a\nn\n0 En98En0 c1029\n \n \n = a\nn\n8En0 c1029 0 En9\n \n \n(5.106)\nand hence identify the coef\ufb01cients cn as given in Eq. (5.105).\nOf course, once we know the probability amplitudes, we can calculate the probabilities for mea-\nsuring the system to have one of the energy eigenvalues:\n \nPEn = 08En0 c1029 0\n2 = 0 cn0\n2. \n(5.107)\nWe showed in Chapter 3 that the probabilities of energy measurements are time independent, but let\u2019s \ndo it again here, using the time-dependent state vector in Eq. (5.103)\n \nP En = 08En0 c1t29 0\n2 \n \n = `8En0 a\nm\ncm0 Em9e-iEmt>U `\n2\n= ` a\nm\ncm8En0 Em9e-iEmt>U `\n2\n \n \n = ` a\nm\ncmdmne-iEmt>U `\n2\n= 0 cne-iEnt>U0\n2 \n \n = 0 cn0\n2.\n \n \n(5.108)\nThe Kronecker delta from the energy eigenstate orthonormality condition collapses the sum to a single \nterm. Time independence of the energy probabilities implies that the expectation value of the energy is \nalso time independent:\n \n8H9 = a\nn\nPEnEn = a\nn\n0 cn0\n2En. \n(5.109)\n\n5.7 Superposition States and Time Dependence \n139\nWe can also show this by explicit calculation with the time-dependent states:\n \n 8H9 = 8c1t2 0 H0 c1t29\n \n \n = a\nm\nc*\nm8Em0 eiEmt>UHa\nn\ncn0 En9e-iEnt>U \n \n = a\nm,n\nc*\nmcneiEmt>Ue-iEnt>U8Em0 H0 En9\n \n \n = a\nm,n\nc*\nmcnei 1Em-En2 t>U En8Em0 En9\n \n \n = a\nm,n\nc*\nmcnei 1Em-En2 t>U Endmn\n \n \n = a\nn\nc*\nncnEn\n \n \n = a\nn\n0 cn0\n2\n En.\n \n \n(5.110)\nNote that we had no need to use wave function notation in these calculations. Wave function calcula-\ntions of Eqs. (5.108) and (5.110) would require spatial integrals that would also yield the Kronecker \ndelta from the energy eigenstate orthonormality condition that collapses the sums. The results would \nclearly be the same, so the message is: if you",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 159
  },
  {
    "child_id": "d04d4c63-fbd3-44fa-b7a6-3481733d70b0",
    "parent_id": "df3dc39a-d035-41f5-8bb8-be4cff004a0a",
    "text": "H0 En9\n \n \n = a\nm,n\nc*\nmcnei 1Em-En2 t>U En8Em0 En9\n \n \n = a\nm,n\nc*\nmcnei 1Em-En2 t>U Endmn\n \n \n = a\nn\nc*\nncnEn\n \n \n = a\nn\n0 cn0\n2\n En.\n \n \n(5.110)\nNote that we had no need to use wave function notation in these calculations. Wave function calcula-\ntions of Eqs. (5.108) and (5.110) would require spatial integrals that would also yield the Kronecker \ndelta from the energy eigenstate orthonormality condition that collapses the sums. The results would \nclearly be the same, so the message is: if you can avoid integrals by using Dirac notation instead of \nwave function notation, do so.\nWe need to use wave function language to answer questions about the spatial distribution of the \nparticle, so let\u2019s use the rules we developed in Section 5.3 to translate the Dirac notation equations \nto wave function notation. The time evolution of the state vector [Eq. (5.103)], in wave function \nlanguage, is\n \nc1x, t2 = a\nn\ncn\n wn1x2e-iEnt>U. \n(5.111)\nTo \ufb01nd the expansion coef\ufb01cients cn (i.e., the probability amplitudes), we translate Eq. (5.105) to wave \nfunction language:\n \ncn =\n \nL\n\u0005\n- \u0005\nw*\nn1x2c1x, 02dx. \n(5.112)\nSo, given the initial wave function of the system c1x, 02, the expansion coef\ufb01cients are overlap inte-\ngrals between each energy eigenstate and the initial wave function. These overlap integrals are analo-\ngous to the integrals used to \ufb01nd Fourier expansion coef\ufb01cients. Let\u2019s brie\ufb02y illustrate the Fourier \napproach for calculating the coef\ufb01cients cn. Set the time equal to zero in Eq. (5.111) to \ufb01nd the initial \nwave function superposition:\n \nc1x, 02 = a\nn\ncn\n wn1x2. \n(5.113)",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 159
  },
  {
    "child_id": "2e71044d-1086-427c-841c-5e86be9a4b8b",
    "parent_id": "a708e669-f060-44d6-8ee4-81532f70d6a1",
    "text": "140 \nQuantized Energies: Particle in a Box\nProject both sides of Eq. (5.113) onto the energy eigenstates by multiplying each side by w*\nm1x2 and \nintegrating over all space:\n \n \nL\n\u0005\n- \u0005\nw*\nm1x2c1x, 02dx =\n \nL\n\u0005\n- \u0005\nw*\nm1x2 a\nn\ncn\n wn1x2dx  \n \n = a\nn\ncn L\n\u0005\n- \u0005\nw*\nm1x2wn1x2dx \n(5.114)\n \n = a\nn\ncndnm\n \n \n = cm,\n \n \nyielding\n \ncm =\n \nL\n\u0005\n- \u0005\nw*\nm1x2c1x, 02dx \n(5.115)\nas we expected from Eq. (5.112). Once we have the wave function expansion coef\ufb01cients in the energy \nbasis, we can predict the future time evolution of the system. Then we can calculate any physical quan-\ntities we need to, such as probabilities and expectation values.\nExample 5.4 Consider a particle in an in\ufb01nite square well with the initial wave function\n \nc 1x, 02 = A J a x\nLb\n3\n- 11\n7\n a x\nLb\n2\n+ 4\n7\n a x\nLb R  \n(5.116)\nin the interval 0 6 x 6 L and zero elsewhere, as shown in Fig. 5.20. Find (i) the wave function at a \nlater time, (ii) the probabilities of energy measurements, and (iii) the expectation value of the energy.\n(i) First we must normalize the state to \ufb01nd the constant A:\n \n 8c0 c9 = 1 =\n \nL\nL\n0\n0 c 1x, 020\n2\n dx\n \n \n = 0 A0\n2\nL\nL\n0\n J a x\nLb\n3\n- 11\n7\n a x\nLb\n2\n+ 4\n7\n a x\nLb R\n2\n dx = 0 A0\n2\n L\n735. \n(5.117)\nWe choose the constant to be real and positive and the normalized wave function is\n \nc1x, 02 = B\n735\nL  J a x\nLb\n3\n- 11\n7\n a x\nLb\n2\n+ 4\n7\n a x\nLb R. \n(5.118)\nNow perform the overlap integral to \ufb01nd the expansion coef\ufb01cients:\n \n cn = 8En0 c9 =\n \nL\n\u0005\n- \u0005\nw*\nn 1x2  c 1x, 02dx\n \n \n =\n \nL\nL\n0 B\n2\nL\n sin anpx\nL b B\n735\nL  J a x\nLb\n3\n- 11\n7\n a x\nLb\n2\n+ 4\n7\n a x\nLb Rdx . \n(5.119)\n\n5.7 Superposition States and Time Dependence \n141\nDo the integral\n \n cn = 7230\nL\n b c3L \n1npx>L2\n2 - 2\n1np24\n sin anpx\nL b - L \n1npx>L2\n3 - 61npx>L2\n1np24\n cos anpx\nL bd\nL\n0\n \n \n -   11\n7\n c 2L \n1npx>L2\n1np23\n sin anpx\nL b - L \n1npx>L2\n2 - 2\n1np23\n cos anpx\nL b d\nL\n0\n \n(5.120)\n \n + 4\n7\n c L \n1\n1np22 sin anpx\nL b - L \n1npx>L2\n1np22\n cos anpx\nL b d\nL\n0\nr .\nEvaluate the limits and simplify:\n \n cn = 322 + 201-12\nn4230\n1np23\n \n \n = e\n2230\n1np2\n3  , if n is odd\n42230\n1np2\n3\n , if n is even .\n \n(5.121)\nThe \ufb01rst few coef\ufb01cients are\n \nc1 = 0.3533  \n \nc2 = 0.9274  \n \nc3 = 0.0131  \n \nc4 = 0.1159 , \n(5.122)\nso the state is composed mostly of the \ufb01rst excited state, which is evident from the shape of the \nwave function in Fig. 5.20.\nL/2\nL\nx\n\u03a8(x)\nFIGURE 5.20 An initial state wave function [Eq. (5.116)] in the in\ufb01nite square well.\n\n142 \nQuantized Energies: Particle in a Box\nThe wave function at later times is the superposition with each energy state evolved at its pre-\nscribed frequency\n \n c 1x, t2 = a\n\u0005\nn=1\ncn\n wn 1x2  e-iEnt = a\n\u0005\nn=1\ncnA\n2\nL\n sin npx\nL\n e-i n2p2Ut>2mL2 \n \n = A\n60\nL a\n\u0005\nn=1\n322 + 201-12\nn4\n1np2\n3\n sin npx\nL\n e-i n2p2Ut>2mL2.\n \n(5.123)\n(ii)  The probabilities of measuring the energy eigenvalues are the squares of the expansion \ncoef\ufb01cients:\n \n PEn = 08En0 c\n 1t290\n2 = 0 cn0\n2\n \n \n =\n30\n1np26 322 + 201-12\nn4\n2\n \n \n =\n120\n1np26 3221 + 2201-12\nn4. \n(5.124)\nThe energy probabilities are shown in the ",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 164
  },
  {
    "child_id": "4467ef3b-e58c-4084-b5ff-b89fbc00f55e",
    "parent_id": "a708e669-f060-44d6-8ee4-81532f70d6a1",
    "text": "tion with each energy state evolved at its pre-\nscribed frequency\n \n c 1x, t2 = a\n\u0005\nn=1\ncn\n wn 1x2  e-iEnt = a\n\u0005\nn=1\ncnA\n2\nL\n sin npx\nL\n e-i n2p2Ut>2mL2 \n \n = A\n60\nL a\n\u0005\nn=1\n322 + 201-12\nn4\n1np2\n3\n sin npx\nL\n e-i n2p2Ut>2mL2.\n \n(5.123)\n(ii)  The probabilities of measuring the energy eigenvalues are the squares of the expansion \ncoef\ufb01cients:\n \n PEn = 08En0 c\n 1t290\n2 = 0 cn0\n2\n \n \n =\n30\n1np26 322 + 201-12\nn4\n2\n \n \n =\n120\n1np26 3221 + 2201-12\nn4. \n(5.124)\nThe energy probabilities are shown in the histogram in Fig. 5.21, re\ufb02ecting the predominance of the \nsecond state.\n(iii) The expectation value of the energy is\n \n 8H9 = a\nn\nPEnEn = a\nn\n0 cn0\n2\n En\n \n \n = a\n\u0005\nn=1\n120\n1np26 1221 + 2201-12\nn2an2p2  U2\n2mL2 b\n \n \n =\na\n\u0005\nn=1,3,5...\n120\n1np26 an2p2U2\n2mL2 b +\na\n\u0005\nn=2,4,6...\n12014412\n 1np26\n an2p2U2\n2mL2 b \n \n =\n60U2\np4mL2 c\na\n\u0005\nn=1,3,5...\n 1\nn4 + 441 \na\n\u0005\nn=2,4,6...\n 1\nn4 d\n \n \n =\n60U2\np4mL2 c p4\n96 + 441 p4\n1440 d\n \n \n = 19 U2\nmL2 = 38\np2 E1 \u0002 3.85E1 ,\n \n(5.125)\nwhich is slightly smaller than the energy (E2 = 4E1) of the \ufb01rst excited state, as expected from the \nhistogram in Fig. 5.21.\n\n5.7 Superposition States and Time Dependence \n143\nNotice that the energy expectation value, such as we calculated in Eq. (5.125), is time inde-\npendent regardless of whether the system is in an energy eigenstate or a general superposition of \nenergy eigenstates. On the other hand, the expectation values of position or momentum are time \nindependent when the system is in an energy eigenstate, but they are time dependent for a general \nsuperposition state. Let\u2019s demonstrate this in the in\ufb01nite square well where the time dependence of \na general state is\n \nc 1x, t2 = a\nn\ncnA\n2\nL\n sin npx\nL\n e-i n2p2Ut>2mL2 . \n(5.126)\nConsider a simple superposition of two states in an in\ufb01nite well. If the initial state is\n \n0 c 1029 =\n1\n12 0 E19 +\n1\n12 0 E29, \n(5.127)\nthen the time-evolved state is\n \n0 c 1t29 =\n1\n12 0 E19e-iE1t>U +\n1\n12 0 E29e-iE2t>U. \n(5.128)\nThe wave function representation is\n \n c 1x, t2 =\n1\n12 w11x2e-iE1t>U +\n1\n12 w21x2e-iE2t>U\n \n \n = A\n1\nL\n c sin px\nL\n e-iE1t>U + sin 2px\nL\n e-iE2t>U d . \n \n(5.129)\nNow \ufb01nd the expectation value of the position:\n \n 8x9 = 8c 1t2 0 x0 c 1t29\n \n \n = E 1\n12 8E10 eiE1t>U +\n1\n12 8E20 eiE2t>UF\n \nx E 1\n12 0 E19e-iE1t>U +\n1\n12 0 E29e-iE2t>UF\n (5.130)\n \n = 1\n2 38E10 x0 E19 + 8E20 x0 E29 + 8E10 x0 E29ei1E1-E22t>U + 8E20 x0 E19e-i1E1-E22t>U4. \nE1\nE2\nE3\nE4\nE\n0.5\n1.0\nP\nPE1\nPE2\nPE3\nPE4\nFIGURE 5.21 Histogram of the probabilities of energy measurements.\n\n144 \nQuantized Energies: Particle in a Box\nAgain notice that we are using Dirac notation to simplify the calculation. However, at this point we \nneed to use integrals to calculate the matrix elements. Let\u2019s de\ufb01ne them in general:\n \n 8x9n = 8En0 x0 En9 =\n \nL\nL\n0\nw*\nn1x2  x wn1x2dx =\n \nL\nL\n0\nx0 wn1x2 0 2 dx \n \n 8x9nk = 8En0 x0 Ek9 =\n \nL\nL\n0\nw*\nn1x2  x wk1x2dx . \n \n(5.131)\nWe calculated the \ufb01rst matrix element, which is the expectation value of position in an energy eigen-\nstate, in Example 5.3. We saw tha",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 164
  },
  {
    "child_id": "9f66f40a-7ecf-4bc9-8cb5-5e29bea181ff",
    "parent_id": "a708e669-f060-44d6-8ee4-81532f70d6a1",
    "text": "ntized Energies: Particle in a Box\nAgain notice that we are using Dirac notation to simplify the calculation. However, at this point we \nneed to use integrals to calculate the matrix elements. Let\u2019s de\ufb01ne them in general:\n \n 8x9n = 8En0 x0 En9 =\n \nL\nL\n0\nw*\nn1x2  x wn1x2dx =\n \nL\nL\n0\nx0 wn1x2 0 2 dx \n \n 8x9nk = 8En0 x0 Ek9 =\n \nL\nL\n0\nw*\nn1x2  x wk1x2dx . \n \n(5.131)\nWe calculated the \ufb01rst matrix element, which is the expectation value of position in an energy eigen-\nstate, in Example 5.3. We saw that the answer is the midpoint of the well L>2. The second integral \ncomes from the cross term in the superposition:\n \n 8x9nk =\n \nL\nL\n0\nw*\nn1x2  x wk1x2dx\n \n \n = 2\nL L\nL\n0\n sin anpx\nL b x sin akpx\nL b dx \n \n = 2\nL\n a L\npb\n2\nL\np\n0\ny sin1ny2 sin1k y2 dy . \n \n(5.132)\nSimplify with a trig identity and integrate\n \n 8x9nk = 2\nL\n a L\npb\n2\nL\np\n0\ny 1\n2 3 cos1n - k2y -  cos1n + k2y4dy\n \n \n = 1\nL\n a L\npb\n2\n c\n cos1n - k2y\n1n - k22\n+\ny sin1n - k2y\n1n - k2\n-\n cos1n + k2y\n1n + k22\n-\ny sin1n + k2y\n1n + k2\nd\np\n0\n \n \n = 1\nL\n a L\npb\n2\n c\n cos1n - k2p\n1n - k22\n-\n cos1n + k2p\n1n + k22\n-\n1\n1n - k22 +\n1\n1n + k22d ,\n \n(5.133)\nyielding\n \n8x9nk =\n-4Lnk\np21n2 - k222 C1 - 1-12\nn+kD . \n(5.134)\nThis result is zero for states where n + k is even (i.e., if the states have the same parity). The results for \nthe two-state example are\n \n 8x91 = 8x92 = L\n2\n \n \n 8x912 = 8x921 = -  16L\n9p2 , \n \n(5.135)\n\n5.7 Superposition States and Time Dependence \n145\ngiving the \ufb01nal result\n \n 8x9 = 8c1t2 0 x0 c1t29\n \n \n = 1\n2\n c L\n2 + L\n2 - 16L\n9p2 ei 1E1-E22 t>U - 16L\n9p2 e-i 1E1-E22 t>U d  \n \n = L\n2\n c 1 - 32\n9p2 cos a 3p2U\n2mL2 tb d .\n \n(5.136)\nThe position of this two-state superposition oscillates at the Bohr frequency 1E2 - E12>U.\nThe time-dependent position is also evident in the spatial probability density:\n \n P1x, t2 = 08x0 c1t290\n2 = 0 c1x, t20\n2\n \n \n = ` A\n1\nL\n c  sin px\nL\n e-iE1t>U +  sin 2px\nL\n e-iE2t>U d `\n2\n \n \n = 1\nL\n csin2 px\nL +  sin2 2px\nL\n+ 2 sin px\nL\n sin 2px\nL\n cos 1E2 - E12t\nU\nd . \n(5.137)\nThe oscillation of the probability density is depicted in the animation frames shown in Fig. 5.22, \nwhere the constant t is the oscillation period t = 2p>vBohr (see activity on time evolution of in\ufb01nite \nwell solutions). The superposition probability distribution \u201csloshes back and forth\u201d in the well at the \nBohr frequency. This motion of the superposition state provides a model for how atoms and other \nbound systems radiate light. An electron undergoing this oscillatory motion accelerates and hence \nradiates electromagnetic energy. So far, our model does not account for the energy loss from this \nradiation, but we will address that in Chapter 14.\n0\nL/2\nL\nt/\u0004 = 0.0\nt/\u0004 = 0.1\nt/\u0004 = 0.2\nt/\u0004 = 0.3\nt/\u0004 = 0.4\nt/\u0004 = 0.5\nFIGURE 5.22 Time dependence of the probability distribution of a superposition state.\n\n146 \nQuantized Energies: Particle in a Box\nA calculation of the momentum expectation value (Problem 5.27) also yields a time-dependent result:\n \n 8  p9 = 8c1t20 p0 c1t29\n \n \n =\n \nL\nL\n0\nc*1x, t2aU\ni\n  d\ndxb ",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 164
  },
  {
    "child_id": "5d513e16-fc2b-474b-aefc-4c2a81b59825",
    "parent_id": "a708e669-f060-44d6-8ee4-81532f70d6a1",
    "text": "ectromagnetic energy. So far, our model does not account for the energy loss from this \nradiation, but we will address that in Chapter 14.\n0\nL/2\nL\nt/\u0004 = 0.0\nt/\u0004 = 0.1\nt/\u0004 = 0.2\nt/\u0004 = 0.3\nt/\u0004 = 0.4\nt/\u0004 = 0.5\nFIGURE 5.22 Time dependence of the probability distribution of a superposition state.\n\n146 \nQuantized Energies: Particle in a Box\nA calculation of the momentum expectation value (Problem 5.27) also yields a time-dependent result:\n \n 8  p9 = 8c1t20 p0 c1t29\n \n \n =\n \nL\nL\n0\nc*1x, t2aU\ni\n  d\ndxb c 1x, t2dx \n \n = 8\n3 U\nL\n sin a 3p2U\n2mL2 tb.\n \n(5.138)\nIf we compare Eqs. (5.136) and (5.138), we notice that the quantum mechanical position and momen-\ntum obey the classical relation p = mv, provided we restrict the relation to expectation values:\n \n8p1t29 = m \nd 8x1t29\ndt\n. \n(5.139)\nThis is another example of Ehrenfest\u2019s theorem, which says that quantum mechanical expectation \nvalues obey classical laws.\n 5.8 \u0002 MODERN APPLICATION: QUANTUM WELLS AND DOTS\nThe square well potential problem has been a staple of quantum mechanics textbooks since the early \ndays. However, for many years it was only a textbook problem because no systems in nature could be \nmodeled accurately as a square well. The progress of semiconductor fabrication technology has changed \nthat, as we are now able to make arti\ufb01cial systems of square potential energy wells. Semiconductor \nquantum wells are now routinely used to fabricate diode lasers and other semiconductor devices.\nThe key advance that allowed fabrication of quantum well devices was the ability to grow pure \ncrystals of semiconductors using techniques such as molecular beam epitaxy (MBE) and metal-\norganic chemical vapor deposition (MOCVD). With these techniques, layers of semiconductors can be \ngrown with atomic scale precision, yielding structures with layers thin enough (several nm or less) for \nquantum effects to be important.\nA typical quantum well structure is shown in Fig. 5.23(a). Alternate layers of GaAs and AlGaAs \nare grown epitaxially on a GaAs substrate. GaAs and AlGaAs have similar crystal unit cell sizes that \npermit dislocation-free crystals to be grown. This lattice-matched growth is crucial to obtaining reli-\nGaAs substrate\nAlGaAs\nGaAs\nAlGaAs\nGaAs\nsubstrate\nAlGaAs\nGaAs\nAlGaAs\nconduction band\nvalence band\nEg\nGaAs\nEg\nAlGaAs\nVc(x)\nVv(x)\n(b)\n(a)\nFIGURE 5.23 (a) Structure and (b) potential energy diagram of a GaAs quantum well.",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 164
  },
  {
    "child_id": "f8e9b506-0602-431d-96b3-0b34bda21ebf",
    "parent_id": "1e641192-d4ad-4b1f-9e7f-9e303747416e",
    "text": "5.9 Asymmetric Square Well: Sneak Peek at Perturbations \n147\nable devices. The band gap of GaAs (1.42 eV) is smaller than the band gap of AlGaAs (2.67 eV), so the \nelectrons in the conduction band and the holes in the valence band experience the different potentials \nshown in Fig. 5.23(b). Because the layers change on the atomic scale, this is as close to a square well \nas nature allows.\nWe can calculate the energy levels in the well using the same analysis we used for the \ufb01nite square \nwell. Figure 5.24 shows the energy levels and how they vary with changes in the GaAs layer thickness. \nNote that there are only two or three bound states in the well for the range of thickness shown.\nFor making practical devices with quantum wells, there are two important features. First, the \nenergy levels can be adjusted, or \u201ctuned,\u201d by changing the thickness of the quantum well layer, as \nshown in Fig. 5.24, or by changing the stoichiometry of the surrounding AlxGa1 -  xAs layers to adjust \nthe band gap and hence the potential energy depth of the well. Second, the quantization of the electron \nenergy in the con\ufb01ned well increases the number of electrons with speci\ufb01c energies (compared to the \ncontinuum of energies of uncon\ufb01ned electrons), which in turn increases the probability of creating \nphotons with the corresponding wavelengths. Hence, a semiconductor diode laser made with quantum \nwells is more ef\ufb01cient than one made with bulk material, so quantum well diode lasers are now the \nmost common type of diode lasers in use.\nThe quantum well structure shown in Fig. 5.23 con\ufb01nes the electron in one dimension, but the \nelectrons are not con\ufb01ned in the plane of the thin well. Further con\ufb01nement leads to quantum wires \n(2D con\ufb01nement) and quantum dots (3D con\ufb01nement). Quantum dots are semiconductor nanocrys-\ntals with a typical size range of 2\u201320 nm. The size of the dot determines the con\ufb01nement size and \nhence the wavelength of light emitted by the dot. A simple Web search reveals beautiful pictures of \nquantum dots glowing in a rainbow of colors.\n 5.9 \u0002 ASYMMETRIC SQUARE WELL: SNEAK PEEK AT PERTURBATIONS\nWhile the square potential wells we have studied in this chapter illustrate many of the ideas of bound \nstate wave functions, there is one important aspect that we have not encountered. All the square well \nsolutions have a constant wave vector and a constant wave function amplitude throughout the well, \nbecause the potential is constant throughout the well. To see how the wave vector and amplitude of \n5\n10\n15\n20 Well width (nm)\n20\n40\n60\n80\n100\nEnergy (meV)\n\u00021\u0003\n\u00022\u0003\n\u00023\u0003\nFIGURE 5.24 Energy levels in a GaAs quantum well as the thickness of the GaAs layer is changed.\n\n148 \nQuantized Energies: Particle in a Box\nan eigenstate can vary within the well, let\u2019s make a slight modi\ufb01cation to the in\ufb01nite square well. \nConsider the well shown in Fig. 5.25, which is commonly referred to as the asymmetric square \nwell. By adding a \u201cshelf\u201d within the well, we now have two regions ",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 171
  },
  {
    "child_id": "c9d82818-4d4d-4465-895f-d2508707169a",
    "parent_id": "1e641192-d4ad-4b1f-9e7f-9e303747416e",
    "text": "wave vector and amplitude of \n5\n10\n15\n20 Well width (nm)\n20\n40\n60\n80\n100\nEnergy (meV)\n\u00021\u0003\n\u00022\u0003\n\u00023\u0003\nFIGURE 5.24 Energy levels in a GaAs quantum well as the thickness of the GaAs layer is changed.\n\n148 \nQuantized Energies: Particle in a Box\nan eigenstate can vary within the well, let\u2019s make a slight modi\ufb01cation to the in\ufb01nite square well. \nConsider the well shown in Fig. 5.25, which is commonly referred to as the asymmetric square \nwell. By adding a \u201cshelf\u201d within the well, we now have two regions of constant but different poten-\ntial energy.\nThe potential energy for this asymmetric square well is\n \nV1x2 = \u03bc\n\u0005,\n0,\nV0,\n\u0005,\n      \nx 6 0\n0 6 x 6 L>2\nL>2 6 x 6 L\nx 7 L.\n  \n(5.140)\nWe know that the in\ufb01nite potential outside the well demands that the energy eigenstates are zero outside \nthe well. Inside the well, we now have different energy eigenvalue equations in the left and right halves:\n \n a-  U2\n2m d 2\ndx2 + 0b wE 1x2 = EwE 1x2,    left half\n \n \n a-  U2\n2m d 2\ndx2 + V0b wE 1x2 = EwE 1x2, \n right half. \n \n(5.141)\nFor this discussion, let\u2019s assume that the energy E is greater than the potential V0 so that the \nsolutions in each half of the well are sinusoidal. We then have different wave vectors in each half, \nde\ufb01ned by\n \n k1 = B\n2mE\nU2 , \n left half\n \n \n k2 = B\n2m 1E - V02\nU2\n,    right half, \n \n(5.142)\nwhich yields a smaller wave vector 1k2 6 k12 and hence larger wavelength of the wave in the right \nhalf. We know that the left-half solution must be a sine function in order to match the zero wave func-\ntion outside the well, so the general solution is\n \nwE 1x2 = e\nA sin k1x ,\nB sin k2x + C cos k2x ,   0 6 x 6 L>2\nL>2 6 x 6 L. \n(5.143)\n0\nL/2\nL\nV0\nx\nV(x)\n\u0002\nFIGURE 5.25 Asymmetric square well.\n\n5.9 Asymmetric Square Well: Sneak Peek at Perturbations \n149\nNow we apply the boundary condition on the wave function continuity at the middle and right side of \nthe well and the boundary condition on the continuity of the \ufb01rst derivative of the wave function at the \nmiddle of the well (recall that the in\ufb01nite potential on the right means that the derivative condition is \nnot applicable). The three boundary conditions are\n \n wE 1L>22: A sin1k1L>22 = B sin1k2L>22 + C cos1k2L>22\n \n \n dwE1x2\ndx\n2\nx=L>2\n: k1A cos1k1L>22 = k2B cos1k2L>22 - k2C sin1k2L>22 \n \n wE 1L2: B sin k2L + C cos k2L = 0.\n \n \n(5.144)\nThese three equations contain four unknowns: the amplitudes A, B, and C, and the energy E through \nthe wave vectors k1 and k2. The normalization condition supplies the fourth equation required to solve \nfor all unknowns. By eliminating the amplitude coef\ufb01cients from the three boundary condition equa-\ntions, we arrive at a transcendental equation for the energy eigenvalues (Problem 5.28):\n \nk1 cos1k1L>22sin1k2L>22 + k2 cos1k2L>22sin1k1L>22 = 0. \n(5.145)\nThis looks a bit intimidating, so how do we know it\u2019s correct? Well, we know what the solutions are \nfor the in\ufb01nite (symmetric) square well, which is the case where V0 = 0; so we can check to see if our \nsolution agrees w",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 171
  },
  {
    "child_id": "d2f8aafd-1687-4955-8593-d41551cf8f85",
    "parent_id": "1e641192-d4ad-4b1f-9e7f-9e303747416e",
    "text": "tion required to solve \nfor all unknowns. By eliminating the amplitude coef\ufb01cients from the three boundary condition equa-\ntions, we arrive at a transcendental equation for the energy eigenvalues (Problem 5.28):\n \nk1 cos1k1L>22sin1k2L>22 + k2 cos1k2L>22sin1k1L>22 = 0. \n(5.145)\nThis looks a bit intimidating, so how do we know it\u2019s correct? Well, we know what the solutions are \nfor the in\ufb01nite (symmetric) square well, which is the case where V0 = 0; so we can check to see if our \nsolution agrees with the in\ufb01nite square well solutions. This won\u2019t tell us whether our solution is cor-\nrect, but we can at least make sure that it is not obviously wrong. If V0 = 0, then the two wave vectors \nare equal and the transcendental equation becomes:\n \n k1cos1k1L>22sin1k1L>22 + k1 cos1k1L>22sin1k1L>22 = 0 \n \n k1 sin31k1L>22 + 1k1L>224 = 0\n \n \n k1 sin k1L = 0.\n \n \n(5.146)\nIf we divide this result by k1, then we have the same equation  sin k1L = 0 that we had for the in\ufb01nite \nsquare well. So our intimidating result may well be correct.\nIn order to compare the asymmetric square well with the in\ufb01nite square well, it is useful to divide \neach transcendental equation by the factor k1 and plot the energy eigenvalue equations for the asym-\nmetric square well\n \ncos1k1L>22sin1k2L>22 + k2\nk1\n cos1k2L>22sin1k1L>22 = 0 \n(5.147)\nand for the in\ufb01nite square well:\n \nsin1k1L2 = 0. \n(5.148)\nA plot of the two equations as a function of k1L is shown in Fig. 5.26 for the case where the potential \nstep height is 0.75 times the energy of the ground state in the in\ufb01nite well case. The in\ufb01nite square well \neigenstates occur at the values k1L = np marked on the axis. The eigenstates for the asymmetric well \nare each slightly larger, with the difference decreasing as the energy increases. This is a sneak preview \nof perturbation theory that we will study in Chapter 10.\nLet\u2019s now use these solutions to draw the energy eigenstates. A plot of a typical energy eigen-\nstate is shown in Fig. 5.27. The wavelength and the amplitude of the wave in the right half are larger, \nmeaning that the probability to \ufb01nd the particle in the right half is larger than in the left half. This is \nconsistent with our classical expectation, because a classical particle moves more slowly in the right \nhalf where its kinetic energy is lower, and so it spends more time in the right half with an increased \nprobability to \ufb01nd it there.\n\n150 \nQuantized Energies: Particle in a Box\n 5.10 \u0002 FITTING ENERGY EIGENSTATES BY EYE OR BY COMPUTER\n 5.10.1 \u0002 Qualitative (Eyeball) Solutions\nThe problems we have solved in this chapter illustrate most of the important features of bound states in \npotential wells. Using these common traits allows us to make qualititative estimates of energy eigen-\nstate solutions to other potential well problems. The important features are\n 1(a). Oscillatory wave solution inside well\n 1(b). Wavelength proportional to 1> 2E - V1x2\n 2(a). Exponentially decaying solution outside well\n 2(b). Decay length prop",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 171
  },
  {
    "child_id": "b1d6081b-e592-4efa-8e32-2b22e810f1ca",
    "parent_id": "1e641192-d4ad-4b1f-9e7f-9e303747416e",
    "text": "UTER\n 5.10.1 \u0002 Qualitative (Eyeball) Solutions\nThe problems we have solved in this chapter illustrate most of the important features of bound states in \npotential wells. Using these common traits allows us to make qualititative estimates of energy eigen-\nstate solutions to other potential well problems. The important features are\n 1(a). Oscillatory wave solution inside well\n 1(b). Wavelength proportional to 1> 2E - V1x2\n 2(a). Exponentially decaying solution outside well\n 2(b). Decay length proportional to 1> 2V1x2 - E\n3.  Amplitude inside well related to wavelength\n4.  Match wE1x2 and dwE1x2>dx at boundaries.\nUsing these rules of thumb, we can get a very good idea of the wave function before we tackle the dif-\nferential equation that gives us the exact solution.\nConsider the potential shown in Fig. 5.28. It has an in\ufb01nite wall, a \ufb02at potential region, a sloped \npotential region, and a \ufb01nite wall. Given our rules, we draw the approximate wave function. From left \nx\nE7\n0\nL/2\nL\nV0\nFIGURE 5.27 An energy eigenstate of the asymmetric square well.\n\u03a0\n2\u03a0\n3\u03a0\n4\u03a0\nk1L\nF(k1L)\nFIGURE 5.26 Transcendental equations for the energy eigenvalues of \nthe asymmetric square well (solid) and the in\ufb01nite square well (dashed).\n\n5.10 Fitting Energy Eigenstates by Eye or by Computer \n151\nto right, starting at zero at the in\ufb01nite wall, the wave function oscillates with a constant wavelength and \nhas a constant amplitude over the \ufb02at potential region; it oscillates with an increasing wavelength and \nhas an increasing amplitude over the sloped potential region; and then it exponentially decays in the \nclassically forbidden region. The wave function is drawn qualitatively and the main features are indi-\ncated. This wave function represents the 17th energy state because there are 17 antinodes in the wave \nfunction. Remember that the wave function oscillates about the value zero in the well and decays to \nzero outside the well. The \ufb01gure shows the wave function c1x2 drawn superimposed on the potential \nwell, so you have to imagine a \u201cc axis\u201d with its zero as indicated by the dashed line.\n 5.10.2 \u0002 Numerical Solutions\nWe can be more quantitative by using a computer to help us \u201cdraw\u201d the wave functions. Rather than \nfollow the rules listed above, we directly solve the energy eigenvalue equation by numerical integra-\ntion, which is a common technique for solving differential equations and is easily accomplished in \ncommon mathematical packages like Matlab, Mathematica, and Maple, and even in a spreadsheet. The \nenergy eigenvalue equation is\n \nd 2wE1x2\ndx2\n= -  2m\nU2  3E - V1x24wE1x2. \n(5.149)\nYou may not yet know how to solve such a differential equation, but you do know how to solve a very \nsimilar one\u2014Newton\u2019s second law, F = ma, which yields the differential equation\n \nd 2x\ndt 2 = F\nm. \n(5.150)\nIn the case where the acceleration a = F>m is constant, one integral of Eq. (5.150) gives\n \nv = dx\ndt = v0 + at, \n(5.151)\nE,\u03a8\nMatch \u03a8\nMatch \u03a8,d\u03a8\u0005dx\nOscillating wave\nExponential decay\nConst",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 171
  },
  {
    "child_id": "a90597b9-29d1-40c3-a435-8dd717629ccd",
    "parent_id": "1e641192-d4ad-4b1f-9e7f-9e303747416e",
    "text": "a spreadsheet. The \nenergy eigenvalue equation is\n \nd 2wE1x2\ndx2\n= -  2m\nU2  3E - V1x24wE1x2. \n(5.149)\nYou may not yet know how to solve such a differential equation, but you do know how to solve a very \nsimilar one\u2014Newton\u2019s second law, F = ma, which yields the differential equation\n \nd 2x\ndt 2 = F\nm. \n(5.150)\nIn the case where the acceleration a = F>m is constant, one integral of Eq. (5.150) gives\n \nv = dx\ndt = v0 + at, \n(5.151)\nE,\u03a8\nMatch \u03a8\nMatch \u03a8,d\u03a8\u0005dx\nOscillating wave\nExponential decay\nConstant \u039b,\namplitude\nIncreasing \u039b,\namplitude\n\u03a8\u0007\b\u0007\t\n0\nL/2\nL\nV0\nV0/2\nx\nFIGURE 5.28 Drawing approximate energy eigenstate solutions.",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 171
  },
  {
    "child_id": "708dd989-edc4-48e7-944c-d9c7a5dbae3d",
    "parent_id": "aaa760a5-b439-4d4c-ab26-5fbc45f1ab7f",
    "text": "152 \nQuantized Energies: Particle in a Box\nand a second integration gives\n \nx = x0 + v0\n t + 1\n2\n at 2, \n(5.152)\nwhich are the equations of motion you learned in introductory physics. With these equations, one can \npredict the future if one knows the initial position x0, the initial velocity v0, and the acceleration a.\nIn the Newtonian case, the motion function x(t) is determined by its curvature d 2x>dt 2, which is \nthe acceleration a. In the quantum case, the wave function is determined by its curvature d 2c>dx 2, which \ndepends on the energy, the potential, and the wave function itself. The potential and the wave function \nboth depend on position, so the wave function curvature is not constant and the simple integrations in \nEqs. (5.151) and (5.152) cannot be used. However, if the acceleration in the Newtonian example is not \nconstant, then we can modify Eqs. (5.151) and (5.152) for use on a computer by using them to predict \nmotion only in the very near future, say from t to t + \u0006t:\n \n x1t + \u0006t2 = x1t2 + v1t2\u0006t + 1\n2\n a1t21\u0006t2\n2 \n \n v1t + \u0006t2 = v1t2 + a1t2\u0006t.\n \n(5.153)\nAs long as we choose the time steps \u0006t small enough that the acceleration does not vary appreciably from \none time step to the next, then these equations can be used to reliably update the position and velocity at \neach time step. These update equations produce estimates of the full motion by iterating from step to step.\nThis method works well but suffers from one failing: the update equations use \u201cold\u201d information \nabout the velocity and the acceleration. We can improve this slightly by using the new acceleration in \nthe velocity update equation:\n \n x1t + \u0006t2 = x1t2 + v1t2\u0006t + 1\n2\n a1t21\u0006t2\n2\n \n \n v1t + \u0006t2 = v1t2 + 1\n2 3a1t2 + a1t + \u0006t24\u0006t. \n(5.154)\nWe can\u2019t use the new acceleration in the position update equation because the acceleration typically \ndepends on position (through the potential), so we do the position update \ufb01rst and then the modi\ufb01ed \nvelocity update. This method is known as the velocity Verlet algorithm and yields more reliable \nresults than Eq. (5.153).\nTo solve the energy eigenvalue equation, we use the wave function and its spatial derivatives \nrather than the position and its time derivatives used in the Newtonian case. Thus, we generalize the \nposition and velocity update equations (5.154) to\n \n wE1x + \u0006x2 = wE1x2 + adwE\ndx b\nx  \n\u0006x + 1\n2\n ad 2wE\ndx2 b\nx\n1\u0006x2\n2\n \n \n adwE\ndx b\nx+\u0006x\n= adwE\ndx b\nx\n+ 1\n2\n c a d 2wE\ndx2 b\nx\n+ ad 2wE\ndx2 b\nx+\u0006x\nd \u0006x. \n(5.155)\nSo, given the wave function (analogous to \u201cposition\u201d), the slope of the wave function (\u201cvelocity\u201d), and \nthe curvature of the wave function (\u201cacceleration\u201d) at any position x (\u201ctime\u201d), we can predict the wave \nfunction and its slope at the next position x + \u0006x. At each step we calculate the wave function curva-\nture using the energy eigenvalue equation\n \nd 2wE1x2\ndx2\n= -  2m\nU2  3E - V1x24wE1x2. \n(5.156)\n\n5.10 Fitting Energy Eigenstates by Eye or by Computer \n153\nWe don\u2019t have to impose the continuity condi",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 176
  },
  {
    "child_id": "5cf7d660-98ad-4580-9cff-a969887070a6",
    "parent_id": "aaa760a5-b439-4d4c-ab26-5fbc45f1ab7f",
    "text": "e wave function (analogous to \u201cposition\u201d), the slope of the wave function (\u201cvelocity\u201d), and \nthe curvature of the wave function (\u201cacceleration\u201d) at any position x (\u201ctime\u201d), we can predict the wave \nfunction and its slope at the next position x + \u0006x. At each step we calculate the wave function curva-\nture using the energy eigenvalue equation\n \nd 2wE1x2\ndx2\n= -  2m\nU2  3E - V1x24wE1x2. \n(5.156)\n\n5.10 Fitting Energy Eigenstates by Eye or by Computer \n153\nWe don\u2019t have to impose the continuity conditions on wE1x2 and dwE1x2>dx at boundaries; the \nupdate equations guarantee that they are met. What we do need are initial values of the wave function \nand the \ufb01rst derivative to get the update equations started. In principle, we should start at x = - \u0005 \nand integrate (i.e., update) all the way to x = + \u0005. In practice, it suf\ufb01ces to start a reasonable way \ninto the left-hand forbidden region, integrate into and through the potential well, and then integrate \na reasonable way into the right-hand forbidden region. The wave function in the forbidden region \nshould be decaying toward zero as it approaches x = { \u0005, which indicates how we should choose \nthe initial values of the wave function and the \ufb01rst derivative. Recall, however, that the energy eigen-\nvalue equation is linear in the wave function wE1x2, so we can scale the wave function by any factor \nand it will still solve the differential equation. This means that we can choose the initial wave function \narbitrarily, but the resultant wave function will not be normalized. In principle, the initial wave func-\ntion slope should be chosen to have the appropriate decay length. In practice, the method is insensitive \nto this choice.\nNotice that the calculation of the wave function curvature from the energy eigenvalue equation \n(5.156) requires us to know the energy. But we don\u2019t know the energy\u2014we are trying to \ufb01nd it! So we \nguess a value of the energy and then we solve for the resultant wave function and see if it \u201c\ufb01ts\u201d into the \npotential well. From the problems above we have plenty of practice recognizing wave functions that \n\ufb01t, so it should be clear. And it is, as you will see.\nAs an example of how this numerical technique works, let\u2019s try it out on the \ufb01nite square well \nand compare to the results in Eq. (5.89). We choose an energy and start integrating with Eq. (5.155). \nThis is well suited to a spreadsheet, and the results shown in Fig. 5.29 are from an Excel worksheet. \nThe trademark results of this technique are illustrated in Fig. 5.29(a). If the chosen energy does not \nmatch an energy eigenstate solution, then as we integrate toward x = + \u0005 the wave function solution \nthat should decay starts to grow exponentially, because as the integration crossed the boundary into \nthe classically forbidden region (at x = a) there was a small component of the growing exponential \nsolution contained in the numerical wave function. Only by choosing the energy exactly equal to one \nof the allowed energies can thi",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 176
  },
  {
    "child_id": "a0de0190-c7fb-4760-95f7-a9365d1f0984",
    "parent_id": "aaa760a5-b439-4d4c-ab26-5fbc45f1ab7f",
    "text": " are illustrated in Fig. 5.29(a). If the chosen energy does not \nmatch an energy eigenstate solution, then as we integrate toward x = + \u0005 the wave function solution \nthat should decay starts to grow exponentially, because as the integration crossed the boundary into \nthe classically forbidden region (at x = a) there was a small component of the growing exponential \nsolution contained in the numerical wave function. Only by choosing the energy exactly equal to one \nof the allowed energies can this \u201cbad\u201d component be eliminated from the integration. Because of the \nseverity of exponential growth, combined with the discreteness of computer calculations, it is impos-\nsible to \ufb01nd the energy solution exactly. However, as Fig. 5.29 illustrates, you can \ufb01nd nearby energies \nthat cause the wave function to grow either negatively [Fig. 5.29(a)] or positively [Fig. 5.29(c)]. These \nsolutions then bracket the approximate solution [Fig. 5.29(b)]. The \ufb01nite square well used for the cal-\nculation in Fig. 5.29 is the same as the well used for Fig. 5.16, and the resultant energy eigenvalue of \nthis fourth energy level matches well with the result in Eq. (5.89). To obtain a more accurate value, one \nhas to be more careful about the initial conditions.\n\u03a8(x)\n\u03a8(x)\n\u03a8(x)\n(a)\n(b)\n(c)\n\na\na\nx\n\na\na\nx\n\na\na\nx\nE = 27.30454\nE = 27.30455\nE = 27.30456\nFIGURE 5.29 Numerical integration for solution of the \ufb01nite square well eigenvalue equation.\n\n154 \nQuantized Energies: Particle in a Box\n 5.10.3 \u0002 General Potential Wells\nGiven our approximate and numerical techniques, we can solve for the bound states in any potential \nwell, in principle. A typical bound state solution is shown in Fig. 5.30. It exhibits the key features that \nwe have mentioned above for bound state solutions:\n\u2022 Oscillatory in allowed region\n\u2022 Exponential decay in forbidden region\n\u2022 Oscillatory wave becomes less wiggly near classical turning point as kinetic energy \ndecreases\n\u2022 Amplitude becomes larger near classical turning points\nThus, though potential energy wells may appear quite different at \ufb01rst glance, they all can be \ncalled \u201cparticle-in-a-box\u201d systems, albeit with differently shaped boxes. Some common boxes are \nshown in Fig. 5.31: (a) in\ufb01nite square well, (b) \ufb01nite square well, (c) harmonic oscillator (mass on a \nspring), and (d) linear potential (bouncing ball potential).\nSUMMARY\nIn this chapter we learned the language of the wave function, which is the representation of the quan-\ntum state vector in position space. We express this as\n \n 0 c9 \u0003 c1x2  \n \n c1x2 = 8x0 c9. \n(5.157)\nThe complex square of the wave function yields the spatial probability density\n \nP1x2 = 0 c1x20\n2. \n(5.158)\nThe normalization condition is\n \n1 = 8c@ c9 =\n \nL\n\u0005\n- \u0005\n@ c1x2@\n2 dx = 1. \n(5.159)\nThe rules for translating bra-ket formulae to wave function formulae are:\n1) Replace ket with wave function \n0 c9 S c1x2\n2) Replace bra with wave function conjugate \n8c0 S c*1x2\n3) Replace bracket with integral over all space \n8@ 9 S\n \nL\n\u0005\n- ",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 176
  },
  {
    "child_id": "d8e1a949-ce52-499d-9a92-6894c97ec3fa",
    "parent_id": "aaa760a5-b439-4d4c-ab26-5fbc45f1ab7f",
    "text": "ce. We express this as\n \n 0 c9 \u0003 c1x2  \n \n c1x2 = 8x0 c9. \n(5.157)\nThe complex square of the wave function yields the spatial probability density\n \nP1x2 = 0 c1x20\n2. \n(5.158)\nThe normalization condition is\n \n1 = 8c@ c9 =\n \nL\n\u0005\n- \u0005\n@ c1x2@\n2 dx = 1. \n(5.159)\nThe rules for translating bra-ket formulae to wave function formulae are:\n1) Replace ket with wave function \n0 c9 S c1x2\n2) Replace bra with wave function conjugate \n8c0 S c*1x2\n3) Replace bracket with integral over all space \n8@ 9 S\n \nL\n\u0005\n- \u0005\n dx\n4) Replace operator with position representation \nAn S A1x2.\nThe probability of measuring the position of a particle to be in a \ufb01nite spatial region is\n \nPa6x6b =\n \nL\nb\na\n0 c1x20\n2 dx. \n(5.160)\n\nSummary \n155\nx\nE,\u03a8\nFIGURE 5.30 Bound state in a generic potential energy well.\n0\n(a)\nL/2\nL\nx\n0\n(b)\n\na\na\nx\nx\n(c)\nx\n(d)\nFIGURE 5.31 Different versions of the particle-in-a-box: (a) in\ufb01nite square well, \n(b) \ufb01nite square well, (c) harmonic oscillator (quadratic potential), and (d) linear potential.\n\n156 \nQuantized Energies: Particle in a Box\nThe probability of measuring the energy to be En is\n \nPEn = @8En@ c9@\n2 = 2\nL\n\u0005\n- \u0005\nw*\nn1x2c1x2dx 2\n2\n, \n(5.161)\nwhere wn1x2 = 8x0 En9 is the wave function representation of the energy eigenstate.\nPosition and momentum operators in the position representation are\n \n xn \u0003 x\n \n \n pn \u0003 -iU d\ndx \n(5.162)\nand lead to the energy eigenvalue equation becoming a differential equation:\n \na-  U2\n2m d 2\ndx2 + V1x2\n b wE1x2 = EwE1x2. \n(5.163)\nIn solving the energy eigenvalue equation, two boundary conditions are imposed upon the wave function:\n1) wE1x2 is continuous\n2) \ndwE1x2\ndx\n is continuous unless V = \u0005.\nIn an in\ufb01nite square potential energy well, the allowed energies are\n \nEn = n2p2\n U2\n2mL2\n ,   n = 1, 2, 3, ..., \n(5.164)\nand the allowed energy eigenstates are\n \nwn1x2 = A\n2\nL\n sin  npx\nL ,   n = 1, 2, 3, ... . \n(5.165)\nThe energy eigenstates obey the following properties:\nProperty\nDirac notation\nWave function notation\nNormalization\n8En0En9 = 1\nL\n\u0005\n- \u0005\n0wn1x20\n2dx = 1\nOrthogonality\n8En0Em9 = dnm\nL\n\u0005\n- \u0005\nw*\nn1x2wm1x2dx = dnm\nCompleteness\n0c9 = a\nn\ncn0En9\nc1x2 = a\nn\ncnwn1x2\nPROBLEMS\n 5.1 Show that the operators xn and pn do not commute.\n 5.2 A particle in an in\ufb01nite square well potential has an initial state vector \n0 c1t = 029 = A10 w19- 0 w29 + i0 w392 where 0 wn9 are the energy eigenstates.",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 176
  },
  {
    "child_id": "c2a50838-85a6-447d-bb4b-4957ef4c439f",
    "parent_id": "b3b45a35-cdcd-45dc-9d26-2ec4991adb66",
    "text": "Problems \n157\na) Normalize the state vector.\nb)  What are the possible outcomes of a measurement of the energy, and with what probabilities \nwould they occur?\nc) What is the average value of the energy?\nd) Find the state vector at some later time, t.\ne)  At time t = U>E1, what are the possible outcomes of a measurement of the energy, and with \nwhat probabilities would they occur?\n 5.3 Solve the in\ufb01nite square well problem using the complex exponential form of the general solu-\ntion in Eq. (5.53) as the assumed form of the wave function inside the well. Assume that the \npotential well boundaries are at x = 0 and x = L.\n 5.4 Solve the in\ufb01nite square well problem with the well boundaries at x = {a. Comment on the \ndifferences and similarities with the solution in the text.\n 5.5 Calculate the expectation values and the uncertainties of position and momentum for the in\ufb01-\nnite square well energy eigenstates.\n 5.6 For a particle in an in\ufb01nite square well, calculate the probability of \ufb01nding the particle in the \nrange 3L>4 6 x 6 L for each of the \ufb01rst three energy eigenstates.\n 5.7 A particle in an in\ufb01nite square well potential has an initial state vector \n0 c1t = 029 = 10 w19 - 2i0 w292> 15 where the 0 wn9 are the eigenfunctions of the Hamiltonian \noperator. Find the time evolution of the state vector.\n 5.8 A particle in an in\ufb01nite square well potential has an initial wave function \nc1x, t =\n 02 = Ax1L - x2. Find the time evolution of the state vector. Find the expectation \nvalue of the position as a function of time.\n 5.9 A particle in an in\ufb01nite square well has the initial wave function\n \nc1x, 02 = A c a x\nLb\n3\n-\n 3\n2\n a x\nLb\n2\n+ 1\n2\n a x\nLbd \n \n in the interval 0 6 x 6 L and zero elsewhere. Find (a) the wave function at a later time, (b) the \nprobabilities of energy measurements, and (c) the expectation value of the energy.\n 5.10 A particle at t = 0 is known to be in the right half of an in\ufb01nite square well with a probability \ndensity that is uniform in the right half of the well. What is the initial wave function of the par-\nticle? Calculate the expectation value of the energy. Find the probabilities that the particle is \nmeasured to have energy E1, E2, or E3.\n 5.11 A particle is in the ground state of an in\ufb01nite square well. The potential wall at x = L suddenly \nmoves to x = 3L such that the well is now three times its original size. Find the probabilities \nthat the particle is measured to have the ground state energy or the \ufb01rst excited state energy of \nthe new well.\n 5.12 Show that the energy eigenstates of the in\ufb01nite square well are orthogonal.\n 5.13 Use the closure relation in Eq. (5.101) to show that the normalization condition is\n \n1 = 8c@ c9 = a\nn\n@8En@ c9@\n2. \n 5.14 Solve the energy eigenvalue problem for the \ufb01nite square well without using the symmetry \nassumption and show that the energy eigenstates must be either even or odd.\n\n158 \nQuantized Energies: Particle in a Box\n 5.15 Derive the transcendental equation (5.85) for the energy eigen",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 181
  },
  {
    "child_id": "42420889-9e9c-4e73-8c52-4b6228a3ee2d",
    "parent_id": "b3b45a35-cdcd-45dc-9d26-2ec4991adb66",
    "text": " new well.\n 5.12 Show that the energy eigenstates of the in\ufb01nite square well are orthogonal.\n 5.13 Use the closure relation in Eq. (5.101) to show that the normalization condition is\n \n1 = 8c@ c9 = a\nn\n@8En@ c9@\n2. \n 5.14 Solve the energy eigenvalue problem for the \ufb01nite square well without using the symmetry \nassumption and show that the energy eigenstates must be either even or odd.\n\n158 \nQuantized Energies: Particle in a Box\n 5.15 Derive the transcendental equation (5.85) for the energy eigenvalues of the odd states in the \n\ufb01nite square well.\n 5.16 Normalize the energy eigenstates of the \ufb01nite square well.\n 5.17 Find the probability that a particle in the ground state of a \ufb01nite square well is measured to \nhave a position outside of the well. Derive a general relation involving only the parameters z \nand z0 de\ufb01ned in Eqs. (5.86). Show that the probability increases as the energy increases.\n 5.18 An electron is bound in a \ufb01nite square well of depth V0 = 5 eV and width 2a = 1.5 nm. Find \nthe allowed energies of the bound states in the well using the transcendental equations (5.88).\n 5.19 Give a qualitative, graphical argument that the difference in energy eigenvalues between the \n\ufb01nite and in\ufb01nite square wells is larger for higher energy states.\n 5.20 Find the bound energy eigenstates and eigenvalues of a \u201chalf-in\ufb01nite\u201d square well (i.e., a \nsquare well with in\ufb01nite potential for x 6 0 and \ufb01nite potential with value V0 for x 7 L).\n 5.21 Consider a quantum system with a set of energy eigenstates 0 Ei9. The system is in the state\n \n0 c9 =\n1\n130 0 E19 +\n2\n130 0 E29 +\n3\n130 0 E39 +\n4\n130 0 E49, \n \n where the energies are given by En = nE1. Find the probabilities for measuring the energy \neigenvalues and make a histogram similar to Fig. 5.2(b). Find the expectation value of the \nenergy. Find the uncertainty of the energy.\n 5.22 Consider a quantum system with a set of energy eigenstates 0 En9 where the energies are given \nby En = 1n + 1\n22U v for n = 0, 1, 2, ... . The system is in the state\n \n0 a9 = a\n\u0005\nn=0\nane-a2>2\n2n!\n0 En9, \n \n where a is a positive real number. Find the probabilities for measuring the energy eigenvalues \nand make a histogram similar to Fig. 5.2(b). Find the expectation value of the energy. Find the \nuncertainty of the energy.\n 5.23 Consider the following wave functions\n \n c1x2 = Ae-x2>3\n \n c1x2 = B \n1\nx2 + 2\n \n c1x2 = C secha x\n5b.\n \n In each case, normalize the wave function, plot the wave function, and \ufb01nd the probability that \nthe particle is measured to be in the range 0 6 x 6 1.\n 5.24 Demonstrate the requirement that the \ufb01rst derivative of the wave function be continuous, \nunless the potential is in\ufb01nite. To do this, integrate the energy eigenvalue equation from -e \nto +e and take the limit as e S 0 to derive a condition on the difference of the wave function \nderivatives between two adjacent points.\n 5.25 Find the energy eigenstates and eigenvalues of a particle con\ufb01ned to a delta function potential \nV1x2 = -b d1x2, where b",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 181
  },
  {
    "child_id": "95e242f2-063a-435f-9314-24867728708c",
    "parent_id": "b3b45a35-cdcd-45dc-9d26-2ec4991adb66",
    "text": "cle is measured to be in the range 0 6 x 6 1.\n 5.24 Demonstrate the requirement that the \ufb01rst derivative of the wave function be continuous, \nunless the potential is in\ufb01nite. To do this, integrate the energy eigenvalue equation from -e \nto +e and take the limit as e S 0 to derive a condition on the difference of the wave function \nderivatives between two adjacent points.\n 5.25 Find the energy eigenstates and eigenvalues of a particle con\ufb01ned to a delta function potential \nV1x2 = -b d1x2, where b is a positive real constant. Note that you will need to follow the \napproach in the previous problem to properly address how the in\ufb01nite potential at the origin affects \nthe wave function derivative. How many bound energy states exist in this potential energy well?\n\nResources \n159\n 5.26 Find the energy eigenstates and eigenvalues of a particle con\ufb01ned to a double delta function \npotential V1x2 = -b 1d1x - a2 + d1x + a22, where b is a positive real constant. How many \nbound energy states exist in this potential energy well?\n 5.27 Calculate the expectation value of the momentum for the two-state superposition in Eq. (5.128) \nand verify Eq. (5.138).\n 5.28 Solve the boundary condition equations (5.144) for the asymmetric square well and verify \nEq. (5.145).\n 5.29 Find the transcendental equation that determines the energy eigenvalues in an asymmetric \nsquare well for the case E 6 V0. Compare with Eq. (5.145) for the E 7 V0 case and comment.\n 5.30 Implement the update equations (5.155) using a spreadsheet or other computer program and \n\ufb01nd the numerical solutions for the energy eigenvalues of a \ufb01nite square well with a well \nparameter z0 = 6. Compare your results with Eq. (5.89).\n 5.31 Use a spreadsheet or other computer program to \ufb01nd the numerical solution of the ground \nstate and \ufb01rst excited state energy eigenvalues and wave functions for a \ufb01nite square well with \nparameters V0 = 5 eV, 2a = 1.5 nm, and m = me. Compare your results with the transcen-\ndental equations (5.88).\n 5.32 Reproduce the results for the GaAs quantum well states shown in Fig. 5.24 using the transcen-\ndental equations (5.88). The relevant GaAs parameters are V0 = 0.1 eV and m = 0.067 me.\n 5.33 For each of the potential wells shown in Fig. 5.32, make a qualitative sketch of the two energy \neigenstate wave functions whose energies are indicated. For each energy state, identify the clas-\nsically allowed and forbidden regions. Discuss the important qualitative features of each state.\n 5.34 Sketch a copy of Fig. 5.30 and identify the classically allowed and forbidden regions. Which \nenergy eigenstate is drawn in Fig. 5.30? Make a similar plot for the next lower energy eigenstate.\nRESOURCES\nActivities\nThe bulleted activities are available at\nwww.physics.oregonstate.edu/qmactivities\n\u2022 Operators and Functions: Students investigate the differential forms of quantum mechanical \noperators and identify eigenfunctions and eigenvalues of quantum mechanical operators.\n\u2022 Solving the Energy Eigenvalue ",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 181
  },
  {
    "child_id": "bd865a27-b26c-43bc-b618-55fd61586af1",
    "parent_id": "b3b45a35-cdcd-45dc-9d26-2ec4991adb66",
    "text": "copy of Fig. 5.30 and identify the classically allowed and forbidden regions. Which \nenergy eigenstate is drawn in Fig. 5.30? Make a similar plot for the next lower energy eigenstate.\nRESOURCES\nActivities\nThe bulleted activities are available at\nwww.physics.oregonstate.edu/qmactivities\n\u2022 Operators and Functions: Students investigate the differential forms of quantum mechanical \noperators and identify eigenfunctions and eigenvalues of quantum mechanical operators.\n\u2022 Solving the Energy Eigenvalue Equation for the Finite Well: Students solve the energy eigenvalue \nequation for different regions of the \ufb01nite well and make their solutions match at the boundaries.\nE,\u03a8\nx\nE11\nE4\nE,\u03a8\nx\nE10\nE5\nFIGURE 5.32 Potential wells for Problem 5.33.\n\n160 \nQuantized Energies: Particle in a Box\n\u2022 Time Evolution of In\ufb01nite Well Solutions: Students animate wave functions consisting of linear \ncombinations of eigenstates.\nQuantum Bound States: This simulation experiment from the PHET group at the \nUniversity of Colorado animates wave function superpositions in bound states: \nhttp://phet.colorado.edu/en/simulation/bound-states\nShooting Method Model: This program from the Open Source Physics group implements \nthe shooting method to numerically solve the energy eigenvalue equation: \nhttp://www.compadre.org/osp/items/detail.cfm?ID=6987\nFurther Reading\nQuantum wells are discussed in these Physics Today articles:\nD. Chemla, \u201cQuantum wells for photonics,\u201d Phys. Today 38(5), 57\u201364 (1985): \nhttp://dx.doi.org/10.1063/1.880974\nD. Gammon, D. Steel, \u201cOptical studies of single quantum dots,\u201d Phys. Today 55(10), 36\u201341 (2002): \nhttp://dx.doi.org/10.1063/1.1522165\nFurther details on numerical solutions of the energy eigenvalue equation are available in these \nreferences:\nR. H. Landau, M. J. P\u00e1ez and C. C. Bordeianu, A Survey of Computational Physics: Introductory \nComputational Science, Princeton, NJ: Princeton University Press, 2008.\nH. Gould, J. Tobochnik, and W. Christian, An Introduction to Computer Simulation Methods: \n Applications to Physical Systems (3rd edition), San Francisco, CA: Addison-Wesley, 2007.\n\n161\nC H A P T E R \n6\nUnbound States\nIn the last chapter we learned how to use the new concept of wave functions to describe the motion of \na particle in a potential well. We found that states corresponding to particles con\ufb01ned within the poten-\ntial well had quantized energies. We now turn our attention to unbound states, and we will \ufb01nd that the \nenergies are no longer quantized. The simplest case is that of the free particle with no potential affect-\ning the particle motion at all. The free particle states help us better understand the wave-particle dual-\nity of quantum mechanics. We then consider the case of particles that are affected by potentials but are \nnot bound. This includes potential wells where the energy is larger than the well depth and cases where \nthe potential has no localized minimum. Studying these unbound states is important in understanding \nscanning tunneli",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 181
  },
  {
    "child_id": "f4f14524-f59a-46ab-afa4-a2a1ed98ed57",
    "parent_id": "b3b45a35-cdcd-45dc-9d26-2ec4991adb66",
    "text": "lest case is that of the free particle with no potential affect-\ning the particle motion at all. The free particle states help us better understand the wave-particle dual-\nity of quantum mechanics. We then consider the case of particles that are affected by potentials but are \nnot bound. This includes potential wells where the energy is larger than the well depth and cases where \nthe potential has no localized minimum. Studying these unbound states is important in understanding \nscanning tunneling microscopy, nuclear alpha decay, and the scattering of particles.\nIn all cases, we are still charged with solving the energy eigenvalue equation\n \nHn 0 E9 = E0 E9 \n(6.1)\nwith the Hamiltonian operator\n \nHn = pn2\n2m\n + V 1xn2. \n(6.2)\nAs we did in the last chapter, we work in wave function language (i.e., in the position representation), \nand so the energy eigenvalue equation becomes a differential equation:\n \n HnwE 1x2 = EwE 1x2  \n \n a-  U2\n2m\n d 2\ndx 2 + V  1x2b  wE 1x2 = EwE 1x2  \n \n -  U2\n2m\n d 2\ndx2 wE 1x2 + V 1x2wE 1x2 = EwE 1x2. \n \n(6.3)\n6.1 \u0002 FREE PARTICLE EIGENSTATES\n6.1.1 \u0002 Energy Eigenstates\nFor a free particle, the potential energy function V1x2 is zero everywhere and the energy eigenvalue \ndifferential equation is\n \nd 2\ndx2 wE 1x2 =  -  2mE\nU2  wE 1x2. \n(6.4)",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 181
  },
  {
    "child_id": "14ea11c4-a1e4-4273-b323-e6f79efd4fba",
    "parent_id": "4824145d-d365-43e7-b5d0-7dee76015f29",
    "text": "162 \nUnbound States\nThis is the same differential equation we solved in Chapter 5 inside the square potential energy well. \nAgain, it is convenient to de\ufb01ne a wave vector\n \nk2 = 2mE\nU2  \n(6.5)\nand write the differential equation as\n \nd 2\ndx2 wE 1x2 =  -k2wE 1x2. \n(6.6)\nThe solutions to this differential equation are the familiar sinusoidal functions, which we can \nexpress either as the trigonometric functions sin kx and cos kx or the complex exponential functions \ne+ikx and e-ikx. Note that the energy E must be positive, so the wave vector is real for this problem. It \nis more convenient in this problem to use the complex exponential functions, so we write the general \nsolution to the energy eigenvalue equation as\n \nwE 1x2 = Ae+ikx + Be-ikx, \n(6.7)\nwhere we need to account for both possible signs of the wave vector and A and B are normalization \nconstants.\nThe critical physical difference between a free particle 1with V1x2 = 02 and a bound particle is \nthe lack of a con\ufb01ning potential. Because the wave function of the free particle is not required to \u201c\ufb01t\u201d \ninto the potential energy well, there are no limitations on the wave functions and hence no quantization \nof the energy. Mathematically, there are not enough constraints on the two normalization constants A \nand B and the energy E (through the wave vector k). There are three unknowns in Eq. (6.7), but the \nnormalization condition is the only constraining equation. The result is that the energy is a continuous \nvariable, not quantized, in contrast to the bound-state solutions in Chapter 5. The continuous nature of \nthe energy has important rami\ufb01cations, which we will explore. But \ufb01rst, let\u2019s look more closely at the \nphysics of quantum wave motion.\nTo understand free particle wave motion, let\u2019s look at the time evolution of the energy eigenstates \nof Eq. (6.7). The time dependence of this state is obtained by applying the recipe for Schr\u00f6dinger time \nevolution that we learned in Chapter 3. Because the state is already written in the energy basis, the \nSchr\u00f6dinger time-evolution recipe says to multiply by a phase factor dependent on the energy of the \nstate, giving\n \n cE1x, t2 = wE1x2e-i Et>U\n \n \n = 1Aeikx + Be-ikx2e-i Et>U. \n(6.8)\nIf we use the Einstein energy relation E = U v, we can rewrite Eq. (6.8) in a suggestive way:\n \n cE1x, t2 = 1Aeikx + Be-ikx2e-ivt\n \n \n = Aei1kx-vt2 + Be-i1kx+vt2\n \n \n = Aeik1x-vt>k2 + Be-ik1x+vt>k2. \n \n(6.9)\nThis quantum wave function has the same form we know from classical waves\u2014a function f  1x { vt2 \nwith the argument 1x { vt2. This functional form represents a wave that retains its shape as it moves, \nand any given point on that shape moves with a speed determined by the parameter \r, which in this \ncase yields 0 v0 = v>k. For the sinusoidal waves of this free particle state, such points of constant \nphase move at the phase velocity. The energy eigenstate has two parts\u2014the ei1kx-vt2 part moving in \nthe positive x-direction and the e-i1kx+vt2 part moving in the nega",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 186
  },
  {
    "child_id": "2603e6c6-b79e-4dea-a384-d6f4be1eb8db",
    "parent_id": "4824145d-d365-43e7-b5d0-7dee76015f29",
    "text": "es\u2014a function f  1x { vt2 \nwith the argument 1x { vt2. This functional form represents a wave that retains its shape as it moves, \nand any given point on that shape moves with a speed determined by the parameter \r, which in this \ncase yields 0 v0 = v>k. For the sinusoidal waves of this free particle state, such points of constant \nphase move at the phase velocity. The energy eigenstate has two parts\u2014the ei1kx-vt2 part moving in \nthe positive x-direction and the e-i1kx+vt2 part moving in the negative x-direction. So now we know\n\n6.1 Free Particle Eigenstates \n163\nthat whenever we see a wave function with spatial dependence e{ikx, the sign of the wave vector in the \nexponent indicates the direction of motion. It is convenient to work with the wave  vector eigenstates\n \nwk1x2 = Aeikx \n(6.10)\nas long as we remember that we must use both positive and negative k values to make a general energy \neigenstate.\n6.1.2 \u0002 Momentum Eigenstates\nTo learn more about the phase velocity of the wave vector eigenstates, it is useful to study the momen-\ntum of these wave functions. Let\u2019s operate on one of the states with the momentum operator, which is \na differential operator in the position representation:\n \n pnwk1x2 = a-iU d\ndxb Aeikx \n \n = -iU1ik2Aeikx\n \n \n = Ukwk1x2.\n \n \n(6.11)\nThus the action of the momentum operator on a wave vector eigenstate yields the same state with \na constant multiplier. Well, that is an eigenvalue equation! So the wave vector eigenstates are also \nmomentum eigenstates. The momentum eigenvalue equation is\n \npnwp1x2 =  pwp1x2 \n(6.12)\n 1 pn 0  p9 = p0  p9 in bra@ket notation2, so we have identi\ufb01ed\n \np = Uk \n(6.13)\nas the momentum eigenvalue and\n \nwp1x2 = Aei px>U \n(6.14)\nas the momentum eigenstate. The momentum eigenstate wave function wp1x2 is a function of position \nand not of momentum\u2014x is a variable and p is the particular momentum eigenvalue. The wave \nvector is related to the wavelength through k = 2p>l, so we can rewrite Eq. (6.13) as\n \np = h\nl  . \n(6.15)\nThis equation was introduced in the early days of quantum mechanics by Louis de Broglie and pro-\nvides the connection between the particle properties (momentum) and the wave properties (wave-\nlength) of a system. The de Broglie relation between momentum and wavelength is at the heart of \nthe wave-particle duality of quantum mechanics. We can turn Eq. (6.15) around to write an equation \nde\ufb01ning the de Broglie wavelength of a particle with momentum p:\n \nlde Broglie = h\np  . \n(6.16)\nThe momentum eigenstates are also energy eigenstates for the free particle, with energy [Eq. (6.5)]\n \nE = p2\n2m. \n(6.17)\n\n164 \nUnbound States\nThe fact that the momentum and energy operators share eigenstates is an important aspect of the free \nparticle problem and is a consequence of the general rule we discussed in Section 2.4 that commuting \noperators have common eigenstates 1like Sz and S2 sharing 0{9 states2 (Problem 6.5). A given momen-\ntum eigenstate has a de\ufb01nite energy given by Eq. (6.17), but a give",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 186
  },
  {
    "child_id": "50d9fa1f-9203-4e8c-ab4a-a56038159fb2",
    "parent_id": "4824145d-d365-43e7-b5d0-7dee76015f29",
    "text": "eigenstates are also energy eigenstates for the free particle, with energy [Eq. (6.5)]\n \nE = p2\n2m. \n(6.17)\n\n164 \nUnbound States\nThe fact that the momentum and energy operators share eigenstates is an important aspect of the free \nparticle problem and is a consequence of the general rule we discussed in Section 2.4 that commuting \noperators have common eigenstates 1like Sz and S2 sharing 0{9 states2 (Problem 6.5). A given momen-\ntum eigenstate has a de\ufb01nite energy given by Eq. (6.17), but a given energy state does not necessarily \nhave a de\ufb01nite momentum, because a general energy eigenstate is a superposition of the two momentum \nstates 0  p9 \u0003 wp1x2 and 0  -p9 \u0003 w-p1x2 with opposite momenta, as in Eq. (6.7). Because a given \nenergy state corresponds to multiple momentum states, we say that the energy state is degenerate with \nrespect to momentum. In the free particle case, the energy states are two-fold degenerate. This is our \n\ufb01rst example of degeneracy, but it will be more common once we address two- and three-dimensional \nsystems in Chapter 7.\nThe wave nature of the quantum mechanical description of the free particle is evident in Fig. 6.1, \nwhich shows the wave function of a momentum eigenstate. It is evident that a single wavelength char-\nacterizes the wave function, consistent with the single momentum of the eigenstate and the de Broglie \nrelation between wavelength and momentum. The wave function is complex, so we must plot both the \nreal and imaginary parts to completely describe the state.\nLet\u2019s now return to the question of the phase velocity of the free particle eigenstates. A momentum \neigenstate has time dependence\n \n cp1x, t2 = wp1x2e-i Ept>U\n \n \n = Aei px>U e-i p2t>2m U \n \n = Aei p>U1x-pt>2m2.  \n \n(6.18)\nThis wave is moving at a speed of v = p>2m, which is half the speed of a classical particle \nvclassical = p>m. This apparent contradiction exists because we are using the phase velocity of the \nwave. As we will see in Section 6.2, the proper way to use a wave to describe a particle leads us to the \nconcept of \u201cgroup velocity of a wave packet\u201d as the more appropriate velocity.\nA more serious problem with the momentum eigenstates becomes evident if we examine the prob-\nability density of the state. Taking the complex square of the wave function yields the probability density\n \nP1x2 = 0 wp1x20\n2\n \n \n = w*\np1x2wp1x2\n \n \n = A*e-i px>U Aei px>U \n \n = 0 A0\n2.\n \n \n(6.19)\nx\nRe \u000bp\u0007x\b\nx\nIm \u000bp\u0007x\b\n(a)\n(b)\nFIGURE 6.1 Momentum eigenstate. Both the (a) real and (b) imaginary parts of the wave \nfunction extend to {\u0005. A single wavelength characterizes the momentum eigenstate.\n\n6.1 Free Particle Eigenstates \n165\nAs shown in Fig. 6.2, the probability density of a momentum eigenstate is a constant independent of \nposition, extending to in\ufb01nity. This presents us with two problems. Conceptually, we expect a particle \nto be localized to a small region of space, not spread out over an in\ufb01nite region. Mathematically, we \ncannot normalize the momentum eigen",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 186
  },
  {
    "child_id": "42e14e7d-30e7-4e11-b2e6-0dda9681e5af",
    "parent_id": "4824145d-d365-43e7-b5d0-7dee76015f29",
    "text": "l and (b) imaginary parts of the wave \nfunction extend to {\u0005. A single wavelength characterizes the momentum eigenstate.\n\n6.1 Free Particle Eigenstates \n165\nAs shown in Fig. 6.2, the probability density of a momentum eigenstate is a constant independent of \nposition, extending to in\ufb01nity. This presents us with two problems. Conceptually, we expect a particle \nto be localized to a small region of space, not spread out over an in\ufb01nite region. Mathematically, we \ncannot normalize the momentum eigenstates because the integral of the probability density over all \nspace is in\ufb01nite. This is a new and quite serious problem. All previous basis states we have encoun-\ntered have been normalizable. This lack of normalizability is a pathology of all continuous bases\u2014\nthis one being our \ufb01rst example. Fortunately, there is a solution to this mathematical problem that \nalso solves our conceptual problem. By constructing superpositions of momentum eigenstates to make \nwave packets, we get wave functions that are normalizable and are localized to \ufb01nite regions of space. \nBefore we construct wave packets, it is useful to discuss some of the mathematical properties of the \nmomentum eigenstates.\nWe expect a set of basis states to exhibit three important properties. The states should be: (1) nor-\nmalized, (2) orthogonal, and (3) complete. All the discrete basis sets we have encountered have satis\ufb01ed \nthese conditions, which we express in Dirac notation as\n \n 8ai0 aj\u0002i9 = 0   orthogonality \n \n 8ai0 ai9 = 1   normalization \n \n a\ni\n0 ai98ai0 = 1   completeness, \n \n(6.20)\nassuming a set of discrete eigenstates 0 ai9. The orthogonality and normalization conditions are com-\nbined into one orthonormality equation by using the Kronecker delta:\n \n8ai0 aj9 = dij. \n(6.21)\nTo adapt this orthonormality equation to a continuous basis, we need to use the continuous analog \nof the discrete Kronecker delta, which is the Dirac delta function. The Dirac delta function, writ-\nten d1x - x02, is a function that is zero at every value of x, except at x = x0, where it is in\ufb01nite (not \nunity). This in\ufb01nity means that the Dirac delta function does not strictly represent the normalization \ncondition, but it is consistent with the in\ufb01nite norm we found for the momentum eigenstates above. \nThus, we expect that the \u201corthonormality\u201d condition for a continuous basis set of momentum states is\n \n8p\u000e 0\n p\u00049 = d1 p\u000e - p\u00042 \n(6.22)\nx\n\u0002\u000bp(x)\u00022\nFIGURE 6.2 Position probability distribution for a momentum eigenstate.",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 186
  },
  {
    "child_id": "fda31c40-8c1b-4c56-90aa-5d7c212e8507",
    "parent_id": "d168177e-0517-4b76-9049-bdf7a4a09761",
    "text": "166 \nUnbound States\nin Dirac notation. Using the rules developed in Chapter 5 for translating bra-ket notation to wave \n function notation, we express the inner product in Eq. (6.22) as an overlap integral\n \nL\n\u0005\n- \u0005\nw*\np\u000e1x2wp\u00041x2dx = d1 p\u000e - p\u00042. \n(6.23)\nThe momentum eigenstates de\ufb01ned in Eq. (6.14) satisfy this new form of the  orthonormality \n equation, as long as we de\ufb01ne the normalization constant A for the momentum eigenstates as \n (Problem 6.7)\n \nA =  \n1\n22pU\n. \n(6.24)\nAlthough continuous basis sets, such as the momentum basis, do not strictly satisfy the normalization \ncondition required by quantum mechanics, it is still practical to use Eqs. (6.22) and (6.23) to \u201cnormalize\u201d \na basis, and we refer to this process as Dirac normalization. We thus write the \u201cnormalized\u201d momen-\ntum eigenstates as\n \nwp1x2 =  \n1\n22pU\n ei px>U    . \n(6.25)\nIt is worth thinking about dimensions at this point. With the normalization of the momentum eigen-\nstates in Eq. (6.25), we see that the dimensions of the left hand side of Eq. (6.23) are 3length4>3U4, \nwhich from Eq. (6.16) are equivalent to 1>3p4 or inverse momentum. Thus, the Dirac delta function \nhas dimensions of the inverse of its argument. This is another difference from the Kronecker delta that \nwe have to live with.\nThe completeness of a basis implies that any function (relevant to the problem at hand) can \nbe written as a superposition of the basis states. Completeness is dif\ufb01cult to prove mathematically, so we \ngenerally just assume that it is satis\ufb01ed. In the discrete basis case, the completeness condition (closure \nrelation) in Eq. (6.20) is a sum of the projection operators over the discrete basis set. To change to a con-\ntinuous basis, we change the sum over the discrete label to an integral over the continuous label. For the \nmomentum eigenstates, the completeness condition is\n \nL\n\u0005\n- \u0005\n0  p98p0 dp = 1, \n(6.26)\nwhere we understand that the right hand side is the identity operator. To demonstrate how complete-\nness allows us to express any general state as a superposition of the basis states, insert Eq. (6.26) into \nthe Dirac expression for a wave function\n \n c1x2 = 8x0 c9\n \n \n = 8x0 b\nL\n\u0005\n- \u0005\n0  p98p0 dpr 0 c9 \n \n =\n \nL\n\u0005\n- \u0005\n8x0  p98p0 c9dp.\n \n \n(6.27)\nThe \ufb01rst term 8x0 p9 in the integrand is the projection of the momentum eigenstate 0  p9 onto the posi-\ntion basis, which is the wave function representation wp1x2 of the momentum eigenstate. The second \nterm 8p0 c9 in the integrand is the projection of the general state 0 c9 onto the momentum basis 0  p9 \n(i.e., the probability amplitude for the general state 0 c9 to have momentum p). Given the rules of Dirac\n\n6.1 Free Particle Eigenstates \n167\nnotation, you might expect the probability amplitude 8p0 c9 to be written as 8p0 c9 = c 1 p2. However, \nthere is risk of confusion here with the wave function c1x2 because c1 p2 and c1x2 are not the same \nmathematical function with different arguments, but rather are different mathematical functions. To ",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 190
  },
  {
    "child_id": "bc283ce6-1ddc-4e30-bed7-d568bbd0ecc4",
    "parent_id": "d168177e-0517-4b76-9049-bdf7a4a09761",
    "text": "he general state 0 c9 onto the momentum basis 0  p9 \n(i.e., the probability amplitude for the general state 0 c9 to have momentum p). Given the rules of Dirac\n\n6.1 Free Particle Eigenstates \n167\nnotation, you might expect the probability amplitude 8p0 c9 to be written as 8p0 c9 = c 1 p2. However, \nthere is risk of confusion here with the wave function c1x2 because c1 p2 and c1x2 are not the same \nmathematical function with different arguments, but rather are different mathematical functions. To \navoid this possible confusion, it is common to use a different symbol for the momentum probability \namplitude, such as\n \nf1 p2 = 8p0 c9, \n(6.28)\nalthough such notation brings its own confusion between the different Greek symbols. The function \nf1 p2 is known as the momentum space wave function. As in the position case, the probability ampli-\ntude f1 p2 = 8p0 c9 is a continuous function that is the collection of numbers that represents the quan-\ntum state vector in terms of the momentum eigenstates. The wave function c1x2 and the momentum \nspace wave function f1 p2 are both representations of the state 0 c9, but they are representing that \nstate in different bases. Which basis we should use is up to us and is generally a matter of convenience \ndecided by what we wish to calculate. Using this de\ufb01nition of the momentum space wave function, we \nwrite Eq. (6.27) as\n \nc1x2 =\n \nL\n\u0005\n- \u0005\nwp1x2f1 p2dp, \n(6.29)\nwhich, in words, says that a general state 0 c9 \u0003 c1x2 can be decomposed into an integral (i.e., super-\nposition) over all momentum eigenstates 0  p9 \u0003 wp1x2 with a proportionality coef\ufb01cient given by the \nprobability amplitude f1p2 = 8p0 c9 for the general state to be measured in that particular momentum \nbasis state.\nIf we put the explicit form of the momentum eigenstates wp1x2 into Eq. (6.29), then the superposi-\ntion becomes\n \nc1x2 =  \n1\n22pU L\n\u0005\n- \u0005\nf1 p2ei px>U dp   . \n(6.30)\nThis should look familiar! It is the Fourier transform of the function f1 p2. Thus, quantum mechani-\ncal superpositions behave much like classical wave superpositions. In both cases, the Fourier trans-\nform represents a superposition of sinusoidal waves that combine to make a wave packet. We thus \nexpect that the connection in the opposite direction (i.e., writing the momentum space wave function \nin terms of the position space wave function) would be an inverse Fourier transform. We can show that \nthis is so by using our prescription for writing a probability amplitude in wave function language as an \noverlap integral. The momentum space wave function f1 p2 is a probability amplitude f1 p2 = 8p0 c9, \nand the rule for converting a Dirac bra-ket projection to wave function overlap integral is to convert the \nket 0 c9 to a wave function c1x2, the bra 8p0  to a wave function conjugate w*\np1x2 = e-i px>U> 12pU, and \nthen integrate over all space. Thus, we get\n \nf1 p2 =  \n1\n22pU L\n\u0005\n- \u0005\nc1x2e-i px>U dx   , \n(6.31)\nwhich we recognize as an inverse Fourier transform. Thus, we see that the",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 190
  },
  {
    "child_id": "90654c82-abe2-4bbb-8ee1-b1cd74e9ff85",
    "parent_id": "d168177e-0517-4b76-9049-bdf7a4a09761",
    "text": "uage as an \noverlap integral. The momentum space wave function f1 p2 is a probability amplitude f1 p2 = 8p0 c9, \nand the rule for converting a Dirac bra-ket projection to wave function overlap integral is to convert the \nket 0 c9 to a wave function c1x2, the bra 8p0  to a wave function conjugate w*\np1x2 = e-i px>U> 12pU, and \nthen integrate over all space. Thus, we get\n \nf1 p2 =  \n1\n22pU L\n\u0005\n- \u0005\nc1x2e-i px>U dx   , \n(6.31)\nwhich we recognize as an inverse Fourier transform. Thus, we see that the connection between the \nmomentum space wave function f1 p2 and the (position space) wave function c1x2 is the Fourier \ntransform. As we saw in the spins case, we are free to use whichever representation of a quantum state \nvector that we \ufb01nd most convenient. The position and momentum representations are similarly equally \nvalid representations. We focus on the position representation because it is generally the most useful.\n\n168 \nUnbound States\n6.2 \u0002 WAVE PACKETS\nThe key result from the previous section is that Fourier superpositions of momentum eigenstates are \nrequired for proper representation of free particle states. Let\u2019s \ufb01rst consider a discrete Fourier series \nexample that illustrates many of the important features of wave packets, and then we\u2019ll make a real \nwave packet using continuous Fourier transforms.\n6.2.1 \u0002 Discrete Superposition\nIn this example, we add just three momentum eigenstates together. We choose one \u201ccentral\u201d state \nwith momentum p0 to have twice the amplitude of two \u201cside mode\u201d states that are equally spaced at \np = p0 { dp about the central state, as shown in the momentum state distribution in Fig. 6.3. As the \ndashed line hints, we are using this three-mode superposition as a model of a continuous momentum \ndistribution characterized by a center momentum p0 and a momentum distribution width dp that we \nwill discuss in Section 6.2.2.\nA graphical representation of this three-state superposition of sinusoidal waves and the resultant \nwave is shown in Fig. 6.4. The different wavelengths of the three components lead to constructive and \ndestructive interference, as indicated in the plots. The resultant wave is localized to a region of space \nand hence is referred to as a wave packet. The wave packet shown in Fig. 6.4 has a characteristic \nwavelength determined by the central momentum, so it resembles a wave, but it also has a limited spa-\ntial extent, and so it also resembles a particle. In this case, we are using a discrete Fourier sum, so this \nlocalization is repeated periodically. For the more realistic continuum distribution, only one localized \nregion exists and a true wave packet is realized. The coexisting particle and wave characteristics of a \nwave packet are the essence of the wave-particle duality of quantum mechanics.\nTo understand the motion of the wave packet, we must study the time evolution. The wave func-\ntion at time t = 0 is given by the weighted superposition of the three momentum eigenstates\n \n c1x, 02 = a\nj\ncj ",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 190
  },
  {
    "child_id": "dc54bced-df6d-4103-81eb-8515f326e320",
    "parent_id": "d168177e-0517-4b76-9049-bdf7a4a09761",
    "text": "is \nlocalization is repeated periodically. For the more realistic continuum distribution, only one localized \nregion exists and a true wave packet is realized. The coexisting particle and wave characteristics of a \nwave packet are the essence of the wave-particle duality of quantum mechanics.\nTo understand the motion of the wave packet, we must study the time evolution. The wave func-\ntion at time t = 0 is given by the weighted superposition of the three momentum eigenstates\n \n c1x, 02 = a\nj\ncj wpj1x2\n \n \n c1x, 02 = a\nj\ncj \n1\n22pU\n ei pj\n x>U\n \n \n c1x, 02 =\n1\n22pU\n 31\n2 ei1 p0-dp2x>U + ei p0\n x>U + 1\n2 ei1 p0+dp2x>U4. \n \n(6.32)\np0 \n \u0394p\np0 \r \u0394p\np0\np\n\u03a6\u0007p\b\nFIGURE 6.3 Discrete momentum distribution used to model continuous distributions \nand to build a discrete wave packet.\n\n6.2 Wave Packets \n169\nThe time-dependent wave function representing this wave packet is obtained by following the Schr\u00f6dinger \ntime-evolution recipe. Momentum eigenstates are also energy eigenstates of free particles, so the \nsuperposition is already written in the energy basis and we multiply each energy eigenstate by its own \nenergy-dependent phase factor:\n \nc1x, t2 = a\nj\ncj wpj1x2e-i Ej\n t>U. \n(6.33)\nThe energy of each momentum eigenstate is given by the free particle energy\n \nEj =\np2\nj\n2m, \n(6.34)\nwhich for the three states yields\n \n Ep0 =\np2\n0\n2m\n \n \n Ep0{dp = 1p0 { dp2\n2\n2m\n=\np2\n0 { 2p0dp + 1dp2\n2\n2m\n. \n \n(6.35)\nWe assume that the width of the momentum distribution is narrow enough that dp V p0 and so we \nneglect the small 1dp22 term in the energies. Hence, the time-evolved wave packet state is\n \nc1x, t2 =\n1\n22pU\n 31\n2\n ei1 p0-dp2x>U e-i1p2\n0 -2p0dp2t>2m  U + ei p0\n x>U e-i p2\n0\n t>2m  U + 1\n2\n ei1 p0+dp2x>U e-i1p2\n0 +2p0dp2t>2m  U4\n \nc1x, t2 =\n1\n22pU\n  ei p0\n x>U e-i p2\n0\n \n t>2m  U 31\n2\n e-idpx>U ei p0dpt>m  U + 1 + 1\n2\n eidpx>U e-i p0dpt>m  U4\n \nc1x, t2 =\n1\n22pU\n ei p0\n x>U e-i p2\n0\n \n t>2m U c 1 + cosadp\nU\n x - p0dp\nm U\n tb d , \n \n(6.36)\nDestructive Interference\nDestructive Interference\nConstructive Interference\n\r\n\r\n\b\nx\n0\n\u0394x\n\n\u0394x\nFIGURE 6.4 Discrete wave packet with three components.\n\n170 \nUnbound States\nwhich yields\n \nc1x, t2 =\n1\n22pU\n eip01x-p0t>2m2>UJ1 + cos adp\nU\n c x - p0\nm\n td b R. \n(6.37)\nThis wave packet contains the expected form f  1x { vt2 of a wave, but it has two such parts with \ndifferent arguments. The \ufb01rst part of Eq. (6.37) (in curly brackets) is characterized by the momentum \np0 and hence wavelength l0 = h>p0 of the single harmonic wave. This part is called the carrier wave, \nand from its argument we \ufb01nd that it moves at the phase velocity vph = p0>2m, as we discussed above. \nThe second part of the wave packet (in square brackets) is characterized by the momentum width dp \nand hence a wavelength lenv = h>dp that is much longer than l0 1because dp V p02. This second \npart is known as the envelope of the wave packet because it modulates the carrier wave, as shown in \nFig. 6.5. Because of the different arguments of the two parts, the envelope moves at a di",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 190
  },
  {
    "child_id": "3fb8f871-5c9b-40ab-b9ee-f1e975f3f87c",
    "parent_id": "d168177e-0517-4b76-9049-bdf7a4a09761",
    "text": "arrier wave, \nand from its argument we \ufb01nd that it moves at the phase velocity vph = p0>2m, as we discussed above. \nThe second part of the wave packet (in square brackets) is characterized by the momentum width dp \nand hence a wavelength lenv = h>dp that is much longer than l0 1because dp V p02. This second \npart is known as the envelope of the wave packet because it modulates the carrier wave, as shown in \nFig. 6.5. Because of the different arguments of the two parts, the envelope moves at a different  velocity \nvgp = p0>m from the carrier. This velocity is called the group velocity because it characterizes the \nvelocity of the group of waves together.\nThe different velocities are evident if the plot of the wave packet in Fig. 6.5 is animated \n( Problem 6.8). Several frames from such an animation are shown in Fig. 6.6, where you can see that \nthe velocity of the envelope\u2014the group velocity\u2014is twice the velocity of the wiggles within the \n envelope\u2014the phase velocity. Notice that the group velocity is equal to the classical velocity of a par-\nticle with momentum p0. This is the sense in which this wave packet can properly represent the motion \nof a particle. This discrete superposition is a good starting point, but it still suffers from the pathologies \nof harmonic waves\u2014it is not normalizable and it therefore cannot predict expectation values\u2014so we \nmust use a continuous momentum distribution to model real experiments. Moreover, the \u201clocaliza-\ntion\u201d of the discrete Fourier series superposition is repeated periodically, and so cannot represent a \nsingle particle.\nx\n\u03a8(x)\nEnvelope\nCarrier\nFIGURE 6.5 Wave packet showing the carrier wave and the modulation envelope.",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 190
  },
  {
    "child_id": "35a23b78-b4c4-4321-8e6c-a71236417f8c",
    "parent_id": "1131087c-ba59-4502-9500-0c8d81834895",
    "text": "6.2 Wave Packets \n171\n6.2.2 \u0002 Continuous Superposition\nTo go from the discrete case to the continuous case, we change the superposition sum in Eq. (6.32) to \na superposition integral (i.e., we change the Fourier series to a Fourier integral or Fourier transform). \nWhile this may seem like a trivial extension, there are important differences. As we did in the dis-\ncrete case, we perform the expansion using the momentum eigenstate basis wp1x2 because these states \nare also energy eigenstates in the free particle example, which then sets us up to use the Schr\u00f6dinger \ntime-evolution recipe. In the integral superposition, we specify the amplitudes of the momentum \neigenstate as a continuous distribution f1 p2 rather than specifying discrete amplitudes. Thus, we \nwrite the initial superposition state as\n \n c1x, 02 =\n \nL\n\u0005\n- \u0005\nf1 p2wp1x2dp\n \n \n =\n \nL\n\u0005\n- \u0005\nf1 p2 \n1\n22pU\n ei px>U dp, \n \n(6.38)\nwhere f1p2 is also called the momentum space wave function. The time-evolved state is found by fol-\nlowing the recipe for Schr\u00f6dinger time evolution and including the energy dependent phase factors:\n \nc1x, t2 =\n \nL\n\u0005\n- \u0005\nf1 p2wp1x2e-iEp\n t>U dp. \n(6.39)\nFIGURE 6.6 Discrete wave packet animation with time increasing from top to bottom. \nOpen circles identify a point of constant phase, which moves at the phase velocity. Filled \ncircles identify the peak of the envelope, which moves at the group velocity.\n\n172 \nUnbound States\nPutting in the explicit momentum eigenstate wave functions and the expression for the free particle \nenergy results in\n \nc1x, t2 =  \n1\n22pU L\n\u0005\n- \u0005\nf1 p2ei px>U e-i p2t>2m U dp, \n(6.40)\nwhich simpli\ufb01es to\n \nc1 x , t2 =  \n1\n22pU L\n\u0005\n- \u0005\nf1 p2ei p1x  - pt>2m2>U dp. \n(6.41)\nThis is the time-dependent generalization of the Fourier transform in Eq. (6.30) for the case of a free \nparticle. The time-dependent generalization of the inverse Fourier transform in Eq. (6.31) is\n \nf1 p, t2 =  \n1\n22pU L\n\u0005\n- \u0005\nc1x, t2e-i px>U dx. \n(6.42)\nTo evaluate the Fourier integral in Eq. (6.41) and determine the wave function for any particular case, \nwe need to know the particular momentum distribution f1p2, which may be speci\ufb01ed as an initial \ncondition, or can be determined from the initial wave function c1x, 02 via the Fourier transform in \nEq. (6.31) that relates the spatial and momentum space wave functions.\nAs an example, consider the case of a Gaussian momentum distribution. This is a very common \nexample because Gaussian functions are easy to integrate\u2014you get another Gaussian in the Fourier \nspace. In addition, the Gaussian distribution is a very good representation of many real experimental \nsituations. The Gaussian function is one of the standard classical probability distributions and is com-\nmonly written as\n \nf 1z2 =  e-1z-m2\n2>2s2\ns22p\n, \n(6.43)\nwhere m is the mean value or average of the distribution and s is the standard deviation of the distribu-\ntion. Relating these de\ufb01nitions to the quantum mechanical quantities, the mean value is the expectation \nval",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 195
  },
  {
    "child_id": "51ee5522-deec-4809-b6f8-1b73ed071121",
    "parent_id": "1131087c-ba59-4502-9500-0c8d81834895",
    "text": "sian in the Fourier \nspace. In addition, the Gaussian distribution is a very good representation of many real experimental \nsituations. The Gaussian function is one of the standard classical probability distributions and is com-\nmonly written as\n \nf 1z2 =  e-1z-m2\n2>2s2\ns22p\n, \n(6.43)\nwhere m is the mean value or average of the distribution and s is the standard deviation of the distribu-\ntion. Relating these de\ufb01nitions to the quantum mechanical quantities, the mean value is the expectation \nvalue 8z9 and the standard deviation is the uncertainty \u0006z. The probability distribution in Eq. (6.43) is \nnormalized to unity:\n \nL\n\u0005\n- \u0005\nf 1z2dz = 1. \n(6.44)\nNotice that the function f 1z2 is not squared in the normalization integral in Eq. (6.44), contrary to \nthe normalization of quantum mechanical wave functions to which you have become accustomed. In \nquantum mechanics, we have to square the wave function to get the probability density, which is then \nnormalized, analogous to Eq. (6.44). So, technically speaking, the phrase \u201cnormalize the quantum \nmechanical wave function\u201d is not correct, because we actually normalize the probability distribution, \nnot the wave function. But that phrase is ingrained into all practicing physicists, so we are stuck with it.\nJust as we did in the discrete case, let\u2019s assume that the momentum distribution is peaked at p0 and \nhas a width characterized by a parameter b. The Gaussian momentum space wave function is\n \nf1 p2 = \u00a2\n1\n2pb2 \u2264\n1>4\n e-1p-p02\n2>4b2, \n(6.45)\n\n6.2 Wave Packets \n173\nwhere the scale factor ensures proper normalization. This momentum space wave function is shown in \nFig. 6.7, with the previous discrete case for comparison. The momentum probability distribution (per \nunit momentum) is the absolute square of the momentum space wave function:\n \nP1 p2 = 0 f1p20\n2 = e-1p-p02\n2>2b2\nb22p\n. \n(6.46)\nComparison of this quantum mechanical momentum probability distribution with the standard \n Gaussian probability function in Eq. (6.43) allows us to determine the momentum expectation value \n8p9 and momentum uncertainty \u0006p by inspection as\n \n 8p9 = p0 \n \n \u0006p = b . \n \n(6.47)\nThe time-evolved spatial wave function for this Gaussian wave packet is obtained by substituting \nEq. (6.45) into the Fourier transform in Eq. (6.41):\n \nc1x, t2 =\n1\n22pU L\n\u0005\n- \u0005\n\u00a2\n1\n2pb2 \u2264\n1>4\n e-1 p-p022>4b2 ei px>U e-i p2t>2m U dp. \n(6.48)\nThis integral can be performed using the standard Gaussian integral shown in Appendix F, Eq. (F.23): \n(Problem 6.9). The result is\n \nc1x, t2 =\n22b\n3Ug22p\n ei p01x-p0t>2m2>U e-1x-p0t>m2\n2b2>U2g, \n(6.49)\nwhere the new parameters are\n \n g = 1 +  it\nt\n \n t =  m U\n2b2 .  \n(6.50)\np\n\u03a6(p)\n2\u0392\np0 \u0004 \u0394p \np0 \u0006 \u0394p\np0\nFIGURE 6.7 Gaussian momentum space wave function.\n\n174 \nUnbound States\nIf we de\ufb01ne\n \na =\nU\n2b , \n(6.51)\nthen we can express the wave function as\n \nc1x, t2 = a\n1\n2pa2b\n1>4 1\n1g\n  ei p01x-p0t>2m2>U e-1x-p0t>m2\n2>4a2g, \n(6.52)\nwhere a is useful later as a measure of the width in position space.\nJust as in Eq. (6.37) fo",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 195
  },
  {
    "child_id": "8a9a1100-83f6-4f4f-90fd-6116fbbf50a2",
    "parent_id": "1131087c-ba59-4502-9500-0c8d81834895",
    "text": "esult is\n \nc1x, t2 =\n22b\n3Ug22p\n ei p01x-p0t>2m2>U e-1x-p0t>m2\n2b2>U2g, \n(6.49)\nwhere the new parameters are\n \n g = 1 +  it\nt\n \n t =  m U\n2b2 .  \n(6.50)\np\n\u03a6(p)\n2\u0392\np0 \u0004 \u0394p \np0 \u0006 \u0394p\np0\nFIGURE 6.7 Gaussian momentum space wave function.\n\n174 \nUnbound States\nIf we de\ufb01ne\n \na =\nU\n2b , \n(6.51)\nthen we can express the wave function as\n \nc1x, t2 = a\n1\n2pa2b\n1>4 1\n1g\n  ei p01x-p0t>2m2>U e-1x-p0t>m2\n2>4a2g, \n(6.52)\nwhere a is useful later as a measure of the width in position space.\nJust as in Eq. (6.37) for the discrete momentum distribution, this wave packet has a carrier wave \npart (in curly brackets) that is characterized by p0 and propagates at the phase velocity p0>2m, and \nan envelope part (in square brackets) that is characterized by the momentum width b (through the a \nparameter) and propagates at the group velocity p0>m. As we expected, the envelope is a Gaussian \nfunction. To isolate the envelope propagation, calculate the spatial probability density by taking the \nsquare modulus of the wave function:\n \nP1x, t2 = 0 c1x, t20\n2 =  \n1\n22pa\u000f\n e-1x -p0t>m2\n2>2a2\u000f2, \n(6.53)\nwhere we have de\ufb01ned a new parameter\n \n\u000f = 30 g0\n2 = B1 + t2\nt2 . \n(6.54)\nThe only velocity that appears in the probability density is the group velocity p0>m, which agrees \nwith our classical expectation that the particle propagates at this velocity. This Gaussian wave packet \nis shown in Fig. 6.8(a) and the probability density is shown in Fig. 6.8(b). This wave packet is truly \nlocalized; the probability density decays to zero away from the central peak in Fig. 6.8(b) with none \nof the secondary peaks that were evident in the discrete superposition in Fig. 6.4. The continuum of \nmomentum states used in this superposition ensures that the destructive interference of the constituent \nwaves away from the central peak is effective in truly localizing the wave/particle. This localization \nthrough interference means that this wave packet superposition is normalizable even though the indi-\nvidual waves used are not themselves normalizable.\nThe experimental parameters that one would like to measure in order to fully characterize a wave \npacket are the position and momentum. The expectation value of the position is, formally,\n \n8x9 =\n \nL\n\u0005\n- \u0005\nx  P1x, t2dx =\n \nL\n\u0005\n- \u0005\nx 0 c1x, t20\n2 dx, \n(6.55)\nx\nRe\t\u03a8\u0007x\b\n2\u0003x\nx\nP\u0007x\b\n2\u0003x\n(a)\n(b)\nFIGURE 6.8 Gaussian wave packet (a) wave function and (b) probability density.\n\n6.2 Wave Packets \n175\nbut it can also be obtained by inspection of the Gaussian probability density [compare Eq. (6.53) with \nEq. (6.43)]:\n \n8x9 =  p0\nm\n t. \n(6.56)\nThis result again shows that the wave packet moves with the group velocity p0>m.\nThe expectation value of the momentum can be calculated either with a spatial integral\n \n8p9 =\n \nL\n\u0005\n- \u0005\nc*1x, t2 pn  \n c1x, t2dx \n(6.57)\nor a momentum integral\n \n8p9 =\n \nL\n\u0005\n- \u0005\np P1p, t2dp =\n \nL\n\u0005\n- \u0005\np 0 f1p, t20\n2 dp. \n(6.58)\nEither way, we get the result found by inspection previously in Eq. (6.47):\n \n8p9 = p0. \n(6.59)\nThe uncertainties of pos",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 195
  },
  {
    "child_id": "9bd3e642-db1b-4c50-8517-01dd97f86553",
    "parent_id": "1131087c-ba59-4502-9500-0c8d81834895",
    "text": "ity [compare Eq. (6.53) with \nEq. (6.43)]:\n \n8x9 =  p0\nm\n t. \n(6.56)\nThis result again shows that the wave packet moves with the group velocity p0>m.\nThe expectation value of the momentum can be calculated either with a spatial integral\n \n8p9 =\n \nL\n\u0005\n- \u0005\nc*1x, t2 pn  \n c1x, t2dx \n(6.57)\nor a momentum integral\n \n8p9 =\n \nL\n\u0005\n- \u0005\np P1p, t2dp =\n \nL\n\u0005\n- \u0005\np 0 f1p, t20\n2 dp. \n(6.58)\nEither way, we get the result found by inspection previously in Eq. (6.47):\n \n8p9 = p0. \n(6.59)\nThe uncertainties of position and momentum are (again by inspection)\n \n \u0006x = a\u000f =\nU\n2b\n B\n1 + a2b2t\nm U b\n2\n \n \n \u0006p = b.\n \n \n(6.60)\nThe wave packet momentum width remains constant, which is consistent with the conservation of \nmomentum. The position width grows in time because the different momentum components used to \nconstruct the wave packet all move with different phase velocities. The spatial spreading of the quan-\ntum mechanical wave packet agrees with our classical ideas about waves. It could be considered analo-\ngous to a short laser pulse propagating through glass with dispersion in the index of refraction such \nthat different colors in the pulse travel at different speeds. However, the wave packet spreading is not \nwhat we expect for a classical particle, and we have uncovered one of the counterintuitive realities of \nthe quantum world\u2014quantum particles do not stay intact.\nAs we did for the discrete wave packet, we visualize the motion of the continuous Gaussian wave \npacket with frames of an animation in Fig. 6.9. Again, we note that the carrier wave moves at the phase \nvelocity, which in this case is half of the group velocity of the envelope motion. From previous study \nof optics or waves, you may recall that the formal de\ufb01nitions of the phase and group velocities that \nwork for any wave packet are\n \n vphase = v\nk\n \n \n vgroup = dv\ndk `\nk0\n, \n \n(6.61)\nwhere the derivative in the group velocity is evaluated at the peak of the distribution of wave vector \nstates comprising the group. Applying these wave relations to the quantum mechanical free particle, \nwe \ufb01nd that the phase velocity of the wave is\n \nvphase = v\nk = U v\nUk = E\np =\np2>2m\np\n=\np\n2m = vclassical\n2\n, \n(6.62)\n\n176 \nUnbound States\nwhich is half the classical particle velocity. The group velocity is\n \nvgroup = dv\ndk `\nk0\n=\nd1U v2\nd1Uk2 `\nk0\n= dE\ndp `\np0\n=\nd1 p2>2m2\ndp\n`\np0\n= p0\nm = vclassical, \n(6.63)\nwhich is equal to the classical particle velocity. Both results agree with the results we obtained by \ninspection of the Gaussian wave packet for a free particle.\n6.3 \u0002 UNCERTAINTY PRINCIPLE\nThe Fourier connection between position space and momentum space is also important for under-\nstanding the Heisenberg uncertainty principle as it applies to position and momentum. We learned \nin Chapter 2 that spin projection measurements along different axes are incompatible, meaning that \nwe cannot simultaneously measure both observables. We saw that, in general, two observables cannot \nbe measured simultaneously if they do ",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 195
  },
  {
    "child_id": "4732b362-71f8-4534-beb1-e46379a8730f",
    "parent_id": "1131087c-ba59-4502-9500-0c8d81834895",
    "text": "Gaussian wave packet for a free particle.\n6.3 \u0002 UNCERTAINTY PRINCIPLE\nThe Fourier connection between position space and momentum space is also important for under-\nstanding the Heisenberg uncertainty principle as it applies to position and momentum. We learned \nin Chapter 2 that spin projection measurements along different axes are incompatible, meaning that \nwe cannot simultaneously measure both observables. We saw that, in general, two observables cannot \nbe measured simultaneously if they do not commute. We expressed this incompatibility in terms of the \nproduct of the measurement uncertainties of the two observables\n \n\u0006A\u0006B \u00da 1\n2 083A, B49 0 , \n(6.64)\nwhere the uncertainty is de\ufb01ned as the standard deviation\n \n\u0006A = 481A - 8A9229 = 48A29 - 8A92. \n(6.65)\nWe can now ask whether position and momentum measurements are compatible. Because we \nknow how to represent the position and momentum operators, we can calculate their commutator to \nanswer this question. The answer is that position and momentum do not commute (Problem 6.6). Their \ncommutator is\n \n3xn,  pn4 = i U. \n(6.66)\nFIGURE 6.9 Gaussian wave packet animation with time increasing from top to bottom. \nOpen circles identify a point of constant phase, which moves at the phase velocity. Filled \ncircles identify the peak of the envelope, which moves at the group velocity.",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 195
  },
  {
    "child_id": "b0c71f9a-32d2-42fc-93d9-f06640fbdc75",
    "parent_id": "4babfbd8-8afc-4a6f-98c5-2bfd231d2186",
    "text": "6.3 Uncertainty Principle \n177\nThus, the Heisenberg uncertainty principle as applied to position and momentum is\n \n\u0006x\u0006p \u00da U\n2  . \n(6.67)\nThis condition limits the product of the uncertainties of position and momentum to a minimum value. \nThe Heisenberg uncertainty principle represents a tradeoff between our knowledge of position and \nour knowledge of momentum. The Fourier connection between position and momentum helps us to \nunderstand this limitation.\nConsider the Fourier wave packet constructed from discrete momentum components. The uncer-\ntainty in momentum \u0006p is approximately the spacing \u0010p of the side modes from the central mode, as \nshown in the momentum distribution of Fig. 6.3. We estimate the uncertainty in position \u0006x as the \nseparation \u0010x of the two destructive interference minima from the central maximum of the correspond-\ning spatial wave function in Fig. 6.4. The minima are located where the phases of the side mode waves \nare p out of phase with the central sinusoid. These phases are determined by the arguments of the \nei pj x>U terms in Eq. (6.32). If we assume that the wave packet maximum, where the three waves are in \nphase, is at x = 0, then the destructive interference minimum on the right is at x = dx, as indicated in \nFig. 6.4. To calculate \u0010x, set the phase difference between the upper side mode 1 p = p0 + dp2 and \nthe central mode 1p = p02 equal to p and solve:\n \n 1p0 + dp2dx\nU\n- p0dx\nU\n= p  \n \n dpdx\nU\n= p. \n \n(6.68)\nThe uncertainty product for this discrete wave packet is approximately\n \n\u0006x\u0006p \u0003 pU. \n(6.69)\nHence, there is an inverse relationship between the width \u0006x of the position distribution and the \nwidth \u0006p of the momentum distribution. A wave packet that is well localized in space 1small \u0006x2 \nrequires a broad distribution \u0006p of momentum states, while a broad spatial distribution requires a \nnarrow momentum distribution. While this wave packet of discrete momentum components (i.e., a \nFourier series) does not strictly obey Eq. (6.69) because the \u201clocalization\u201d is repeated out to in\ufb01nity, \nthe inverse relation between the position and momentum widths is a hallmark of Fourier transforms of \ncontinuous distributions.\nWe learned in the last section that a Gaussian momentum distribution leads to a Gaussian posi-\ntion distribution because the Fourier transform of a Gaussian function is itself a Gaussian function. In \nFig. 6.10 we plot these Fourier transform pairs for a range of widths; the inverse relation between the \nposition and momentum spaces is graphically evident. Using the position and momentum uncertain-\nties in Eq. (6.60), we calculate the uncertainty product of a Gaussian wave packet:\n \n\u0006x\u0006p = U\n2\n D1 + a2b2t\nm U b\n2\n. \n(6.70)\nAt time t = 0 the Gaussian wave packet obeys the equality of the Heisenberg uncertainty relation \n\u0006x\u0006p = U>2. For this reason, a Gaussian wave function 1at t = 02 is a minimum uncertainty state. \nAs the wave packet evolves in time, it broadens in position space and the uncertainty product ",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 201
  },
  {
    "child_id": "7f1811ca-5869-4772-b692-fb46ebccd5a3",
    "parent_id": "4babfbd8-8afc-4a6f-98c5-2bfd231d2186",
    "text": "momentum spaces is graphically evident. Using the position and momentum uncertain-\nties in Eq. (6.60), we calculate the uncertainty product of a Gaussian wave packet:\n \n\u0006x\u0006p = U\n2\n D1 + a2b2t\nm U b\n2\n. \n(6.70)\nAt time t = 0 the Gaussian wave packet obeys the equality of the Heisenberg uncertainty relation \n\u0006x\u0006p = U>2. For this reason, a Gaussian wave function 1at t = 02 is a minimum uncertainty state. \nAs the wave packet evolves in time, it broadens in position space and the uncertainty product increases \n(Problem 6.12).",
    "source_file": "David H McIntyre_ Corinne A Manogue_ Janet Tate_ Oregon State Un - Quantum mechanics _ a paradigms approach (2012, Pearson ).pdf",
    "page_number": 201
  },
  {
    "child_id": "400270f9-a5e6-460d-9885-2be9308e0949",
    "parent_id": "5a0dfd32-e1b2-4966-8487-f3d91c562a9b",
    "text": "Sterman \nI\n1\n \nISBN : 007238915X \nTITLE: BUSINESS DYNAMICS : SYSTEMS THINKING \nI \n1 \nt \nRIAL : \n291000 \nCLASS: BUSINESS \nEXHIB :\n\nBusiness Dynamics \nSystems Thinking and \nModeling for a Complex World \nJohn D. Sterman \nMassachusetts Institute of Technology \nSloan School of Management \nBoston Burr Ridge, IL Dubuque, IA Madison, WI New York San Francisco St. Louis \nBangkok Bogota Caracas Lisbon London Madrid \nMexico City Milan New Delhi Seoul Singapore Sydney Taipei Toronto\n\nMcGraw-Hill Higher Education \nA Division of f i e  McGraw-Hill Companies \nBUSINESS DYNAMICS \nSYSTEMS THINKING AND MOOELING \nFOR A COMPLEX WORLD \nCopyright 0 \n2000 by The McGraw-Hill Companies, Inc. AU rights reserved. Printcd in the United ' \nStates of America. Except as permitted under the United States Copyright Act of 1976, no part of \nthis publication may be reproduced or dismbuted in any form or by m y  means, or stored in a \ndatabase or retrieval system, without the prior written permission of the publisher. \nThis book is printed on acid-free paper. \n.h \n4 5 6 7 8 9 0 KGPiKGP 0 9 8 7 6 5 4 3 2 \nISBN 0-07-231135-5 \nPublisher: Jeffrey J. Shelsfud \nSenior sponsoring editor: Scott Isenberg \nMarketing manager: Zina Cra3 \nSenior project manager: Gladys True \nSenior production supervisor: Lori Koetters \nFreelance design coordinator: A4av L. Christianson \nFreelance cover designer: The Wsrrul \nCover image: 0 \nSonia Delaumy/L & M Services, Amsterdaflute Gulleo, LondodArt Resource, NY \nCompositor: GAChdianapolis \nTypeface: 11/13 Ernes Roman \nPrinter: Quebecor Printing Book Group/Kingsport \nLibrary of Congress Cataloging-in-Publication Data \nSterman, John. \nBusiness dynamics : systems thinking and modeling for a complex world I John D. Sterman. \nIncludes hibliographical references and index. \nISBN 0-07-231135-5 (alk. paper) \n1. Indusmal management. \n2. System theory. 3. Management information systems. I. \np. cm. \nTitle. \nHD30.2.S7835 2000 \n658.4'038'011Ldc21 \n99-056030 \nhttp://www.mhhe.com\n\nABOUT THE AUTHOR \nJohn D. Sterman is J. Spencer Standish Professor of Management at the Sloan \nSchool of Management of the Massachusetts Institute of Technology and Director \nof MIT\u2019s System Dynamics Group. His research centers on the development of \npractical methods for systems thinking and dynamic modeling of complex sys- \ntems, with applications to organizational learning and change, operations manage- \nment, corporate strategy, and nonlinear dynamics in a wide range of systems, from \nsupply chains to scientific revolutions. He has pioneered the development of man- \nagement flight simulators of corporate and economic systems. These flight simu- \nlators are used in research to understand and improve managerial decision making \nin complex dynamic systems; more importantly, they are now widely used by cor- \nporations and universities around the world for teaching, problem solving, and pol- \nicy design. Professor Sterman discovered system dynamics modeling in high \nschool, studied it as an undergra",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 1
  },
  {
    "child_id": "90c0bf0b-afd7-4198-9e74-08de1fbc5476",
    "parent_id": "5a0dfd32-e1b2-4966-8487-f3d91c562a9b",
    "text": "ientific revolutions. He has pioneered the development of man- \nagement flight simulators of corporate and economic systems. These flight simu- \nlators are used in research to understand and improve managerial decision making \nin complex dynamic systems; more importantly, they are now widely used by cor- \nporations and universities around the world for teaching, problem solving, and pol- \nicy design. Professor Sterman discovered system dynamics modeling in high \nschool, studied it as an undergraduate at Dartmouth College, and received his PhD \nfrom MIT. He has been awarded the Jay W. Forrester Prize, given for the best pub- \nlished work in the field of system dynamics over the prior five years, and has four \ntimes won awards for teaching excellence from the students of the Sloan School. \nvi\n\nPreface \nAccelerating economic, technological, social, and environmental change challenge \nmanagers and policy makers to learn at increasing rates, while at the same time the \ncomplexity of the systems in which we live is growing. Many of the problems we \nnow face arise as unanticipated side effects of our own past actions. All too often \nthe policies we implement to solve important problems fail, make the problem \nworse, or create new problems. \nEffective decision making and learning in a world of growing dynamic com- \nplexity requires us to become systems thinkers-to expand the boundaries of our \nmental models and develop tools to understand how the structure of complex sys- \ntems creates their behavior. \nThis book introduces you to system dynamics modeling for the analysis of pol- \nicy and strategy, with a focus on business and public policy applications. System \ndynamics is a perspective and set of conceptual tools that enable us to understand \nthe structure and dynamics of complex systems. System dynamics is also a rigor- \nous modeling method that enables us to build formal computer simulations of com- \nplex systems and use them to design more effective policies and organizations. \nTogether, these tools allow us to create management flight simulators-micro- \nworlds where space and time can be compressed and slowed so we can experience \nthe long-term side effects of decisions, speed learning, develop our understanding \nof complex systems, and design structures and strategies for greater success. \nThe field of system dynamics is thriving. Over the past decade, many top com- \npanies, consulting firms, and governmental organizations have used system dy- \nnamics to address critical issues. More innovative universities and business \nschools are teaching system dynamics and finding enthusiastic and growing en- \nrollments. Hundreds of primary and secondary schools, from kindergarten to high \nschool, are integrating systems thinking, system dynamics, and computer simula- \ntion into their curricula. Tools and methods for system dynamics modeling, the li- \nbrary of successful applications, and insights into the effective use of the tools with \nexecutives and organi",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 1
  },
  {
    "child_id": "e33b152b-d26e-4ca9-a64b-4cac0ffd8541",
    "parent_id": "5a0dfd32-e1b2-4966-8487-f3d91c562a9b",
    "text": "ress critical issues. More innovative universities and business \nschools are teaching system dynamics and finding enthusiastic and growing en- \nrollments. Hundreds of primary and secondary schools, from kindergarten to high \nschool, are integrating systems thinking, system dynamics, and computer simula- \ntion into their curricula. Tools and methods for system dynamics modeling, the li- \nbrary of successful applications, and insights into the effective use of the tools with \nexecutives and organizations are all expanding rapidly. \nvii\n\nviii \nPreface \nFEATURES AND CONTENT \nUniversity and graduate-level texts, particularly those focused on business and \npublic policy applications, have not kept pace with the growth of the field. This \nbook is designed to provide thorough coverage of the field of system dynamics to- \nday, by examining \nSystems thinking and the system dynamics worldview; \nTools for systems thinking, including methods to elicit and map the \nstructure of complex systems and relate those structures to their dynamics; \nTools for modeling and simulation of complex systems; \nProcedures for testing and improving models; \nGuidelines for working with client teams and successful implementation. \nYou will learn about the dynamics of complex systems, including the structures \nthat create growth, goal-seeking behavior, oscillation and instability, S-shaped \ngrowth, overshoot and collapse, path dependence, and other nonlinear dynamics. \nExamples and applications include \nCorporate growth and stagnation, \nThe diffusion of new technologies, \nThe dynamics of infectious disease such as HIV/AIDS, \nBusiness cycles, \nSpeculative bubbles, \nThe use and reliability of forecasts, \nThe design of supply chains in business and other organizations, \nService quality management, \nTransportation policy and traffic congestion, \nProject management and product development, \nand many others. \nThe goal of systems thinking and system dynamics modeling is to improve our \nunderstanding of the ways in which an organization\u2019s performance is related to its \ninternal structure and operating policies, including those of customers, competi- \ntors, and suppliers and then to use that understanding to design high leverage poli- \ncies for success. To do so this book utilizes \nProcess Points that provide practical advice for the successful application \nof the tools in real organizations. \nCase studies of System Dynamics in Action that present successful \napplications ranging from global warming and the war on drugs to \nreengineering the supply chain of a major computer firm, marketing \nstrategy in the automobile industry, and process improvement in the \npetrochemicals industry. \nSystem dynamics is not a spectator sport. Developing systems thinking and mod- \neling skills requires the active participation of you, the reader, via\n\nPreface \nix \nChallenges. The challenges, placed throughout the text, give you practice \nwith the tools and techniques presented in the book and will stimulate ",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 1
  },
  {
    "child_id": "205ce0d3-1b12-4002-9d61-05e4e1d66068",
    "parent_id": "5a0dfd32-e1b2-4966-8487-f3d91c562a9b",
    "text": " and the war on drugs to \nreengineering the supply chain of a major computer firm, marketing \nstrategy in the automobile industry, and process improvement in the \npetrochemicals industry. \nSystem dynamics is not a spectator sport. Developing systems thinking and mod- \neling skills requires the active participation of you, the reader, via\n\nPreface \nix \nChallenges. The challenges, placed throughout the text, give you practice \nwith the tools and techniques presented in the book and will stimulate your \noriginal thinking about important real world issues. The challenges range \nfrom simple thought experiments to full-scale modeling projects. \nSimulation software and models. The accompanying CD-ROM and web \nsite (http://www.mhhe.com/sterman) \ninclude all the models developed in \nthe text along with state-of-the-art simulation software to run them. There \nare several excellent software packages designed to support system \ndynamics modeling. These include ithink, Powersim, and Vensim. The CD \nand website include the models for the text in all three software formats. \nThe disk also includes fully functional versions of the ithink, Powersim, and \nVensim software so you can run the models using any of these packages \nwithout having to purchase any additional software. \nAdditionally, the Instructor\u2019s Manual and instructor\u2019s section of the \nweb site include suggested solutions for the challenges, additional \nassignments, Powerpoint files with the diagrams and figures from the text \nsuitable for transparencies, suggested course sequences and syllabi, and \nother materials. \nINTENDED AUDIENCE \nThe book can be used as a text in courses on systems thinking, simulation model- \ning, complexity, strategic thinking, operations, and industrial engineering, among \nothers. It can be used in full or half-semester courses, executive education, and \nself-study. The book also serves as a reference for managers, engineers, consul- \ntants, and others interested in developing their systems thinking skills or using sys- \ntem dynamics in their organizations. \nA NOTE ON MATHEMATICS \nSystem dynamics is grounded in control theory and the modern theory of nonlin- \near dynamics. There is an elegant and rigorous mathematical foundation for the \ntheory and models we develop. System dynamics is also designed to be a practical \ntool that policy makers can use to help them solve the pressing problems they con- \nfront in their organizations. Most managers have not studied nonlinear differential \nequations or even calculus, or have forgotten it if they did. To be useful, system dy- \nnamics modeling must be accessible to the widest range of students and practicing \nmanagers without becoming a vague set of qualitative tools and unreliable gener- \nalizations. That tension is compounded by the diversity of backgrounds within the \ncommunity of managers, students, and scholars interested in system dynamics, \nbackgrounds ranging from people with no mathematics education beyond high \nschool to thos",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 1
  },
  {
    "child_id": "d0e3ddbb-0e01-4d02-8488-9ce7e234dd3b",
    "parent_id": "5a0dfd32-e1b2-4966-8487-f3d91c562a9b",
    "text": "ations or even calculus, or have forgotten it if they did. To be useful, system dy- \nnamics modeling must be accessible to the widest range of students and practicing \nmanagers without becoming a vague set of qualitative tools and unreliable gener- \nalizations. That tension is compounded by the diversity of backgrounds within the \ncommunity of managers, students, and scholars interested in system dynamics, \nbackgrounds ranging from people with no mathematics education beyond high \nschool to those with doctorates in physics.",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 1
  },
  {
    "child_id": "5eb53135-0b89-4f72-8d39-b2a05e2af834",
    "parent_id": "e55f9309-a76e-48be-bdec-6d3b09fa2702",
    "text": "X \nPreface \nIF YOU DON\u2019T HAVE A STRONG MATHEMATICS BACKGROUND, \nFEAR NOT \nThis book presents system dynamics with a minimum of mathematical formalism. \nThe goal is to develop your intuition and conceptual understanding, without sacri- \nficing the rigor of the scientific method. You do not need calculus or differential \nequations to understand the material. Indeed, the concepts are presented using only \ntext, graphs, and basic algebra. Mathematical details and references to more ad- \nvanced material are set aside in separate sections and footnotes. Higher mathemat- \nics, though useful, is not as important as the critical thinking skills developed here. \nIF YOU HAVE A STRONG MATHEMATICS BACKGROUND, FEAR NOT \nRealistic and useful models are almost always of such complexity and nonlinearity \nthat there are no known analytic solutions, and many of the mathematical tools you \nhave studied have limited applicability. This book will help you use your strong \ntechnical background to develop your intuition and conceptual understanding of \ncomplexity and dynamics. Modeling human behavior differs from modeling phy s- \nical systems in engineering and the sciences. We cannot put managers up on the lab \nbench and run experiments to determine their transfer function or frequency re- \nsponse. We believe all electrons follow the same laws of physics, but we cannot \nassume all people behave in the same way. Besides a solid grounding in the mathe- \nmatics of dynamic systems, modeling human systems requires us to develop our \nknowledge of psychology, decision malung, and organizational behavior. Finally, \nmathematical analysis, while necessary, is far from sufficient for successful sys- \ntems thinlung and modeling. For your work to have impact in the real world you \nmust learn how to develop and implement models of human behavior in organiza- \ntions, with all their ambiguity, time pressure, personalities, and politics. Through- \nout the book I have sought to illustrate how the technical tools and mathematical \nconcepts you may have studied in the sciences or engineering can be applied to the \nmessy world of the policy maker. \n~ \nFEEDBACK \nI welcome your comments, criticisms, and suggestions. Suggestions for additional \nexamples, cases, theory, models, flight simulators, and so on, to make the book \nmore relevant and useful to you are especially invited. I will update the website \nto incorporate user feedback and new materials. Email comments to <BusDyn@ \nmit .edu > . \nACKNOWLEDGMENTS \nThis work benefited immensely from the advice, criticism, and encouragement of \nmany colleagues, students, and friends. I owe an immeasurable debt to my first \nsystem dynamics teachers, Dana Meadows, Dennis Meadows, and Jay Forrester, \nfor their integrity, high standards, and passionate commitment. I\u2019m particularly \nindebted to the exceptional students of the MIT Sloan School of Management. \nThey constantly challenge me to make the discipline of system dynamics relevant,\n\nPreface \nxi \nu",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 9
  },
  {
    "child_id": "fb03946f-2967-4ced-9483-8714cabc7059",
    "parent_id": "e55f9309-a76e-48be-bdec-6d3b09fa2702",
    "text": "DGMENTS \nThis work benefited immensely from the advice, criticism, and encouragement of \nmany colleagues, students, and friends. I owe an immeasurable debt to my first \nsystem dynamics teachers, Dana Meadows, Dennis Meadows, and Jay Forrester, \nfor their integrity, high standards, and passionate commitment. I\u2019m particularly \nindebted to the exceptional students of the MIT Sloan School of Management. \nThey constantly challenge me to make the discipline of system dynamics relevant,\n\nPreface \nxi \nuseful, and exciting; I hope they\u2019ve learned as much from me as I\u2019ve learned from \nthem. In addition, I thank my colleagues at the Sloan School and in the system \ndynamics community around the world, who helped by providing data and exam- \nples, reviewing the draft, testing early versions in their courses, and in countless \nother ways. This group includes (but is not limited to) the following folks and \ninstitutions: \nTarek Abdel-Hamid (Naval Postgraduate School); David Andersen, George \nRichardson (SUNY Albany); Ed Anderson (Univ. of Texas); Carlos Ariza, Sharon \nEls, Ken Cooper, Jim Lyneis, Hank Taylor (Pugh-Roberts Associates); George \nBackus (Policy Assessment Corporation); Bent Bakken (Norwegian Defense Re- \nsearch Establishment); Yaman Barlas (Bogazici University, Istanbul); Michael \nBean (Powersim Corp.); Eric Beinhocker, Damon Beyer, Andrew Doman, Usman \nGhani, Maurice Glucksman, Paul Langley, Norman Marshall (McKinsey and \nCompany); Laura Black, John Carroll, Vanessa Colella, Ernst Diehl, Steve Ep- \npinger, Charlie Fine, Mila Getmansky, Paulo Goncalves, Janet Gould Wilkinson, \nJim Hines, Nan Lux, Brad Morrison, Tim Nugent, Nelson Repenning, Ed Roberts, \nScott Rockart, George Roth, Ed Schein, Peter Senge (MIT); Allen and Jane \nBoorstein; Steve Cavaleri (Central Connecticut State Univ.); Geoff Coyle (Royal \nMilitary College of Science, UK, retired); Brian Dangerfield (Univ. of Salford); \nPi1 Davidsen (Univ. of Bergen); Jim Doyle, Mike Radzicki, Khalid Saeed \n(Worcester Polytechnic Institute); Bob Eberlein, Tom Fiddaman, Dan Goldner, \nDavid Peterson, Laura Peterson (Ventana Systems); David Foley and Judy Berk; \nAndy Ford (Washington State Univ.); David Ford (Texas A&M University); \nNathan Forrester (A. T. Kearney); Rich Goldbach (Metro Machine Corp.); Chris- \ntian Haxholdt, Heather Hazard (Copenhagen Business School); Jack Homer \n(Homer Consulting); Jody House (Oregon Graduate Institute); Bill Isaacs (Dia- \nlogos); Sam Israelit (Arthur Andersen); Nitin Joglekar (Boston Univ. School \nof Management); Drew Jones (Sustainability Institute); Christian Kampmann, \nErik Mosekilde (Technical Univ. of Denmark); Daniel Kim, Virginia Wiley \n(Pegasus Communications); Craig Kirkwood (Arizona State Univ.); Elizabeth \nKrahmer Keating (Northwestern Univ.); Don Kleinmuntz (Univ. of Illinois, \nUrbana-Champaign); David Kreutzer (GKA, Inc.); Robert Landel (Darden School \nof Business, Univ. of Virginia); David Lane (London School of Economics); Erik \nLarsen (City Universit",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 9
  },
  {
    "child_id": "95f38e91-b95f-40ea-98ad-c92a65a919ee",
    "parent_id": "e55f9309-a76e-48be-bdec-6d3b09fa2702",
    "text": " (Boston Univ. School \nof Management); Drew Jones (Sustainability Institute); Christian Kampmann, \nErik Mosekilde (Technical Univ. of Denmark); Daniel Kim, Virginia Wiley \n(Pegasus Communications); Craig Kirkwood (Arizona State Univ.); Elizabeth \nKrahmer Keating (Northwestern Univ.); Don Kleinmuntz (Univ. of Illinois, \nUrbana-Champaign); David Kreutzer (GKA, Inc.); Robert Landel (Darden School \nof Business, Univ. of Virginia); David Lane (London School of Economics); Erik \nLarsen (City University, London); Winston J. Ledet, Winston P. Ledet (The Man- \nufacturing Game, Inc.); Ralph Levine (Michigan State Univ.); Angela Lipinski \n(Society for Organizational Learning); Martin GroBmann, Frank Maier, Peter \nMilling (Univ. of Mannheim, Germany); Ali Mashayekhi (Sharif Univ. of Tech- \nnology, Teheran); Nathaniel Mass (GenCorp); Paul Monus (BP/Amoco), John \nMorecroft, Ann van Ackere, Kim Warren (London Business School); Erling \nMoxnes (Norwegian School of Economics and Business Administration); Rogelio \nOliva (Harvard Business School); Mark Paich (Colorado College); Steve Peterson, \nBarry Richmond (High Performance Systems); Greg Petsch (Compaq Computer); \nNick Pudar (General Motors); Jack Pugh, Julia Pugh, Roberta Spencer (System \nDynamics Society), JQrgen Randers (World Wildlife Fund International); Nancy \nRoberts (Leslie College); Jenny Rudolph (Boston College); Jorge Rufat-Latre \n(Strategos); Anjali Sastry, Marshall van Alstyne (University of Michigan); Bob \nStearns; Susan Sterman; Jim Thompson (Global Prospectus, LLC); John Voyer\n\nxii \nPreface \n(Univ. of Southern Maine); Lyle Wallis (Decisio, Inc.); Jim Waters (Waters Busi- \nness Systems); Jason Wittenberg (Harvard Univ.); Eric Wolstenholme (Leeds Busi- \nness School, UK); Pave1 Zamudio Ramirez (Monitor Company); the Copenhagen \nBusiness School, The International Network of Resource Information Centers \n(aka the Balaton Group), McKinsey and Company, the Norwegian School of \nManagement, Pugh-Roberts Associates, the Society for Organizational Learning, \nthe Technical University of Denmark, and, of course, the MIT Sloan School of \nManagement. \nSpecial thanks to High Performance Systems, Powersim, SA, and Ventana \nSystems-and their great people-for providing their simulation software and \ntranslations of the models for the CD and website. \nThe team at IrwidMcGraw-Hill deserves special mention for their enthusiasm, \npatience, and editorial help, particularly Scott Isenberg, Carol Rose, Jeff Shelstad, \nand Gladys True. \nCara Barber and Kelley Donovan provided important secretarial support. \nKathy Sullivan went beyond the call of duty on library research, data collec- \nFinally, the love and support of my family have been constant and essential. \ntion, editorial changes, and graphics. \nThanks, Cindy, David, and Sarah.\n\nTable of Contents \nPreface vii \nPART I PERSPECTIVE AND PROCESS 1 \n1 Learning in and about Complex Systems 3 \n1.1 \nIntroduction 3 \n1.1.1 \n1.1.2 \nCauses of Policy Resistance \n10 \n1.1.3 \nFeedback",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 9
  },
  {
    "child_id": "4332fb88-ce0a-4984-9e86-bbe4b1714638",
    "parent_id": "e55f9309-a76e-48be-bdec-6d3b09fa2702",
    "text": "ue. \nCara Barber and Kelley Donovan provided important secretarial support. \nKathy Sullivan went beyond the call of duty on library research, data collec- \nFinally, the love and support of my family have been constant and essential. \ntion, editorial changes, and graphics. \nThanks, Cindy, David, and Sarah.\n\nTable of Contents \nPreface vii \nPART I PERSPECTIVE AND PROCESS 1 \n1 Learning in and about Complex Systems 3 \n1.1 \nIntroduction 3 \n1.1.1 \n1.1.2 \nCauses of Policy Resistance \n10 \n1.1.3 \nFeedback \n12 \n1.1.4 \nProcess Point: The Meaning of Feedback \n14 \nChallenge: Dynamics of Multiple-Loop Systems \nPolicy Resistance, the Law of Unintended Consequences, \nand the Counterintuitive Behavior of Social Systems \n5 \n14 \n1.2 \nLearning Is a Feedback Process 14 \n1.3 \nBarriers to Learning 19 \n1.3.1 \nDynamic Complexity 21 \n1.3.2 \nLimited Information 23 \n1.3.3 \nConfounding Variables and Ambiguity 25 \n1.3.4 \nBounded Rationality and the Misperceptions \nof Feedback 26 \n1.3.5 \nFlawed Cognitive Maps 28 \n1.3.6 \nErroneous Inferences about Dynamics 29 \n1.3.7 \nUnscientific Reasoning: Judgmental Errors \nandBiases 30 \nChallenge: Hypothesis Testing 30 \n1.3.8 \nDefensive Routines and Interpersonal Impediments \nto Learning \n32 \n1.3.9 \nImplementation Failure 33 \n1.4.1 \nImproving the Learning Process: Virtues \nof Virtual Worlds 34 \n1.4.2 \nPitfalls of Virtual Worlds 35 \n1.4.3 \nWhy Simulation Is Essential \n37 \n1.4 \nRequirements for Successful Learning in Complex Systems 33 \n1.5 \nSummary 39 \nxiii\n\nxiv \nContents \n2 System Dynamics in Action 41 \n2.1 \n2.2 \n2.3 \n2.4 \n2.5 \nApplications of System Dynamics 41 \nAutomobile Leasing Strategy: Gone Today, Here Tomorrow \n2.2.1 \nDynamic Hypothesis 44 \n2.2.2 \nElaborating the Model 48 \n2.2.3 \nPolicy Analysis 5 1 \n2.2.4 \nImpact and Follow-up 54 \nOn Time and Under Budget: The Dynamics \nof Project Management 55 \n2.3.1 \nThe Claim 56 \n2.3.2 \nInitial Model Development \n57 \n2.3.3 \nDynamic Hypothesis 58 \n2.3.4 \nThe Modeling Process 61 \n2.3.5 \nContinuing Impact 64 \nPlaying the Maintenance Game 66 \n2.4.1 \nDynamic Hypothesis \n67 \n2.4.2 \nThe Implementation Challenge 74 \n2.4.3 \nResults 76 \n2.4.4 \nTransferring the Learning: The Lima Experience 77 \n42 \nSummary: Principles for Successful Use of System Dynamics 79 \n3.1 \nThe Purpose of Modeling: Managers as Organization Designers 84 \n3.2 \nThe Client and the Modeler 84 \n3.3 \nSteps of the Modeling Process 85 \n3.4 \nModeling Is Iterative 87 \n3.5 \nOverview of the Modeling Process 89 \n3 The Modeling Process 83 \n3.5.1 \nProblem Articulation: The Importance of Purpose \n89 \n3.5.2 \nFormulating a Dynamic Hypothesis \n94 \n3.5.3 \nFormulating a Simulation Model \n102 \n3.5.4 \nTesting 103 \n3.5.5 \nPolicy Design and Evaluation \n103 \n4 Structure and Behavior of Dynamic Systems 107 \n3.6 \nSummary \n104 \n4.1 \n4.2 \n4.3 \nFundamental Modes of Dynamic Behavior \n4.1.1 \nExponential Growth 108 \n4.1.2 \nGoal Seeking \n11 1 \n4.1.3 \nOscillation \n114 \n4.1.4 \nProcess Point \n116 \nChallenge: Identifying Feedback Structure \nfrom System Behavior \n117 \nInterac",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 9
  },
  {
    "child_id": "d3d43b0a-dfea-4a8b-99ba-7698ac59d9b2",
    "parent_id": "e55f9309-a76e-48be-bdec-6d3b09fa2702",
    "text": "ulation: The Importance of Purpose \n89 \n3.5.2 \nFormulating a Dynamic Hypothesis \n94 \n3.5.3 \nFormulating a Simulation Model \n102 \n3.5.4 \nTesting 103 \n3.5.5 \nPolicy Design and Evaluation \n103 \n4 Structure and Behavior of Dynamic Systems 107 \n3.6 \nSummary \n104 \n4.1 \n4.2 \n4.3 \nFundamental Modes of Dynamic Behavior \n4.1.1 \nExponential Growth 108 \n4.1.2 \nGoal Seeking \n11 1 \n4.1.3 \nOscillation \n114 \n4.1.4 \nProcess Point \n116 \nChallenge: Identifying Feedback Structure \nfrom System Behavior \n117 \nInteractions of the Fundamental Modes \n4.2.1 \nS-Shaped Growth 118 \n4.2.2 \nS-Shaped Growth with Overshoot \n121 \nChallenge: Identifying the Limits to Growth \n4.2.3 \nOvershoot and Collapse \n123 \nOther Modes of Behavior \n127 \n4.3.1 \nStasis, or Equilibrium 127 \n108 \n11 8 \n121",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 9
  },
  {
    "child_id": "fa2d2d75-0e0b-4f4a-929d-61ec932c9aec",
    "parent_id": "c5ea71b2-89fb-4c98-8821-32d73a82a586",
    "text": "Contents \nxv \n4.3.2 \nRandomness 127 \n4.3.3 \nChaos 129 \n4.4 \nSummary 133 \nPART I1 TOOLS FOR SYSTEMS THINKING 135 \n5 Causal Loop Diagrams 137 \n5.1 \n5.2 \n5.3 \n5.4 \n5.5 \n5.6 \nCausal Diagram Notation 137 \nGuidelines for Causal Loop Diagrams \n5.2.1 \nCausation versus Correlation 141 \n5.2.2 \nLabeling Link Polarity \n142 \nChallenge: Assigning Link Polarities 143 \n5.2.3 \nDetermining Loop Polarity \n143 \nChallenge: Identifying Link and Loop Polarity \nChallenge: Employee Motivation 147 \n5.2.4 \nName YourLoops 148 \n5.2.5 \nIndicate Important Delays in Causal Links \n150 \n5.2.6 \nVariable Names \n152 \n5.2.7 \nTips for Causal Loop Diagram Layout \n153 \n5.2.8 \nChoose the Right Level ofAggregation 154 \n5.2.9 \nDon\u2019t Put All the Loops into One Large Diagram \n5.2.10 \nMake the Goals of Negative Loops Explicit \n155 \n5.2.11 \nDistinguish between Actual \nProcess Point: Developing Causal Diagrams \nfrom Interview Data 157 \nChallenge: Process Improvement 158 \nConceptualization Case Study: Managing Your Workload \n5.4.1 \nProblem Definition \n159 \n5.4.2 \nIdentiJLing Key Variables 160 \n5.4.3 \nDeveloping the Reference Mode \n160 \n5.4.4 \nDeveloping the Causal Diagrams \n163 \n5.4.5 \nLimitations of the Causal Diagram \n166 \nChallenge: Policy Analysis with Causal Diagrams \nAdam Smith\u2019s Invisible Hand and the \nFeedback Structure of Markets 169 \nChallenge: The Oil Crises of the 1970s 172 \nChallenge: Speculative Bubbles 173 \nChallenge: The Thoroughbred Horse Market \n5.5.1 \nMarket Failure, Adverse Selection, \nChallenge: The Medigap Death Spiral 176 \nExplaining Policy Resistance: Traffic Congestion \n5.6.1 \nMental Models of the Traffic Problem \n178 \n5.6.2 \nCompensating Feedback: The Response \nto Decreased Congestion \n18 1 \n5.6.3 \nThe Mass Transit Death Spiral \n185 \n5.6.4 \nPolicy Analysis: The Impact of Technology 188 \n5.6.5 \nCompensating Feedback: The Source \nof Policy Resistance \n189 \n141 \n145 \n154 \nand Perceived Conditions 156 \n159 \n168 \n174 \nand the Death Spiral \n174 \n177\n\nxvi \nContents \nChallenge: Identifying the Feedback Structure \nof Policy Resistance 190 \n5.7 \nSummary \n190 \n6.1 \nStocks, Flows, and Accumulation \n191 \n6 Stocks and Flows 191 \n6.1.1 \nDiagramming Notation for Stocks and Flows \n192 \n6.1.2 \nMathematical Representation of Stocks and Flows \n193 \n6.1.3 \nThe Contribution of Stocks to Dynamics \n195 \n6.2.1 \nUnits of Measure in Stock and Flow Networks \n198 \n6.2.2 \nThe Snapshot Test 199 \nChallenge: Identifying Stocks and Flows 201 \n6.2.3 \nConservation of Material in \nStock and Flow Networks 201 \n6.2.4 \nState-Determined Systems 202 \n6.2.5 \nAuxiliary Variables 202 \n6.2.6 \nStocks Change Only through Their Rates 204 \n6.2.7 \nContinuous Time and Instantaneous Flows 206 \n6.2.8 \nContinuously Divisible versus Quantized Flows 207 \n6.2.9 \nWhich Modeling Approach Should You Use? 208 \n6.2.10 \nProcess Point: Portraying Stocks and Flows \nin Practice 209 \nWhen Should Causal Loop Diagrams Show \nStock and Flow Structure? 210 \n6.2 \nIdentifying Stocks and Flows \n197 \n6.3 \nMapping Stocks and Flows 210 \n6.3.1 \nCha",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 14
  },
  {
    "child_id": "98e8cc50-5019-4475-9227-505b46dcd029",
    "parent_id": "c5ea71b2-89fb-4c98-8821-32d73a82a586",
    "text": "\nState-Determined Systems 202 \n6.2.5 \nAuxiliary Variables 202 \n6.2.6 \nStocks Change Only through Their Rates 204 \n6.2.7 \nContinuous Time and Instantaneous Flows 206 \n6.2.8 \nContinuously Divisible versus Quantized Flows 207 \n6.2.9 \nWhich Modeling Approach Should You Use? 208 \n6.2.10 \nProcess Point: Portraying Stocks and Flows \nin Practice 209 \nWhen Should Causal Loop Diagrams Show \nStock and Flow Structure? 210 \n6.2 \nIdentifying Stocks and Flows \n197 \n6.3 \nMapping Stocks and Flows 210 \n6.3.1 \nChallenge: Adding Stock and Flow Structure \nto Causal Diagrams 2 11 \nChallenge: Linking Stock and Flow Structure with Feedback \n6.3.2 \nAggregation in Stock and Flow Mapping \n213 \nChallenge: Modifying Stock and Flow Maps \nChallenge: Disaggregation 214 \n6.3.3 \nGuidelines for Aggregation \n216 \n6.3.4 \nSystem Dynamics in Action: \n6.3.5 \nSetting the Model Boundary: \n6.3.6 \nSystem Dynamics in Action: Automobile Recycling \n225 \n212 \n213 \nModeling Large-Scale Construction Projects \n\u201cChallenging the Clouds\u2019\u2019 222 \n2 18 \n6.4 \nSummary 229 \n7.1 \nRelationship between Stocks and Flows 232 \n7 Dynamics of Stocks and Flows 231 \n7.1.1 \nStatic and Dynamic Equilibrium 232 \n7.1.2 \nCalculus without Mathematics 232 \n7.1.3 \nGraphical Integration \n234 \nChallenge: Graphical Integration 239 \n7.1.4 \nGraphical Diflerentiation 239 \nChallenge: Graphical Differentiation 24 1 \n7.2 \nSystem Dynamics in Action: Global Warming 241\n\nContents \nxvii \n7.3 \nSystem Dynamics in Action: The War on Drugs 250 \n7.4 \nSummary 262 \nDynamics of Simple Structures 263 \n7.3.1 \nThe Cocaine Epidemic after 1990 258 \n8 Closing the Loop: \n8.1 \n8.2 \n8.3 \n8.4 \n8.5 \n8.6 \nFirst-Order Systems 263 \nPositive Feedback and Exponential Growth \n8.2.1 \nAnalytic Solution for the Linear First-Order System 265 \n8.2.2 \nGraphical Solution of the Linear First-Order \nPositive Feedback System 266 \n8.2.3 \nThe Power of Positive Feedback: Doubling Times 268 \nChallenge: Paper Folding 268 \n8.2.4 \nMisperceptions of Exponential Growth 269 \n8.2.5 \nProcess Point: Overcoming Overconfidence 272 \nNegative Feedback and Exponential Decay \n8.3.1 \nTime Constants and Half-Lives \n279 \nChallenge: Goal-Seeking Behavior 281 \nMultiple-Loop Systems 282 \nNonlinear First-Order Systems: S-Shaped Growth \nChallenge: Nonlinear Birth and Death Rates \n8.5.1 \nFormal Definition of Loop Dominance \n288 \n8.5.2 \nFirst-Order Systems Cannot Oscillate 290 \nSummary 290 \n264 \n274 \n285 \n286 \nPART I11 THE DYNAMICS OF GROWTH 293 \n9 S-Shaped Growth: Epidemics, Innovation Diffusion, and the Growth of \nNew Products 295 \n9.1 \nModeling S-Shaped Growth 296 \n9.1.1 \nLogistic Growth 296 \n9.1.2 \nAnalytic Solution of the Logistic Equation 297 \n9.1.3 \nOther Common Growth Models 299 \n9.1.4 \nTesting the Logistic Model \n300 \n9.2 \nDynamics of Disease: Modeling Epidemics 300 \n9.2.1 \nA Simple Model of Infectious Disease 300 \n9.2.2 \nModeling Acute Infection: The SIR Model \n303 \n9.2.3 \nModel Behavior: The Tipping Point 305 \nChallenge: Exploring the SIR Model \n9.2.4 \nImmunization and the Eradication of S",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 14
  },
  {
    "child_id": "7ded2eb6-c769-445a-a47f-c4513129a413",
    "parent_id": "c5ea71b2-89fb-4c98-8821-32d73a82a586",
    "text": "th of \nNew Products 295 \n9.1 \nModeling S-Shaped Growth 296 \n9.1.1 \nLogistic Growth 296 \n9.1.2 \nAnalytic Solution of the Logistic Equation 297 \n9.1.3 \nOther Common Growth Models 299 \n9.1.4 \nTesting the Logistic Model \n300 \n9.2 \nDynamics of Disease: Modeling Epidemics 300 \n9.2.1 \nA Simple Model of Infectious Disease 300 \n9.2.2 \nModeling Acute Infection: The SIR Model \n303 \n9.2.3 \nModel Behavior: The Tipping Point 305 \nChallenge: Exploring the SIR Model \n9.2.4 \nImmunization and the Eradication of Smallpox 309 \nChallenge: The Efficacy of Immunization Programs \n9.2.5 \nHerd Immunity 3 12 \n9.2.6 \nMoving Past the Tipping Point: Mad Cow Disease \n314 \nChallenge: Extending the SIR Model \n9.2.7 \nModeling the HIV/AIDS Epidemic 319 \nChallenge: Modeling HIV/AIDS 321 \nModeling New Ideas and New Products \n9.3.1 \n308 \n3 SO \n3 16 \n9.3 \nInnovation Diffusion as Infection: \n323 \nThe Logistic Model of Innovation DiJj\u2019usion: \nExamples 325\n\nxviii \nContents \n9.3.2 \nProcess Point: Historical Fit and Model Validity 328 \n9.3.3 \nThe Bass Dijfusion Model \n332 \nChallenge: Phase Space of the Bass Diffusion Model 333 \n9.3.4 \nBehavior of the Bass Model \n334 \nChallenge: Critiquing the Bass Diffusion Model 334 \nChallenge: Extending the Bass Model 335 \n9.3.5 \nFad and Fashion: \nChallenge: Modeling Fads 341 \n9.3.6 \nReplacement Purchases 342 \nChallenge: Modeling the Life Cycle of Durable Products \nModeling the Abandonment of an Innovation \n339 \n345 \n9.4 \nSummary 346 \n10.1 Path Dependence 349 \nChallenge: Identifying Path Dependence 353 \n10.2 A Simple Model of Path Dependence: The Polya Process 354 \n10.2.1 \nGeneralizing the Model: Nonlinear Polya Processes 357 \n10.3 Path Dependence in the Economy: VHS versus Betamax 359 \nChallenge: Formulating a Dynamic Hypothesis \nfor the VCR Industry \n364 \n10.4.1 \nProduct Awareness 365 \n10.4.2 \nUnit Development Costs 367 \n10.4.3 \nPrice and Production Cost 368 \n10.4.4 \nNetwork Effects and Complementary Goods 370 \n10.4.5 \nProduct Differentiation 371 \n10.4.6 \nNew Product Development \n373 \n10.4.7 \nMarket Power 374 \n10.4.8 \nMergers and Acquisitions 375 \n10.4.9 \nWorkforce Quality and Loyalty \n376 \n10.4.10 The Cost of Capital 378 \n10.4.11 The Rules of the Game 380 \n10.4.12 Ambition and Aspirations 380 \n10.4.13 Creating Synergy for Corporate Growth 382 \n10 Path Dependence and Positive Feedback 349 \n10.4 Positive Feedback: The Engine of Corporate Growth 364 \n10.5 Positive Feedback, Increasing Returns, and Economic Growth 385 \n10.6 Does the Economy Lock in to Inferior Technologies? \n387 \n10.7 Limits to Lock In 389 \n10.8 Modeling Path Dependence and Standards Formation 391 \n10.8.1 \nModel Structure 392 \n10.8.2 \nModel Behavior \n396 \n10.8.3 \nPolicy Implications 402 \nChallenge: Policy Analysis 403 \nChallenge: Extending the Model 404 \n10.9 Summary 406 \nPART IV TOOLS FOR MODELING DYNAMIC SYSTEMS 407 \n11 Delays 409 \n11.1 Delays: An Introduction 409\n\nContents \nxix \nChallenge: Duration and Dynamics of Delays \n11.1.1 \nDefining Delays 4 1 1 \n11.2 Material Delays: Structure a",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 14
  },
  {
    "child_id": "e91f3bc2-4d66-4bfd-93b1-fc295690142b",
    "parent_id": "c5ea71b2-89fb-4c98-8821-32d73a82a586",
    "text": "nologies? \n387 \n10.7 Limits to Lock In 389 \n10.8 Modeling Path Dependence and Standards Formation 391 \n10.8.1 \nModel Structure 392 \n10.8.2 \nModel Behavior \n396 \n10.8.3 \nPolicy Implications 402 \nChallenge: Policy Analysis 403 \nChallenge: Extending the Model 404 \n10.9 Summary 406 \nPART IV TOOLS FOR MODELING DYNAMIC SYSTEMS 407 \n11 Delays 409 \n11.1 Delays: An Introduction 409\n\nContents \nxix \nChallenge: Duration and Dynamics of Delays \n11.1.1 \nDefining Delays 4 1 1 \n11.2 Material Delays: Structure and Behavior 412 \n11.2.1 \nWhat Is the Average Length of the Delay? 413 \n11.2.2 \n11.2.3 \nPipeline Delay 415 \n11.2.4 \nFirst-Order Material Delay 415 \n11.2.5 \nHigher-Order Material Delays 417 \n11.2.6 \nHow Much Is in the Delay? Little\u2019s Law 421 \nChallenge: Response of Material Delays to \nSteps, Ramps, and Cycles 425 \n11.3 Information Delays: Structure and Behavior 426 \n11.3.1 \nModeling Perceptions: Adaptive Expectations and \nExponential Smoothing 428 \n11.3.2 \nHigher-Order Information Delays 432 \nChallenge: Response of Delays to Changing Delay Times \n11.4.1 \nNonlinear Adjustment Times: \n409 \nWhat Is the Distribution of the Output around the Average \nDelay Time? 413 \n11.4 Response to Variable Delay Times 434 \n435 \nModeling Ratchet Effects 436 \n11.5 Estimating the Duration and Distribution of Delays 437 \n11.5.1 \nEstimating Delays When Numerical Data \nAre Available 437 \n11.5.2 \nEstimating Delays When Numerical Data \nAre Not Available 445 \n11.5.3 \nProcess Point: Walk the Line 449 \nForecasting Semiconductor Demand 449 \n11.7.1 \nGeneral Formulation for Delays 462 \n11.7.2 \nFirst-Order Delay 464 \n11.7.3 \nHigher-Order Delays 465 \n11.7.4 \nRelation of Material and Information Delays 466 \n11.6 System Dynamics in Action: \n11.7 Mathematics of Delays: Koyck Lags and Erlang Distributions 462 \n11.8 Summary 466 \n12.1 Aging Chains 470 \n12 Coflows and Aging Chains 469 \n12.1.1 \nGeneral Structure of Aging Chains 470 \n12.1.2 \nExample: Population and Infrastructure in Urban \nDynamics 472 \n12.1.3 \nExample: The Population Pyramid and the Demographic \nTransition 474 \n12.1.4 \nAging Chains and Population Inertia 480 \n12.1.5 \nSystem Dynamics in Action: \n12.1.6 \nCase Study: \n12.1.7 \nPromotion Chains and the Learning Curve 490 \nWorld Population and Economic Development \nGrowth and the Age Structure of Organizations \n48 1 \n485\n\nxx \nContents \n12.2 \n12.3 \n12.1.8 \nMentoring and On-The-Job Training 493 \nChallenge: The Interactions of Training Delays and Growth 495 \nCoflows: Modeling the Attributes of a Stock 497 \nChallenge: Coflows 503 \n12.2.1 \nCofzows with Nonconsewed Flows 504 \nChallenge: The Dynamics of Experience and Learning 508 \n12.2.2 \nIntegrating Cofzows and Aging Chains 509 \nChallenge: Modeling Design Wins in the \nSemiconductor Industry 5 11 \nSummary 511 \n13 Modeling Decision Making 513 \n13.1 Principles for Modeling Decision Making 5 13 \n13.1.1 \nDecisions and Decision Rules 5 14 \n13.1.2 \nFive Formulation Fundamentals 516 \nChallenge: Finding Formulation Flaws 520 \n13.2.1 \nFractional Increase",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 14
  },
  {
    "child_id": "a6fc2b7d-73b1-40c4-a022-963394f587df",
    "parent_id": "c5ea71b2-89fb-4c98-8821-32d73a82a586",
    "text": "497 \nChallenge: Coflows 503 \n12.2.1 \nCofzows with Nonconsewed Flows 504 \nChallenge: The Dynamics of Experience and Learning 508 \n12.2.2 \nIntegrating Cofzows and Aging Chains 509 \nChallenge: Modeling Design Wins in the \nSemiconductor Industry 5 11 \nSummary 511 \n13 Modeling Decision Making 513 \n13.1 Principles for Modeling Decision Making 5 13 \n13.1.1 \nDecisions and Decision Rules 5 14 \n13.1.2 \nFive Formulation Fundamentals 516 \nChallenge: Finding Formulation Flaws 520 \n13.2.1 \nFractional Increase Rate 522 \n13.2.2 \nFractional Decrease Rate 523 \n13.2.3 \nAdjustment to a Goal 523 \n13.2.4 \nThe Stock Management Structure: \nRate = Normal Rate + Adjustments \n13.2.5 \nFlow = Resource * Productivity 524 \n13.2.6 \nY = Y* * Effect of X I  on Y * Effect of X2 on Y * . . . * Effect \nofX,on Y 525 \n13.2.7 \nY = Y* + Effect ofX, on Y + Effect 0 f X 2  on Y + . . . + \nEffect of X ,  on Y 527 \nChallenge: Multiple Nonlinear Effects 529 \n13.2.8 \nFuzzy MIN Function 529 \n13.2.9 \nFuzzy MAX Function 530 \n13.2.10 Floating Goals 532 \nChallenge: Floating Goals 533 \nChallenge: Goal Formation with Internal and External Inputs 535 \n13.2.11 Nonlinear Weighted Average \n535 \n13.2.12 Modeling Search: Hill-Climbing Optimization 537 \nChallenge: Finding the Optimal Mix of Capital and Labor \n13.2.13 Resource Allocation 544 \n13.3.1 \nAll Outflows Require First-Order Control 545 \nChallenge: Preventing Negative Stocks 547 \n13.3.2 \n13.3.3 \nDisaggregate Net Flows 547 \n13.2 Formulating Rate Equations 522 \n524 \n543 \n13.3 Common Pitfalls 545 \nAvoid I F .  . . THEN. . . ELSE Formulations \n547 \n13.4 Summary 549 \n14.1 Table Functions 552 \n14 Formulating Nonlinear Relationships 551 \n14.1.1 \nSpeciJLing Table Functions 552 \n14.1.2 \nExample: Building a Nonlinear Function 552",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 14
  },
  {
    "child_id": "c8400869-a5db-4ef4-9aac-6a3099afcf74",
    "parent_id": "afb59cab-0f74-4bd6-946e-8f4687347afa",
    "text": "Contents \nxxi \n14.2 \n14.3 \n14.4 \n14.5 \n14.6 \n14.1.3 \nProcess Point: Table Functions versus \nAnalytic Functions 562 \nCase Study: Cutting Corners versus Overtime 563 \nChallenge: Formulating Nonlinear Functions 566 \n14.2.1 \nWorking Overtime: \n14.2.2 \nCutting Corners: \n568 \nCase Study: Estimating Nonlinear Functions with Qualitative and \nNumerical Data 569 \nChallenge: Refining Table Functions with Qualitative Data 569 \nCommon Pitfalls 573 \n14.4.1 \nUsing the Wrong Input 573 \nChallenge: Critiquing Nonlinear Functions 575 \n14.4.2 \nImproper Normalization \n576 \n14.4.3 \nAvoid Hump-Shaped Functions 577 \nChallenge: Formulating the Error Rate \nChallenge: Testing the Full Model \nEliciting Model Relationships Interactively 585 \n14.5.1 \nCase Study: Estimating Precedence Relationships in \nProduct Development 587 \nSummary 595 \nThe Effect of Schedule Pressure on Workweek 567 \nThe Effect of Schedule Pressure on Time per Task \n583 \n585 \n15 Modeling Human Behavior: Bounded Rationality or \nRational Expectations? 597 \n15.1 \n15.2 Cognitive Limitations 599 \n15.3 \nHuman Decision Making: Bounded Rationality or \nRational Expectations? 598 \nIndividual and Organizational Responses to \nBounded Rationality 601 \n15.3.1 \nHabit, Routines, and Rules of Thumb 601 \n15.3.2 \nManaging Attention 601 \n15.3.3 \nGoal Formation and Satisficing 601 \n15.3.4 \nProblem Decomposition and Decentralized \nDecision Making \n602 \n15.4 Intended Rationality 603 \n15.5 Case Study: Modeling High-Tech Growth Firms 605 \n15.4.1 \nTesting for Intended Rationality: Partial Model Tests 605 \n15.5.1 \nModel Structure: Overview 606 \n15.5.2 \nOrder Fulfillment 607 \n15.5.3 \nCapacity Acquisition 609 \nChallenge: Hill Climbing 6 15 \n15.5.4 \nThe Sales Force 615 \n15.5.5 \nThe Market 619 \n15.5.6 \nBehavior of the Full System 621 \nChallenge: Policy Design in the Market Growth Model 624 \n15.6 Summary 629\n\nxxii \nContents \n16 Forecasts and Fudge Factors: Modeling Expectation Formation 631 \n16.1 Modeling Expectation Formation 63 1 \n16.1.1 \nModeling Growth Expectations: \nThe TREND Function 634 \n16.1.2 \nBehavior of the TREND Function 638 \n16.2 Case Study: Energy Consumption 638 \n16.3 Case Study: Commodity Prices 643 \n16.4 Case Study: Inflation 645 \n16.5 Implications for Forecast Consumers 655 \nChallenge: Extrapolation and Stability 656 \n16.6 Initialization and Steady State Response of \nthe TREND Function 658 \n16.7 Summary 660 \nPART V INSTABILITY AND OSCILLATION 661 \n17 Supply Chains and the Origin of Oscillations 663 \n17.1 Supply Chains in Business and Beyond 664 \n17.2 The Stock Management Problem 666 \n17.1,l \nOscillation, Amplification, and Phase Lag \n664 \n17.2.1 \nManaging a Stock: Structure 668 \n17.2.2 \nSteady State Error 671 \n17.2.3 \nManaging a Stock: Behavior \n672 \nChallenge: Exploring Amplification 674 \n17.3.1 \nBehavior of the Stock Management Structure 680 \nChallenge: Exploring the Stock Management Structure 683 \n17.4.1 \nMismanaging the Supply Line: \n17.4.2 \nWhy Do We Ignore the Supply Line? 695 \n17.4.3 \nChallenge: Expanding the Rea",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 20
  },
  {
    "child_id": "ba7b41dd-4286-48e7-adc4-af575e0487e3",
    "parent_id": "afb59cab-0f74-4bd6-946e-8f4687347afa",
    "text": " and Beyond 664 \n17.2 The Stock Management Problem 666 \n17.1,l \nOscillation, Amplification, and Phase Lag \n664 \n17.2.1 \nManaging a Stock: Structure 668 \n17.2.2 \nSteady State Error 671 \n17.2.3 \nManaging a Stock: Behavior \n672 \nChallenge: Exploring Amplification 674 \n17.3.1 \nBehavior of the Stock Management Structure 680 \nChallenge: Exploring the Stock Management Structure 683 \n17.4.1 \nMismanaging the Supply Line: \n17.4.2 \nWhy Do We Ignore the Supply Line? 695 \n17.4.3 \nChallenge: Expanding the Real Estate Model 707 \n17.3 The Stock Management Structure 675 \n17.4 The Origin of Oscillations 684 \nThe Beer Distribution Game 684 \nCase Study: Boom and Bust in Real Estate Markets 698 \n17.5 Summary 707 \n18.1 The Policy Structure of Inventory and Production 710 \n18 The Manufacturing Supply Chain 709 \n18.1.1 \nOrder Fulfillment 7 11 \n18.1.2 \nProduction 7 13 \n18.1.3 \nProduction Starts 714 \n18.1.4 \nDemand Forecasting 7 16 \n18.1.5 \nProcess Point: Initializing a Model in Equilibrium \n7 16 \nChallenge: Simultaneous Initial Conditions 7 18 \n18.1.6 \nBehavior of the Production Model \n720 \n18.1.7 \nEnriching the Model: Adding Order Backlogs 723 \n18.1.8 \nBehavior of the Firm with Order Backlogs 725 \n18.1.9 \nAdding Raw Materials Inventory 725 \n18.2 Interactions among Supply Chain Partners 729 \n18.2.1 \nInstability and Trust in Supply Chains 735\n\nContents \nxxiii \n18.2.2 \nChallenge: Reengineering the Supply Chain \nSystem Dynamics in Action: Reengineering the Supply Chain in a \nHigh-Velocity Industry 743 \n18.3.1 \nInitial Problem Definition 743 \n18.3.2 \nReference Mode and Dynamic Hypothesis 746 \n18.3.3 \nModel Formulation 749 \n18.3.4 \nTesting the Model 749 \n18.3.5 \nPolicy Analysis 75 1 \n18.3.6 \nImplementation: Sequential Debottlenecking 753 \n18.3.7 \nResults 755 \nFrom Functional Silos to Integrated Supply Chain \nManagement \n740 \n74 1 \n18.3 \n18.4 Summary 755 \nThe Labor Supply Chain and the Origin of Business Cycles \n19.1 The Labor Supply Chain 758 \n19 \n757 \n19.1.1 \nStructure of Labor and Hiring 758 \n19.1.2 \nBehavior of the Labor Supply Chain 760 \nChallenge: Mental Simulation of \nInventory Management with Labor 766 \n19.2.1 \nInventory-Workforce Interactions: Behavior 766 \n19.2.2 \nProcess Point: Explaining Model Behavior 767 \nChallenge: Explaining Oscillations 767 \n19.2.3 \nUnderstanding the Sources of Oscillation 771 \nChallenge: Policy Design to Enhance Stability \n19.2.4 \nAdding Overtime 774 \n19.2.5 \nResponse to Flexible Workweeks 776 \nChallenge: Reengineering a Manufacturing Firm \nfor Enhanced Stability 778 \n19.2.6 \nThe Costs of Instability 779 \nChallenge: The Costs of Instability 780 \nChallenge: Adding Training and Experience \n19.3.1 \nIs the Business Cycle Dead? 785 \n19.2 Interactions of Labor and Inventory Management 764 \n773 \n780 \n19.3 Inventory-Workforce Interactions and the Business Cycle 782 \n19.4 Summary 788 \n20.1 \nCommodity Cycles: From Aircraft to Zinc 792 \n20.2 \nA Generic Commodity Market Model 798 \n20.2.1 \nProduction and Inventory \n801 \n20.2.2 \nCapacity Utilization 802 \n2",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 20
  },
  {
    "child_id": "ba6119f1-a182-4693-909c-d341abbcc53a",
    "parent_id": "afb59cab-0f74-4bd6-946e-8f4687347afa",
    "text": "d Stability 778 \n19.2.6 \nThe Costs of Instability 779 \nChallenge: The Costs of Instability 780 \nChallenge: Adding Training and Experience \n19.3.1 \nIs the Business Cycle Dead? 785 \n19.2 Interactions of Labor and Inventory Management 764 \n773 \n780 \n19.3 Inventory-Workforce Interactions and the Business Cycle 782 \n19.4 Summary 788 \n20.1 \nCommodity Cycles: From Aircraft to Zinc 792 \n20.2 \nA Generic Commodity Market Model 798 \n20.2.1 \nProduction and Inventory \n801 \n20.2.2 \nCapacity Utilization 802 \n20.2.3 \nProduction Capacity 805 \n20.2.4 \nDesired Capacity 807 \nChallenge: Intended Rationality of the Investment Process \n20.2.5 \nDemand \n8 11 \n20.2.6 \nThe Price-Setting Process 813 \nChallenge: Sensitivity to Uncertainty in Parameters \n20 The Invisible Hand Sometimes Shakes: Commodity Cycles 791 \n8 10 \n20.3 Application: Cycles in the Pulp and Paper Industry 824 \n828\n\nxxiv \nContents \nChallenge: Sensitivity to Structural Changes \nChallenge: Implementing Structural Changes- \nModeling Livestock Markets 836 \nChallenge: Policy Analysis 840 \n83 1 \n20.4 \nSummary 841 \nPART VI MODEL TESTING 843 \n21 Truth and Beauty: Validation and Model Testing 845 \n21.1 Validation and Verification Are Impossible 846 \n21.2 Questions Model Users Should Ask-But Usually Don\u2019t 85 1 \n21.3 Pragmatics and Politics of Model Use 85 1 \n21.3.1 \nTypes ofData 853 \n21.3.2 \nDocumentation \n855 \n21.3.3 \nReplicability \n855 \n21.3.4 \nProtective versus Reflective Modeling \n858 \n2 1.4.1 \nBoundary Adequacy Tests 861 \n21.4.2 \nStructure Assessment Tests 863 \n21.4.3 \nDimensional Consistency 866 \n21.4.4 \nParameter Assessment 866 \n2 1.4.5 \nExtreme Condition Tests 869 \nChallenge: Extreme Condition Tests \n21.4.6 \nIntegration Error Tests 872 \n21.4.7 \nBehavior Reproduction Tests 874 \n21.4.8 \nBehavior Anomaly Tests 880 \n21.4.9 \nFamily Member Tests 88 1 \n21.4.10 \nSurprise Behavior Tests 882 \n21.4.11 \nSensitivity Analysis 883 \n21.4.12 System Improvement Tests 887 \nChallenge: Model Testing 889 \n21.4 Model Testing in Practice 858 \n87 1 \n21.5 \nSummary 890 \nPART VI1 COMMENCEMENT 893 \n22 Challenges for the Future 895 \n22.1 Theory 895 \n22.2 Technology 896 \n22.3 Implementation 899 \n22.4 Education 900 \n22.5 Applications 901 \nChallenge: Putting System Dynamics into Action \nAPPENDIX A NUMERICAL INTEGRATION 903 \nChallenge: Choosing a Time Step 910 \nAPPENDIXB \nNOISE 913 \nChallenge: Exploring Noise 922 \nREFERENCES 925 \nINDEX 947 \n901\n\nList of Challenges \nDynamics of Multiple-Loop Systems 14 \nHypothesis Testing 30 \nIdentifying Feedback Structure from System Behavior \nIdentifying the Limits to Growth \nAssigning Link Polarities 143 \nIdentifying Link and Loop Polarity \nEmployee Motivation \n147 \nProcess Improvement 158 \nPolicy Analysis with Causal Diagrams \nThe Oil Crises of the 1970s \nSpeculative Bubbles \n173 \nThe Thoroughbred Horse Market 174 \nThe Medigap Death Spiral 176 \nIdentifying the Feedback Structure of Policy Resistance \nIdentifying Stocks and Flows 201 \nAdding Stock and Flow Structure to Causal Diagrams \nLinking Stock and Fl",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 20
  },
  {
    "child_id": "fa7784ce-c897-4893-b0de-8ae8c919b489",
    "parent_id": "afb59cab-0f74-4bd6-946e-8f4687347afa",
    "text": "ture from System Behavior \nIdentifying the Limits to Growth \nAssigning Link Polarities 143 \nIdentifying Link and Loop Polarity \nEmployee Motivation \n147 \nProcess Improvement 158 \nPolicy Analysis with Causal Diagrams \nThe Oil Crises of the 1970s \nSpeculative Bubbles \n173 \nThe Thoroughbred Horse Market 174 \nThe Medigap Death Spiral 176 \nIdentifying the Feedback Structure of Policy Resistance \nIdentifying Stocks and Flows 201 \nAdding Stock and Flow Structure to Causal Diagrams \nLinking Stock and Flow Structure with Feedback 212 \nModifying Stock and Flow Maps \nDisaggregation 214 \nGraphical Integration 239 \nGraphical Differentiation 241 \nPaper Folding 268 \nGoal-Seeking Behavior 28 1 \nNonlinear Birth and Death Rates \nExploring the SIR Model 308 \nThe Efficacy of Immunization Programs \nExtending the SIR Model 3 16 \nModeling HIV/AIDS 321 \nPhase Space of the Bass Diffusion Model \nCritiquing the Bass Diffusion Model \nExtending the Bass Model 335 \nModeling Fads 341 \n117 \n122 \n145 \n168 \n172 \n190 \n211 \n213 \n286 \n3 10 \n333 \n334 \nxxv\n\nxxvi \nList of Challenges \nModeling the Life Cycle of Durable Products 345 \nIdentifying Path Dependence 353 \nFormulating a Dynamic Hypothesis for the VCR Industry 364 \nPolicy Analysis 403 \nExtending the Model 404 \nDuration and Dynamics of Delays 409 \nResponse of Material Delays to Steps, Ramps, and Cycles 425 \nResponse of Delays to Changing Delay Times 435 \nThe Interactions of Training Delays and Growth 495 \nCoflows 503 \nThe Dynamics of Experience and Learning \nModeling Design Wins in the Semiconductor Industry \nFinding Formulation Flaws 520 \nMultiple Nonlinear Effects 529 \nFloating Goals 533 \nGoal Formation with Internal and External Inputs \nFinding the Optimal Mix of Capital and Labor 543 \nPreventing Negative Stocks 547 \nFormulating Nonlinear Functions 566 \nRefining Table Functions with Qualitative Data \nCritiquing Nonlinear Functions 575 \nFormulating the Error Rate 583 \nTesting the Full Model 585 \nHill Climbing 615 \nPolicy Design in the Market Growth Model \nExtrapolation and Stability 656 \nExploring Amplification 674 \nExploring the Stock Management Structure 683 \nExpanding the Real Estate Model \nSimultaneous Initial Conditions 7 18 \nReengineering the Supply Chain 74 1 \nMental Simulation of Inventory Management with Labor \nExplaining Oscillations 767 \nPolicy Design to Enhance Stability \nReengineering a Manufacturing Firm for Enhanced Stability \nThe Costs of Instability 780 \nAdding Training and Experience 780 \nIntended Rationality of the Investment Process \nSensitivity to Uncertainty in Parameters 828 \nSensitivity to Structural Changes \nImplementing Structural Changes-Modeling Livestock Markets \nPolicy Analysis 840 \nExtreme Condition Tests 871 \nModel Testing 889 \nhtting System Dynamics Into Action \nChoosing a Time Step 910 \nExploring Noise 922 \n508 \n5 11 \n535 \n569 \n624 \n707 \n766 \n773 \n778 \n8 10 \n83 1 \n836 \n901\n\nLearning in and about \nComplex Systems \nExperience is an expensive school. \n-Benjamin Franklin \nExperience is something yo",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 20
  },
  {
    "child_id": "b7d3b617-86f0-4ace-bd81-8e4c2c7037fb",
    "parent_id": "afb59cab-0f74-4bd6-946e-8f4687347afa",
    "text": "estment Process \nSensitivity to Uncertainty in Parameters 828 \nSensitivity to Structural Changes \nImplementing Structural Changes-Modeling Livestock Markets \nPolicy Analysis 840 \nExtreme Condition Tests 871 \nModel Testing 889 \nhtting System Dynamics Into Action \nChoosing a Time Step 910 \nExploring Noise 922 \n508 \n5 11 \n535 \n569 \n624 \n707 \n766 \n773 \n778 \n8 10 \n83 1 \n836 \n901\n\nLearning in and about \nComplex Systems \nExperience is an expensive school. \n-Benjamin Franklin \nExperience is something you get just after you need it. \n-Anonymous \n1 .I \nINTRODUCTION \nThe greatest constant of modern times is change. Accelerating changes in tech- \nnology, population, and economic activity are transforming our world, from the \nprosaic-the effect of information technology on the way we use the telephone- \nto the profound-the effect of greenhouse gases on the global climate. Some of the \nchanges are wonderful; others defile the planet, impoverish the human spirit, and \nthreaten our survival. All challenge traditional institutions, practices, and beliefs. \nMost important, most of the changes we now struggle to comprehend arise as \nconsequences, intended and unintended, of humanity itself. All too often, well- \nintentioned efforts to solve pressing problems lead to policy resistance, where our \npolicies are delayed, diluted, or defeated by the unforeseen reactions of other \npeople or of nature. Many times our best efforts to solve a problem actually make \nit worse. \nThe dizzying effects of accelerating change are not new. Henry Adams, a \nperceptive observer of the great changes wrought by the industrial revolution, \n3",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 20
  },
  {
    "child_id": "57628eda-f357-4e48-ad38-2af931478d78",
    "parent_id": "a7feb56a-666e-4fb3-9466-5b84aa585ba4",
    "text": "4 \nPart I Perspective and Process \nformulated the Law of Acceleration to describe the exponential growth of tech- \nnology, production, and population that made the legacy of colonial America he \ninherited irrelevant: \nSince 1800, scores of new forces had been discovered; old forces had been raised \nto higher powers . . . Complexity had extended itself on immense horizons, \nand arithmetical ratios were useless for any attempt at accuracy. \nIf science were to go on doubling or quadrupling its complexities every \n10 years, even mathematics should soon succumb. An average mind had suc- \ncumbed already in 1850; it could no longer understand the problem in 1900. \n(Adams 1918, pp. 490,496) \nAdams believed the radical changes in society induced by these forces \u201cwould \nrequire a new social mind.\u201d With uncharacteristic, and perhaps ironic, optimism, \nhe concluded, \u201cThus far, since 5 or 10 thousand years, the mind had successfully \nreacted, and nothing yet proved that it would fail to react-but it would need \nto jump.\u201d \nA steady stream of philosophers, scientists, and management gurus have since \nechoed Adams, lamenting the acceleration and calling for similar leaps to funda- \nmental new ways of thinking and acting. Many advocate the development of sys- \ntems thinking-the ability to see the world as a complex system, in which we \nunderstand that \u201cyou can\u2019t just do one thing\u201d and that \u201ceverything is connected to \neverything else.\u201d If people had a holistic worldview, it is argued, they would then \nact in consonance with the long-term best interests of the system as a whole, iden- \ntify the high leverage points in systems, and avoid policy resistance. Indeed, for \nsome, the development of systems thinking is crucial for the survival of humanity. \nThe challenge facing us all is how to move from generalizations about accel- \nerating learning and systems thinking to tools and processes that help us under- \nstand complexity, design better operating policies, and guide change in systems \nfrom the smallest business to the planet as a whole. However, learning about com- \nplex systems when you also live in them is difficult. We are all passengers on an \naircraft we must not only fly but redesign in flight. \nSystem dynamics is a method to enhance learning in complex systems. Just as \nan airline uses flight simulators to help pilots learn, system dynamics is, partly, a \nmethod for developing management flight simulators, often computer simulation \nmodels, to help us learn about dynamic complexity, understand the sources of pol- \nicy resistance, and design more effective policies. \nBut learning about complex dynamic systems requires more than technical \ntools to create mathematical models. System dynamics is fundamentally interdis- \nciplinary. Because we are concerned with the behavior of complex systems, system \n\u2018There are many schools of systems thinking (for surveys, see Richardson 1991 and Lane \n1994). Some emphasize qualitative methods; others stress formal modeling",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 29
  },
  {
    "child_id": "5062de61-1c17-462c-8a4d-7194d59aaad2",
    "parent_id": "a7feb56a-666e-4fb3-9466-5b84aa585ba4",
    "text": "ynamic complexity, understand the sources of pol- \nicy resistance, and design more effective policies. \nBut learning about complex dynamic systems requires more than technical \ntools to create mathematical models. System dynamics is fundamentally interdis- \nciplinary. Because we are concerned with the behavior of complex systems, system \n\u2018There are many schools of systems thinking (for surveys, see Richardson 1991 and Lane \n1994). Some emphasize qualitative methods; others stress formal modeling. As sources of method \nand metaphor they draw on fields as diverse as anthropology, biology. engineering, linguistics, psy- \nchology, physics, and Taoism and seek applications in fields still more diverse. All agree, however, \nthat a systems view of the world is still rare. Jay Forrester developed system dynamics in the 1950s \nat MIT. Richardson (1991) traces the history of the field and relates system dynamics to other sys- \ntems approaches.\n\nChapter 1 Learning in and about Complex Systems \n5 \ndynamics is grounded in the theory of nonlinear dynamics and feedback control \ndeveloped in mathematics, physics, and engineering. Because we apply these tools \nto the behavior of human as well as physical and technical systems, system \ndynamics draws on cognitive and social psychology, economics, and other social \nsciences. Because we build system dynamics models to solve important real world \nproblems, we must learn how to work effectively with groups of busy policy \nmakers and how to catalyze sustained change in organizations. \nThis chapter discusses the skills required to develop your systems thinking ca- \npabilities, how to create an effective learning process in dynamically complex sys- \ntems, and how to use system dynamics in organizations to address important \nproblems. I first review what we know about how people learn in and about com- \nplex dynamic systems. Such learning is difficult and rare because a variety of \nstructural impediments thwart the feedback processes required for learning to oc- \ncur. Successful approaches to learning about complex dynamic systems require \n(1) tools to elicit and represent the mental models we hold about the nature of dif- \nficult problems; (2) formal models and simulation methods to test and improve our \nmental models, design new policies, and practice new skills; and (3) methods to \nsharpen scientific reasoning skills, improve group processes, and overcome defen- \nsive routines for individuals and teams. \n1 .I .I \nPolicy Resistance, the Law of Unintended \nConsequences, and the Counterintuitive \nBehavior of Social Systems \nAnd it will fall out as in a complication of diseases, that by applying a \nremedy to one sore, you will provoke another; and that which removes the \none ill symptom produces others . . . \n-Sir Thomas More \nThe best-laid schemes o\u2019 mice an \u2019men/ Gang a@ a-gley. \n-Robert Burns \nAnything that can go wrong will go wrong. \n--\u201cMurphy\u201d \nWe have met the enemy and he is us. \n-Pogo \nFrom Thomas More in 15 16 to ",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 29
  },
  {
    "child_id": "38db4c11-0ff2-4839-93e3-52de293e1d5e",
    "parent_id": "a7feb56a-666e-4fb3-9466-5b84aa585ba4",
    "text": "ce, the Law of Unintended \nConsequences, and the Counterintuitive \nBehavior of Social Systems \nAnd it will fall out as in a complication of diseases, that by applying a \nremedy to one sore, you will provoke another; and that which removes the \none ill symptom produces others . . . \n-Sir Thomas More \nThe best-laid schemes o\u2019 mice an \u2019men/ Gang a@ a-gley. \n-Robert Burns \nAnything that can go wrong will go wrong. \n--\u201cMurphy\u201d \nWe have met the enemy and he is us. \n-Pogo \nFrom Thomas More in 15 16 to Pogo in the mid 20th century it has long been ac- \nknowledged that people seeking to solve a problem often make it worse. Our poli- \ncies may create unanticipated side effects. Our attempts to stabilize the system may \ndestabilize it. Our decisions may provoke reactions by others seehng to restore the \nbalance we upset. Forrester (1971a) calls such phenomena the \u201ccounterintuitive \nbehavior of social systems.\u201d These unexpected dynamics often lead to policy re- \nsistance, the tendency for interventions to be delayed, diluted, or defeated by the \nresponse of the system to the intervention itself (Meadows 1982).\n\n6 \nPart I Perspective and Process \nFIGURE 1-1 \nPolicy resistance: \nRomanian birth \nrates \nThe crude birth \nrate in Romania \nshowing the effect \nof restricting abor- \ntion beginning in \n1966 \n1971 \n1994 \nStatistical Yearbook 1995, \nAs an example, consider the birth rate in Romania in the late 1960s. The crude \nbirth rate (births per year per 1000 people) was extremely low-about 15 per \nthousand (Figure 1- 1). For various reasons, including national pride and ethnic \nidentity, the low birth rate was considered to be a grave problem by the govern- \nment, including the dictator Nicolau CeausesCu. The Ceausesp regime responded \nby imposing policies designed to stimulate the birth rate. Importation of contra- \nceptive devices was outlawed; propaganda campaigns extolling the virtues of large \nfamilies and the patriotic (matriotic would be more accurate) duty to have more \nchildren were introduced, along with some modest tax incentives for larger fami- \nlies. Perhaps most important, abortion-freely available on demand since 1957 \nthrough the state health care system-was banned in October 1966 (David and \nWright 197 1). \nThe result was immediate and dramatic. The birth rate rose sharply to nearly \n40 per 1000 per year, rivaling those of the fastest growing nations. The policy ap- \npeared to be a sensational success. However, within months the birth rate began to \nfall. By the end of 1970, only 4 years after the policy was implemented, the birth \nrate had dropped below 20 per thousand, close to the low levels seen prior to the \nintervention. Though the policy continued in force, the birth rate continued to fall, \nreaching 16 per thousand by 1989-about the same low rate that led to the impo- \nsition of the policy. What happened? \nThe system responded to the intervention in ways the regime did not antici- \npate. The people of Romania found ways around the policy.",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 29
  },
  {
    "child_id": "ecefc659-c559-4593-92a3-66c131b4e174",
    "parent_id": "a7feb56a-666e-4fb3-9466-5b84aa585ba4",
    "text": "By the end of 1970, only 4 years after the policy was implemented, the birth \nrate had dropped below 20 per thousand, close to the low levels seen prior to the \nintervention. Though the policy continued in force, the birth rate continued to fall, \nreaching 16 per thousand by 1989-about the same low rate that led to the impo- \nsition of the policy. What happened? \nThe system responded to the intervention in ways the regime did not antici- \npate. The people of Romania found ways around the policy. They practiced alter- \nnative methods of birth control. They smuggled contraceptive pills and devices in \nfrom other countries. Desperate women sought and found back-alley abortions. \nMany of these were unsanitary or botched, leading to a near tripling of deaths due",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 29
  },
  {
    "child_id": "de934137-085e-4a24-8a1b-bb95409f7139",
    "parent_id": "626ce0b5-533f-4b60-9c2d-f5944e3e5f26",
    "text": "Chapter 1 Learning in and about Complex Systems \n7 \nto complications of abortion from 1965 to 1967. Most horribly, the number of \nneonatal deaths rose by more than 300% between 1966 and 1967, a 20% increase \nin the infant mortality rate (David and Wright 1971). The result: the policy was \nrendered completely ineffective almost immediately after implementation. \nBut the unanticipated consequences didn\u2019t end with the failure of the popu- \nlation policy. The people of Romania, among the poorest in Europe, were having \nsmall families because they couldn\u2019t afford larger ones. Child care was unavail- \nable for some. Many others lived with their extended families in small, crowded \napartments. Jobs were scarce; income was low. Many people gave children they \ncouldn\u2019t support to state-run orphanages. The government\u2019s policy didn\u2019t prevent \nthe people of Romania from controlling their own fertility, but it did breed intense \nresentment against the intrusive policies of the regime. In 1989, when the Berlin \nwall fell and the totalitarian regimes of Eastern Europe toppled, Romania was the \nonly nation where the velvet revolution was violent. The hated Ceausesp and his \nequally hated wife were summarily executed by firing squad. Their bloody bodies \nwere left in the courtyard of the presidential palace while the scene was broadcast \non national television. The law banning abortion was the first overturned by the \nnew government. The birth rate, already low, fell further. By the mid 1990s, the \npopulation of Romania was actually declining as births dropped below deaths. \nThe children of Romania suffered the most from the population policy. During \nthe years of the population policy thousands of children were placed in the care of \nstate orphanages, where they were kept like animals in cribs (cages, really) with- \nout attention to basic needs, much less the love that all of us need and deserve. \nFood was so scarce that blood transfusions were routinely given as nutritional sup- \nplements. Because needles were used repeatedly, an epidemic of AIDS spread \nrapidly among the children. The side effects of the failed population policy cast a \nshadow on the health and happiness of an entire nation, a shadow stretching over \ngenerations. \nPolicy resistance is not limited to dictators. It doesn\u2019t respect national borders, \npolitical ideology, or historical epoch. Consider the US government\u2019s fight against \ninflation in the early 1970s. Figure 1-2 shows the Consumer Price Index (CPI) for \nthe United States between 1968 and 1976. In the early 1970s inflation had acceler- \nated and the Nixon administration felt action had to be taken. Though a Republi- \ncan, Nixon chose to implement wage and price controls. The policy was expensive: \nA new federal bureaucracy, the Council on Wage and Price Stability, was created \nto oversee the controls and enforce compliance. Wage and price controls were \nviewed by many in Nixon\u2019s own party as verging on socialism, costing Nixon \nvaluabl",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 32
  },
  {
    "child_id": "96ec6cca-6ce2-45ca-90f7-e36baf4dedc0",
    "parent_id": "626ce0b5-533f-4b60-9c2d-f5944e3e5f26",
    "text": "CPI) for \nthe United States between 1968 and 1976. In the early 1970s inflation had acceler- \nated and the Nixon administration felt action had to be taken. Though a Republi- \ncan, Nixon chose to implement wage and price controls. The policy was expensive: \nA new federal bureaucracy, the Council on Wage and Price Stability, was created \nto oversee the controls and enforce compliance. Wage and price controls were \nviewed by many in Nixon\u2019s own party as verging on socialism, costing Nixon \nvaluable political capital. At first, the policy seemed to work, although imperfectly. \nDuring so-called Phase I of the controls, the rate of inflation fell by about half. The \nadministration decided the controls could be relaxed. In Phase 11, President Ford \n(who inherited the program from Nixon) launched a jawboning campaign, com- \nplete with campaign-style buttons labeled \u201cWIN!\u201d for \u201cWhip Inflation Now!\u201d. \nFew observers expected WIN! buttons to have any effect, and most felt inflation \nwould return to its rate prior to the start of controls. Instead, inflation actually ac- \ncelerated until, by 1975, the CPI had returned to the trajectory it was on prior to the \nimposition of the price controls. Less than 4 years after the intervention there was\n\n8 \nPart I Perspective and Process \nFIGURE 1-2 \nThe US Consumer Price Index (CPI) showing the Nixon/Ford wage and price \ncontrols \nPolicy resistance in the fight against inflation \n60 \nh \n0 \n2 50 \n30 \n1968 \n1969 \n1970 \n1971 \n1972 \n1973 \n1974 \n1975 \n1976 \nno residue of benefit. Other examples of policy resistance can be found nearly \nevery day in the newspaper. Table 1-1 lists a few.\u2019 \nMachiavelli, a keen observer of human systems, discussed policy resistance at \nlength, observing in the Discourses that \nWhen a problem arises either from within a republic or outside it, one brought \nabout either by internal or external reasons, one that has become so great that it \nbegins to make everyone afraid, the safest policy is to delay dealing with it rather \nthan trying to do away with it, because those who try to do away with it almost \nalways increase its strength and accelerate the harm which they feared might come \nfrom it. (Machiavelli 1979, pp. 240-241). \nI find Machiavelli\u2019s view too cynical but can sympathize with his frustration in ob- \nserving his client princes (the CEOs of Renaissance Italy) take actions that only \nmade their problems worse. A more reflective view is offered by the late biologist \nand essayist Lewis Thomas (1974, p. 90): \nWhen you are confronted by any complex social system, such as an urban center or \na hamster, with things about it that you\u2019re dissatisfied with and anxious to fix, you \ncannot just step in and set about fixing with much hope of helping. This realization \nis one of the sore discouragements of our century . . . You cannot meddle with one \npart of a complex system from the outside without the almost certain risk of setting \noff disastrous events that you hadn\u2019t counted on in other, remo",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 32
  },
  {
    "child_id": "17c8909d-5fe4-4648-9d7a-fe05b41917b0",
    "parent_id": "626ce0b5-533f-4b60-9c2d-f5944e3e5f26",
    "text": "4, p. 90): \nWhen you are confronted by any complex social system, such as an urban center or \na hamster, with things about it that you\u2019re dissatisfied with and anxious to fix, you \ncannot just step in and set about fixing with much hope of helping. This realization \nis one of the sore discouragements of our century . . . You cannot meddle with one \npart of a complex system from the outside without the almost certain risk of setting \noff disastrous events that you hadn\u2019t counted on in other, remote parts. If you want \nto fix something you are first obliged to understand. . . the whole system. . . \nIntervening is a way of causing trouble. \n2Further reading: John McPhee (1989) offers a wonderful description of policy resistance in the \nrelationship of people with nature. McPhee brilliantly describes the unanticipated side effects and \npolicy resistance arising from attempts to defeat three elemental forces of nature: volcanism, flood, \nand fire. Edward Tenner (1996) also identifies many examples of policy resistance.\n\nChapter 1 Learning in and about Complex Systems \n9 \n\u201cUse of Cheaper Drugs Pushes Costs Up, Not Down, Study Finds: Limiting \nwhat is prescribed, as managed-care systems do, has unintended effect of \nincreasing costs, results show\u201d (Headline in LA Times, 3/20/96, p. 1, report- \ning Univ. of Utah study of 13,000 patients in various HMOs). \nsoil out of cultivation for a decade to combat erosion and help the environ- \nment, is a waste of money, so says a new study of the 11-year-old \nprogram . . . For every eroding acre a farmer idles, another farmer-or \nsometimes the same one-simply plows up nearly as much additional \nerosion-prone land . . . In the Great Plains, for instance, farmers set aside \n17 million acres, yet the total cultivated land dropped by only 2 million acres\u201d \n(Business Week, 3/18/96, p. 6, reporting a Univ. of Minnesota study). \nLow tar and nicotine cigarettes actually increase intake of carcinogens, CO, \netc. as smokers compensate for the low nicotine content by smoking more \ncigarettes per day, by taking longer, more frequent drags, and by holding the \nsmoke in their lungs longer. \nAntilock brakes and other automotive safety devices cause some people to \ndrive more aggressively, offsetting some of their benefits. \nInformation technology has not enabled the \u201cpaperless off ice\u201d-paper con- \nsumption per capita is up. \nRoad building programs designed to reduce congestion have increased traf- \nfic, delays, and pollution. \nDespite widespread use of labor-saving appliances, Americans have less \nleisure today than 50 years ago. \nThe US government\u2019s war on drugs, focusing on interdiction and supply dis- \nruption (particularly cocaine production in South America), with a cost in the \nbillions, has had only a small impact on cocaine cultivation, production, or \nsmuggling. Drug use in America and elsewhere remains high. \nThe US policy of fire suppression has increased the size and severity of \nforest fires. Rather than frequent, sma",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 32
  },
  {
    "child_id": "2c0863dd-a831-4e75-b116-bcc26f3ae1b1",
    "parent_id": "626ce0b5-533f-4b60-9c2d-f5944e3e5f26",
    "text": "pread use of labor-saving appliances, Americans have less \nleisure today than 50 years ago. \nThe US government\u2019s war on drugs, focusing on interdiction and supply dis- \nruption (particularly cocaine production in South America), with a cost in the \nbillions, has had only a small impact on cocaine cultivation, production, or \nsmuggling. Drug use in America and elsewhere remains high. \nThe US policy of fire suppression has increased the size and severity of \nforest fires. Rather than frequent, small fires, fire suppression leads to the \naccumulation of dead wood and other fuels leading to larger, hotter, and \nmore dangerous fires, often consuming the oldest and largest trees which \npreviously survived smaller fires unharmed. \nFlood control efforts such as levee and dam construction have led to more \nsevere floods by preventing the natural dissipation of excess water in flood \nplains. The cost of flood damage has increased as the flood plains were de- \nveloped by people who believed they were safe. \nImposing 200-mile territorial limits and quotas to protect fish stocks did \nnot prevent the collapse of the Georges Bank fishery off the coast of North \nAmerica. Once the world\u2019s richest, by the mid 1990s many species were \ncommercially extinct, the fishery was shut down, the fleets were idled, \nand the local economies were in depression. \nDeregulation of the US Savings and Loan industry, designed to save the \nindustry from financial problems, led to a wave of speculation followed by \ncollapse, at a cost to taxpayers in the hundreds of billions of dollars. \nAntibiotics have stimulated the evolution of drug-resistant pathogens, \nincluding virulent strains of TB, strep, staph, and sexually transmitted \ndiseases. \nand weeds, killed off natural predators, and accumulated up the food chain \nto poison fish, birds, and possibly humans. \nTABLE 1-1 \nExamples Of policy \nresistance \n\u201cWashington\u2019s biggest conservation program, which pays farmers to take \nPesticides and herbicides have stimulated the evolution of resistant pests",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 32
  },
  {
    "child_id": "bd444ade-3cdf-4d5e-a894-518e1e04ae2d",
    "parent_id": "fa46b508-8218-42d2-bf15-d0e189f19457",
    "text": "10 \nPart I Perspective and Process \nFIGURE 1-3 \nEvent-oriented \nview of the world \nBut how can one come to understand the whole system? How does policy resis- \ntance arise? How can we learn to avoid it, to find the high leverage policies that \ncan produce sustainable benefit? \n1 .I .2 \nCauses of Policy Resistance \nOne cause of policy resistance is our tendency to interpret experience as a series of \nevents, for example, \u201cinventory is too high,\u201d or \u201csales fell this month.\u201d Accounts \nof who did what to whom are the most common mode of discourse, from the mail- \nroom to the boardroom, from headlines to history books. We are taught from an \nearly age that every event has a cause, which in turn is an effect of some still ear- \nlier cause: \u201cInventory is too high because sales unexpectedly fell. Sales fell be- \ncause the competitors lowered their price. The competitors lowered their price \nbecause. . .,\u2019 Such event-level explanations can be extended indefinitely, in an un- \nbroken Aristotelian chain of causes and effects, until we arrive at some First Cause, \nor more likely, lose interest along the way. \nThe event-oriented worldview leads to an event-oriented approach to problem \nsolving. Figure 1-3 shows how we often try to solve problems. We assess the state \nof affairs and compare it to our goals. The gap between the situation we desire and \nthe situation we perceive defines our problem. For example, suppose sales of your \norganization were $80 million last quarter, but your sales goal was $100 million. \nThe problem is that sales are 20% less than you desired. You then consider various \noptions to correct the problem. You might cut prices to stimulate demand and in- \ncrease market share, replace the vice president of sales with someone more ag- \ngressive, or take other actions. You select the option you deem best and implement \nit, leading (you hope) to a better result. You might observe your sales increase: \nproblem solved. Or so it seems. \nThe system reacts to your solution: As your sales rise, competitors cut prices, \nand sales fall again. Yesterday\u2019s solution becomes today\u2019s problem. We are not \npuppet masters influencing a system out there-we are embedded in the system. \nThe puppet master\u2019s movements respond to the position of the marionette on the \nstrings. There is feedback The results of our actions define the situation we face in \nthe future. The new situation alters our assessment of the problem and the deci- \nsions we take tomorrow (see the top of Figure 1-4). \nPolicy resistance arises because we often do not understand the full range of \nfeedbacks operating in the system (Figure 1-4). As our actions alter the state of the \nsystem, other people react to restore the balance we have upset. Our actions may \nalso trigger side effects. \nGoals \\ \nProblem -b \nDecision -b \nResults \n7 \nSituation\n\nChapter 1 Learning in and about Complex Systems \n11 \nFIGURE 1-4 \nThe feedback view \nWe frequently talk about side effects as if they were a feature of rea",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 35
  },
  {
    "child_id": "f3cf1002-dc6f-44c9-8d27-f388a8b002d8",
    "parent_id": "fa46b508-8218-42d2-bf15-d0e189f19457",
    "text": "igure 1-4). \nPolicy resistance arises because we often do not understand the full range of \nfeedbacks operating in the system (Figure 1-4). As our actions alter the state of the \nsystem, other people react to restore the balance we have upset. Our actions may \nalso trigger side effects. \nGoals \\ \nProblem -b \nDecision -b \nResults \n7 \nSituation\n\nChapter 1 Learning in and about Complex Systems \n11 \nFIGURE 1-4 \nThe feedback view \nWe frequently talk about side effects as if they were a feature of reality. Not so. \nIn reality, there are no side effects, there are just effects. When we take action, there \nare various effects. The effects we thought of in advance, or were beneficial, we \ncall the main, or intended effects. The effects we didn\u2019t anticipate, the effects \nwhich fed back to undercut our policy, the effects which harmed the system-these \nare the ones we claim to be side effects. Side effects are not a feature of reality but \na sign that our understanding of the system is narrow and flawed. \nUnanticipated side effects arise because we too often act as if cause and effect \nwere always closely linked in time and space. But in complex systems such as an \nurban center or a hamster (or a business, society, or ecosystem) cause and effect are \noften distant in time and space. Narrow model boundaries often lead to beliefs that \nviolate the laws of physics: in the mid 1990s California and the automobile indus- \ntry debated the introduction of so-called zero emission vehicles (ZEVs) to reduce \nair pollution. True, the ZEVs-electric cars-would have no tailpipe. But the \npower plants required to make the electricity to run them do generate pollution. In \nreality, California was promoting the adoption of DEVs-displaced \nemission ve- \nhicles-cars whose wastes would blow downwind to other states or accumulate in \nnuclear waste dumps outside its borders. Electric cars may turn out to be an envi- \nronmental boon compared to internal combustion. The technology is improving \nrapidly, and air pollution is a major health problem in many cities. But no mode of \n/ \nDecisions \nJ \nEnvironment \nOur decisions alter our environment, leading to new decisions, \nEnvironment \nGoals<( \nOther \nAgents LAct;t;;sof \nbut also triggering side effects, delayed reactions, changes \nin goals and interventions by others. These feedbacks may \nlead to unanticipated results and ineffective policies.\n\n12 \nPart I Perspective and Process \ntransport or energy conversion process is free of environmental impact, and no \nlegislature can repeal the second law of  thermodynamic^.^ \nTo avoid policy resistance and find high leverage policies requires us to ex- \npand the boundaries of our mental models so that we become aware of and under- \nstand the implications of the feedbacks created by the decisions we make. That is, \nwe must learn about the structure and dynamics of the increasingly complex sys- \ntems in which we are embedded. \n1 .I -3 Feedback \nMuch of the art of system dynamics modeling is dis",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 35
  },
  {
    "child_id": "9de534c0-5915-4f1c-8e17-d41e377cade6",
    "parent_id": "fa46b508-8218-42d2-bf15-d0e189f19457",
    "text": "impact, and no \nlegislature can repeal the second law of  thermodynamic^.^ \nTo avoid policy resistance and find high leverage policies requires us to ex- \npand the boundaries of our mental models so that we become aware of and under- \nstand the implications of the feedbacks created by the decisions we make. That is, \nwe must learn about the structure and dynamics of the increasingly complex sys- \ntems in which we are embedded. \n1 .I -3 Feedback \nMuch of the art of system dynamics modeling is discovering and representing the \nfeedback processes, which, along with stock and flow structures, time delays, and \nnonlinearities, determine the dynamics of a system. You might imagine that there \nis an immense range of different feedback processes and other structures to be \nmastered before one can understand the dynamics of complex systems. In fact, the \nmost complex behaviors usually arise from the interactions (feedbacks) among the \ncomponents of the system, not from the complexity of the components themselves. \nAll dynamics arise from the interaction of just two types of feedback loops, \npositive (or self-reinforcing) and negative (or self-correcting) loops (Figure 1-5). \nPositive loops tend to reinforce or amplify whatever is happening in the system: \nThe more nuclear weapons NATO deployed during the Cold War, the more the So- \nviet Union built, leading NATO to build still more. If a firm lowers its price to gain \nmarket share, its competitors may respond in kind, forcing the firm to lower its \nprice still more. The larger the installed base of Microsoft software and Intel ma- \nchines, the more attractive the \u201cWintel\u201d architecture became as developers sought \nthe largest market for their software and customers sought systems compatible \nwith the most software; the more Wintel computers sold, the larger the installed \nbase. These positive loops are all processes that generate their own growth, lead- \ning to arms races, price wars, and the phenomenal growth of Microsoft and Intel, \nrespectively. \nNegative loops counteract and oppose change. The less nicotine in a cigarette, \nthe more smokers must consume to get the dose they need. The more attractive a \nneighborhood or city, the greater the inmigration from surrounding areas will be, \nincreasing unemployment, housing prices, crowding in the schools, and traffic \ncongestion until it is no more attractive than other places people might live. The \nhigher the price of a commodity, the lower the demand and the greater the pro- \nduction, leading to inventory accumulation and pressure for lower prices to elimi- \nnate the excess stock. The larger the market share of dominant firms, the more \nlikely is government antitrust action to limit their monopoly power. These loops \nall describe processes that tend to be self-limiting, processes that seek balance and \nequilibrium. \n3Even scientists suffer from these problems. I once heard a distinguished physicist argue that the \nsolution to the energy problem was to buil",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 35
  },
  {
    "child_id": "e555860f-6aca-4a07-8045-358d9e2f2ecb",
    "parent_id": "fa46b508-8218-42d2-bf15-d0e189f19457",
    "text": " the pro- \nduction, leading to inventory accumulation and pressure for lower prices to elimi- \nnate the excess stock. The larger the market share of dominant firms, the more \nlikely is government antitrust action to limit their monopoly power. These loops \nall describe processes that tend to be self-limiting, processes that seek balance and \nequilibrium. \n3Even scientists suffer from these problems. I once heard a distinguished physicist argue that the \nsolution to the energy problem was to build hundreds of huge offshore nuclear power stations, to be \ncooled by seawater. The warm wastewater would be pumped back in the ocean where, he said, \n\u201cThe waste heat would disappear.\u201d Out of sight, out of mind.\n\nChapter 1 Learning in and about Complex Systems \n13 \nFIGURE 1-5 \nPositive and negative feedback loops \nPositive feedback: Positive loops are self-reinforcing. \nIn this case, more chickens lay more eggs, which hatch \nand add to the chicken population, leading to still more \neggs, and so on. A Causal Loop Diagram or CLD (chap- \nter 5) captures the feedback dependency of chickens \nand eggs. The arrows indicate the causal relationships. \nThe + signs at the arrowheads indicate that the effect is \npositively related to the cause: an increase in the \nchicken population causes the number of eggs laid each \nday to rise above what it would have been (and vice \nversa: a decrease in the chicken population causes egg \nlaying to fall below what it would have been). The loop is \nself-reinforcing, hence the loop polarity identifier R. If \nthis loop were the only one operating, the chicken and \negg population would both grow exponentially. \nOf course, no real quantity can grow forever. There must \nbe limits to growth. These limits are created by negative \nfeedback. \nNegative feedback: Negative loops are self-correcting. \nThey counteract change. As the chicken population \ngrows, various negative loops will act to balance the \nchicken population with its carrying capacity. One clas- \nsic feedback is shown here: The more chickens, the \nmore road crossings they will attempt. If there is any \ntraffic, more road crossings will lead to fewer chickens \n(hence the negative - polarity for the link from road \ncrossings to chickens). An increase in the chicken popu- \nlation causes more risky road crossings, which then \nbring the chicken population back down. The B in the \ncenter of a loop denotes a balancing feedback. If the \nroad-crossing loop was the only one operating (say be- \ncause the farmer sells all the eggs), the number of \nchickens would gradually decline until none remained. \nAll systems, no matter how complex, consist of net- \nworks of positive and negative feedbacks, and all \ndynamics arise from the interaction of these loops \nwith one another. \nEggs \nChickens \n+u\nA system\u2019s feedback structure \nU \ngenerates its dynamics \nI\nTime \nStructure: n+\nChickens @ cr:Z:gs \n-u\nU I\nBehavior: \nChickens \nTime",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 35
  },
  {
    "child_id": "1fb35ce2-9fcd-4394-b29c-2303acd6615f",
    "parent_id": "67b90b9b-67a1-44cd-85a3-4466e401b94e",
    "text": "14 \nPart I Perspective and Process \n1 .I .4 Process Point: The Meaning of Feedback \nIn common parlance the term \u201cfeedback\u201d has come to serve as a euphemism for \ncriticizing others, as in \u201cthe boss gave me feedback on my presentation.\u201d This use \nof feedback is not what we mean in system dynamics. Further, \u201cpositive feedback\u201d \ndoes not mean \u201cpraise\u201d and \u201cnegative feedback\u201d does not mean \u201ccriticism.\u201d Posi- \ntive feedback denotes a self-reinforcing process, and negative feedback denotes a \nself-correcting one. Either type of loop can be good or bad, depending on which \nway it is operating and of course on your values. Reserve the terms positive and \nnegative feedback for self-reinforcing and self-correcting processes, and avoid de- \nscribing the criticism you give or receive to others as feedback. Telling someone \nyour opinion does not constitute feedback unless they act on your suggestions and \nthus lead you to revise your view. \nThough there are only two types of feedback loop, models may easily contain \nthousands of loops, of both types, coupled to one another with multiple time de- \nlays, nonlinearities, and accumulations. The dynamics of all systems arise from the \ninteractions of these networks of feedbacks. Intuition may enable us to infer the \ndynamics of isolated loops such as those shown in Figure 1-5. But when multiple \nloops interact, it is not so easy to determine what the dynamics will be. Before con- \ntinuing, try the challenge shown in Figure 1-6. When intuition fails, we usually \nturn to computer simulation to deduce the behavior of our models. \n1.2 \nLEARNING Is A FEEDBACK PROCESS \nJust as dynamics arise from feedback, so too all learning depends on feedback. We \nmake decisions that alter the real world; we gather information feedback about the \nreal world, and using the new information we revise our understanding of the \nworld and the decisions we make to bring our perception of the state of the system \ncloser to our goals (Figure 1-7). \nThe feedback loop in Figure 1-7 appears in many guises throughout the social \nsciences. George Richardson (1991), in his history of feedback concepts in the \nsocial sciences, shows how beginning in the 1940s leading thinkers in economics,\n\nChapter 1 Learning in and about Complex Systems \n15 \nFIGURE 1-7 \nLearning is a \nfeedback process. \nFeedback from the \nreal world to the \ndecision maker \nincludes all forms \nof information, \nboth quantitative \nand qualitative. \npsychology, sociology, anthropology, and other fields recognized that the con- \ncept of feedback developed in physics and engineering applied not only to servo- \nmechanisms but to human decision making and social settings as well. By 1961, \nForrester, in Industrial Dynamics, asserted that all decisions (including learning) \ntake place in the context of feedback loops. Later, the psychologist Powers (1973, \np. 351) wrote: \nFeedback is such an all-pervasive and fundamental aspect of behavior that it is as \ninvisible as the air that we breathe.",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 39
  },
  {
    "child_id": "114c98b2-8729-4dc5-8657-f9a613abde03",
    "parent_id": "67b90b9b-67a1-44cd-85a3-4466e401b94e",
    "text": "fields recognized that the con- \ncept of feedback developed in physics and engineering applied not only to servo- \nmechanisms but to human decision making and social settings as well. By 1961, \nForrester, in Industrial Dynamics, asserted that all decisions (including learning) \ntake place in the context of feedback loops. Later, the psychologist Powers (1973, \np. 351) wrote: \nFeedback is such an all-pervasive and fundamental aspect of behavior that it is as \ninvisible as the air that we breathe. Quite literally it is behavior-we know nothing \nof our own behavior but the feedback effects of our own outputs. \nThese feedback thinkers followed in the footsteps of John Dewey, who recognized \nthe feedback loop character of learning around the beginning of the 20th century \nwhen he described learning as an iterative cycle of invention, observation, reflec- \ntion, and action (Schon 1992). Feedback accounts of behavior and learning have \nnow permeated most of the social and management sciences. Learning as an ex- \nplicit feedback process has even appeared in practical management tools such as \nTotal Quality Management, where the so-called Shewhart-Deming PDCA cycle \n(Plan-Do-Check-Act) lies at the heart of the improvement process in the quality \nimprovement literature (Shewhart 1939; Shiba, Graham, and Walden 1993). \nThe single feedback loop shown in Figure 1-7 describes the most basic type of \nlearning. The loop is a classical negative feedback whereby decision makers com- \npare information about the state of the real world to various goals, perceive dis- \ncrepancies between desired and actual states, and take actions that (they believe) \nwill cause the real world to move towards the desired state. Even if the initial \nchoices of the decision makers do not close the gaps between desired and actual \nstates, the system might eventually reach the desired state as subsequent decisions \nare revised in light of the information received (see Hogarth 1981). When driving, \nI may turn the steering wheel too little to bring the car back to the center of my \nlane, but as visual feedback reveals the error, I continue to turn the wheel until the \ncar returns to the straight and narrow. If the current price for products of my firm \nis too low to balance orders with production, depleted inventories and long deliv- \nery delays may cause me to gradually raise price until I discover a price that clears \nthe market.4 \nI \nt \nInformation \nDecisions uFe\n4Depending on the time delays and other elements of dynamic complexity in the system, these \nexamples may not converge. It takes but little ice, fog, fatigue, or alcohol to cause an accident, and \nequilibrium eludes many industries that experience chronic business cycles.\n\n16 \nPart I Perspective and Process \nFIGURE 1-8 \nSingle-loop \nlearning: \ninformation \nfeedback is \ninterpreted by \nexisting mental \nmodels. \nThe learning \nfeedback operates \nin the context of \nexisting decision \nrules, strategies, \nculture, and \ninstitutions w",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 39
  },
  {
    "child_id": "eda6671e-4e48-4b3f-a76d-be1562762b7e",
    "parent_id": "67b90b9b-67a1-44cd-85a3-4466e401b94e",
    "text": " other elements of dynamic complexity in the system, these \nexamples may not converge. It takes but little ice, fog, fatigue, or alcohol to cause an accident, and \nequilibrium eludes many industries that experience chronic business cycles.\n\n16 \nPart I Perspective and Process \nFIGURE 1-8 \nSingle-loop \nlearning: \ninformation \nfeedback is \ninterpreted by \nexisting mental \nmodels. \nThe learning \nfeedback operates \nin the context of \nexisting decision \nrules, strategies, \nculture, and \ninstitutions which \nin turn are derived \nfrom our mental \nmodels. \nThe feedback loop shown in Figure 1-7 obscures an important aspect of the \nlearning process. Information feedback about the real world is not the only input \nto our decisions. Decisions are the result of applying a decision rule or policy to \ninformation about the world as we perceive it (see Forrester 1961, 1992). The poli- \ncies are themselves conditioned by institutional structures, organizational strate- \ngies, and cultural norms. These, in turn, are governed by our mental models \n(Figure 1-8). As long as the mental models remain unchanged, the feedback loop \nshown in the figure represents what Argyris (1985) calls single-loop learning, a \nprocess whereby we learn to reach our current goals in the context of our existing \nmental models. Single-loop learning does not result in deep change to our mental \nmodels-our understanding of the causal structure of the system, the boundary we \ndraw around the system, the time horizon we consider relevant-nor our goals and \nvalues. Single-loop learning does not alter our worldview. \nMental models are widely discussed in psychology and philosophy. Different \ntheorists describe mental models as collections of routines or standard operating \nprocedures, scripts for selecting possible actions, cognitive maps of a domain, ty- \npologies for categorizing experience, logical structures for the interpretation of \nlanguage, or attributions about individuals we encounter in daily life (Axelrod \n1976; Bower and Morrow 1990; Cheng and Nisbett 1985; Doyle and Ford 1998; \nGentner and Stevens 1983; Halford 1993; Johnson-Laird 1983; Schank and Abel- \nson 1977; Vennix 1990). The concept of the mental model has been central to sys- \ntem dynamics from the beginning of the field. Forrester (1961) stresses that all \ndecisions are based on models, usually mental models. In system dynamics, the \nterm \u201cmental model\u201d includes our beliefs about the networks of causes and effects \nthat describe how a system operates, along with the boundary of the model (which \nvariables are included and which are excluded) and the time horizon we consider \nrelevant-ur framing or articulation of a problem. \nMost of us do not appreciate the ubiquity and invisibility of mental models, \ninstead believing naively that our senses reveal the world as it is. On the contrary, \nI \nDecis ions \nt \nInformation \nFeedback \nStrategy, Structure, \nMental Models \nDecision Rules \nof Real World \nu\n\nChapter 1 Learning in and ab",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 39
  },
  {
    "child_id": "050a5d52-5e5a-49a9-ab29-98cf42cfb4e6",
    "parent_id": "67b90b9b-67a1-44cd-85a3-4466e401b94e",
    "text": " system operates, along with the boundary of the model (which \nvariables are included and which are excluded) and the time horizon we consider \nrelevant-ur framing or articulation of a problem. \nMost of us do not appreciate the ubiquity and invisibility of mental models, \ninstead believing naively that our senses reveal the world as it is. On the contrary, \nI \nDecis ions \nt \nInformation \nFeedback \nStrategy, Structure, \nMental Models \nDecision Rules \nof Real World \nu\n\nChapter 1 Learning in and about Complex Systems \n17 \nFIGURE 1-9 \nKanizsa triangle \nDo you see the \nbright white \ntriangle lying on \ntop of the three \ndark circles and a \nsecond triangle? \nour world is actively constructed (modeled) by our senses and brain. Figure 1-9 \nshows an image developed by psychologist Gaetano Kanizsa. The vast majority of \npeople see a bright white triangle resting on top of three circles and a second tri- \nangle with black edges. The illusion is extremely powerful (try to look at the fig- \nure and \u201cnot see\u201d the two triangles!). Research shows that the neural structures \nresponsible for the ability to see illusory contours such as the white triangle exist \nbetween the optic nerve and the areas of the brain responsible for processing visual \ninf~rmation.~ \nActive modeling occurs well before sensory information reaches the \nareas of the brain responsible for conscious thought.6 Powerful evolutionary pres- \nsures are responsible: Our survival depends so completely on the ability to rapidly \ninterpret our environment that we (and other species) long ago evolved structures \nto build these models automatically. Usually we are completely unaware these \nmental models even exist. It is only when a construction such as the Kanizsa tri- \nangle reveals the illusion that we become aware of our mental models. \nThe Kanizsa triangle illustrates the necessity of active and unconscious mental \nmodeling or construction of \u201creality\u201d at the level of visual perception. Modeling of \nhigher-level knowledge is likewise unavoidable and often equally unconscious. \nFigure 1-10 shows a mental model elicited during a meeting between my colleague \nFred Kofman and a team from a large global corporation. The company worked \nwith the Organizational Learning Center at MIT in the early 1990s to reduce \nthe total cycle time for their supply chain. At that time the cycle time was 182 days \nand they sought to cut it in half. The company viewed reductions in cycle time as \nessential for continued competitiveness and even corporate survival. With the \nG \n%ee Science, 256, (12 June 1992), pp. 1520-1521. \n6Even more obviously, our ability to see a three-dimensional world is the result of extensive \nmodeling by the visual processing system, since the retina images a planar projection of the visual \nfield.",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 39
  },
  {
    "child_id": "105f3cef-60e6-4c4c-a8f8-03e5556ef1fe",
    "parent_id": "bd21173f-795b-4225-a7df-e9a523b78335",
    "text": "18 \nFIGURE 1-10 \nMental model \nrevealed by \na diagram of a \ncompany\u2019s \nsupply chain \nThe figure has \nbeen simplified \ncompared to the \nactual chart to \nprotect company- \nconfidential \ninformation but is \ndrawn to scale. \nPart I Perspective and Process \nCurrent supply chain cycle time, 182 days; \ngoal, 50% reduction. \nManufacturing \nLead Time \nOrder Fulfillment \nLead Time \nCustomer \nAcceptance \nLead Time \nsupport of senior management, they assembled a team to address these issues. \nAt the first meeting the team presented background information, including \nFigure 1-10. \nThe figure shows the current cycle time divided into three intervals along a \nline: manufacturing lead time, order fulfillment lead time, and customer accep- \ntance lead time. Order fulfillment, which then required 22 days, occupies more \nthan half of the total length of the line, while the manufacturing lead time, then re- \nquiring 75 days (70 days due to suppliers), receives about one-fourth of the length. \nCustomer acceptance, then requiring 85 days, occupies only about one-eighth of \nthe total length. What the figure reveals is the prominence of order fulfillment op- \nerations in the mental models of the people on the team and the insignificance in \ntheir minds of suppliers and customers. It will come as no surprise that the mem- \nbers of the team all worked in functions contributing to order fulfillment. There \nwas not a single person at the meeting representing procurement, nor a single sup- \nplier representative, nor anyone from accounting, nor a single customer. Until Fred \npointed out this distortion, the members of the group were as unaware of the illu- \nsory character of their image of the supply line as we normally are of the illusory \ncontours our brains project onto the data transmitted by our optic nerves. The dis- \ntorted mental model of the supply chain significantly constrained the company\u2019s \nability to reduce cycle time: Even if order fulfillment could be accomplished in- \nstantly the organization would fall well short of its goal. \nThe type of reframing stimulated by Fred\u2019s intervention, denoted double-loop \nlearning by Argyris (1985), is illustrated in Figure 1 - 11. Here information feed- \nback about the real world not only alters our decisions within the context of exist- \ning frames and decision rules but also feeds back to alter our mental models. As \nour mental models change we change the structure of our systems, creating differ- \nent decision rules and new strategies. The same information, processed and inter- \npreted by a different decision rule, now yields a different decision. Altering the \nstructure of our systems then alters their patterns of behavior. The development of \nsystems thinking is a double-loop learning process in which we replace a reduc- \ntionist, narrow, short-run, static view of the world with a holistic, broad, long-term, \ndynamic view and then redesign our policies and institutions accordingly.\n\nChapter 1 Learning in and about Comple",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 43
  },
  {
    "child_id": "1cb19e2e-4fbf-46b9-994a-daea6f7be7e0",
    "parent_id": "bd21173f-795b-4225-a7df-e9a523b78335",
    "text": "es. The same information, processed and inter- \npreted by a different decision rule, now yields a different decision. Altering the \nstructure of our systems then alters their patterns of behavior. The development of \nsystems thinking is a double-loop learning process in which we replace a reduc- \ntionist, narrow, short-run, static view of the world with a holistic, broad, long-term, \ndynamic view and then redesign our policies and institutions accordingly.\n\nChapter 1 Learning in and about Complex Systems \n19 \nFIGURE 1-11 \nDouble-loop \nlearning \nFeedback from the \nreal world can also \nstimulate changes \nin mental models. \nSuch learning \ninvolves new \nunderstanding \nor reframing of \na situation and \nleads to new goids \nand new decision \nrules, not just \nnew decisions. \nf \nInformation \nFeedback \nI \nDecisions \nStrategy, ( Structure, \n-( \nMental Models :I \nDecision Rules \nof Real World \nv \n1.3 \nBARRIERS TO LEARNING \nFor learning to occur each link in the two feedback loops shown in Figure 1-11 \nmust work effectively and we must be able to cycle around the loops quickly \nrelative to the rate at which changes in the real world render existing knowledge \nobsolete. Yet in the real world, particularly the world of social action, these feed- \nbacks often do not operate well. More than two and a half centuries elapsed from \nthe first experiments showing that lemon juice could prevent and cure scurvy until \ncitrus use was mandated in the British merchant marine (Table 1-2). Learning in \nthis case was terribly slow, despite the enormous importance of the problem and \nTABLE 1-2 \nTeaching scurvy \ndogs new tricks \nTotal delay \nin learning: \n264 years. \nrn \nrn \nrn \nPrior to the 16OOs, scurvy (vitamin C deficiency) was the greatest killer of \nseafarers-more than battle deaths, storms, accidents, and all others \ncombined. \n1601 : Lancaster conducts a controlled experiment during an East India \nCompany voyage: \nThe crew on one ship received 3 tsp. of lemon juice daily; the crew on three \nother ships did not. \nResults: At the Cape of Good Hope 11 0 out of 278 sailors had died, most \nfrom scurvy. The crew receiving lemon juice remained largely healthy. \n1747: Dr. James Lind conducts a controlled experiment in which scurvy \npatients were treated with a variety of elixirs. Those receiving citrus were \ncured in a few days; none of the other treatments worked. \n1795: The British Royal Navy begins using citrus on a regular basis. Scurvy \nwiped out. \n1865: The British Board of Trade mandates citrus use. Scurvy wiped out in \nthe merchant marine. \n~~ \nSource: Mosteller (1981).\n\n20 \nSelective perception \nMissing feedback \nDelay \nBias, distortion, error \nAmbiguity \nImplementation failure \nGame playing \nInconsistency \nPerformance is goal \nPart I Perspective and Process \nStrategy, Structure, \nDecision Rules \nfrom mental models \nInability to infer dynamics \nFIGURE 1-12 \nImpediments \nto learning \nthe decisive evidence supplied by controlled experiments throughout the years. \nYou may",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 43
  },
  {
    "child_id": "58ab2537-1552-4715-9d0b-96cd7e415ed2",
    "parent_id": "bd21173f-795b-4225-a7df-e9a523b78335",
    "text": "andates citrus use. Scurvy wiped out in \nthe merchant marine. \n~~ \nSource: Mosteller (1981).\n\n20 \nSelective perception \nMissing feedback \nDelay \nBias, distortion, error \nAmbiguity \nImplementation failure \nGame playing \nInconsistency \nPerformance is goal \nPart I Perspective and Process \nStrategy, Structure, \nDecision Rules \nfrom mental models \nInability to infer dynamics \nFIGURE 1-12 \nImpediments \nto learning \nthe decisive evidence supplied by controlled experiments throughout the years. \nYou may reply that today we are much smarter and learn faster. Perhaps. Yet the \nrate of corporate and organizational failure remains high (for example, over one- \nthird of the Fortune 500 largest industrial firms in 1970 had disappeared by 1983 \n[de Geus 19971). Today the rate of change in our systems is much faster, and their \ncomplexity is much greater. The delays in learning for many pressing problems \nremain woefully long. In most settings we lack the ability to run experiments, \nand the delays between interventions and outcomes are much longer. As the \nrate of change accelerates throughout society, learning remains slow, uneven, and \ninadequate. \nFigure 1-12 shows the main ways in which each link in the learning feedbacks \ncan fail. These include dynamic complexity, imperfect information about the state \nof the real world, confounding and ambiguous variables, poor scientific reasoning \nskills, defensive routines, and other barriers to effective group processes, imple- \nmentation failure, and the misperceptions of feedback that hinder our ability to un- \nderstand the structure and dynamics of complex systems. \nMental Models \nMisperceptions of feedback \nUnscientific reasoning \nJudgmental biases \nDefensive routines\n\nChapter 1 Learning in and about Complex Systems \n21 \n1.3.1 \nDynamic Complexity \nMuch of the literature in psychology, economics, and other fields suggests learn- \ning proceeds via the simple negative feedback loops described in Figure 1- 11. Im- \nplicitly, the loops are seen as swift, linear, negative feedbacks that produce stable \nconvergence to an equilibrium or optimal outcome, just as immediate visual feed- \nback allows you to fill a glass of water without spilling. The real world is not so \nsimple. From the beginning, system dynamics emphasized the multiloop, multi- \nstate, nonlinear character of the feedback systems in which we live (Forrester \n1961). The decisions of any one agent form but one of many feedback loops that \noperate in any given system. These loops react to the decision maker\u2019s actions in \nways both anticipated and unanticipated; there may be positive as well as negative \nfeedback loops, and these loops will contain many stocks (state variables) and \nmany nonlinearities. Natural and human systems have high levels of dynamic com- \nplexity. Table 1-3 shows some of the characteristics of systems that give rise to \ndynamic complexity. \nMost people think of complexity in terms of the number of components in a \nsystem or the number o",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 43
  },
  {
    "child_id": "a8d74fe1-3d5b-4c34-ac97-6647616bbf50",
    "parent_id": "bd21173f-795b-4225-a7df-e9a523b78335",
    "text": "These loops react to the decision maker\u2019s actions in \nways both anticipated and unanticipated; there may be positive as well as negative \nfeedback loops, and these loops will contain many stocks (state variables) and \nmany nonlinearities. Natural and human systems have high levels of dynamic com- \nplexity. Table 1-3 shows some of the characteristics of systems that give rise to \ndynamic complexity. \nMost people think of complexity in terms of the number of components in a \nsystem or the number of combinations one must consider in making a decision. \nThe problem of optimally scheduling an airline\u2019s flights and crews is highly com- \nplex, but the complexity lies in finding the best solution out of an astronomical \nnumber of possibilities. Such needle-in-a-haystack problems have high levels of \ncombinatorial complexity (also known as detail complexity). Dynamic complex- \nity, in contrast, can arise even in simple systems with low combinatorial complex- \nity. The Beer Distribution Game (Sterman 1989b, chap. 17.4) provides an example: \nComplex and dysfunctional behavior arises from a very simple system whose rules \ncan be explained in 15 minutes. Dynamic complexity arises from the interactions \namong the agents over time. \nTime delays between taking a decision and its effects on the state of the system \nare common and particularly troublesome. Most obviously, delays reduce the num- \nber of times one can cycle around the learning loop, slowing the ability to accu- \nmulate experience, test hypotheses, and improve. Schneiderman (1988) estimated \nthe improvement half life-the time required to cut defects in half-in a wide \nrange of manufacturing firms. He found improvement half lives as short as a few \nmonths for processes with short delays, for example reducing operator error in a \njob shop, while complex processes with long time delays such as product develop- \nment had improvement half lives of several years or more.7 \nDynamic complexity not only slows the learning loop; it also reduces the \nlearning gained on each cycle. In many cases controlled experiments are prohibi- \ntively costly or unethical. More often, it is simply impossible to conduct controlled \nexperiments. Complex systems are in disequilibrium and evolve. Many actions \nyield irreversible consequences. The past cannot be compared well to current cir- \ncumstance. The existence of multiple interacting feedbacks means it is difficult to \nhold other aspects of the system constant to isolate the effect of the variable of \ninterest. Many variables change simultaneously, confounding the interpretation \n7Sterman, Repenning, and Kofman (1997) show how these differential improvement rates led to \ndifficulty at a leading semiconductor manufacturer.",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 43
  },
  {
    "child_id": "e78034fa-f8e7-42f0-a16d-11df56b595e2",
    "parent_id": "8d994fcd-92f0-42b8-b4f8-a95198c4777c",
    "text": "22 \nPart I Perspective and Process \nTABLE 1-3 \nDynamic \ncomplexity \nDynamic complexity arises because systems are \nDynamic: Heraclitus said, \u201cAll is change.\u201d What appears to be unchanging is, over a \nlonger time horizon, seen to vary. Change in systems occurs at many time scales, \nand these different scales sometimes interact. A star evolves over billions of years as \nit burns its hydrogen fuel, then can explode as a supernova in seconds. Bull markets \ncan go on for years, then crash in a matter of hours. \nTightly coupled: The actors in the system interact strongly with one another and \nwith the natural world. Everything is connected to everything else. As a famous \nbumper sticker from the 1960s proclaimed, \u201cYou can\u2019t do just one thing.\u201d \nGoverned by feedback: Because of the tight couplings among actors, our actions \nfeed back on themselves. Our decisions alter the state of the world, causing changes \nin nature and triggering others to act, thus giving rise to a new situation which then \ninfluences our next decisions. Dynamics arise from these feedbacks. \nNonlinear: Effect is rarely proportional to cause, and what happens locally in a sys- \nI \ntem (near the current operating point) often does not apply in distant regions (other \nstates of the system). Nonlinearity often arises from the basic physics of systems: In- \nsufficient inventory may cause you to boost production, but production can never fall \nbelow zero no matter how much excess inventory you have. Nonlinearity also arises \nas multiple factors interact in decision making: Pressure from the boss for greater \nachievement increases your motivation and effort-up to the point where you per- \nceive the goal to be impossible. Frustration then dominates motivation and you give \nup or get a new boss. \nHistory-dependent: Taking one road often precludes taking others and determines \nwhere you end up (path dependence). Many actions are irreversible: You can\u2019t un- \nscramble an egg (the second law of thermodynamics). Stocks and flows (accumu- \nlations) and long time delays often mean doing and undoing have fundamentally \ndifferent time constants: During the 50 years of the Cold War arms race the nuclear \nnations generated more than 250 tons of weapons-grade plutonium (239Pu). The half \nlife of 239Pu is about 24,000 years. \nstructure. Often, small, random perturbations are amplified and molded by the feed- \nback structure, generating patterns in space and time and creating path dependence. \nThe pattern of stripes on a zebra, the rhythmic contraction of your heart, the persis- \ntent cycles in the real estate market, and structures such as sea shells and markets \nall emerge spontaneously from the feedbacks among the agents and elements of the \nsystem. \nchange over time. Evolution leads to selection and proliferation of some agents while \nothers become extinct. Adaptation also occurs as people learn from experience, es- \npecially as they learn new ways to achieve their goals in the face of obstacles. Lear",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 47
  },
  {
    "child_id": "4ef5f0d3-5e99-497e-825c-dd951e21837a",
    "parent_id": "8d994fcd-92f0-42b8-b4f8-a95198c4777c",
    "text": "s on a zebra, the rhythmic contraction of your heart, the persis- \ntent cycles in the real estate market, and structures such as sea shells and markets \nall emerge spontaneously from the feedbacks among the agents and elements of the \nsystem. \nchange over time. Evolution leads to selection and proliferation of some agents while \nothers become extinct. Adaptation also occurs as people learn from experience, es- \npecially as they learn new ways to achieve their goals in the face of obstacles. Learn- \ning is not always beneficial, however. \nCounterintuitive: In complex systems cause and effect are distant in time and space \nwhile we tend to look for causes near the events we seek to explain. Our attention is \ndrawn to the symptoms of difficulty rather than the underlying cause. High leverage \npolicies are often not obvious. \nwhelms our ability to understand them. The result: Many seemingly obvious solutions \nto problems fail or actually worsen the situation. \nCharacterized by trade-offs: Time delays in feedback channels mean the long-run \nresponse of a system to an intervention is often different from its short-run response. \nHigh leverage policies often cause worse-before-better behavior, while low leverage \npolicies often generate transitory improvement before the problem grows worse. \nSelf-organizing: The dynamics of systems arise spontaneously from their internal \nAdaptive: The capabilities and decision rules of the agents in complex systems \nPolicy resistant: The complexity of the systems in which we are embedded over-\n\nChapter 1 Learning in and about Complex Systems \n23 \nof system behavior and reducing the effectiveness of each cycle around the learn- \ning loop. \nDelays also create instability in dynamic systems. Adding time delays to \nnegative feedback loops increases the tendency for the system to oscillate.8 Sys- \ntems from driving a car, to drinking alcohol, to raising hogs, to construction of \noffice buildings all involve time delays between the initiation of a control action \n(acceleratinghraking, deciding to \u201chave another,\u201d choosing to breed more hogs, \ndeveloping a new building) and its effects on the state of the system. As a result, \ndecision makers often continue to intervene to correct apparent discrepancies \nbetween the desired and actual state of the system even after sufficient corrective \nactions have been taken to restore the system to equilibrium. The result is over- \nshoot and oscillation: stop-and-go traffic, drunkenness, commodity cycles, and real \nestate boom-and-bust cycles (see chapter 17.4). Oscillation and instability reduce \nour ability to control for confounding variables and discern cause and effect, fur- \nther slowing the rate of learning. \n1.3.2 \nLimited Information \nWe experience the real world through filters. No one knows the current sales rate \nof their company, the current rate of production, or the true value of the order back- \nlog at any given time. Instead we receive estimates of these data based on samp",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 47
  },
  {
    "child_id": "5a0fcf78-7172-443d-922c-ebfe2778cee6",
    "parent_id": "8d994fcd-92f0-42b8-b4f8-a95198c4777c",
    "text": "ycles, and real \nestate boom-and-bust cycles (see chapter 17.4). Oscillation and instability reduce \nour ability to control for confounding variables and discern cause and effect, fur- \nther slowing the rate of learning. \n1.3.2 \nLimited Information \nWe experience the real world through filters. No one knows the current sales rate \nof their company, the current rate of production, or the true value of the order back- \nlog at any given time. Instead we receive estimates of these data based on sampled, \naveraged, and delayed measurements. The act of measurement introduces distor- \ntions, delays, biases, errors, and other imperfections, some known, others unknown \nand unknowable. \nAbove all, measurement is an act of selection. Our senses and information sys- \ntems select but a tiny fraction of possible experience. Some of the selection is hard- \nwired (we cannot see in the infrared or hear ultrasound). Some results from our \nown decisions. We define gross domestic product (GDP) so that extraction of non- \nrenewable resources counts as production rather than depletion of natural capital \nstocks and so that medical care and funeral expenses caused by pollution-induced \ndisease add to the GDP while the production of the pollution itself does not reduce \nit. Because the prices of most goods in our economic system do not include the \ncosts of resource depletion or environmental degradation, these externalities re- \nceive little weight in decision making (see Cobb and Daly 1989 for thoughtful dis- \ncussion of alternative measures of economic welfare). \nOf course, the information systems governing the feedback we receive can \nchange as we learn. They are part of the feedback structure of our systems. \nThrough our mental models we define constructs such as GDP or scientific re- \nsearch, create metrics for these ideas, and design information systems to evaluate \nand report them. These then condition the perceptions we form. Changes in our \nmental models are constrained by what we previously chose to define, measure, \n8Technically, negative loops with no time delays are first-order; the eigenvalue of the linearized \nsystem can only be real and oscillation is impossible. Adding delays (state variables) allows the \neigenvalues to become complex conjugates, yielding oscillatory solutions. Whether the oscillations \nof the linearized system are damped or expanding depends on the parameters. All else equal, the \nmore phase lag in a control loop, the less stable the system will be.\n\n24 \nPart I Perspective and Process \nand attend to. Seeing is believing and believing is seeing. They feed back on one \nanother. \nIn a famous experiment, Bruner and Postman (1949) showed playing cards to \npeople using a tachistoscope to control exposure time to the stimuli. Most could \nidentify the cards rapidly and accurately. They also included some anomalous \ncards, such as a black three of hearts or a red ten of spades. People took on average \nfour times as long to judge the anomalous ",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 47
  },
  {
    "child_id": "3b51fc91-43c5-4ef0-8917-9a3d92735f03",
    "parent_id": "8d994fcd-92f0-42b8-b4f8-a95198c4777c",
    "text": "l be.\n\n24 \nPart I Perspective and Process \nand attend to. Seeing is believing and believing is seeing. They feed back on one \nanother. \nIn a famous experiment, Bruner and Postman (1949) showed playing cards to \npeople using a tachistoscope to control exposure time to the stimuli. Most could \nidentify the cards rapidly and accurately. They also included some anomalous \ncards, such as a black three of hearts or a red ten of spades. People took on average \nfour times as long to judge the anomalous cards. Many misidentified them \n(e.g., they said three of spades or three of hearts when shown a black three of \nhearts). Some could not identify the card at all, even with very long exposure \ntimes, and grew anxious and confused. Only a small minority correctly identified \nthe cards. Bruner and Postman concluded, \u201cPerceptual organization is powerfully \ndetermined by expectations built upon past commerce with the environment.\u201d \nHenri Bergson put it more succinctly: \u201cThe eye sees only what the mind is pre- \npared to comprehend.\u201d \nThe self-reinforcing feedback between expectations and perceptions has been \nrepeatedly demonstrated in a wide variety of experimental studies (see Plous 1993 \nfor excellent discussion). Sometimes the positive feedback assists learning by \nsharpening our ability to perceive features of the environment, as when an experi- \nenced naturalist identifies a bird in a distant bush where the novice birder sees only \na tangled thicket. Often, however, the mutual feedback of expectations and per- \nception limits learning by blinding us to the anomalies that might challenge our \nmental models. Thomas Kuhn (1970) cited the Bruner-Postman study to argue that \na scientific paradigm suppresses the perception of data inconsistent with the para- \ndigm, makmg it hard for scientists to perceive anomalies that might lead to scien- \ntific revol~tion.~ \nAs one of many examples, the history of ozone depletion by chlorofluoro- \ncarbons (CFCs) shows the mutual dependence of expectation and perception is no \nlaboratory artifact but a phenomenon with potentially grave consequences for \nhumanity. \nThe first scientific papers describing the ability of CFCs to destroy atmos- \npheric ozone were published in 1974 (Molina and Rowland 1974; Stolarski and \nCicerone 1974). Yet much of the scientific community remained skeptical, and \ndespite a ban on CFCs as aerosol propellants, global production of CFCs remained \nnear its all time high. It was not until 1985 that evidence of a deep ozone hole in \nthe Antarctic was published (Farman, Gardiner, and Shanklin 1985). As described \nby Meadows, Meadows, and Randers (1992, pp. 151-152): \nThe news reverberated around the scientific world. Scientists at [NASA] . . . scram- \nbled to check readings on atmospheric ozone made by the Nimbus 7 satellite, mea- \nsurements that had been taken routinely since 1978. Nimbus 7 had never indicated \nan ozone hole. \n9Sterman (1985a) developed a formal model of Kuhn\u2019s theory, which showed tha",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 47
  },
  {
    "child_id": "2d4b3218-8024-4c1b-a0fc-c8c3596ff19f",
    "parent_id": "8d994fcd-92f0-42b8-b4f8-a95198c4777c",
    "text": "a deep ozone hole in \nthe Antarctic was published (Farman, Gardiner, and Shanklin 1985). As described \nby Meadows, Meadows, and Randers (1992, pp. 151-152): \nThe news reverberated around the scientific world. Scientists at [NASA] . . . scram- \nbled to check readings on atmospheric ozone made by the Nimbus 7 satellite, mea- \nsurements that had been taken routinely since 1978. Nimbus 7 had never indicated \nan ozone hole. \n9Sterman (1985a) developed a formal model of Kuhn\u2019s theory, which showed that the positive \nfeedback between expectations and perceptions suppressed the recognition of anomalies and the \nemergence of new paradigms. Sterman and Wittenberg (1999) extended the model to simulate \nthe competition among rival theories.",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 47
  },
  {
    "child_id": "ccea65ee-b1b8-4028-95d9-2cc4a4de9672",
    "parent_id": "1ecc4813-3591-4a52-a65e-d0edf3699814",
    "text": "Chapter 1 Learning in and about Complex Systems \n25 \nChecking back, NASA scientists found that their computers had been pro- \ngrammed to reject very low ozone readings on the assumption that such low \nreadings must indicate instrument error. \nThe NASA scientists\u2019 belief that low ozone readings must be erroneous led them \nto design a measurement system that made it impossible to detect low readings that \nmight have shown their belief to be wrong. Fortunately, NASA had saved the orig- \ninal, unfiltered data and later confirmed that ozone concentrations had indeed been \nfalling since the launch of Nimbus 7. Because NASA created a measurement sys- \ntem immune to disconfirmation the discovery of the ozone hole and resulting \nglobal agreements to cease CFC production were delayed by as much as 7 years. \nThose 7 years could be significant: ozone levels in Antarctica dropped to less than \none-third of normal in 1993, and current models show that even with full compli- \nance with the ban (there is a thriving black market in CFCs), atmospheric chlorine \nwill not begin to fall until the first decade of the 21st century, and then only slowly. \nData collected near Toronto in the early 1990s showed a 5% increase in cancer- \ncausing UV-B ultraviolet radiation at ground level, indicating that ozone depletion \nalready affects the heavily populated and agriculturally vital northern hemisphere \n(Culotta and Koshland 1993). The thinning of the ozone layer is a global phenom- \nenon, not just a problem for penguins. \n1.3.3 \nConfounding Variables and Ambiguity \nTo learn we must use the limited and imperfect information available to us to un- \nderstand the effects of our own decisions, so we can adjust our decisions to align \nthe state of the system with our goals (single-loop learning) and so we can revise \nour mental models and redesign the system itself (double-loop learning). Yet much \nof the information we receive is ambiguous. Ambiguity arises because changes in \nthe state of the system resulting from our own decisions are confounded with si- \nmultaneous changes in a host of other variables. The number of variables that \nmight affect the system vastly overwhelms the data available to rule out alternative \ntheories and competing interpretations. This identification problem plagues both \nqualitative and quantitative approaches. In the qualitative realm, ambiguity arises \nfrom the ability of language to support multiple meanings. In the opening solilo- \nquy of Richard ZZZ, the hump-backed Richard laments his deformity: \nAnd therefore, since I cannot prove a lover \nTo entertain these fair well-spoken days, \nI am determinbd to prove a villain \nAnd hate the idle pleasures of these days. \n(I, i, 28-31) \nDoes Richard celebrate his free choice to be evil or resign himself to a predestined \nfate? Did Shakespeare intend the double meaning? Rich, ambiguous texts, with \nmultiple layers of meaning often make for beautiful and profound art, along with \nemployment for literary cr",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 50
  },
  {
    "child_id": "b6dcb4d8-24d1-4e69-9f73-e03904446617",
    "parent_id": "1ecc4813-3591-4a52-a65e-d0edf3699814",
    "text": " hump-backed Richard laments his deformity: \nAnd therefore, since I cannot prove a lover \nTo entertain these fair well-spoken days, \nI am determinbd to prove a villain \nAnd hate the idle pleasures of these days. \n(I, i, 28-31) \nDoes Richard celebrate his free choice to be evil or resign himself to a predestined \nfate? Did Shakespeare intend the double meaning? Rich, ambiguous texts, with \nmultiple layers of meaning often make for beautiful and profound art, along with \nemployment for literary critics, but also make it hard to know the minds of others, \nrule out competing hypotheses, and evaluate the impact of our past actions so we \ncan decide how to act in the future.\n\n26 \nPart I Perspective and Process \nIn the quantitative realm, engineers and econometricians have long struggled \nwith the problem of uniquely identifying the structure and parameters of a system \nfrom its observed behavior. Elegant and sophisticated theory exists to delimit the \nconditions in which one can identify a system from its behavior alone. In practice \nthe data are too scarce and the plausible alternative specifications are too numer- \nous for statistical methods to discriminate among competing theories. The same \ndata often support wildly divergent models equally well, and conclusions based on \nsuch models are not robust. As Learner (1983) put it in an article entitled \u201cLet\u2019s \nTake the \u2018Con\u2019 Out of Econometrics\u201d: \nIn order to draw inferences from data as described by econometric texts, it is neces- \nsary to make whimsical assumptions . . . The haphazard way we individually and \ncollectively study the fragility of inferences leaves most of us unconvinced that any \ninference is believable.\u2019O \n1.3.4 \nBounded Rationality and the Misperceptions \nof Feedback \nDynamic complexity and limited information reduce the potential for learning and \nperformance by limiting our knowledge of the real world. But how wisely do we \nuse the knowledge we do have? Do we process the information we do get in the \nbest way and make the best decisions we can? Unfortunately, the answer is no. \nHumans are not only rational beings, coolly weighing the possibilities and \njudging the probabilities. Emotions, reflex, unconscious motivations, and other \nnonrational or irrational factors all play a large role in our judgments and behavior. \nBut even when we find the time to reflect and deliberate we cannot behave in a \nfully rational manner (that is, make the best decisions possible given the informa- \ntion available to us). As marvelous as the human mind is, the complexity of the real \nworld dwarfs our cognitive capabilities. Herbert Simon has best articulated the \nlimits on human decision-making ability in his famous \u201cprinciple of bounded ra- \ntionality,\u201d for which he won the Nobel Memorial Prize in economics in 1979: \nThe capacity of the human mind for formulating and solving complex problems is \nvery small compared with the size of the problem whose solution is required for ob- \njectively rational beh",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 50
  },
  {
    "child_id": "c6535a71-3b5e-4793-9b26-5bee42e3bb09",
    "parent_id": "1ecc4813-3591-4a52-a65e-d0edf3699814",
    "text": "le to us). As marvelous as the human mind is, the complexity of the real \nworld dwarfs our cognitive capabilities. Herbert Simon has best articulated the \nlimits on human decision-making ability in his famous \u201cprinciple of bounded ra- \ntionality,\u201d for which he won the Nobel Memorial Prize in economics in 1979: \nThe capacity of the human mind for formulating and solving complex problems is \nvery small compared with the size of the problem whose solution is required for ob- \njectively rational behavior in the real world or even for a reasonable approximation \nto such objective rationality. (Simon 1957, p. 198) \nFaced with the overwhelming complexity of the real world, time pressure, and lim- \nited cognitive capabilities, we are forced to fall back on rote procedures, habits, \nrules of thumb, and simple mental models to make decisions. Though we some- \ntimes strive to make the best decisions we can, bounded rationality means we of- \nten systematically fall short, limiting our ability to learn from experience. \nWhile bounded rationality affects all decision contexts, it is particularly acute \nin dynamic systems. Indeed, experimental studies show that people do quite poorly \nl0I am not arguing that econometrics should be abandoned, despite its difficulties. On the con- \ntrary, wise use of numerical data and statistical estimation is central to good system dynamics prac- \ntice, and more effort should be devoted to the use of these tools in simulation model development \nand testing. See chap. 2 1.\n\nChapter 1 Learning in and about Complex Systems \n27 \nTABLE 1-4 \nMisperceptions \nof feedback \nhave been \ndocumented \nin many \nexperimental \nstudies. \nin systems with even modest levels of dynamic complexity (Table 1-4). These \nstudies led me to suggest that the observed dysfunction in dynamically complex \nsettings arises from misperceptions offeedback. The mental models people use \nto guide their decisions are dynamically deficient. As discussed above, people \ngenerally adopt an event-based, open-loop view of causality, ignore feedback \nprocesses, fail to appreciate time delays between action and response and in the \nreporting of information, do not understand stocks and flows and are insensitive to \nnonlinearities that may alter the strengths of different feedback loops as a system \nevolves. \nSubsequent experiments show that the greater the dynamic complexity of the \nenvironment the worse people do relative to potential. Further, the experiments \nshow the misperceptions of feedback are robust to experience, financial incentives, \nexperience, and the presence of market institutions (see, e.g., Diehl and Sterman \n1993; Paich and Sterman 1993; Kampmann and Sterman 1998). \nThe robustness of the misperceptions of feedback and the poor performance \nthey cause are due to two basic and related deficiencies in our mental model. First, \nour cognitive maps of the causal structure of systems are vastly simplified com- \npared to the complexity of the systems themselves. S",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 50
  },
  {
    "child_id": "07800119-5903-4d27-8015-3b1eefb692cc",
    "parent_id": "1ecc4813-3591-4a52-a65e-d0edf3699814",
    "text": "s of feedback are robust to experience, financial incentives, \nexperience, and the presence of market institutions (see, e.g., Diehl and Sterman \n1993; Paich and Sterman 1993; Kampmann and Sterman 1998). \nThe robustness of the misperceptions of feedback and the poor performance \nthey cause are due to two basic and related deficiencies in our mental model. First, \nour cognitive maps of the causal structure of systems are vastly simplified com- \npared to the complexity of the systems themselves. Second, we are unable to infer \ncorrectly the dynamics of all but the simplest causal maps. Both are direct conse- \nquences of bounded rationality, that is, the many limitations of attention, memory, \nrecall, information processing capability, and time that constrain human decision \nmaking. \ne \ne \ne \ne \nIn a simple production-distribution system (the Beer Distribution Game), \npeople, from high school students to CEOs, generate costly fluctuations \n(business cycles). Average costs were more than 10 times greater than \noptimal (Sterman 1989b). \nSubjects responsible for capital investment in a simple multiplier-accelerator \nmodel of the economy generate large amplitude cycles even though con- \nsumer demand is constant. Average costs were more than 30 times greater \nthan optimal (Sterman 1989a). \nSubjects managing a firm in a simulated consumer product market generate \nthe boom and bust, price war, and shake-out characteristic of industries from \nvideo games to chain saws (Paich and Sterman 1993). \nParticipants in experimental asset markets repeatedly bid prices well above \nfundamental value, only to see them plummet when a \u201cgreater fool\u201d can no \nlonger be found to buy. These speculative bubbles do not disappear when \nthe participants are investment professionals, when monetary incentives are \nprovided, or when short-selling is allowed (Smith, Suchanek, and Williams \n1988). \nIn a forest fire simulation, many people allow their headquarters to burn \ndown despite their best efforts to put out the fire (Brehmer 1989). \nIn a medical setting, subjects playing the role of doctors order more tests \nwhile the (simulated) patients sicken and die (Kleinmuntz and Thomas \n1987).",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 50
  },
  {
    "child_id": "27e89b2a-3fc8-489f-a0d1-bbcd90e779b0",
    "parent_id": "abced29b-49ca-421b-a386-c405bd49cda7",
    "text": "28 \nPart I Perspective and Process \n1.3.5 \nFlawed Cognitive Maps \nCausal attributions are a central feature of mental models. We all create and update \ncognitive maps of causal connections among entities and actors, from the pro- \nsaic-if I touch a flame I will be burned-to the grand-the larger the government \ndeficit, the higher interest rates will be. Studies of cognitive maps show that few \nincorporate any feedback loops. Axelrod (1976) found virtually no feedback \nprocesses in studies of the cognitive maps of political leaders; rather, people tended \nto formulate intuitive decision trees relating possible actions to probable conse- \nquences-an event-level representation. Hall (1976) reports similar open-loop \nmental maps in a study of the publishing industry. Dorner (1980, 1996) found that \npeople tend to think in single strand causal series and had difficulty in systems with \nside effects and multiple causal pathways (much less feedback loops). Similarly, \nexperiments in causal attribution show people tend to assume each effect has a sin- \ngle cause and often cease their search for explanations when the first sufficient \ncause is found (see the discussion in PIOUS 1993). \nThe heuristics we use to judge causal relations lead systematically to cognitive \nmaps that ignore feedbacks, multiple interconnections, nonlinearities, time delays, \nand the other elements of dynamic complexity. The causal field or mental model of \nthe stage on which the action occurs is crucial in framing people\u2019s judgments of \ncausation (Einhorn and Hogarth 1986). Within a causal field, people use various \ncues to causality including temporal and spatial proximity of cause and effect, tem- \nporal precedence of causes, covariation, and similarity of cause and effect. These \nheuristics lead to difficulty in complex systems where cause and effect are often \ndistant in time and space, where actions have multiple effects, and where the de- \nlayed and distant consequences are different from and less salient than proximate \neffects (or simply unknown). The multiple feedbacks in complex systems cause \nmany variables to be correlated with one another, confounding the task of judging \ncause. However, people are poor judges of correlation. Experiments show people \ncan generally detect linear, positive correlations among variables if they are given \nenough trials and if the outcome feedback is accurate enough. However, we have \ngreat difficulty in the presence of random error, nonlinearity, and negative correla- \ntions, often never discovering the true relationship (Brehmer 1980). \nA fundamental principle of system dynamics states that the structure of the \nsystem gives rise to its behavior. However, people have a strong tendency to at- \ntribute the behavior of others to dispositional rather than situational factors, that is, \nto character and especially character flaws rather than the system in which these \npeople are acting. The tendency to blame the person rather than the system ",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 53
  },
  {
    "child_id": "7c3a3fd5-ded8-4e75-a3d9-251de4dd0a38",
    "parent_id": "abced29b-49ca-421b-a386-c405bd49cda7",
    "text": "nd negative correla- \ntions, often never discovering the true relationship (Brehmer 1980). \nA fundamental principle of system dynamics states that the structure of the \nsystem gives rise to its behavior. However, people have a strong tendency to at- \ntribute the behavior of others to dispositional rather than situational factors, that is, \nto character and especially character flaws rather than the system in which these \npeople are acting. The tendency to blame the person rather than the system is so \nstrong psychologists call it the \u201cfundamental attribution error\u201d (Ross 1977). In \ncomplex systems different people placed in the same structure tend to behave in \nsimilar ways. When we attribute behavior to personality we lose sight of how the \nstructure of the system shaped our choices. The attribution of behavior to individ- \nuals and special circumstances rather than system structure diverts our attention \nfrom the high leverage points where redesigning the system or governing policy \ncan have significant, sustained, beneficial effects on performance (Forrester 1969, \nchap. 6; Meadows 1982). When we attribute behavior to people rather than system \nstructure the focus of management becomes scapegoating and blame rather than\n\nChapter 1 Learning in and about Complex Systems \n29 \nthe design of organizations in which ordinary people can achieve extraordinary \nresults. l1 \n1.3.6 \nErroneous Inferences about Dynamics \nEven if our cognitive maps of causal structure were perfect, learning, especially \ndouble-loop learning, would still be difficult. To use a mental model to design a \nnew strategy or organization we must make inferences about the consequences of \ndecision rules that have never been tried and for which we have no data. To do so \nrequires intuitive solution of high-order nonlinear differential equations, a task far \nexceeding human cognitive capabilities in all but the simplest systems (Forrester \n1971a; Simon 1982). In many experimental studies, including Diehl and Sterman \n(1995) and Sterman (1989a), the participants were given complete knowledge of \nall structural relationships and parameters, along with perfect, comprehensive, and \nimmediate knowledge of all variables. Further, the systems were simple enough \nthat the number of variables to consider was small. Yet performance was poor and \nlearning was slow. Poor performance in these tasks is due to our inability to make \nreasonable inferences about the dynamics of the system despite perfect and com- \nplete knowledge of the system structure. \nPeople cannot simulate mentally even the simplest possible feedback system, \nthe first-order linear positive feedback 10op.l~ Such positive feedback processes are \ncommonplace, from the compounding of interest to the growth of populations. \nWagenaar and Sagaria (1975) and Wagenaar and Timmers (1978, 1979) showed \nthat people significantly underestimate exponential growth, tending to extrapolate \nlinearly rather than exponentially. Using more data poin",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 53
  },
  {
    "child_id": "4ef3c08c-14c6-41a0-ac81-93784c3f9683",
    "parent_id": "abced29b-49ca-421b-a386-c405bd49cda7",
    "text": "- \nplete knowledge of the system structure. \nPeople cannot simulate mentally even the simplest possible feedback system, \nthe first-order linear positive feedback 10op.l~ Such positive feedback processes are \ncommonplace, from the compounding of interest to the growth of populations. \nWagenaar and Sagaria (1975) and Wagenaar and Timmers (1978, 1979) showed \nthat people significantly underestimate exponential growth, tending to extrapolate \nlinearly rather than exponentially. Using more data points or graphing the data did \nnot help, and mathematical training did not improve performance. \nBounded rationality simultaneously constrains the complexity of our cognitive \nmaps and our ability to use them to anticipate the system dynamics. Mental mod- \nels in which the world is seen as a sequence of events and in which feedback, non- \nlinearity, time delays, and multiple consequences are lacking lead to poor \nperformance when these elements of dynamic complexity are present. Dysfunction \nin complex systems can arise from the misperception of the feedback structure of \nthe environment. But rich mental models that capture these sources of complexity \ncannot be used reliably to understand the dynamics. Dysfunction in complex sys- \ntems can arise from faulty mental simulation-the misperception of feedback \ndynamics. These two different bounds on rationality must both be overcome for \neffective learning to occur. Perfect mental models without a simulation capability \nyield little insight; a calculus for reliable inferences about dynamics yields sys- \ntematically erroneous results when applied to simplistic models. \n\"Repenning and Sterman (1999) show how the fundamental attribution error arose in a \nmajor manufacturing organization, thwarting their efforts to improve operations and product \ndevelopment. \nyields pure exponential growth, x = x,exp(gt); see chap. 8. \n12The first-order linear positive loop is represented by the differential equation dddt = gx and\n\n30 \nPart I Perspective and Process \n1.3.7 \nUnscientific Reasoning: \nJudgmental Errors and Biases \nTo learn effectively in a world of dynamic complexity and imperfect information \npeople must develop what Davis and Hogarth (1992) call \u201cinsight skills\u201d-the \nskills that help people learn when feedback is ambiguous: \n[Tlhe interpretation of feedback . . . needs to be an active and disciplined task gov- \nerned by the rigorous rules of scientific inference. Beliefs must be actively chal- \nlenged by seeking possible disconfirming evidence and asking whether alternative \nbeliefs could not account for the facts (emphasis in original). \nUnfortunately, people are poor intuitive scientists, generally failing to reason in ac- \ncordance with the principles of scientific method. For example, people do not gen- \nerate sufficient alternative explanations or consider enough rival hypotheses. \nPeople generally do not adequately control for confounding variables when they \nexplore a novel environment. People\u2019s judgments are",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 53
  },
  {
    "child_id": "d0161f4a-bad7-482d-850d-1ad3d8634da0",
    "parent_id": "abced29b-49ca-421b-a386-c405bd49cda7",
    "text": "onfirming evidence and asking whether alternative \nbeliefs could not account for the facts (emphasis in original). \nUnfortunately, people are poor intuitive scientists, generally failing to reason in ac- \ncordance with the principles of scientific method. For example, people do not gen- \nerate sufficient alternative explanations or consider enough rival hypotheses. \nPeople generally do not adequately control for confounding variables when they \nexplore a novel environment. People\u2019s judgments are strongly affected by the \nframe in which the information is presented, even when the objective information \nis unchanged. People suffer from overconfidence in their judgments (under- \nestimating uncertainty), wishful thinking (assessing desired outcomes as more \nlikely than undesired outcomes), and the illusion of control (believing one can pre- \ndict or influence the outcome of random events). People violate basic rules of \nprobability, do not understand basic statistical concepts such as regression to the \nmean, and do not update beliefs according to Bayes\u2019 rule. Memory is distorted by \nhindsight, the availability and salience of examples, and the desirability of out- \ncomes. And so on. Hogarth (1987) discusses 30 different biases and errors docu- \nmented in decision-making research and provides a good guide to the literature \n(see also Kahneman, Slovic, and Tversky 1982). The research convincingly shows \nthat scientists and professionals, not only \u201cordinary\u201d people, suffer from many of \nthese judgmental biases. \nAmong the failures of scientific reasoning most inimical to learning is the ten- \ndency to seek evidence consistent with current beliefs rather than potential discon- \nfirmation (Einhorn and Hogarth 1978; Klayman and Ha 1987). In a famous series \nof experiments, Wason and colleagues presented people tasks of the sort shown in \nFigure 1-13.13 Before continuing, try the challenge shown in the figure. \n13The summary of the Wason test is drawn from PIOUS (1993, chap. 20).",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 53
  },
  {
    "child_id": "9d68b256-33c1-40b4-b353-f0afb322825b",
    "parent_id": "75254704-11e2-401c-b8cd-3d8674f0b8bd",
    "text": "Chapter 1 Learning in and about Complex Systems \n31 \nIn one version you are shown one side of four cards, each with a letter on one \nside and a number on the other, say E, K, 4, and 7. You are told that if a card has a \nvowel on it, then it has an even number on the other side. You must then identify \nthe smallest set of cards to turn over to see if the proposed rule is correct. \nWason and Johnson-Laird (1972) found that the vast majority of subjects se- \nlected E or E and 4 as the answers. Less than 4% gave the correct answer: E and 7. \nThe rule has the logical form ifp, then q. Falsification requires observation of \np and not-q. The only card showing p is the E card, so it must be examined (the \nback of the E card must be an even number for the rule to hold). The only card \nshowing not-q is the 7, so it too must be examined. The K and 4 cards are irrele- \nvant. Yet people consistently choose the card showing q, a choice that can only \nprovide data consistent with the theory, but cannot test it; if the back of the 4 is a \nconsonant, you have learned nothing, since the rule is silent about the numbers as- \nsociated with consonants. Experiments show the tendency to seek confirmation is \nrobust in the face of training in logic, mathematics, and statistics. Search strategies \nthat focus only on confirmation of current beliefs slow the generation and recogni- \ntion of anomalies that might lead to learning, particularly double-loop learning. \nSome argue that while people err in applying the principles of logic, at least \npeople are rational in the sense that they appreciate the desirability of scientific ex- \nplanation. Unfortunately, the situation is far worse. The rational, scientific world- \nview is a recent development in human history and remains rare. Many people \nplace their faith in what Dostoyevsky\u2019s Grand Inquisitor called \u201cmiracle, mystery, \nand authority,\u201d for example, astrology, ESP, UFOs, creationism, conspiracy theo- \nries of history, channeling of past lives, cult leaders promising Armageddon, and \nElvis sightings. The persistence of such superstitious beliefs depends partly on the \nbias towards confirming evidence. Wade Boggs, former Boston Red Sox batting \nchampion, ate chicken every day for years because he once had a particularly good \nday at the plate after a dinner of lemon chicken (Shaughnessy 1987). During this \ntime Boggs won five batting championships, proving the wisdom of the \u201cchicken \ntheory.\u201d Consider the continued popularity of astrology, psychics, and economic \nforecasters, who publicize their successes and suppress their (more numerous) \nfailures. Remember that the 40th president of the United States and first lady man- \naged affairs of state on the basis of astrology (Robinson 1988). And it worked: He \nwas reelected in a landslide. \nSuch lunacy aside, there are deeper and more disturbing reasons for the preva- \nlence of these learning failures and the superstitions they engender. Human beings \nare more than cognitive ",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 56
  },
  {
    "child_id": "1bb70a64-6e02-4a75-8862-d88d07323382",
    "parent_id": "75254704-11e2-401c-b8cd-3d8674f0b8bd",
    "text": "trology, psychics, and economic \nforecasters, who publicize their successes and suppress their (more numerous) \nfailures. Remember that the 40th president of the United States and first lady man- \naged affairs of state on the basis of astrology (Robinson 1988). And it worked: He \nwas reelected in a landslide. \nSuch lunacy aside, there are deeper and more disturbing reasons for the preva- \nlence of these learning failures and the superstitions they engender. Human beings \nare more than cognitive information processors. We have a deep need for emo- \ntional and spiritual sustenance. But from Copernican heliocentrism through evolu- \ntion, relativity, quantum mechanics, and Godelian uncertainty, science has stripped \naway ancient and comforting beliefs placing humanity at the center of a rational \nuniverse designed for us by a supreme authority. For many people scientific \nthought leads not to enlightenment and empowerment but to existential angst and \nthe absurdity of human insignificance in an incomprehensibly vast universe. \nOthers believe science and technology were the shock troops for the triumph of \nmaterialism and instrumentalism over the sacred and spiritual. These antiscientific \nreactions are powerful forces. In many ways they are important truths. They have \nled to many of the most profound works of art and literature. But they can also lead \nto mindless new-age psychobabble.\n\n32 \nPart I Perspective and Process \nThe reader should not conclude from this discussion that I am a naive defender \nof science as it is practiced nor an apologist for the real and continuing damage \ndone to the environment and to our cultural, moral, and spiritual lives in the name \nof rationality and progress. On the contrary, I have stressed the research showing \nthat scientists are often as prone to the judgmental errors and biases discussed \nabove as laypeople. It is precisely because scientists are subject to the same cog- \nnitive limitations and moral failures as others that we experience abominations \nsuch as the US government funded research in which plutonium was injected into \nseriously ill patients, and in which radioactive calcium was fed to retarded chil- \ndren, all without their knowledge or consent (Mann 1994). A central principle of \nsystem dynamics is to examine issues from multiple perspectives; to expand the \nboundaries of our mental models to consider the long-term con.sequences and \u201cside \neffects\u201d of our actions, including their environmental, cultural, and moral implica- \ntions (Meadows, Richardson, and Bruckmann 1982). \n1.3.8 \nDefensive Routines and Interpersonal \nImpediments to Learning \nLearning by groups, whether system dynamics is used or not, can be thwarted even \nif participants receive excellent information feedback and reason well as individu- \nals. We rely on our mental models to interpret the language and acts of others, con- \nstruct meaning, and infer motives. However, as Forrester (1971) argues, \nThe mental model is fuzzy. It is inc",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 56
  },
  {
    "child_id": "23743377-bb11-4cb1-852f-2b32a4ae83b3",
    "parent_id": "75254704-11e2-401c-b8cd-3d8674f0b8bd",
    "text": "d moral implica- \ntions (Meadows, Richardson, and Bruckmann 1982). \n1.3.8 \nDefensive Routines and Interpersonal \nImpediments to Learning \nLearning by groups, whether system dynamics is used or not, can be thwarted even \nif participants receive excellent information feedback and reason well as individu- \nals. We rely on our mental models to interpret the language and acts of others, con- \nstruct meaning, and infer motives. However, as Forrester (1971) argues, \nThe mental model is fuzzy. It is incomplete. It is imprecisely stated. Furthermore, \nwithin one individual, a mental model changes with time and even during the flow \nof a single conversation. The human mind assembles a few relationships to fit the \ncontext of a discussion. As the subject shifts so does the model . . . [Elach partici- \npant in a conversation employs a different mental model to interpret the subject. \nFundamental assumptions differ but are never brought into the open. \nArgyris (1985), Argyris and Schon (1978), Janis (1982), Schein (1969, 1985, \n1987), and others document the defensive routines and cultural assumptions peo- \nple rely on, often unknowingly, to interact with and interpret their experience of \nothers. We use defensive routines to save face, assert dominance over others, make \nuntested inferences seem like facts, and advocate our positions while appearing to \nbe neutral. We make conflicting, unstated attributions about the data we receive. \nWe fail to distinguish between the sense-data of experience and the attributions and \ngeneralizations we readily form from them. We avoid publicly testing our hy- \npotheses and beliefs and avoid threatening issues. Above all, defensive behavior \ninvolves covering up the defensiveness and making these issues undiscussable, \neven when all parties are aware they exist. \nDefensive routines are subtle. They often arrive cloaked in apparent concern \nand respect for others. Consider the strategy called \u201ceasing-in:\u201d \nIf you are about to criticize someone who might become defensive and you want \nhim to see the point without undue resistance, do not state the criticism openly; in- \nstead, ask questions such that if he answers them correctly, he will figure out what \nyou are not saying (Argyris, Putnam, and Smith 1985, p. 83).\n\nChapter 1 Learning in and about Complex Systems \n33 \nBut easing-in often \nCreates the very defensiveness that it is intended to avoid, because the recipient \ntypically understands that the actor is easing-in. Indeed, easing-in can be successful \nonly if the recipient understands that he is supposed to answer the questions in a \nparticular way, and this entails the understanding that the actor is negatively evalu- \nating the recipient and acting as if this were not the case (Argyris, Putnam, and \nSmith 1985, p. 85). \nDefensive behavior, in which the espoused theories we offer to others differ from \nour theories in use, prevents learning by hiding important information from others, \navoiding public testing of importa",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 56
  },
  {
    "child_id": "9345f956-338c-444d-ae1d-6faf43b853d6",
    "parent_id": "75254704-11e2-401c-b8cd-3d8674f0b8bd",
    "text": "in can be successful \nonly if the recipient understands that he is supposed to answer the questions in a \nparticular way, and this entails the understanding that the actor is negatively evalu- \nating the recipient and acting as if this were not the case (Argyris, Putnam, and \nSmith 1985, p. 85). \nDefensive behavior, in which the espoused theories we offer to others differ from \nour theories in use, prevents learning by hiding important information from others, \navoiding public testing of important hypotheses, and tacitly communicating that \nwe are not open to having our mental models challenged. Defensive routines often \nyield groupthink (Janis 1982), where members of a group mutually reinforce their \ncurrent beliefs, suppress dissent, and seal themselves off from those with different \nviews or possible disconfirming evidence. Defensive routines ensure that the men- \ntal models of team members remain ill formed, ambiguous, and hidden. Thus \nlearning by groups can suffer even beyond the impediments to individual learning. \n1.3.9 Implementation Failure \nIn the real world decisions are often implemented imperfectly, further hindering \nlearning. Even if a team agreed on the proper course of action, the implementation \nof these decisions can be delayed and distorted as the actual organization responds. \nLocal incentives, asymmetric information, and private agendas can lead to game \nplaying by agents throughout a system. Obviously implementation failures can \nhurt the organization. Imperfect implementation can defeat the learning process as \nwell, because the management team evaluating the outcomes of their decisions \nmay not know the ways in which the decisions they thought they were implement- \ning were distorted. \nFinally, in the real world of irreversible actions and high stakes the need to \nmaintain performance often overrides the need to learn by suppressing new strate- \ngies for fear they would cause present harm even though they might yield great in- \nsight and prevent future harm. \nREQUIREMENTS FOR SUCCESSFUL LEARNING IN \nCOMPLEX SYSTEMS \nWe face grave impediments to learning in complex systems like a nation, firm, or \nfamily. Every link in the feedback loops by which we might learn can be weakened \nor cut by a variety of structures. Some of these are physical or institutional features \nof the environment-the elements of dynamic complexity that reduce opportuni- \nties for controlled experimentation, prevent us from learning the consequences of \nour actions, and distort the outcome feedback we do receive. Some are conse- \nquences of our culture, group process, and inquiry skills. Still others are funda- \nmental bounds on human cognition, particularly the poor quality of our mental \nmaps and our inability to make correct inferences about the dynamics of complex \nnonlinear systems.",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 56
  },
  {
    "child_id": "e03edb06-7f5a-4425-9e4c-5a34a7f390a9",
    "parent_id": "37f8df73-e147-4d74-9a9c-62a09279a92e",
    "text": "34 \nDecision Rules \nSimulation used to infer \ndynamics of mental \nPart I Perspective and Process \nMapping of feedback structure \nDisciplined application of \nscientific reasoning \nDiscussability of group \nFIGURE 1-14 \nIdealized learning \nprocess \nEffective learning \ninvolves \ncontinuous \nexperimentation \nin both the virtual \nworld and real \nworld. Feedback \nfrom both informs \nthe development \nof mental \nmodels, formal \nmodels, and \nthe design of \nexperiments for \nthe next iteration. \n1.4.1 \nImproving the Learning Process: \nVirtues of Virtual Worlds \nWhat then are the requirements for successful learning in complex systems? If we \nare to create useful protocols and tools for learning effectively in a world of dy- \nnamic complexity we must attend to all of the impediments to learning. Figure \n1-14 shows how the learning feedbacks would operate when all the impediments \nto learning are addressed. The diagram features a new feedback loop created by the \nuse of virtual worlds. Virtual worlds (the term is Schon\u2019s [ 19831) are formal mod- \nels, simulations, or \u201cmicroworlds\u201d (Papert 1980), in which decision makers can re- \nfresh decision-making skills, conduct experiments, and play. They can be physical \nmodels, role plays, or computer simulations. In systems with significant dynamic \ncomplexity, computer simulation will typically be needed (though there are notable \nexceptions, such as the Beer Distribution Game (Sterman 1989b) and the Mainte- \nnance Game described in section 2.4, along with role-playkomputer hybrids such \nUnknown structure \nDynamic complexity \nInability to conduct controlled \n\\ \nVirtual World \nKnown structure \nVariable level of complexity \nControlled experiments \nI \nI \nr \nDecisions \n\\ \n/ \nComplete, \nSelective perception \n[=]\u2018-\naccurate, \nMissing feedback \nfeedback \nBias, distortion, error \nInformation Feedback \nVirtual World: \nReal World: \nAmbiguity \n\\\n\nChapter 1 Learning in and about Complex Systems \n35 \nas Fish Banks, Ltd. (Meadows, Fiddaman, and Shannon 1993). Many of the tools \nof system dynamics are designed to help you develop useful, reliable, and effective \nmodels to serve as virtual worlds to aid learning and policy design. \nVirtual worlds have several virtues. First, they provide low-cost laboratories \nfor learning. The virtual world allows time and space to be compressed or dilated. \nActions can be repeated under the same or different conditions. One can stop the \naction to reflect. Decisions that are dangerous, infeasible, or unethical in the real \nsystem can be taken in the virtual world. Thus controlled experimentation becomes \npossible, and the time delays in the learning loop through the real world are dra- \nmatically reduced. In the real world the irreversibility of many actions and the need \nto maintain high performance often override the goal of learning by preventing ex- \nperiments with untried possibilities (\u201cIf it ain\u2019t broke, don\u2019t fix it\u201d). In the virtual \nworld you can try strategies that you suspect will lead t",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 59
  },
  {
    "child_id": "502f0a6f-c23f-4c60-906a-c9027d63b2cc",
    "parent_id": "37f8df73-e147-4d74-9a9c-62a09279a92e",
    "text": "l in the real \nsystem can be taken in the virtual world. Thus controlled experimentation becomes \npossible, and the time delays in the learning loop through the real world are dra- \nmatically reduced. In the real world the irreversibility of many actions and the need \nto maintain high performance often override the goal of learning by preventing ex- \nperiments with untried possibilities (\u201cIf it ain\u2019t broke, don\u2019t fix it\u201d). In the virtual \nworld you can try strategies that you suspect will lead to poor performance or even \n(simulated) catastrophe. Often pushing a system into extreme conditions reveals \nmore about its structure and dynamics than incremental adjustments to successful \nstrategies. Virtual worlds are the only practical way to experience catastrophe \nin advance of the real thing. Thus a great deal of the time pilots spend in flight \nsimulators is devoted to extreme conditions such as engine failure or explosive \ndecompression. \nVirtual worlds provide high-quality outcome feedback. In the People Express \nManagement Flight Simulator (Sterman 1988a), for example, and similar system \ndynamics simulations, players receive perfect, immediate, undistorted, and com- \nplete outcome feedback. In an afternoon one can gain years of simulated experi- \nence. The degree of random variation in the virtual world can be controlled. Virtual \nworlds offer the learner greater control over strategy, lead to more consistent deci- \nsion making, and deter implementation failure and game playing. In contrast to the \nreal world, which, like a black box, has a poorly resolved structure, virtual worlds \ncan be open boxes whose assumptions are fully known and can even be modified \nby the learner. \nVirtual worlds for learning and training are commonplace in the military, in \npilot training, in power plant operations, and in many other real time tasks where \nhuman operators interact with complex technical systems. Virtual worlds are also \ncommon in professions such as architecture and engineering that lend themselves \nto the use of physical models (Schon 1983). The use of virtual worlds in man- \nagerial tasks, where the simulation compresses into minutes or hours dynamics ex- \ntending over years or decades, is more recent and less widely adopted. Yet these \nare precisely the settings where dynamic complexity is most problematic, where \nthe learning feedbacks described above are least effective, and where the stakes are \nhighest. \n1.4.2 \nPitfalls of Virtual Worlds \nVirtual worlds are effective when they engage people in what Dewey called \u201cre- \nflective thought\u201d and what Schon (1992) calls \u201creflective conversation with the \nsituation.\u201d Though simulation models and virtual worlds may be necessary for \neffective learning in dynamically complex systems, they are not sufficient to over- \ncome the flaws in our mental models, scientific reasoning skills, and group \nprocesses.\n\n36 \nPart I Perspective and Process \nObviously, while the virtual world enables controlled experimen",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 59
  },
  {
    "child_id": "203d6f53-041d-4406-acfa-7c33bcfb0c8d",
    "parent_id": "37f8df73-e147-4d74-9a9c-62a09279a92e",
    "text": "ds are effective when they engage people in what Dewey called \u201cre- \nflective thought\u201d and what Schon (1992) calls \u201creflective conversation with the \nsituation.\u201d Though simulation models and virtual worlds may be necessary for \neffective learning in dynamically complex systems, they are not sufficient to over- \ncome the flaws in our mental models, scientific reasoning skills, and group \nprocesses.\n\n36 \nPart I Perspective and Process \nObviously, while the virtual world enables controlled experimentation, it does \nnot require the learner to apply the principles of scientific method. Many partici- \npants in system dynamics projects lack training in scientific method and awareness \nof the pitfalls in the design and interpretation of experiments. A commonly ob- \nserved behavior among modelers and in workshops using management flight sim- \nulators is the video game syndrome in which people play too much and think too \nlittle. People often do not take time to reflect on the outcome of a simulation, iden- \ntify discrepancies between the outcomes and their expectations, formulate hy- \npotheses to explain the discrepancies, and then devise experiments to discriminate \namong the competing alternatives. Effective learning using system dynamics will \noften require training for participants in scientific method. Protocols for the use of \nsimulations should be structured to encourage proper procedure, such as keeping \nlaboratory notebooks, explicitly formulating hypotheses and presenting them to the \ngroup, and so on. \nDefensive routines and groupthink can operate in the learning laboratory just \nas in the real organization. Indeed, protocols for effective learning in virtual worlds \nsuch as public testing of hypotheses, accountability, and comparison of different \nstrategies can be highly threatening, inducing defensive reactions that prevent \nlearning (Isaacs and Senge 1992). The use of system dynamics to stimulate learn- \ning in organizations often requires members of the client team to spend time ad- \ndressing their own defensive behavior. Managers unaccustomed to disciplined \nscientific reasoning and an open, trusting environment with learning as its goal will \nhave to build these basic skills before a system dynamics model-or indeed, any \nmodel-can prove useful. Developing these skills takes effort and practice. \nStill, settings with high dynamic complexity can garble the reflective conver- \nsation between the learner and the situation. Long time delays, causes and effects \nthat are distant in time and space, and the confounding effects of multiple nonlin- \near feedbacks can slow learning even for people with good insight and group \nprocess skills. Learning in virtual worlds can be accelerated when the modeling \nprocess also helps people learn how to represent complex feedback structures and \nunderstand their implications rather than simply presenting the results of an analy- \nsis. To learn in dynamically complex systems participants must have confidence \n",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 59
  },
  {
    "child_id": "82ae21fa-3c12-4020-8c57-18b258c38a2d",
    "parent_id": "37f8df73-e147-4d74-9a9c-62a09279a92e",
    "text": "effects \nthat are distant in time and space, and the confounding effects of multiple nonlin- \near feedbacks can slow learning even for people with good insight and group \nprocess skills. Learning in virtual worlds can be accelerated when the modeling \nprocess also helps people learn how to represent complex feedback structures and \nunderstand their implications rather than simply presenting the results of an analy- \nsis. To learn in dynamically complex systems participants must have confidence \nthat the model is an appropriate representation of the problem they care about. \nThey must believe it mimics the relevant parts of the real world well enough that \nthe lessons emerging from the virtual world apply to the real one. To develop such \nconfidence the virtual world must be an open box whose assumptions can be in- \nspected, criticized, and changed. To learn, participants must become modelers, not \nmerely players in a simulation game. \nIn practice, effective learning from models occurs best, and perhaps only, \nwhen the decision makers participate actively in the development of the model. \nModeling here includes the elicitation of the participants\u2019 existing mental models, \nincluding articulating the issues (problem structuring), selecting the model bound- \nary and time horizon, and mapping the causal structure of the relevant system. \nAlong with techniques developed in system dynamics, many tools and protocols \nfor group model-building are now available, including causal loop diagrams, \npolicy structure diagrams, interactive computer mapping, and various problem \nstructuring and soft systems methods (see, e.g., Checkland 1981; Eden, Jones and",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 59
  },
  {
    "child_id": "888ca3b7-71a9-4393-a07f-3f54ceac3a61",
    "parent_id": "b39f6723-e422-4e05-b3d9-6f96cf0a5414",
    "text": "Chapter 1 Learning in and about Complex Systems \n37 \nSims 1983; Lane 1994; Morecroft 1982; Morecroft and Sterman 1994; Reagan- \nCirincione et al. 1991; Richmond 1987, 1993; Rosenhead 1989; Senge and \nSterman 1992; and Wolstenholme 1990). \n1.4.3 \nWhy Simulation Is Essential \nEliciting and mapping the participants\u2019 mental models, while necessary, is far from \nsufficient. As discussed above, the temporal and spatial boundaries of our mental \nmodels tend to be too narrow. They are dynamically deficient, omitting feedbacks, \ntime delays, accumulations, and nonlinearities. The great virtue of many protocols \nand tools for elicitation is their ability to improve our models by encouraging peo- \nple to identify the elements of dynamic complexity normally absent from mental \nmodels. However, most problem structuring methods yield qualitative models \nshowing causal relationships but omitting the parameters, functional forms, exter- \nnal inputs, and initial conditions needed to fully specify and test the model. Re- \ngardless of the form of the model or technique used, the result of the elicitation and \nmapping process is never more than a set of causal attributions, initial hypotheses \nabout the structure of a system, which must then be tested. \nSimulation is the only practical way to test these models. The complexity of \nour mental models vastly exceeds our capacity to understand their implications. \nTypical conceptual models such as the type of causal diagram shown in Figure 1-6 \nare too large and complex to simulate mentally. Without simulation, even the best \nconceptual models can only be tested and improved by relying on the learning \nfeedback through the real world. As we have seen, this feedback is very slow and \noften rendered ineffective by dynamic complexity, time delays, inadequate and \nambiguous feedback, poor reasoning skills, defensive reactions, and the costs of \nexperimentation. In these circumstances simulation becomes the only reliable way \nto test hypotheses and evaluate the likely effects of policies. \nSome scholars argue that formal modeling can at best provide quantitative \nprecision within preexisting problem definitions but cannot lead to fundamentally \nnew conceptions (for various views see Dreyfus and Dreyfus 1986 and the discus- \nsion in Lane 1994). On the contrary, formalizing qualitative models and testing \nthem via simulation often leads to radical changes in the way we understand real- \nity. Simulation speeds and strengthens the learning feedbacks. Discrepancies \nbetween formal and mental models stimulate improvements in both, including \nchanges in basic assumptions such as model boundary, time horizon, and dynamic \nhypotheses (see Forrester 1985 and Homer 1996 for philosophy and examples). \nWithout the discipline and constraint imposed by the rigorous testing enabled by \nsimulation, it becomes all too easy for mental models to be driven by ideology or \nunconscious bias. \nSome argue that formalization forces the modeler to omit",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 62
  },
  {
    "child_id": "463f4421-2283-4f53-b045-2b3d8431c5d9",
    "parent_id": "b39f6723-e422-4e05-b3d9-6f96cf0a5414",
    "text": " feedbacks. Discrepancies \nbetween formal and mental models stimulate improvements in both, including \nchanges in basic assumptions such as model boundary, time horizon, and dynamic \nhypotheses (see Forrester 1985 and Homer 1996 for philosophy and examples). \nWithout the discipline and constraint imposed by the rigorous testing enabled by \nsimulation, it becomes all too easy for mental models to be driven by ideology or \nunconscious bias. \nSome argue that formalization forces the modeler to omit important aspects of \nthe problem to preserve tractability and enable theorems to be proved or to omit \nsoft variables for which no numerical data exist. These are indeed dangers. The lit- \nerature of the social sciences is replete with models in which elegant theorems are \nderived from questionable axioms, where simplicity dominates utility, and where \nvariables known to be important are ignored because data to estimate parameters \nare unavailable. System dynamics was designed specifically to overcome these\n\n38 \nPart I Perspective and Process \nlimitations and from the beginning stressed the development of useful models; \nmodels unconstrained by the demands of analytic tractability, based on realistic as- \nsumptions about human behavior, grounded in field study of decision making, and \nutilizing the full range of available data, not only numerical data, to specify and es- \ntimate relationships (see Forrester 1961, 1987). \nSome people don\u2019t believe that models of human behavior can be developed. \nSimulations of natural and technical systems such as the climate or an oil refinery \nare based on well-understood laws of physics, but, it is argued, there are no com- \nparably reliable laws of human behavior. This view overestimates our understand- \ning of nature and underestimates the regularities in human decision making. As \nKenneth Boulding points out, \u201cAnything that exists is possible.\u201d You will see many \nexamples of models of human systems throughout this book (see also the models \nin Levine and Fitzgerald 1992; Roberts 1978; Langley et al. 1987; Sterman 1985a; \nHomer 1985; and many of the models cited in Sastry and Sterman 1993). \nIs it possible to learn effectively in complex settings without simulation? Can \nthe use of problem structuring methods, elicitation techniques, and other qualita- \ntive systems methods overcome the impediments to learning? If intuition is devel- \noped highly enough, if systems thinking is incorporated in precollege education \nearly enough, or if we are taught how to recognize a set of \u201csystem archetypes\u201d \n(Senge 1990), will we be able to improve our intuition about complex dynamics \nenough to render simulation unnecessary? \nThe answer is clearly no. It is true that systems thinkmg techniques, including \nsystem dynamics and qualitative methods such as soft systems analysis, can en- \nhance our intuition about complex situations, just as studying physics can improve \nour intuition about the natural w0r1d.I~ As Wolstenholme (1990) a",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 62
  },
  {
    "child_id": "32f6b5ca-5058-4d6c-9fe2-46277ee4aa2f",
    "parent_id": "b39f6723-e422-4e05-b3d9-6f96cf0a5414",
    "text": ", or if we are taught how to recognize a set of \u201csystem archetypes\u201d \n(Senge 1990), will we be able to improve our intuition about complex dynamics \nenough to render simulation unnecessary? \nThe answer is clearly no. It is true that systems thinkmg techniques, including \nsystem dynamics and qualitative methods such as soft systems analysis, can en- \nhance our intuition about complex situations, just as studying physics can improve \nour intuition about the natural w0r1d.I~ As Wolstenholme (1990) argues, qualitative \nsystems tools should be made widely available so that those with limited mathe- \nmatical background can benefit from them. I am a strong advocate for the intro- \nduction of system dynamics and related methods at all levels of the educational \nsystem. Yet even if we all began serious study of physics in kindergarten and con- \ntinued it through a Ph.D., it is ludicrous to suggest that we could predict the track \nof a hurricane or understand by intuition alone what happens when two galaxies \ncollide. Many human systems are at least as complex. Even if children learn to \nthink in systems terms-a goal I believe is vitally important-it will still be nec- \nessary to develop formal models, solved by simulation, to learn about such sys- \ntems. \nMost important, when experimentation in real systems is infeasible, simulation \nbecomes the main, and perhaps the only, way you can discover for yourself how \ncomplex systems work. The alternative is rote learning based on the authority of \nthe teacher and textbook, a method that dulls creativity and stunts the development \nof the scientific reasoning skills needed to learn about complexity. \n14Such knowledge of basic physics is desperately needed. When asked the question \u201cIf a pen is \ndropped on the moon, will it (a) float away; (b) float where it is; (c) fall to the surface of the \nmoon?\u201d 48 out of 168 students in physics courses at Iowa State University gave incorrect answers. \nTypical student explanations were \u201cThe gravity of the moon can be said to be negligible\u201d and \u201cThe \nmoon\u2019s a vacuum, there is no external force on the pen. Therefore it will float where it is.\u201d (Partee, \npersonal communication, 1992).\n\nChapter 1 Learning in and about Complex Systems \n39 \n1.5 \nThe implications for this book are clear. System dynamics is not a spectator \nsport: Throughout the book I have tried to encourage the active participation of \nyou, the reader. You will find Challenges in each chapter-examples for you to \nconsider and work through yourself, such as the chicken and egg causal loop dia- \ngram in Figure 1-6 and the Wason card puzzle in Figure 1-13. Some of these are \nfollowed by a suggested response. Others are not. As you work through the book, \nextend the examples. Build the models. Experiment with them. Apply your skills \nto new problems and new issues. And, most of all, have fun.I5 \nS u NI MARY \nComplex dynamic systems present multiple barriers to learning. The challenge of \nbettering the way we learn about",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 62
  },
  {
    "child_id": "fe65ad7d-40b5-4296-b895-0aac1a8fe705",
    "parent_id": "b39f6723-e422-4e05-b3d9-6f96cf0a5414",
    "text": " work through yourself, such as the chicken and egg causal loop dia- \ngram in Figure 1-6 and the Wason card puzzle in Figure 1-13. Some of these are \nfollowed by a suggested response. Others are not. As you work through the book, \nextend the examples. Build the models. Experiment with them. Apply your skills \nto new problems and new issues. And, most of all, have fun.I5 \nS u NI MARY \nComplex dynamic systems present multiple barriers to learning. The challenge of \nbettering the way we learn about these systems is itself a classic systems problem. \nSystem dynamics is a powerful method to gain useful insight into situations of \ndynamic complexity and policy resistance. It is increasingly used to design more \nsuccessful policies in companies and public policy settings. However, no one \nmethod is a panacea. Overcoming the barriers to learning requires a synthesis of \nmany methods and disciplines, from mathematics and computer science to \npsychology and organizational theory. Theoretical studies must be integrated with \nfield work. Interventions in real organizations must be subjected to rigorous \nfollow-up research. \nThe field of system dynamics is itself dynamic. Recent advances in interactive \nmodeling, tools for representation of feedback structure, and simulation software \nmake it possible for anyone to engage in the modeling process. Corporations, uni- \nversities, and schools are experimenting vigorously. The library of successful in- \nterventions and insightful research is growing. Much further work is needed to test \nthe utility of the tools and protocols, evaluate their impact on individual and orga- \nnizational learning, and develop effective ways to train others to use them. Never \nbefore have the challenges of our increasingly dynamic world been more daunting. \nNever before have the opportunities been greater. It\u2019s an exciting time to be learn- \ning in and about complex systems. \nl5The accompanying CD-ROM and website (http://www.mhhe.com/sterman) \ninclude the models \ndeveloped in the text and simulation software you can use to run and extend them.\n\n2 \nSystem Dynamics in Action \n[System dynamics] is an approach that should help in important top- \nmanagement problems . . . The solutions to small problems yield small \nrewards. Very often the most important problems are but little more difficult to \nhandle than the unimportant. Many [people] predetermine mediocre results by \nsetting initial goals too low. The attitude must be one of enterprise design. The \nexpectation should be for major improvement. . . The attitude that the goal is \nto explain behaviol; which is fairly common in academic circles, is not \nsufficient. The goal should be to find management policies and organizational \nstructures that lead to greater success. \n-Jay W. Forrester (Industrial Dynamics, 1961, p. 449). \nThis chapter presents three case studies of the successful application of system dy- \nnamics to solve important real world problems. The cases span a range of indus- \n",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 62
  },
  {
    "child_id": "0f8a15cf-2b90-4bf2-84a8-44b8562a333d",
    "parent_id": "b39f6723-e422-4e05-b3d9-6f96cf0a5414",
    "text": "e \nexpectation should be for major improvement. . . The attitude that the goal is \nto explain behaviol; which is fairly common in academic circles, is not \nsufficient. The goal should be to find management policies and organizational \nstructures that lead to greater success. \n-Jay W. Forrester (Industrial Dynamics, 1961, p. 449). \nThis chapter presents three case studies of the successful application of system dy- \nnamics to solve important real world problems. The cases span a range of indus- \ntries and issues. They illustrate different contexts for the use of system dynamics \nand different modeling processes, from large, data intensive models to small mod- \nels, interactive management flight simulators, and role-playing games. The cases \nillustrate how system dynamics can be used to help solve high-stakes problems in \nreal time. The cases illustrate the principles discussed in chapter 1 and preview \nmany of the tools and methods discussed in subsequent chapters. \n2.1 \nAPPL-ICATIONS \nOF SYSTEM DYNAMICS \nSystem dynamics has been applied to issues ranging from corporate strategy to the \ndynamics of diabetes, from the cold war arms race between the US and USSR to \nthe combat between HIV and the human immune system. System dynamics can be \n41",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 62
  },
  {
    "child_id": "0adc8543-2426-422c-a0e0-bf8e1ff17a05",
    "parent_id": "4518ea93-6bb2-4cdd-af54-33dcf791a72f",
    "text": "42 \nPart I Perspective and Process \napplied to any dynamic system, with any time and spatial scale. In the world of \nbusiness and public policy, system dynamics has been applied to industries from \naircraft to zinc and issues from AIDS to welfare reform.\u2019 \nDeveloping an insightful model is difficult enough; using modeling to help \nchange organizations and implement new policies is even harder. The greatest po- \ntential for improvement comes when the modeling process changes deeply held \nmental models. Yet the more fundamental the mental model you challenge, the \nmore defensive the client may be. To resolve the dilemma the clients must discover \nthe insights for themselves by active participation in the modeling process. \nThis chapter presents three case studies illustrating the process. Each ad- \ndressed an important real world issue. Each involved a different context and there- \nfore used a different approach. Yet each also succeeded in involving the clients as \npartners in the modeling process, in changing long-established mental models, and \nin generating significant benefit. \n2.2 \nAUTOMOBILE LEASING STRATEGY: \nGONE TODAY, HERE TOMORROW* \nIn the 1990s a new way to buy cars emerged in the United States-the used car \nsuperstore. National chains like CarMax and AutoNation offered a large selection \nof clean, low mileage late model cars with warranties, roadside assistance plans, \nand other amenities traditionally available only to new car buyers. Superstore sales \ngrew from nothing in 1992 to more than $13 billion in 1998. Internet car vendors \nbegan to spring up as well. Many analysts believed the combination of superstores \nand internet sales heralded a revolution in the retail auto market. \nIn 1995 some senior managers at General Motors were concerned about the \nimpact of the superstores on new car sales. Would they cut into GM\u2019s core market? \nWould they force prices down? How could GM respond? Ron Zarella, then vice \npresident and group executive for North American vehicle sales, service, and mar- \nketing (VSSM) and later promoted to president of GM\u2019s North American region, \nneeded a way to examine these issues. \nThere was little research on the used car market available to help. For many \ndecades the new and used car markets were only loosely coupled because people \ntended to keep their cars a long time. Market research in the early 1990s showed \nnew car buyers were keeping their cars an average of more than 6 years. The bulk \nof used cars offered for sale were 4 or more years old and were poor substitutes for \nnew cars. The prevailing mental model in the auto industry, including GM, was \n\u2018Richardson (1996), Roberts (1978), and Morecroft and Sterman (1994), among others, provide \nexamples of the application of system dynamics to important problems in a wide range of industries \nand public policy issues. Mosekilde (1996) describes applications in physics and biology. Ford \n(1999) describes environmental applications. \n*This case is based on t",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 67
  },
  {
    "child_id": "94672ff3-db89-43ad-924a-0f83ab08ca61",
    "parent_id": "4518ea93-6bb2-4cdd-af54-33dcf791a72f",
    "text": " sale were 4 or more years old and were poor substitutes for \nnew cars. The prevailing mental model in the auto industry, including GM, was \n\u2018Richardson (1996), Roberts (1978), and Morecroft and Sterman (1994), among others, provide \nexamples of the application of system dynamics to important problems in a wide range of industries \nand public policy issues. Mosekilde (1996) describes applications in physics and biology. Ford \n(1999) describes environmental applications. \n*This case is based on the work of the General Motors Strategy Support Center, led by Nick \nPudar. I\u2019m grateful to Nick and GM for permission to present the case and to Nick and Mark Paich \nfor help in its preparation.\n\nChapter 2 System Dynamics in Action \n43 \nthat auto companies were in the business of selling new cars; the vehicles people \ntraded in were old and effectively disappeared into a separate system, the used car \nmarket. \u201cThere are really two markets-new and used,\u201d the executive director of \nsales operations at Ford told The Wall Street Journal in 1994 (3 June, p. B 1). \nZarella contacted Vince Barabba, then general manager of corporate strategy \nand knowledge development in the VSSM organization, and described his con- \ncerns. Barabba, former head of the US Census Bureau, also headed up the Decision \nSupport Center (DSC) and asked Nick Pudar, then a senior business analyst in the \nDSC, to work on the superstore issue. The DSC is an internal group GM formed to \nhelp business units and project teams throughout the company develop and imple- \nment strategy. The DSC uses a variety of analytical tools, including system dy- \nnamics. More than simply a group of analytical modelers, the DSC developed a \nsophisticated approach, the dialogue decision process, designed to build consensus \nthat leads to action, not merely analysis and reports. Barabba and Pudar (1996) de- \nscribe the dialogue decision process as \na disciplined decision making process which involves a series of structured dia- \nlogues between two groups responsible for reaching a decision and implementing \nthe resulting action plan. The first group (Decision Review Board) consists of the \ndecision-makers, who generally represent different functions. What they have in \ncommon is the authority to allocate resources: people, capital, materials, time, and \nequipment . . . The second group (Core Team), consists of. . . those with a stake in \nthe implementation. \nThe dialogue between the two groups, which involves sharing and learning for \nboth, takes place in four sequential stages: 1) framing the problem; 2) developing \nalternatives; 3) conducting the analysis; and 4) establishing connection. Each of \nthese four steps is completed by the Core Team and supported by facilitators \nequipped with decision analytic tools. At the end of each phase, they have a dia- \nlogue session with the Decision Review Board where they jointly review the \nprogress. In an atmosphere of inquiry . . . senior leadership converses with a cross",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 67
  },
  {
    "child_id": "477e7f69-400f-4de4-b581-eba1f093a5f1",
    "parent_id": "4518ea93-6bb2-4cdd-af54-33dcf791a72f",
    "text": "arning for \nboth, takes place in four sequential stages: 1) framing the problem; 2) developing \nalternatives; 3) conducting the analysis; and 4) establishing connection. Each of \nthese four steps is completed by the Core Team and supported by facilitators \nequipped with decision analytic tools. At the end of each phase, they have a dia- \nlogue session with the Decision Review Board where they jointly review the \nprogress. In an atmosphere of inquiry . . . senior leadership converses with a cross- \nfunctional team of managers on a topic of mutual strategic importance. \nPudar told Zarella he would need to commit to a several hour meeting each week \nfor a month \u201cto be sure we are working on the right problem.\u201d While Zarella\u2019s \nschedule was extremely tight he offered to meet with Barabba and Pudar the \nnext day. \nPudar, working with Mark Paich, an external system dynamics consultant and \nprofessor of economics at Colorado College, Darren Post of the DSC, and Tom Pa- \nterson (another consultant to the DSC) scrambled to develop an initial model of the \nissue. That afternoon they developed a simple diagram representing the stocks and \nflows of cars through the new and used markets and some of the feedbacks that \nmight couple them. They deliberately kept it very simple, both to be sure they \ncould complete it in time and so they could explain it clearly. \nThat night Pudar developed a simple, working simulation model of the inter- \nactions between the new and used markets. The model included sectors for \nnew and used cars (divided into GM and non-GM vehicles) and tracked vehicles \nfrom production through initial sale or lease, trade-in, the used car market, and,\n\n44 \nPart I Perspective and Process \nultimately, scrapping. It also tracked the flows of customers moving into and out \nof the market and included a simple consumer choice model for the newhsed pur- \nchase decision. Pudar used data at hand and his judgment to estimate parameters. \nFigure 2-lshows a simplified diagram of the initial model. The structure in \nblack captures the prevailing mental model focused on the new car market. The left \nside tracks the stocks and flows of vehicles. Starting at the top, the inventory of \nunsold new cars is increased by production and drained by new car sales. New car \nsales add to the stock of late model cars on the road. People sell or trade in their car \nand buy a new one with a frequency defined by the average trade-in time. \nFigure 2-1 also shows the main feedbacks operating in the new car market. \nManufacturers and dealers pay close attention to the stock of new cars. Inventory \ncoverage of about 45 days provides a good balance between the selection available \non dealer lots and carrying costs. Low coverage hurts sales because cars aren\u2019t \navailable; high inventories slash dealer and automaker profits as carrying costs bal- \nloon. If inventory coverage rises above normal, carmakers cut production, which \nhelps reduce inventories back to normal. The response ",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 67
  },
  {
    "child_id": "aafc090a-87b7-45a1-93c0-f60ddd4942f8",
    "parent_id": "4518ea93-6bb2-4cdd-af54-33dcf791a72f",
    "text": "rating in the new car market. \nManufacturers and dealers pay close attention to the stock of new cars. Inventory \ncoverage of about 45 days provides a good balance between the selection available \non dealer lots and carrying costs. Low coverage hurts sales because cars aren\u2019t \navailable; high inventories slash dealer and automaker profits as carrying costs bal- \nloon. If inventory coverage rises above normal, carmakers cut production, which \nhelps reduce inventories back to normal. The response of production to inventories \nforms the negative (balancing) Production Control feedback loop, B 1. However, \nautomakers are reluctant to cut production and in any case, it takes time. The delay \nin adjusting production means inventories tend to fluctuate around desired levels \nas demand varies. \nThe second main response to excess inventories is lower prices. When inven- \ntory coverage is high, dealers are more willing to cut their margins and manu- \nfacturers offer incentives such as cash-back and low annual percentage rates \n(APRs) on loans financed through their credit divisions. Lower prices make new \ncars more attractive relative to the cars people already own. People trade in their \nold cars sooner, boosting new car sales until inventories fall back to normal (the \nnegative Pricing loop, B2). \n2.2.1 \nDynamic Hypothesis \nChallenging the conventional wisdom, the team expanded the stock and flow struc- \nture to include late model used cars. Instead of disappearing, trade-ins add to in- \nventories of late model used cars on dealer lots or available for auction. When \nthese cars are purchased, they reenter the stock of late model cars on the road. The \nsum of the cars on the road and cars on dealer lots is the total stock of late model \nvehicles (shown by the large rectangle in Figure 2- 1); these cars gradually age into \nthe population of older cars and are eventually scrapped. The model used an \u201caging \nchain\u201d to keep track of the cars on the road and in used car inventories by 1-year \ncohorts. The aging chain (chapter 12) allowed the team to examine how the \nnumber of 1-, 2-, and 3-year-old cars on the road and for sale changed in response \nto sales. \nThe stock and flow perspective motivated the modeling team to ask where the \nsuperstores got the large inventories of attractive late model cars they required. \nPart of the answer was the growing quality of new cars. Stimulated by the high \nquality of foreign cars, particularly the Japanese imports, all manufacturers had\n\nChapter 2 System Dynamics in Action \n45 \nFIGURE 2-1 \nA simple model of the automobile market \nProduction \nControl \nq \nReinforcing \nBalancing \nFeedback \nRectangles represent stocks of cars; pipes and valves represent flows between \ncategories (chapter 6). Arrows and polarities (+ or -) indicate causal influences: \nAn increase in New Car Inventory leads to an increase in Inventory Coverage (and a \ndecrease leads to a decrease); an increase (decrease) in Inventory Coverage causes \nnew car pr",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 67
  },
  {
    "child_id": "e1759a95-a25a-42b6-b89d-40761dd9695c",
    "parent_id": "4518ea93-6bb2-4cdd-af54-33dcf791a72f",
    "text": "s had\n\nChapter 2 System Dynamics in Action \n45 \nFIGURE 2-1 \nA simple model of the automobile market \nProduction \nControl \nq \nReinforcing \nBalancing \nFeedback \nRectangles represent stocks of cars; pipes and valves represent flows between \ncategories (chapter 6). Arrows and polarities (+ or -) indicate causal influences: \nAn increase in New Car Inventory leads to an increase in Inventory Coverage (and a \ndecrease leads to a decrease); an increase (decrease) in Inventory Coverage causes \nnew car prices to decrease (increase); see chapter 5. Gray structure was not captured \nin the prevailing industry mental model in which new and used car markets do not \ninteract. \nPrice & APR \n-Late Model C \nLease \nTerm \nLease \nLease \u2019 Subveytion \nSubvention \nRelative \nAttractiveness \nof New Cars \nAverage \nTrade-In Time / \nv \nk",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 67
  },
  {
    "child_id": "b2f91fa9-e553-4543-8927-fc12b8b28367",
    "parent_id": "5c1cfe28-6975-4414-a02e-cd60c3f39ee4",
    "text": "46 \nPart I Perspective and Process \ninvested in major quality programs. Though there was still room for improvement, \nby the 1990s the quality and durability of new cars was significantly higher than in \nthe 1980s. \nBut quality improvement alone could not explain the rise of the superstores. \nBy the time most cars are traded in they are too old to compete against new cars \nand are unsuitable for the superstores. Quality improvements might even lengthen \nthe trade-in cycle time, reducing the supply of late model used cars. \nThe answer was leasing. In the early 1990s leasing was the hot new marketing \ntool in the automobile industry. Leasing offered what seemed to be a sure-fire way \nto boost sales. Rising quality meant the market value of 2-, 3-, and 4-year-old cars \nwas much higher relative to new cars than in the past. The higher the residual value \nat the end of a lease, the lower the lease payments. Leases also give customers the \noption to buy the car when the lease expires at the specified residual value, trans- \nferring the risk of fluctuations in the market value of used vehicles from the cus- \ntomer to the carmaker. Most important to the manufacturers, typical lease terms are \n2 to 4 years, stimulating sales by cutting the trade-in cycle time. Leasing increased \nfrom 4.1% of all new car sales in 1990 to more than 22% in 1997. \nFrom the perspective of the prevailing mental model, leasing was a boon. First, \nit stimulated sales. Whenever inventories rise carmakers could increase incentives \nfor leasing through lease subvention. Subvention lowers lease payments by as- \nsuming higher residuals, lower interest rates, or lower initial capitalization; typi- \ncally carmakers would raise residual values above guidebook values for used cars. \nLower lease payments boost the attractiveness of new cars and induce some people \nto trade their current car for a new leased vehicle (forming the balancing Lease \nIncentive loop B3 in Figure 2-1). Second, the shorter the average lease term, the \nshorter the trade-in time and the greater the sales (the balancing Lease Term loop \nB4). If all new car buyers switched to leases with an average term of 3 years, the \ntrade-in cycle time would be cut in half and new car sales would double-all else \nequal. \nThe modeling team quickly challenged the assumption that all else was equal. \nWhile a 6-year old car is a poor substitute for a new car, a 1- to 3-year-old car with \nlow mileage might be attractive to many people. As the growing volume of leases \nexpired the used car market could be flooded with high-quality nearly new cars. \nUsed car prices might plummet. Some people who might have traded their current \ncars for new ones opt instead for off-lease vehicles, raising the average trade-in \ntime and returning more late model used cars to the stock of cars on the road (the \nbalancing Used Car Market loop, B5). Leasing also shortens the average trade-in \ncycle time, raising the average quality of used cars for sale. More",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 71
  },
  {
    "child_id": "9da67497-5e7c-4a15-8e73-c26d2846f35d",
    "parent_id": "5c1cfe28-6975-4414-a02e-cd60c3f39ee4",
    "text": "wing volume of leases \nexpired the used car market could be flooded with high-quality nearly new cars. \nUsed car prices might plummet. Some people who might have traded their current \ncars for new ones opt instead for off-lease vehicles, raising the average trade-in \ntime and returning more late model used cars to the stock of cars on the road (the \nbalancing Used Car Market loop, B5). Leasing also shortens the average trade-in \ncycle time, raising the average quality of used cars for sale. More people opt for \noff-lease vehicles instead of buying new. The average trade-in time for the popula- \ntion as a whole rises, forming the balancing Used Car Quality loop, B6. Even more \ninteresting, the used market could feed back to affect the fraction of customers who \nchoose to buy their car when their lease expires. If, at lease end, used car prices are \nhigher than the residual value written into the lease, the customer can purchase the \ncar below market value. The customer retention fraction would rise. If, however, \nused car prices dropped below residual values, the retention fraction would fall as \nmore customers turned their cars back to the lessor. The inventory of late model\n\nChapter 2 System Dynamics in Action \n47 \ncars would rise and used car prices would drop still more, in a vicious cycle, the \npositive (self-reinforcing) Purchase Option loop, R1 .3 \nHowever, the feedbacks shown in gray operate with a long delay (roughly \nequal to the average lease term) and were poorly understood in the industry. Leas- \ning stimulates sales in the short-run. Unaware of the structure shown in gray in \nFigure 2-1, the experience of the early 1990s taught carmakers that leasing \nworks-and they diverted still more marketing dollars to subvention and shorter \nterms. \nInitial results suggested, however, that leasing would eventually create a glut \nof high-quality nearly new cars, depressing late model used car prices. New car \nsales would suffer as more consumers opted for cheap off-lease vehicles. The car- \nmakers\u2019 credit companies (General Motors Acceptance Corporation [GMAC], \nFord Credit Corporation, and Chrysler Credit Corporation) would face losses as \nmarket values fell short of the residual value they had booked and as fewer con- \nsumers exercised their option to buy, turning the car back to the lessors instead. \nThe following day Pudar and his team presented these results to Zarella, in- \ncluding the structure of the initial model and simulations showing the problems ag- \ngressive leasing could cause. By shortening trade-in cycle times through leasing \nand fleet sales, carmakers were creating a glut of high-quality used cars at attrac- \ntive prices. Superstores were simply the market response to the opportunity the \nmanufacturers themselves had created. \nUsed car superstores were only the symptom of a deeper problem-the leasing \npolicies of the carmakers. Leasing increased sales in the short run but set in motion \nfeedbacks that caused sales to slump when",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 71
  },
  {
    "child_id": "7ca843fe-d97f-4f75-b059-88cc5dc1e026",
    "parent_id": "5c1cfe28-6975-4414-a02e-cd60c3f39ee4",
    "text": "ms ag- \ngressive leasing could cause. By shortening trade-in cycle times through leasing \nand fleet sales, carmakers were creating a glut of high-quality used cars at attrac- \ntive prices. Superstores were simply the market response to the opportunity the \nmanufacturers themselves had created. \nUsed car superstores were only the symptom of a deeper problem-the leasing \npolicies of the carmakers. Leasing increased sales in the short run but set in motion \nfeedbacks that caused sales to slump when the leased vehicles reentered the mar- \nket. In the old days, people kept their cars long enough that trade-ins effectively \ndisappeared from concern. But in a world of short-term leases, new cars are gone \ntoday, here tomorrow. \nThe realization that superstores were an endogenous consequence of the car- \nmakers\u2019 own actions dramatically redefined the focus of the work. Initial model \nanalysis suggested GM should de-emphasize leasing, exactly counter to industry \ntrends. \nThese effects may seem obvious (especially now that you have read the de- \nscription of the model above), and auto industry executives did know that some \noff-lease cars would reenter the market. However, most discounted the possibility \nof any problems. In 1994, USA Today quoted a General Motors leasing executive \nwho said, \u201cThe demand for cars coming off leases is triple the supply. Lease-end \ncars have \u2018not created a bottleneck in the industry\u201d\u2019 (2 November). A Detroit-area \n3The Purchase Option loop is partially offset because customers turning their cars back to \nlessors purchase another vehicle. If lease customers used their purchase option to make a pure arbi- \ntrage play when used car prices fell below residual values by turning their cars in and immediately \nbuying identical ones at the lower market price, then the net effect of changes in the retention frac- \ntion would be zero. However, some customers turning their cars back to lessors will buy a new car \nor different used car, possibly from a competitor. On net a lower retention fraction for a given make \nand model will tend to push prices for that car down still more, triggering even lower retention. \nThese effects were captured in the full model but for clarity are not shown in Figure 2-1.\n\nPart I Perspective and Process \nCadillac dealer dismissed any linkage between the new and used markets for high- \nend cars, scoffing, \u201cYou\u2019ll never get a luxury buyer to take a car with 30,000 miles \non it\u201d (The Wall Street Journal, 3 June 1994). In the same article, The Journal went \non to note that Ford\u2019s executive director of sales operations \nargues that the industry has had a chronic shortage of good two-year-old cars to \nsell . . . \u201cThis [short-term leasing] brings the cars back at just the right time, when \ndemand is highest,\u201d he says. Moreover, the used-car market is at least twice as big \nas the new-car market and can easily absorb the projected volumes. \nThe underlying strength in used-car demand will safely absorb the volume o",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 71
  },
  {
    "child_id": "2709816f-f4cd-45c2-8a17-5a60717d4018",
    "parent_id": "5c1cfe28-6975-4414-a02e-cd60c3f39ee4",
    "text": "In the same article, The Journal went \non to note that Ford\u2019s executive director of sales operations \nargues that the industry has had a chronic shortage of good two-year-old cars to \nsell . . . \u201cThis [short-term leasing] brings the cars back at just the right time, when \ndemand is highest,\u201d he says. Moreover, the used-car market is at least twice as big \nas the new-car market and can easily absorb the projected volumes. \nThe underlying strength in used-car demand will safely absorb the volume of \nused vehicles coming off lease, without cannibalizing new-car sales,\u201d predicts . . . \n[an] auto securities analyst at Salomon Bros. \nThere appeared to be ample evidence to support these views. Used car sales grew \nfrom 37.5 million in 1990 to nearly 42 million in 1995 while 1995 new car sales \nwere about 15 million, a rise of only about a million vehicledyear since 1990. \nUsed car prices rose more than 6%/year between 1990 and 1995, much faster than \ninflation. With rising used car prices, more and more people opted to keep their ve- \nhicle when their lease expired. Many in the industry, including GM, argued that \nstrong demand and rising used car values justified even higher residual values, al- \nlowing lower lease payments and boosting new car sales still more. \nWhile the initial results were intriguing, more work was needed before credi- \nble policy recommendations could be made, much less any action taken. Even if \nleasing was a devil\u2019s bargain, every carmaker felt strong pressure to match the \nterms and prices of its competitors. Once all major manufacturers were offering \nshort lease terms with aggressive subvention, unilaterally backing away from leas- \ning might risk too much market share. Zarella asked the team to continue the mod- \neling to address these questions. The DSC formed a decision review board, chaired \nby Zarella and Barabba, to oversee the project and the modeling team then began \nto refine the model and gather the data needed to calibrate it. They had 20 days. \n2.2.2 \nElaborating the Model \nThe modeling team interviewed people throughout the organization to understand \nthe issues and gather data. Through the meetings of the core and modeling teams \nthey opened up the model to critical review and presented interim results for \ndiscussion. \nOne area for improvement was the treatment of the competition and segmen- \ntation of the market into different vehicle types. Some argued for explicit treatment \nof every major manufacturer and market segment. Brand loyalty is important: \nPeople who bought GM cars last time are more likely to buy another GM car than \nnon-GM owners. They also argued that GM customers were different from Ford or \nHonda customers and that markets for luxury cars, family sedans, sport utility ve- \nhicles, and so on were all different. The team countered that the data requirements \nfor such a detailed model would be enormous and would delay development of a \nuseful model. They preferred an iterative approach, with mor",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 71
  },
  {
    "child_id": "80340550-6f1c-4491-aaf0-66a49f342d70",
    "parent_id": "5c1cfe28-6975-4414-a02e-cd60c3f39ee4",
    "text": "ent. Brand loyalty is important: \nPeople who bought GM cars last time are more likely to buy another GM car than \nnon-GM owners. They also argued that GM customers were different from Ford or \nHonda customers and that markets for luxury cars, family sedans, sport utility ve- \nhicles, and so on were all different. The team countered that the data requirements \nfor such a detailed model would be enormous and would delay development of a \nuseful model. They preferred an iterative approach, with more limited disaggrega- \ntion; if sensitivity analysis showed that further segmentation was needed they \ncould then revise the model to include more detail. The team agreed to separate the",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 71
  },
  {
    "child_id": "adf883e2-7884-4e46-9f28-a6b7d634abb5",
    "parent_id": "38934d12-6c2d-46d2-9991-8abb4f586563",
    "text": "Chapter 2 System Dynamics in Action \n49 \nFIGURE 2-2 \nThe matrix shows \nthe probability \np(i, j) that cus- \ntomers in each \ncategory shown \nin row i will, on \ntrade-in, move \nto the category \nin column j. \nThe transition \nprobabilities in \nthe full model \nare variable and \ndepend on relative \nprices. The full \nmatrix disaggre- \ngates GM and \nnon-GM vehicles. \nmarket into GM and non-GM vehicles but to represent only a single aggregate \nvehicle type. \nAnother important area of discussion was disaggregation of the customer base. \nParallel to the flow of cars between the \u201con the road\u201d and \u201cfor sale\u201d stocks are \nstocks and flows of drivers. Every car traded in moves a customer from \u201con the \nroad\u201d to \u201cin the market;\u201d every new or used car sold puts a driver on the road \nagain. Changes in the relative attractiveness of new and used cars shift the propor- \ntion of drivers in the market opting for a new car. The choice between new and \nused vehicles also depends on their past behavior. The chance a customer will \nlease, buy new, or buy used depends on whether he or she leased, bought new, or \nbought used last time. Some members of the organization pointed out that the com- \npany, through extensive market research, already knew a lot about consumer be- \nhavior in the new car market. They insisted that the dynamic model incorporate \nthese data so the DSC could speak with one voice and avoid the need to reconcile \nconflicting models. \nTo address the brand loyalty and consumer behavior issues the modeling team \ndisaggregated the customer base into several categories: those who leased a new \ncar, purchased a new car, or purchased used cars of various ages. Figure 2-2 shows \na simplified representation of the resulting transition matrix. Each entry in the ma- \ntrix is the probability that buyers coming from a particular category shown in a row \nwill, when they next trade in, move to the categories shown in the columns. The \nactual matrix had twice as many categories as it included probabilities for each \npurchase option for both GM and non-GM vehicles. \nThe transition probabilities in the matrix were not constant but changed as \nthe prices of new and used cars changed. Lower payments on GM leases increase \nNew Car Purchase \nNew Car Lease \n1 -Yr-Old Used Car \n2-Yr-Old Used Car \n3-Yr-Old Used Car \n4-Yr-Old Used Car \nSource: Adapted from GM Decision Support Center diagram. Used with \npermission.\n\n50 \nPart I Perspective and Process \nthe proportion opting for a GM lease, while lower used car prices increase the \nshare of people buying used cars at the expense of new purchases and leases. The \nresponse to such changes differed for each category of customer. \nThe disaggregation of the model was not accomplished in one step but in sev- \neral iterations. At each stage modeling team members made sure they understood \nthe structure and behavior of the model and presented it to Zarella and his team for \ncomment and review. Each iteration they incorporated the criticisms and",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 74
  },
  {
    "child_id": "31708dfd-722c-4aa0-9aab-c67ddcdb7a6e",
    "parent_id": "38934d12-6c2d-46d2-9991-8abb4f586563",
    "text": " lower used car prices increase the \nshare of people buying used cars at the expense of new purchases and leases. The \nresponse to such changes differed for each category of customer. \nThe disaggregation of the model was not accomplished in one step but in sev- \neral iterations. At each stage modeling team members made sure they understood \nthe structure and behavior of the model and presented it to Zarella and his team for \ncomment and review. Each iteration they incorporated the criticisms and sugges- \ntions they received. Even with the limited disaggregation of the model the data \nchallenges were formidable. Given the 20-day deadline, the team had to use data \nalready available in various parts of the organization. The market research data for \nnew cars were excellent. Data on leasing, a relatively new phenomenon, were \nsketchy. And consistent with the prevailing mental model that downplayed the \nused car market, there was almost no research describing how people traded off \nnew and late model used vehicles. They drew on the best data sources available \nand used judgment and qualitative data where numerical data were not available. \nAt the end of the 20 days the team met again with Zarella and his team. Instead \nof presenting the model and results, they configured the model as an interactive \nmanagement flight simulator. A \u201cdashboard\u201d contained dials and gauges reporting \nstandard accounting information such as inventory levels, sales volumes, prices, \nmarket share, and profitability. Players set production targets, incentives, lease \nterms, and so on. By clicking a button on the screen players could get additional in- \nformation including the structure and assumptions of the model. \nBy playing the game instead of listening to a presentation, Zarella and his team \nexplored the dynamics of leasing for themselves. They could try various strategies, \nfrom aggressive subvention of leases to pulling out of the lease market altogether, \nand see the impact on sales and profits in the short run and the long run. They dis- \ncovered that the full impact of leasing decisions took up to 5 years to play out. \nWhile leasing did provide a lift to sales in the short run, it often caused problems \nwhen the off-lease cars returned to the market. \nAfter 20 days the modeling process revealed the challenges leasing posed for \nthe company and indicated preliminary policy recommendations. However, before \nany consensus for action could be developed, the process had to be broadened to \ninclude other key decision makers throughout North American Operations (NAO). \nThe modeling team began to work with the Leasing Strategy Implementation \nTeam, a task force including people from marketing, finance, and other functions. \nTheir mandate was to boost market share and profitability. They didn\u2019t think a \nmodel was necessary, didn\u2019t trust the modeling approach, and opposed the initial \nrecommendations. Viewed through the lens of their mental model, this posi- \ntion was entirel",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 74
  },
  {
    "child_id": "240deea7-acc0-468d-8a0e-775be72695f6",
    "parent_id": "38934d12-6c2d-46d2-9991-8abb4f586563",
    "text": "dened to \ninclude other key decision makers throughout North American Operations (NAO). \nThe modeling team began to work with the Leasing Strategy Implementation \nTeam, a task force including people from marketing, finance, and other functions. \nTheir mandate was to boost market share and profitability. They didn\u2019t think a \nmodel was necessary, didn\u2019t trust the modeling approach, and opposed the initial \nrecommendations. Viewed through the lens of their mental model, this posi- \ntion was entirely rational. The success of leasing and strength of the used car \nmarket provided ample evidence that competitive leasing was essential to GM\u2019s \nstrategy. \nWorking with your critics is often the best way to improve your understanding \nof complex issues. Over the next few months the modeling team refined the model \nstructure, improved the data and calibration, and tested the model over a wide \nrange of conditions. They met with the leasing team about once a month to present \ninterim results and listen to critiques.\n\nChapter 2 System Dynamics in Action \n51 \n2.2.3 \nPolicy Analysis \nFIGURE 2-3 \nPolicy analysis \nThe policy matrix \nshows the \nsiinulated net \npresent value \n(NPV) of GM \nprofits as a \nfunction of GM\u2019s \nlensing policy \n(no leasing or 2- to \n4-year terms) for \neach combination \nof economic \nscenario and \ncompetitor \nstrategy. \nAs their confidence in the formulations and calibration of the model grew, the team \nturned to policy analysis. Policy levers include lease terms and subvention levels, \nalong with purchase incentives, fleet sales, and various decision rules for produc- \ntion, The impact of each policy combination depended on the policies of the com- \npetitors and a host of market uncertainties, from changes in the economy, \ndemographics, gasoline prices, and interest rates to changes in the unit costs of \neach carmaker, car quality, and brand loyalty. \nThe combination of policies and market scenarios define a policy matrix. The \nteam used the model to find the optimal lease policies for each cell in the matrix. \nFigure 2-3 shows a sample illustrating the net present value of GM profits as a \nfunction of leasing policy (no leasing vs. 2-, 3-, or 4-year terms) for each combi- \nnation of competitor lease terms and economic growth scenario (stable, boom, or \nrecession). \nThe policy analysis showed that there was no going back: Profits without leas- \ning were consistently negative, reflecting the attractiveness of leasing to consumers \nand the prisoner\u2019s dilemma that unilaterally stopping leasing while competitors \ncontinued to offer it dramatically reduced GM sales. \nThe analysis also showed that GM\u2019s profits were consistently higher with 4- \nyear lease terms. Four-year terms were superior over a wide range of competitor \nstrategies and uncertainties. Longer terms have two main beneficial effects. First, \nthough shorter terms do shorten the trade-in cycle, the resulting glut of nearly new \ncars depresses used prices so much that the substitution o",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 74
  },
  {
    "child_id": "d2c5edc3-4472-4a43-819e-217380eec4b4",
    "parent_id": "38934d12-6c2d-46d2-9991-8abb4f586563",
    "text": "emma that unilaterally stopping leasing while competitors \ncontinued to offer it dramatically reduced GM sales. \nThe analysis also showed that GM\u2019s profits were consistently higher with 4- \nyear lease terms. Four-year terms were superior over a wide range of competitor \nstrategies and uncertainties. Longer terms have two main beneficial effects. First, \nthough shorter terms do shorten the trade-in cycle, the resulting glut of nearly new \ncars depresses used prices so much that the substitution of used for new purchases \noffsets their benefit. In terms of Figure 2-1, the Used Car Market, Used Car Qual- \nity, and Purchase Option loops overwhelm the benefit of the Lease Term and Lease \nCompetitor Lease Term \n2 year \nh \nz \n3 year \n~ \nh \nz \n4 year \nh \nz \nh \nz \nSource: Adapted from GM DSC diagram. Used with permission\n\n52 \nFIGURE 2-4 \nBathtub \ndiagram to \nillustrate \nthe impact \nof leasing \nPart I Perspective and Process \nIncentive loops. Four-year terms mean the cars coming off lease are less attractive \nsubstitutes for new cars, while still speeding the trade-in cycle somewhat. \nThe second benefit of longer terms is a more subtle, disequilibrium effect. By \nincreasing the substitutability between new and nearly new used cars, short-term \nleases increased the vulnerability of earnings to industry downturns. Rather than \nshowing complex diagrams such as Figure 2-1 to explain why, Pudar developed \nFigure 2-4, showing the stock of late model vehicles as a bathtub. The bathtub di- \nagram uses a simple metaphor to illustrate the dynamics of leasing. The stock of \nnew and new-car substitutes is increased by production and the flow of late model \nused cars coming off lease (and out of rental car fleets). Sales drain the tub. \nDuring recessions, auto sales drop. The water level in the tub rises. Carmakers \ncome under pressure to cut prices and subsidize leases to drain cars out of the tub \nfaster and also cut production to stop the inflow. However, the flow of new car sub- \nstitutes into the market from expiring leases cannot be turned off. When a recession \nhits, leases sold during the preceding boom continue to expire, boosting the level \nin the tub. Lower used car prices and concerns over future income lead more peo- \nple to turn their off-lease cars back to the lessor rather than exercising their option \nto buy. The larger the share of new cars sold through leasing, the larger the un- \nstoppable flow of returning vehicles. Prices are forced down even farther, and pro- \nduction cuts must be even deeper, significantly eroding profits. \nThe team used the bathtub diagram in presentations to senior managers \nthroughout the firm, including all brand managers. Of course the formal analysis, \nmodel structure, and other details were presented, but the bathtub provided a pow- \nerful metaphor to communicate an important dynamic insight and helped in the \ndifficult process of changing mental models. \nWhy do short-term leases make us more vulnerable \nduring an economi",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 74
  },
  {
    "child_id": "6ddb2a00-615d-43fa-959d-0c3aa95f22a2",
    "parent_id": "38934d12-6c2d-46d2-9991-8abb4f586563",
    "text": "ro- \nduction cuts must be even deeper, significantly eroding profits. \nThe team used the bathtub diagram in presentations to senior managers \nthroughout the firm, including all brand managers. Of course the formal analysis, \nmodel structure, and other details were presented, but the bathtub provided a pow- \nerful metaphor to communicate an important dynamic insight and helped in the \ndifficult process of changing mental models. \nWhy do short-term leases make us more vulnerable \nduring an economic downturn? \nProduction \nNew Car Substitutes \nWhen industry demand falls, the flow of returning lease cars cannot be stopped: \n- Prices of used cars will be driven down; \n- New car transaction prices will be forced down; \n- Some returning lessees will opt for cheap used cars. \nPrice does not alter the supply of new car substitutes \nSource: GM Decision Support Center. Used with permission.",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 74
  },
  {
    "child_id": "32d26007-7dfe-4839-a367-a9151cde4087",
    "parent_id": "c79a9e9c-f970-439d-8cf8-e4466adc6d86",
    "text": "Chapter 2 System Dynamics in Action \n53 \nPudar and his team made two main recommendations to Zarella and other \nsenior managers in NAO. First, GM should shift incentives to favor longer leases \nand move the mix of the leasing portfolio toward a higher average term. Second, \nthey recommended that all proposals for new pricing and marketing programs for- \nmally include analysis of their impact on the used car market and its feedback to \nthe new car market. They recommended the market research organization create \nnew clinics to assess new/used/lease consumer choice behavior so that up-to-date \ndata would be available on an ongoing basis. They also supported changing the \nincentives and metrics for managers of the car groups to include the profit or loss \nGMAC realized as a result of leasing. \nMany brand managers and brand analysts were initially opposed to these rec- \nommendations. They argued that consumers had been conditioned to prefer short- \nterm leases. Competition was intense and GM\u2019s market share had been slipping. \nFord, in particular, was aggressively pushing 2-year leases with significant sub- \nvention; unless GM responded in kind, they argued, market share would suffer \nmore. Given the tremendous pressure they faced to stay competitive, they were not \nwilling to sacrifice market share and profits today to avoid the possibility that leas- \ning might lead to problems in a few years. Brand managers and the sales organiza- \ntion put strong pressure on the senior management of NAO to increase residual \nlevels. They pointed to strong used car demand and rising used car prices to justify \nincreased residuals. They also argued that subvention levels should be increased \neven further above the higher residuals they were recommending. Finally, they ar- \ngued for a decrease in the fraction of off-lease vehicles GM predicted it would \nhave to take back at lease end. The costs of subvention are deferred because they \nare only realized when cars come off lease. Accounting rules require carmakers to \nset aside reserves to cover the expected cost of subvention; these reserves reduce \ncurrent period earnings. The amount set aside in reserves depends on the fraction \nof cars they expect to be returned. If customers exercise their option to buy when \ntheir lease expires then GMAC never has to pay the difference between the sub- \nvented residual and market value. Many brand managers believed that the strong \nused car market meant reserves were too high and could safely be cut, allowing the \ncar divisions to show higher current period profits while increasing market share. \nThey supported their case with spreadsheets in which recent trends toward higher \nused car prices and higher customer retention of off-lease vehicles were assumed \nto continue, that is, in which all feedbacks between the new and used markets \nwere cut. \nThe dynamic model, in contrast, suggested that used car prices would soon de- \ncline as the large volume of leased and fleet vehicles so",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 78
  },
  {
    "child_id": "fc93791b-a9e5-4b0a-967b-0f18f0cbef3d",
    "parent_id": "c79a9e9c-f970-439d-8cf8-e4466adc6d86",
    "text": "ely be cut, allowing the \ncar divisions to show higher current period profits while increasing market share. \nThey supported their case with spreadsheets in which recent trends toward higher \nused car prices and higher customer retention of off-lease vehicles were assumed \nto continue, that is, in which all feedbacks between the new and used markets \nwere cut. \nThe dynamic model, in contrast, suggested that used car prices would soon de- \ncline as the large volume of leased and fleet vehicles sold in the last few years \nreentered the market. The team\u2019s analysis suggested some of the surge in used car \nprices was a temporary blip generated by the used car superstores as they bought \nheavily to stock their lots. When that period of inventory building ended, used car \nsales would slump while the flow of cars coming off lease continued. As used \nprices fell below the contracted residuals, more customers would terminate their \nleases early and fewer would exercise their option to buy, decreasing the retention \nfraction and boosting the supply of late model used cars still more. GM would have \nto take a significant charge against earnings for residual reconciliation, and new car \nsales would suffer as customers opted for late model off-lease vehicles.\n\n54 \nFIGURE 2-5 \nUsed car prices, \n1989-1999 \nIndex shows the \nused car and truck \ncomponent of the \nUS Consumer \nPrice Index, \nseasonally \nadjusted. \nPart I Perspective and Process \nSenior managers at NAO decided to focus on 36- to 48-month terms and elim-\ninated 2-year leases. They also chose not to increase residual values and moved to \nfull accrual of residual risk in calculating reserves. These decisions made subven-\ntion much more expensive to brand managers and raised lease payments. \n2.2.4 \nImpact and Follow-up \nIn 1997 a flood of off-lease vehicles inundated the market. Used car prices fell sig-\nnificantly (Figure 2-5). The data show the aggregate for all used cars; the drop for \nlate model vehicles was much steeper and was most severe in the segments in \nwhich leasing had grown most rapidly. \nAs prices fell, fewer customers opted to keep their cars. The Consumer Bank-\ning Association reported that the fraction of vehicles from expiring full-term leases \nreturned to lessors jumped from 29% in 1997 to 39% in 1998. About three-quarters \nof all off-lease vehicles returned to lessors incurred losses; the average loss in 1998 \nwas $1878 per vehicle, 220% more than the average for 1993. \nGM's early action helped it avoid these losses, while other carmakers found \nthemselves facing huge reconciliation charges. Profits at Ford Credit Corporation \nfell $410 million in 1997 compared to 1996, a 28% drop, largely due to losses on \noff-lease vehicles. At GMAC, net income from automotive financing operations \nfell only $36 million, less than 4%, and overall GMAC profits rose more than 6%. \nIn 1997 several carmakers, including Ford and Nissan USA, attempted to prop \nup wholesale prices for their cars by paying ",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 78
  },
  {
    "child_id": "1798fd87-2cb4-4195-add5-163314b36b32",
    "parent_id": "c79a9e9c-f970-439d-8cf8-e4466adc6d86",
    "text": " it avoid these losses, while other carmakers found \nthemselves facing huge reconciliation charges. Profits at Ford Credit Corporation \nfell $410 million in 1997 compared to 1996, a 28% drop, largely due to losses on \noff-lease vehicles. At GMAC, net income from automotive financing operations \nfell only $36 million, less than 4%, and overall GMAC profits rose more than 6%. \nIn 1997 several carmakers, including Ford and Nissan USA, attempted to prop \nup wholesale prices for their cars by paying dealers to keep off-lease cars instead \nof returning them to the manufacturer for sale at auction. Ford paid dealers $700 to \n$6000 (depending on the model) for each 2-year old off-lease vehicle the dealer \nagreed to keep, dipping into its residual reserves for the first time to do so. This \npolicy reduced the number of 2-year-old cars sold at auction, but of course, since \nretention of these cars added to dealer inventories, the number of these cars dealers \nbought at auction fell by the same amount, so wholesale prices continued to slide. \nIn 1998 GE Capital dropped its partnership with Chrysler to finance leases be-\ncause, as Automotive News (24 August, p. 1) reported, \nI \n150 \n0 \n0 \nII \n\"2' \nco \n1 \nN \nco \n0') \n, \n110 i , , \ni \ni \ni , \ni \n1988 \n1990 \n1992 \n1994 \n1996 \n1998 \n2000 \nSource: US Bureau of Labor Statistics, series CUSROOOSETA02.\n\nChapter 2 System Dynamics in Action \n55 \nGE Capital Auto Financial Services got burned on residual-value losses in 1997. \nMuch of that was due to off-lease products from Chrysler . . . GE Capital cited \nresidual losses as one reason for the decline in operating profits for Consumer \nServices, the GE unit that includes Auto Financial Services. Profits fell from \n$1.3 billion in 1996 to $563 million [in 19971. \nIn 1998 net income at Ford Credit rose $53 million over the depressed level of \n1997 but remained 25% below the net for 1996.4 GMAC\u2019s net on auto financing \nrose $74 million over 1997, a rise of 4% over 1996, and total GMAC profit for \n1998 rose $181 million over 1996, a gain of 15%. In 1998 Ford and other car- \nmakers belatedly followed GM\u2019s lead and began to move away from short-term \nleasing. \nSince 1996 the leasing model has been updated several times, disaggregated \nfurther to separate the car and light truck segments, and used to examine issues \nsuch as sales of fleet vehicles. The model is now used on an ongoing basis by \nNAO\u2019s Portfolio Pricing Team, the group responsible for review and approval of \nall pricing and incentive programs in North America. \nPudar, now Director of the DSC (renamed the Strategy Support Center [SSC]), \nreports that the SSC continues to apply system dynamics, in combination with \nother analytic methods, to a wide range of issues, from negotiating joint ventures \nwith foreign governments to designing business plans for new products, services, \nand business units. \nO N  \u2019TIME AND UNDER BUDGET: \nTHE DYNAMICS OF PROJECT MANAGEMENT5 \nIn 1970, Ingalls Shipbuilding of Pascagoula, Missis",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 78
  },
  {
    "child_id": "1171afa7-ceef-4549-827f-72a1bc20701c",
    "parent_id": "c79a9e9c-f970-439d-8cf8-e4466adc6d86",
    "text": "d incentive programs in North America. \nPudar, now Director of the DSC (renamed the Strategy Support Center [SSC]), \nreports that the SSC continues to apply system dynamics, in combination with \nother analytic methods, to a wide range of issues, from negotiating joint ventures \nwith foreign governments to designing business plans for new products, services, \nand business units. \nO N  \u2019TIME AND UNDER BUDGET: \nTHE DYNAMICS OF PROJECT MANAGEMENT5 \nIn 1970, Ingalls Shipbuilding of Pascagoula, Mississippi, won a major contract to \nbuild a fleet of 30 new destroyers for the US Navy. Combined with its 1969 con- \ntract for 9 LHAs (an amphibious assauWaircraft carrier), Ingalls found itself in the \nhappy position of landing two of the largest shipbuilding programs in the world \nand looked forward to healthy sales and profits for years to come. By the mid- \n1970s, however, Ingalls was in deep trouble, facing cost overruns projected to ex- \nceed $500 million. With annual sales in the mid-1970s of $500-800 million, the \noverrun threatened to sink Ingalls, and its parent Litton Industries, altogether. Ad- \njusted for inflation the overrun would exceed $1.5 billion in 1999 dollars. \nBoth contracts were awarded as total package procurement projects with a firm \nfixed-price contract structure in which Ingalls \u201cwas provided only with the perfor- \nmance specifications, and was thereafter solely responsible for all system design, \ndetailed design, materials procurement, planning, testing, and construction\u201d \n(Cooper 1980, p. 22). \nBoth programs involved innovative and technically sophisticated new designs. \nThe DD class multimission destroyers were twice as large as earlier \u201ctin cans.\u201d The \n4Excluding one-time income from asset sales. \n5This section is based on Cooper (1980) and personal communication with Ken Cooper \n(president, Pugh-Roberts Associates), Rich Goldbach (formerly with IngallsLitton Industries and \ncurrently president, Metro Machine Corporation), and many others at hgh-Roberts Associates. \nI\u2019m grateful for their help.",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 78
  },
  {
    "child_id": "b7ed0332-796c-45e8-bd90-bf395143c45f",
    "parent_id": "9f1bb7a2-1741-46fa-8c16-39b0b58d87fa",
    "text": "56 \nPart I Perspective and Process \nLHA was also an entirely new design. More than 20 stories high and three football \nfields long, each LHA carries a complement of 2000 battle-ready Marines and 200 \ncombat vehicles that can be deployed by landing craft and several dozen heli- \ncopters. The DD and LHA contracts required a massive mobilization of Ingalls\u2019 re- \nsources. Already one of the largest shipyards in the world, Ingalls doubled its \nworkforce to more than 20,000. During this time there were shortages of some \nskilled trades and critical materials. Ingalls also had to create new organizational \nstructures to manage the two programs. \nLarge-scale projects are among the most important and consistently misman- \naged endeavors in modern society. Large-scale projects include the design and con- \nstruction of civil works and infrastructure (e.g., bridges, tunnels, power plants, and \ntelecommunications networks), military systems (e.g., aircraft, ships, and weapons \nsystems), and new products in every industry (e.g., software, automobiles, semi- \nconductor chip design, and wafer fab construction). \nProjects of all types routinely experience cost overruns, delays, and quality \nproblems. Cooper and Mullen (1993) examined a sample of large civilian and mil- \nitary projects (averaging 130,000 person-hours of planned work over about a year \nfor the civilian projects and 170,000 person-hours of planned work over more than \n2 years for the military projects). They found commercial projects cost 140% and \ntook 190% as long as originally scheduled, while defense projects cost 310% of the \noriginal estimates and took 460% as long to complete. \nDelays, cost overruns, and quality problems in commercial new product de- \nvelopment can kill a company, particularly in high-velocity industries such as soft- \nware and high technology. Overruns and delays in civil works and military projects \ncan affect the economic vitality of a region and the ability of a nation to defend \nitself. \n2.3.1 \nThe Claim \nThe Navy and Ingalls disagreed sharply over the causes of the delays and cost \noverrun. Ingalls believed the majority of the cost overrun was caused by the ac- \ntions of the Navy. As is common in large, lengthy projects, the technologies and \nsystems to be used in the DD and LHA ships were not mature at the time the con- \ntracts were awarded. Technologies for navigation, intelligence, communications, \nand weapons systems, for example, were advancing rapidly, and the Navy natu- \nrally sought to incorporate the most up-to-date systems in the ships. Rich Gold- \nbach, then a senior manager at Ingalls and one of the key participants in the claim, \ncommented that \u201cIngalls was convinced that the government interfered with the \ndesign for the LHA from the start by micro-managing the design pro~ess.~\u2019 \nAs \nhigh-level design, detailed design, and even construction proceeded, Ingalls re- \nceived many thousands of design changes from the Navy. Ingalls believed that \nmuch of the ove",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 81
  },
  {
    "child_id": "1b3557e5-f47a-4331-9af9-9fdfda93693e",
    "parent_id": "9f1bb7a2-1741-46fa-8c16-39b0b58d87fa",
    "text": "ally sought to incorporate the most up-to-date systems in the ships. Rich Gold- \nbach, then a senior manager at Ingalls and one of the key participants in the claim, \ncommented that \u201cIngalls was convinced that the government interfered with the \ndesign for the LHA from the start by micro-managing the design pro~ess.~\u2019 \nAs \nhigh-level design, detailed design, and even construction proceeded, Ingalls re- \nceived many thousands of design changes from the Navy. Ingalls believed that \nmuch of the overrun was caused by the imposition of these design changes. After \nthe Navy repeatedly refused to compensate Ingalls for these costs, Ingalls brought \na claim against the Navy to recover the $500 million in losses it expected. \nSuing your customers is always tricky. In the case of Ingalls it was particularly \ndelicate. Ingalls brought the claim early, while the two programs still had many \nyears to run. Ingalls had to continue to manage the two programs and maintain a\n\nChapter 2 System Dynamics in Action \n57 \ngood working relationship with the Navy while simultaneously pursuing the claim. \nFurther, since commercial shipbuilding was in decline in the US, the Navy was \nIngalls\u2019 most important customer and would be for the indefinite future.6 \nThe Navy conceded that it had generated the design changes but argued that \ntheir impact was limited to the direct cost of reissuing the specifications and re- \nworking the affected engineering drawings. The total cost of these direct impacts \nwas a small fraction of the total claim. Ingalls countered that a design change could \ncreate much larger costs, for example, by altering the sequence of tasks and re- \nquiring overtime and unscheduled hiring that interfered with other phases of the \nwork, diluted experience, and reduced productivity even in work phases not di- \nrectly affected by change orders. Ingalls believed such ripple effects could multi- \nply the direct impact of a change notice many times, leading to significant overall \n\u201cdelay and disruption.\u201d \nThe Navy countered that the supposed delay and disruption were actually the \nresult of contractor mismanagement or deliberate underbidding to win the contract. \nDisputes over the delay and disruption component of prior claims throughout the \ndefense industry often dragged out over many years. The Navy had never paid a \nsignificant delay and disruption claim. \n2.3.2 \nInitial Model Development \nIngalls spent several years pursuing the claim, but traditional project management \ntools did not provide a means to quantify the ripple effects. Ingalls turned to \nsystem dynamics to quantify the delay and disruption created by Navy design \nchanges. The model, developed by Pugh-Roberts Associates of Cambridge, \nMassachusetts, simulated all phases of the DD and LHA projects, from the award \nof the contract to the delivery of the last ship, then 5 years in the future. \nThe model ultimately contained many thousands of equations, a very large \nmodel indeed (especially considering ",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 81
  },
  {
    "child_id": "95552c10-e2ef-4fff-aefa-e91802090462",
    "parent_id": "9f1bb7a2-1741-46fa-8c16-39b0b58d87fa",
    "text": "tools did not provide a means to quantify the ripple effects. Ingalls turned to \nsystem dynamics to quantify the delay and disruption created by Navy design \nchanges. The model, developed by Pugh-Roberts Associates of Cambridge, \nMassachusetts, simulated all phases of the DD and LHA projects, from the award \nof the contract to the delivery of the last ship, then 5 years in the future. \nThe model ultimately contained many thousands of equations, a very large \nmodel indeed (especially considering the state of computer technology at the time). \nIt began, however, as a much smaller model designed to illuminate the basic feed- \nbacks that might be responsible for ripple effects. The modeling team worked \nclosely with Ingalls\u2019 claim management organization, including managers from all \nmajor phases of each program and key attorneys. Lead modeler Ken Cooper de- \nscribed the process this way (1980, pp. 26-27): \nThe Ingalls project team guided and reviewed the decision of what elements \nto include in the model, and with what measures and in what detail to include \nthem . . . [Dlozens of individuals in all stages of shipbuilding, from workers \nthrough vice presidents, were interviewed. They offered qualitative and quantitative \nobservations on ship design and construction. As the design of the model began to \ngel, the numerical data requirements were clarified; a massive data collection ef- \nfort, in concert with other elements of the claim, was undertaken. These data and \ninformation provided enough material to assemble a preliminary mathematical \nmodel of a single work phase. The equations, parameters, and detailed output \nwere reviewed by the project team, and several model modifications made. \n6Due in part to the problems encountered in the program, the number of LHAs utlimately \nbuilt was cut to 5. LHA5, the USS Peleliu, was completed in mid 1980, as was the last DD class \ndestroyer, USS Fletcher.\n\n58 \nBe Done \nPart I Perspective and Process \nReally Done \n2.3.3 \nDynamic Hypothesis \nWork Being \nDone \nFIGURE 2-6 \nStock and flow \nstructure of a \nproject phase \nRectangles \nrepresent the \nstock of tasks, \nstraight lines and \nvalves represent \nflows of tasks \nbetween \ncategories \n(chapter 6). \nQuality is the \nfraction of tasks \ndone correctly. \nThe diagram is \nhighly simplified \nand omits several \ntask categories \nand flows included \nin the full model. \nKnown \nv \nRework \nRework \nA full description of the feedback structure of the model is beyond the scope of this \ndiscussion; this section provides only a few illustrations of the type of ripple ef- \nfects the model addressed. \nFigure 2-6 shows a highly simplified stock and flow structure for the flow of \nwork within a single project phase. The tasks could be high-level systems design \ntasks, preparation of detailed engineering drawings, or construction of a vessel. \nThe rectangles and valves represent the stock and flow structure of the ~ y s t e m . ~  \nThe stocks represent the accumulations of work in diff",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 81
  },
  {
    "child_id": "2847ca83-21bd-4bc6-9a77-1761809328d0",
    "parent_id": "9f1bb7a2-1741-46fa-8c16-39b0b58d87fa",
    "text": "scussion; this section provides only a few illustrations of the type of ripple ef- \nfects the model addressed. \nFigure 2-6 shows a highly simplified stock and flow structure for the flow of \nwork within a single project phase. The tasks could be high-level systems design \ntasks, preparation of detailed engineering drawings, or construction of a vessel. \nThe rectangles and valves represent the stock and flow structure of the ~ y s t e m . ~  \nThe stocks represent the accumulations of work in different categories; the valves \nrepresent the flow of tasks through the system. Initially all tasks are in the stock of \nWork to be Done. Completing a task requires resources such as a productive labor \nforce with appropriate skills; the number and productivity of the labor force vary \nover time as project conditions change. Tasks can be done correctly or incorrectly, \ndepending on the quality of the work. Tasks done correctly add to the stock of \nWork Really Done while tasks containing errors of various types add to the stock \nof Undiscovered Rework. Work quality is often quite low, as new-product devel- \nopment and large-scale projects usually involve new technologies, materials, and \nsystems and often involve unique new circumstances. Cooper and Mullen (1993) \nUndiscovered \nRework \nPeople \nProductivity \nQuality \nDiscovery \nObsolescence \nRate t \nCustomer \nChanges \nSource: Adapted from a diagram developed by Pugh-Roberts Associates, Cambridge, MA. Used with \npermission. \n7Mathematically, each stock is the integral of the flows in less the flows out. Stocks and flows \nare discussed in chapters 6 and 7.",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 81
  },
  {
    "child_id": "222846a2-0905-42af-947d-925a199c3262",
    "parent_id": "7a4affb5-64dc-490e-b240-bde8b7ed6d08",
    "text": "Chapter 2 System Dynamics in Action \n59 \nfound the average fraction of work done correctly the first time in their sample to \nbe 68% for commercial projects and just 34% for defense projects. \nUncovering errors takes time and resources. Often, errors are only detected by \na downstream phase, as when a design flaw is discovered during the construction \nphase. Tasks in the stock of undiscovered rework are therefore perceived to be \ncomplete and are treated as done by the organization. Discovery of errors by qual- \nity assurance, testing, or a downstream phase moves the imperfectly done tasks to \nthe stock of Known Rework. Cooper and Mullen (1993) found average rework dis- \ncovery delays of about 9 months for both civil and military projects, a significant \nfraction of scheduled project duration. \nChanges in customer specifications have effects similar to the discovery of \nerrors. Specification changes make some work previously done correctly obsolete, \nmoving those tasks from the stock of Work Really Done to the stock of Known \nRework. The affected phase must recall work it previously released to other phases \nand upon which those downstream phases have based their own work. The or- \nganization must then increase the resources and attention devoted to rework, slow- \ning completion of remaining basework tasks and potentially disrupting the entire \nproject. * \nObviously customer changes that make completed design work obsolete are \ncostly because the affected tasks must be reworked; these are the direct impacts of \nchanges the Navy was willing to pay for. But the indirect effects can be many times \nlarger. Figure 2-7 shows a few of the feedbacks that explain how the indirect ef- \nfects of customer changes could be amplified. \nAs a project falls behind contractors have only a few choices. They can put the \nexisting workforce on overtime, thus increasing the effective number of people \nworking on the project. This negative or balancing feedback is the intended effect \nof overtime and is shown in the diagram by solid lines. However, excessive or ex- \ntended overtime causes fatigue and burnout. Productivity and quality fall, reducing \nprogress and increasing the stock of undiscovered rework. Burnout also leads to \nabsenteeism and attrition as employees request transfers or quit, reducing the num- \nber of people on the project. These unintended effects, shown as dashed lines, form \npositive (self-reinforcing) feedbacks that act as vicious cycles to undercut the \nprogress-enhancing effect of overtime. To avoid the side effects of overtime more \npeople can be hired (another balancing loop). But rapid hiring dilutes the experi- \nence base of the employees. If the pool of qualified workers in the region is small \nrelative to hiring needs, accelerated hiring lowers the average quality of available \ncandidates. Recruiting standards often erode so vacancies can be filled quickly. All \nthese effects lower productivity and quality and slow progress even as manage-",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 84
  },
  {
    "child_id": "3e0c54a3-72f8-4d63-a3ee-a29c90a4d340",
    "parent_id": "7a4affb5-64dc-490e-b240-bde8b7ed6d08",
    "text": "ogress-enhancing effect of overtime. To avoid the side effects of overtime more \npeople can be hired (another balancing loop). But rapid hiring dilutes the experi- \nence base of the employees. If the pool of qualified workers in the region is small \nrelative to hiring needs, accelerated hiring lowers the average quality of available \ncandidates. Recruiting standards often erode so vacancies can be filled quickly. All \nthese effects lower productivity and quality and slow progress even as manage- \nment seeks to boost headcount and speed progress. \n\u2018Most large military and civilian projects specify deadlines for delivery. Failure to meet the \ndeadline leads to penalties, known as liquidated damages (LDs), for every day the project is late; \nLDs can rapidly mount to many millions. In disputes such as discussed here the LDs form the \nprimary basis for the customer\u2019s counterclaim against the contractor. In several cases for which \nsystem dynamics models have been used the difference between the contractor delay and disruption \nclaim and the customer\u2019s counterclaim was several billion dollars. Even when LDs do not apply, as \nfor in-house commercial product development projects, every day the project is late erodes the \ncompetitiveness of the product and the sales and profits it can generate.\n\n60 \nI \nI \nf \n\\ \n\\ \n/ \n1 \nPart I \nand Process \nSide effects of corrective measures lead to vicious cycles \nAs customer \ncause a project to fall \ncan accelerate the \nschedule, use \nand hire more people, forming negative feedbacks designed \nto get the \nback on track (solid lines). However, each of these ne(]aIIVe \ngers side effects that undercut the intended \nforming vicious \nbacks, shown by the dashed lines). \n/' ,,-\n\" \n/' \n-\n......... \n\" \n.... \n'-\n/' \n/ \n/' \n/ \n/ \nSkill, Quality ___ _ \nA \n_-\n....... \n'\\ '< / \n\\ / '\\ 1 \n\\1 \nI \nWork, \nWorksite Congestion, \nCoordination Problems, \nMorale Problems \n/ \n.,,-\n/,-r \n/ \nApparent \nObsolescence \nRate \nCustomer \nChanges \n, \n\\ \n\\ \nI \nJ \nI \nI \n/ \nAcceleration \nSource: Adapted from a diagram developed by \nInn--H(',nAI1<'lAssociates, Cambridge, MA. Used with permission. \nAs a project falls behind .,,,,,,,,\", ..... ,,,u,, management often \nemployees to \nwork harder and compresses \nby overlapping \nthat should be \nin \nApparent \nrises, but there are also unanticipated side \nvu,\",,,,,,,. Schedule compression \npeople to do work out \nsequence, meaning \ninformation or \nfrom upstream \nare not available. \nmay start before \ndesign is mature and stable. Prototype \nbuilds may \nbefore \nspecifications are \n9 Schedule com-\nnrC'\",,,,>\" also leads to work site \nbe it overloaded CAD/CAM facilities \nIVlanal';ers and \nfind their \ntoday havc \nto shorten \ncycle times. Successful \nand even in \nconcurrent programs the \nbetween different \ncan be too aggressive, \nto excessive rework. See Ford and Sterman (l998a) and (l998b) for \ndynamics \nof concurrent engineering, with \nto semiconductor \nalso section 14.5.\n\nChapter 2 System Dynamics in Action \n61 \ntime is ",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 84
  },
  {
    "child_id": "f476b3a2-0940-4e2c-af95-41b472bc1bf1",
    "parent_id": "7a4affb5-64dc-490e-b240-bde8b7ed6d08",
    "text": ". Prototype \nbuilds may \nbefore \nspecifications are \n9 Schedule com-\nnrC'\",,,,>\" also leads to work site \nbe it overloaded CAD/CAM facilities \nIVlanal';ers and \nfind their \ntoday havc \nto shorten \ncycle times. Successful \nand even in \nconcurrent programs the \nbetween different \ncan be too aggressive, \nto excessive rework. See Ford and Sterman (l998a) and (l998b) for \ndynamics \nof concurrent engineering, with \nto semiconductor \nalso section 14.5.\n\nChapter 2 System Dynamics in Action \n61 \ntime is increasingly consumed by meetings to work out conflicts arising from the \naccelerated schedule and ad hoc, last-minute coordination of out-of-sequence ac- \ntivities. Stress from work pressure, increased fire fighting, and constant changes in \nschedules can lead to morale problems that cut productivity and quality and in- \ncrease absenteeism and attrition. These effects are further multiplied by the rework \ncycle. Lower quality means more tasks contain errors. Because many errors are not \ndiscovered immediately, subsequent work begins using designs, materials, and in- \nformation that appear to be correct at the time but are later recalled for rework. \nThus customer changes can disrupt and delay upstream activities such as sys- \ntem design. These phases must then recall some previously released work, so de- \nlays and quality problems cascade to downstream phases such as detailed design, \nmaterials procurement, and construction. The downstream phases must then redo \nmuch of their job, often at great expense (particularly when construction has al- \nready begun). To the extent different projects such as the DD and LHA programs \nshare resources such as work sites, workers, support infrastructure, and manage- \nment, problems in one can spill over to another. \nThe diagrams above are highly simplified, and many other important feed- \nbacks captured in the full model are omitted (how many other such effects can you \nidentify from your own experience?). But they illustrate how apparently small \nchanges in customer specifications can snowball into much larger delay and dis- \nruption despite management\u2019s best efforts to get the project back on track. The \nmodel augmented traditional project analysis through the explicit recognition of \nthe rework cycle, variable staff productivity and quality, and the bane of most de- \nvelopment projects-undiscovered rework. Conventionally, any indirect effects \nwere viewed as a small additional percentage over the direct costs. Explicit recog- \nnition of the feedback structure described here helped explain how the indirect ef- \nfects of customer changes could be many times larger than the direct effects. \n2.3.4 The Modeling Process \nThe modeling team assembled the full model by replicating the generic project \nphase module to represent each phase for each ship in each program. The major ac- \ntivities (system design, detailed design, procurement, construction, etc.) were dis- \naggregated further where necessary; for example, constructi",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 84
  },
  {
    "child_id": "3a98a7e3-c160-4d0a-a9e9-7973763addec",
    "parent_id": "7a4affb5-64dc-490e-b240-bde8b7ed6d08",
    "text": "\nnition of the feedback structure described here helped explain how the indirect ef- \nfects of customer changes could be many times larger than the direct effects. \n2.3.4 The Modeling Process \nThe modeling team assembled the full model by replicating the generic project \nphase module to represent each phase for each ship in each program. The major ac- \ntivities (system design, detailed design, procurement, construction, etc.) were dis- \naggregated further where necessary; for example, construction was divided into \nseveral major activities (e.g., hull, piping, electrical, etc.) and the construction \nworkforce was disaggregated by major crafts (e.g., steelworkers, electricians, etc.). \nConstruction progress for each ship was represented separately. Each instance of \nthe generic phase module was calibrated to the particular activity it represented. \nThe individual activities, phases, and programs were linked by additional structure \nrepresenting overall program management, progress monitoring, scheduling, hir- \ning, resource allocation, and so on. \nA model of this scope could never be built, calibrated, maintained, or under- \nstood if such a modular architecture were not used. To represent such a diverse ar- \nray of activities the generic module had to be extremely robust. Considerable effort \nwent into extreme conditions tests to ensure that the model behaved appropriately \nunder any conceivable combination of inputs or conditions (see chapter 21). The \nteam worked to ensure the model was consistent with all available information,",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 84
  },
  {
    "child_id": "0e7b6a79-7cef-4fdb-bce3-830b543449fc",
    "parent_id": "a5e7dec1-1b4b-44dd-a47f-1cb128413811",
    "text": "62 \nPart I Perspective and Process \nincluding the qualitative assessments gleaned from interviews and observations in \nthe field, not only the numerical data. \nEarly on the team compared the output of the model to the history of the pro- \njects to date. The purpose of the comparison to historical behavior was not to prove \nto Ingalls that the model was right, but rather to identify areas where the model \nrequired improvement. These comparisons sometimes identified omissions and \nproblems, leading to revisions in model structure and parameters. Other times, \ndiscrepancies between model and data suggested the data were inconsistent or \nincomplete, leading to additional data collection, interviews, and refinement of the \nvalues and justification for parameters. This process led to three major and many \nminor iterations in the model. \nThe model ultimately replicated the historical performance of the projects \nquite well. But, as discussed in chapter 21, it is quite easy to fit a model to a set of \ndata. It is also necessary that the model replicate the data for the right reasons, rea- \nsons the modelers and Ingalls\u2019 management understand and can explain in plain \nlanguage. While particularly important in the adversarial setting of a large lawsuit, \nthese are important in any modeling project. Ultimately the clients for any model- \ning project will take action only to the extent their mental models have changed. In \nturn, the clients\u2019 mental models are unlikely to change unless they have confidence \nin the integrity and appropriateness of the formal model. Developing that confi- \ndence requires a modeling process that gives the clients the opportunity to delve as \ndeeply into the details as they want, to question any assumption, and to challenge \nany result. Opening the model to review by the clients is also essential for the mod- \nelers to ensure it addresses the issues the client cares most deeply about and to gen- \nerate the best model for that purpose. \nTo uncover model flaws and create opportunities for the Ingalls team to chal- \nlenge the model the modeling team used several other procedures. Cooper (1980, \np. 27) explains: \nFirst, we established at the outset explicit limits of reasonableness for each numeri- \ncal parameter in the model; these would not be violated in order to achieve a more \n\u201caccurate\u201d simulation. Further, the numerical parameters in different sections of the \nmodel were required to be consistent with one another in terms of relative magni- \ntude. These guidelines . . . were never violated. The model was also subjected to a \nseries of \u201cshock tests\u201d to assess robustness in responding as the company would to \nradically different circumstances. Finally, several different plausible combinations \nof equations and parameters were tested to explore \u201calternative models\u201d that might \naccurately represent Ingalls operations. \nAs time passed the model-generated projections for schedule and costs turned out \nto be quite close to what actua",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 87
  },
  {
    "child_id": "049f9034-0296-46c9-b4bf-a4fef4413dec",
    "parent_id": "a5e7dec1-1b4b-44dd-a47f-1cb128413811",
    "text": "gni- \ntude. These guidelines . . . were never violated. The model was also subjected to a \nseries of \u201cshock tests\u201d to assess robustness in responding as the company would to \nradically different circumstances. Finally, several different plausible combinations \nof equations and parameters were tested to explore \u201calternative models\u201d that might \naccurately represent Ingalls operations. \nAs time passed the model-generated projections for schedule and costs turned out \nto be quite close to what actually happened, further boosting confidence in the abil- \nity of the model to capture the underlying structure of the projects. \nThe modeling team assessed the systemwide effects of the Navy\u2019s design \nchanges by comparing two simulations. The \u201cas-built\u2019\u2019 case was the historical sim- \nulation including all the Navy design changes; this was compared to the \u201cwould \nhave\u201d case in which the design changes were removed. The difference in total costs \nand completion times represented the cumulative impact of the design changes. \nSensitivity analysis then placed confidence bounds around the estimated cost of the \ndelay and disruption.\n\nChapter 2 System Dynamics in Action \n63 \nThe model also allowed Ingalls to estimate the role of its own management de- \ncisions in the overrun. Simulations of alternative policies showed how much lower \nproject costs and duration might have been if Ingalls had managed the project more \neffectively. The ability to quantify the contribution of customer interference and \ncontractor mismanagement to the delays and cost overrun was a critical part of the \nprocess. Goldbach (personal communication, 1999) described the dispute resolu- \ntion process prior to the development of the system dynamics model as \njust a bunch of finger-pointing. A contractor would say \u201cHere\u2019s what the govern- \nment did wrong\u201d and blame all their problems on that. Then the government would \nsend the GAO [General Accounting Office] in to find all the things the contractor \ndid wrong. It went nowhere. \nat the time there was no way to separate the impact of government and contractor \nproblems or examine the synergy between them. In the end we had to have the \nability to say \u201chere are the things the contractor didn\u2019t do well and here are the \nthings the government didn\u2019t do well, and here\u2019s how much each contributed to \ncosts and time.\u201d \nThe problem was that with the [project management] technologies available \nThe adversarial setting of a large dispute accentuates the need for a robust, well- \nunderstood model whose parameters and assumptions can be justified with inde- \npendent data. As part of the discovery process in the lawsuit Ingalls had to turn the \nmodel, documentation, analysis, and supporting data over to the Navy, which hired \nits own experts to try to debunk it. A common criticism of such models, and one \nused by the Navy, is that the parameters and assumptions are \u201ccooked\u201d to achieve \na preselected outcome. \u201cGarbage in, garbage out,\u201d they would say, and arg",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 87
  },
  {
    "child_id": "8dd30e62-074f-4662-a3f2-88a8ff61fa8a",
    "parent_id": "a5e7dec1-1b4b-44dd-a47f-1cb128413811",
    "text": "robust, well- \nunderstood model whose parameters and assumptions can be justified with inde- \npendent data. As part of the discovery process in the lawsuit Ingalls had to turn the \nmodel, documentation, analysis, and supporting data over to the Navy, which hired \nits own experts to try to debunk it. A common criticism of such models, and one \nused by the Navy, is that the parameters and assumptions are \u201ccooked\u201d to achieve \na preselected outcome. \u201cGarbage in, garbage out,\u201d they would say, and argued that \nthe model was merely a complicated ruse designed to impress the court. \nThe Navy\u2019s outside experts examined and criticized the model. After they de- \nlivered their reports, the modeling team, along with Ingalls management and their \nattorneys, Navy officials, the government\u2019s attorneys, and the Navy\u2019s outside ex- \nperts met for several days in a large conference room to discuss the critique. Each \nissue was discussed in detail, from high-level issues of modeling methodology and \nmodel architecture to specific equations and parameters. Ingalls and the modeling \nteam then had a chance to respond. They revised the model to address the criti- \ncisms leveled by the Navy\u2019s experts. In the next round of meetings, they showed \nthe Navy team how they had modified the model to incorporate the changes the \nNavy\u2019s experts wanted. Repeating the comparison of the as-built to would have \ncases, the modeling team found that the fraction of the overrun and delay caused \nby the Navy\u2019s design changes had actually increased.\u2019O \nThe Navy clearly expected that incorporating the critiques and parameter esti- \nmates of its experts into the model would show more of the overrun was due \nto contractor mismanagement. The counterintuitive result that the claim value \n\u2018OGiven the technology of the time (mainframe computers operating with time-sharing, teletype \nprinters, and 100 baud acoustic coupler modems) it was not feasible to run the model live in the \nmeetings. The model developers painfully recall overnight sessions running the model on the \nlargest computer then available. Today it is possible to bring the model to such meetings on a laptop \nand make many changes in assumptions on the spot, slashing the cycle time for experimentation \nand greatly increasing client involvement.\n\n64 \nPart I Perspective and Process \nincreased demonstrated to all that it is actually quite difficult to engineer a model \nto generate a preselected result. Goldbach commented, \u201cFor the first time the Navy \nsaw that Ingalls had a credible case.\u201d Intensive negotiations then began at the high- \nest levels of Litton and the Navy. In June 1978 the parties settled out of court. In- \ngalls received $447 million. \nThus the clients for the modeling work were not only Ingalls\u2019 management and \nattorneys but also the court and the Navy. It may seem counterintuitive to include \nthe opposing side among the client group for a model used in a lawsuit. And indeed \nthe Navy attempted to discredit the model and ",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 87
  },
  {
    "child_id": "04fce949-04a8-41de-9830-3d96f56200e0",
    "parent_id": "a5e7dec1-1b4b-44dd-a47f-1cb128413811",
    "text": "vy \nsaw that Ingalls had a credible case.\u201d Intensive negotiations then began at the high- \nest levels of Litton and the Navy. In June 1978 the parties settled out of court. In- \ngalls received $447 million. \nThus the clients for the modeling work were not only Ingalls\u2019 management and \nattorneys but also the court and the Navy. It may seem counterintuitive to include \nthe opposing side among the client group for a model used in a lawsuit. And indeed \nthe Navy attempted to discredit the model and have it excluded from the proceed- \nings. However, to the extent the model became the focus, even through the critique \nof the Navy experts, the structures in the model and the dynamics they generated \nstarted to become the common framework for discussion of the claim by all par- \nties. The process of changing mental models was well underway. This process has \nsince been observed in many other conflicts (see, e.g., Weil and Etherton 1990, Re- \nichelt and Sterman 1990). Experience shows that the better the oppositions\u2019 under- \nstanding of the model, the more likely it will be influential in the resolution of the \ndispute. \nThough the setting here was a lawsuit, the process applies to any modeling \nproject. Even when the clients for the work are all from the same management \nteam, there will always be different sides and factions, proponents and opponents \nof each policy. Only the intensive involvement of the clients in the modeling \nprocess can create the understanding of the issues needed to change entrenched \nmental models and lead to consensus for action. \n2.3.5 \nContinuing Impact \nThe system dynamics model was the sole technical basis for the delay and disrup- \ntion component of Ingalls\u2019 claim against the Navy. Estimates from the attorneys \nand Ingalls management \u201cplace the model\u2019s dollar contribution to the settlement \nbetween $170-350 million\u201d (Cooper 1980, pp. 28). But these sums, large as they \nare, underestimate the benefits of the modeling process. The lawsuit itself can be \nviewed as a large project that generated its own ripple effects. By achieving a set- \ntlement a little over 2 years after beginning the modeling process (a very short in- \nterval in such large disputes), \nThe direct dollar costs of continuing the claim effort were avoided [legal fees and \ncourt costs]. Even more significant, however, was the vast amount of managerial \nand professional time and talent (an entire \u201cclaim organization\u201d of over 100 Ingalls \npersonnel) that would have continued to be spent on something other than ship \ndesign and construction . . . Above all, the elimination of the adversary relationship \nbetween Ingalls and its best customer was a milestone achievement (Cooper 1980, \np. 28). \nSince this groundbreaking work Pugh-Roberts and other firms have gone on to ap- \nply system dynamics to disputes totaling many billions of dollars. These range \nfrom other military and commercial shipbuilding projects to aerospace and \nweapons systems, power plants, civil work",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 87
  },
  {
    "child_id": "8f077bda-0252-4d5d-af89-d5ca17d6f3c0",
    "parent_id": "a5e7dec1-1b4b-44dd-a47f-1cb128413811",
    "text": "ed to be spent on something other than ship \ndesign and construction . . . Above all, the elimination of the adversary relationship \nbetween Ingalls and its best customer was a milestone achievement (Cooper 1980, \np. 28). \nSince this groundbreaking work Pugh-Roberts and other firms have gone on to ap- \nply system dynamics to disputes totaling many billions of dollars. These range \nfrom other military and commercial shipbuilding projects to aerospace and \nweapons systems, power plants, civil works such as the cross-channel tunnel, and \nsoftware projects. In most cases contractors use the models in actions against their \ncustomers. In each case the defendants have sought to debunk the models and",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 87
  },
  {
    "child_id": "ad68f1d4-758c-4542-b713-d2d19a99626e",
    "parent_id": "4c34fd19-5c4d-466f-a7db-fbe7fbebf492",
    "text": "Chapter 2 System Dynamics in Action \n65 \nexclude them from the allowable expert testimony but each time the models have \nbeen allowed and have contributed to favorable settlements. \nWhile the dollar value of these actions is impressive and of undoubted benefit \nto the plaintiffs, the damage (the cost overrun) has already been done, and the dis- \npute is only over who pays. The real leverage lies in using these models proac- \ntively so overruns and delays are avoided in the first place. Since the first Ingalls \nmodel, many organizations have gone on to apply similar models to the manage- \nment of large-scale projects in a wide range of industries (for examples see sec- \ntions 6.3.4 and 14.5).\u201d Ingalls itself has used descendants of that first model to \nhelp manage virtually every program since the LHA and DD. The benefits of such \nproactive modeling are harder to quantify but likely outweigh the value of dispute \nsettlements many times. \nAs one illustration, Rich Goldbach left Ingalls in the late 1970s to head up \nMetro Machine, a shipyard in Norfolk, Virginia. Then small and struggling, Metro \ntoday is a highly successful yard specializing in repair and refitting work for the \nNavy with about 700 employees and sales of about $90 milliodyear. Goldbach in- \ntroduced a wide range of innovative management practices including employee in- \nvolvement. The firm is 100% employee owned, with universal participation in the \nemployee stock ownership plan. Metro has won several awards for the high qual- \nity of their work, including National Small Business Prime Contractor of the Year \nand the US Navy AEGIS Excellence Award \u201cfor superior performance in quality, \nreliability, delivery and cost\u201d-the first ever given to a repair yard. \nModels continue to play an important role. Goldbach commissioned the de- \nvelopment of a simulation model to project the financial consequences of various \ndecisions for up to 10 years. Metro uses the model to assess acquisitions, capital \ninvestment decisions, new ventures, and all aspects of bidding for jobs. \nWe built the model to a spec[ification] I provided based on what I learned from the \nIngalls model. The model helps the government understand our bids better. It lets \nthe DCAA [Defense Contract Audit Agency, a Department of Defense agency that \naudits defense contractor bids and assesses their ability to do the work] look at al- \nternative scenarios. We use the model interactively with them. There is an on-site \nDCAA auditor who knows the model. She can ask us to run any set of assumptions, \nand we usually get the answer back in an hour (Goldbach, personal communication, \n1999). \nThe financial simulation has been very effective, but far more important, Goldbach \nsays, are the lessons he learned about the challenges of managing complex \nsystems: \nFor the [shipbuilding] industry I thought I was a pretty sophisticated manager, but it \nchanged my whole perspective. I never had the ability I think I got from working \nwith sys",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 90
  },
  {
    "child_id": "52a422e9-14b6-478b-8caa-167b8a0682ba",
    "parent_id": "4c34fd19-5c4d-466f-a7db-fbe7fbebf492",
    "text": "nows the model. She can ask us to run any set of assumptions, \nand we usually get the answer back in an hour (Goldbach, personal communication, \n1999). \nThe financial simulation has been very effective, but far more important, Goldbach \nsays, are the lessons he learned about the challenges of managing complex \nsystems: \nFor the [shipbuilding] industry I thought I was a pretty sophisticated manager, but it \nchanged my whole perspective. I never had the ability I think I got from working \nwith system dynamics to ask \u201dhow will this decision ripple out?\u201d I got to the point \nthat I had the mental self-discipline to fight my impulses and not just do the macho \nthing when there\u2019s a problem. The playing field changes while you\u2019re playing the \n\u201cSee also Abdel-Hamid and Madnick (1989a-c, 1990, 1991); Cooper (1993a-c, 1994); Cooper \nand Mullen (1993); Ford and Sterman (1998a-b); Homer et al. (1993); Weil and Etherton (1990); \nand Yourdon (1993).\n\n66 \nPart I Perspective and Process \ngame. Now I ask how customers, employees, suppliers and so on will react to what \nwe might do. Sometimes I get it right and sometimes I don't. \nIt permeates every aspect of my thinking. I'm a different person than I was \nbefore. \n2.4 \nPLAYING THE MAINTENANCE GAME'* \nIn 1991, Winston Ledet, then a manager in Gulf Coast Regional Manufacturing \nServices at Du Pont, reflected on the results of an in-house benchmarking study \ndocumenting a large gap between Du Pont's maintenance record and those of the \nbest-practice companies in the global chemicals industry. \nThe benchmarking study revealed an apparent paradox: Du Pont spent more \non maintenance than industry leaders but got less for it. Du Pont had the highest \nnumber of maintenance employees per dollar of plant value yet its mechanics \nworked more overtime. Spare parts inventories were excessive yet the plants re- \nlied heavily on costly expedited procurement of critical components. Most \ndisturbing, Du Pont spent 10-30% more on maintenance per dollar of plant value \nthan the industry leaders, while at the same time overall plant uptime was some \n10-15% lower. \nMany people found the results of the benchmarking study to be counterintu- \nitive. Their mental models suggested that equipment quality should suffer and up- \ntime should be low in a company that spends little on maintenance, while spending \nmore on maintenance should yield high-quality equipment and high uptime. How \ncould Du Pont be spending more and getting less? \nMany people blamed the problem on the difficult competitive environment. \nThe chemicals industry is mature and intensely competitive. Because there is little \nproduct differentiation for bulk (commodity) feedstocks, chemical manufacturers \ncompete on other dimensions, mostly cost and delivery reliability. Since the early \n1970s the industry was hit by one crisis after another: Two severe energy crises \nwreaked havoc with input and operating costs. Always cyclical, the three worst re- \ncessions since the Great D",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 90
  },
  {
    "child_id": "115daf1f-40fb-4bc2-92f3-5e9989fac2e4",
    "parent_id": "4c34fd19-5c4d-466f-a7db-fbe7fbebf492",
    "text": "ed the problem on the difficult competitive environment. \nThe chemicals industry is mature and intensely competitive. Because there is little \nproduct differentiation for bulk (commodity) feedstocks, chemical manufacturers \ncompete on other dimensions, mostly cost and delivery reliability. Since the early \n1970s the industry was hit by one crisis after another: Two severe energy crises \nwreaked havoc with input and operating costs. Always cyclical, the three worst re- \ncessions since the Great Depression caused widespread excess capacity. New com- \npetitors from the Pacific rim and the oil-rich nations of the Middle East entered the \nmarket. Environmental concerns and regulations were growing. \nLedet knew all this; he had lived through it during his 25 years with Du Pont. \nBut blaming outside forces for the problems, while psychologically safe, didn't \nprovide any leverage to improve. Ledet felt that the explanation of the paradox lay \nnot in the outside pressures the company had faced during two turbulent decades \nbut in its response to those pressures. \nLedet and his team needed a way to explore the ways in which different parts \nof the maintenance system interacted, explain why past attempts to improve had \nfailed, and assist in the design of new policies. And they needed to explain these \ncomplex dynamics to the experienced plant operations and maintenance people \nwho had to take action. \n\"Tm indebted to Winston P. Ledet and Winston J. Ledet (principals, The Manufacturing Game), \nPaul Moms (BP Chemicals), and Mark Paich (Colorado College) for permission to present their \nwork and their assistance in the preparation of the material. Thanks also to Tony Cardella, Mark \nDowning, Vince Flynn, and the rest of the Du Pont team.\n\nChapter 2 System Dynamics in Action \n67 \nLedet and his team began the development of a simulation model to capture \nthe systemwide, dynamic benefits and costs of different maintenance initiatives. \nThey developed the model with the assistance of an experienced modeler, Mark \nPaich. The model was developed interactively, with the participation of Ledet and \nother key team members. The role of the expert modeler was more of a coach and \nfacilitator, and the modeling process involved extensive hands-on workshops in \nwhich the model was discussed, tested, and changed in real time as members of the \nmodeling team identified problems or areas needing improvement. \nDu Pont, like most large firms, already used a number of maintenance plan- \nning tools. These tools tend to focus on the detail complexity of the maintenance \nchallenge, for example, databases to track the maintenance history of each indi- \nvidual piece of equipment, statistical models to optimize maintenance schedules, \nscheduling systems to assign mechanics to planned and reactive work, and so on. \nThese tools are important for the day-to-day management of large plants but they \ndon\u2019t capture the dynamic complexity of the maintenance system. Where the de- \ntailed plan",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 90
  },
  {
    "child_id": "40620e5b-c0c6-4946-ae2b-e4681dee7ffa",
    "parent_id": "4c34fd19-5c4d-466f-a7db-fbe7fbebf492",
    "text": "ning tools. These tools tend to focus on the detail complexity of the maintenance \nchallenge, for example, databases to track the maintenance history of each indi- \nvidual piece of equipment, statistical models to optimize maintenance schedules, \nscheduling systems to assign mechanics to planned and reactive work, and so on. \nThese tools are important for the day-to-day management of large plants but they \ndon\u2019t capture the dynamic complexity of the maintenance system. Where the de- \ntailed planning and scheduling models tracked each pump and motor in the plant \nseparately, the dynamic model divided all equipment into just three categories: op- \nerable, broken down, or taken down for planned maintenance. But where the ex- \nisting models assumed failure rates and repair costs and durations were exogenous, \nthe dynamic model treated these factors endogenously. It encompassed technical \nissues such as equipment characteristics; logistical issues such as spare parts avail- \nability, maintenance scheduling, and mechanic assignments; human resources is- \nsues such as mechanic skill, training, and motivation; and financial issues \nincluding maintenance budgets, resource allocation, and overall plant performance. \nThe system dynamics model was a complement to, and not a replacement for, ex- \nisting planning and scheduling tools. \n2.4.1 Dynamic Hypothesis \nUsing the model as a laboratory to design and test different policies, the team grad- \nually developed an appreciation for the dynamic complexity of the maintenance \nsystem. The dynamic hypothesis they developed explained the paradox that Du \nPont spent more on maintenance and got less for it in terms of uptime and equip- \nment reliability. \nThe modeling process led to several important conceptual shifts in the way \nthey viewed maintenance. Prior to the modeling work maintenance was largely \nseen as a process of defect correction (repair of failed equipment) and the mainte- \nnance function was viewed as a cost to be minimized. The first conceptual shift \nwas to change the focus from defect correction to defect prevention and defect \nelimination. The model therefore centered on the physics of breakdowns rather \nthan the cost minimization mentality that prevailed throughout the organization. \nEquipment fails when a sufficient number of latent defects accumulate in it. Latent \ndefects are any problem that might ultimately cause a failure. They include leaky \noil seals in pumps, dirty equipment that causes bearing wear, pump and motor \nshafts that are out of true and cause vibration, poorly calibrated instrumentation, \nand so on. A pump with a leaky oil seal or dirty bearings can still run but will even- \ntually fail unless these latent defects are eliminated.",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 90
  },
  {
    "child_id": "b58c97ed-324d-4454-8c95-c362a45e9a33",
    "parent_id": "0ef8507c-aa30-47a2-aef0-fb045b4b4fab",
    "text": "68 \nPart I Perspective and Process \nThe total number of latent defects in a plant's equipment is a stock (Figure \n2-8). Defects are created by operations (normal wear and tear) and by collateral \ndamage arising from breakdowns (when the oil leaks out of the pump bearing and \nthe bearing seizes, the shaft may be bent, the motor may overheat, and the vibra- \ntion may break couplings and pipes, introducing new problems). More subtly, \nmaintenance activity can create new defects, through mechanic errors or the use of \npoor quality replacement parts. The lower the intrinsic design quality of the equip- \nment, the more defects these activities create. \nThe stock of defects is drained by two flows: reactive maintenance (repair of \nfailed equipment) and planned maintenance (proactive repair of operable equip- \nment).13 Each of these activities forms a balancing feedback loop. As defects ac- \ncumulate, the chance of a breakdown increases. Breakdowns lead to more reactive \nFIGURE 2-8 \nDefect creation and elimination \nThe diagram is simplified. In the full model equipment was divided into operable, broken \ndown, and taken down for planned maintenance, with an associated stock of latent \ndefects for each category. \nOperations \\ \n+ \nPlanned -b \nDefect \nMaintenance \nElimin-tinn \nEquipment \nQuality \nPart Quality \nQuality and \nProductivity \nEquipment \nDefects \n\\ \nI\n\\\n \nDefect \n4- \nReactive \nElimination -Maintenance \nThrough Repair \nQuality and \nProductivity \nPlanned \nReactive \n.. \nPlanned \nMaintenance \nMaintenance \n4 \nEffort \nTakedown \nRate \n- \n+ \nMaintenance \nRe&.tive \nMaintenance \nBreakdown \nEffort \nRate J \n/ \n+ \n\\ A  \nPlant \nUptime \nI3Planned maintenance includes preventive (time-based) work, e.g., replace worn parts on \npumps every n months, and predictive (condition-based) work, e.g., replace worn parts on a pump \nif vibration exceeds a certain tolerance.\n\nChapter 2 System Dynamics in Action \n69 \nmaintenance, and, after repair, the equipment is returned to service and the stock \nof defects is reduced (the Reactive Maintenance loop B 1). Similarly, scheduled \nmaintenance or equipment monitoring may reveal the presence of latent defects (a \nvibrating pump, an oil leak). The equipment is then taken out of service and the de- \nfects are corrected before a breakdown occurs (the Planned Maintenance loop B2). \nObviously breakdowns reduce plant uptime. In addition, most planned main- \ntenance activity also reduces uptime since planned maintenance frequently re- \nquires operable equipment be taken out of service so the needed work can be done. \nFigure 2-8 shows only the most basic physics of defect accumulation. The two \nnegative feedbacks regulating the stock of defects appear to be symmetrical: De- \nfects can be eliminated either by planned maintenance or repair of failed equip- \nment. The full system is more complex, however, and includes a number of \npositive, self-reinforcing feedbacks (Figure 2-9). \nFIGURE 2-9 \nPositive feedbacks undercutting planned maintenan",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 93
  },
  {
    "child_id": "793f8c24-43d4-4210-8b55-431047b11de9",
    "parent_id": "0ef8507c-aa30-47a2-aef0-fb045b4b4fab",
    "text": "ble equipment be taken out of service so the needed work can be done. \nFigure 2-8 shows only the most basic physics of defect accumulation. The two \nnegative feedbacks regulating the stock of defects appear to be symmetrical: De- \nfects can be eliminated either by planned maintenance or repair of failed equip- \nment. The full system is more complex, however, and includes a number of \npositive, self-reinforcing feedbacks (Figure 2-9). \nFIGURE 2-9 \nPositive feedbacks undercutting planned maintenance \nEquipment \nOperations \nPart Quality \nDefect \nCollateral \nReactive \nMaintenance - \nElimination \nElimination \nMaintenance \nThrough Repair \nMaintenance \nMaintenance \nDamage \nfor PM\n\n70 \nPart I Perspective and Process \nConsider the impact of the first oil crisis in late 1973. Input and operating costs \nskyrocketed. But the severe recession that began in 1974 meant chemical produc- \ners could not pass the entire cost increase on to consumers. Under intense financial \npressure, all plants and functions had to cut costs. If maintenance departments are \nasked to cut expenses nearly all of the cut has to come from activities such as plan- \nning and preventive maintenance: When critical equipment breaks down, it must \nbe fixed. At the same time, financial pressure leads to other actions (e.g., postpon- \ning replacement of older, less reliable equipment or running equipment longer and \nmore aggressively than original design specifications indicate), which increase the \nmaintenance workload. With resources for planned maintenance diminishing and \nmaintenance needs increasing, the stock of defects grows. Breakdowns increase. \nBreakdowns cause collateral damage, directly increasing the stock of defects fur- \nther and leading to still more breakdowns in a vicious cycle (the positive loop Rl). \nBecause the total number of mechanics is limited, more breakdowns necessarily \npull mechanics off planned work as management reassigns mechanics to repair \nwork. But many mechanics also prefer repair work. A planned maintenance man- \nager in one plant commented, \u201cWe\u2019ve had several people who say they want to get \ninvolved in preventive work but when an outage comes and [they] have a chance \nto work 14-16 hours per week overtime they say \u2018to hell with this vibration [mon- \nitoring] stuff, I\u2019m going to the outage area.\u201d\u2019 With less planned work, breakdowns \nincrease still more, forming the reinforcing Go to the Outage loop R2. \nThe rising breakdown rate means more critical equipment will be out of ser- \nvice awaiting repair. Plant uptime falls. Plant operators find it harder to meet de- \nmand. When a mechanic or maintenance supervisor requests that a certain piece of \nequipment be taken off line to correct latent defects, the harried line manager is \nlikely to shout something like \u201cI can barely meet demand as it is and you want me \nto take this line down? No way. If you maintenance people were doing your job, I \nwouldn\u2019t have so many down pumps in the first place. Now get out of h",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 93
  },
  {
    "child_id": "f2a88296-4065-49a8-badd-0381071104c9",
    "parent_id": "0ef8507c-aa30-47a2-aef0-fb045b4b4fab",
    "text": " out of ser- \nvice awaiting repair. Plant uptime falls. Plant operators find it harder to meet de- \nmand. When a mechanic or maintenance supervisor requests that a certain piece of \nequipment be taken off line to correct latent defects, the harried line manager is \nlikely to shout something like \u201cI can barely meet demand as it is and you want me \nto take this line down? No way. If you maintenance people were doing your job, I \nwouldn\u2019t have so many down pumps in the first place. Now get out of here, I\u2019ve \ngot a plant to run.\u201d The balancing Too Busy for PM loop (B3) means operators are \nless willing to take working equipment down for planned maintenance when up- \ntime is low. The side effect of that policy, however, is a further increase in defects \nand breakdowns and still lower uptime. The plant slowly slides down the slippery \nslope (reinforcing loop R3) into a trap of high breakdowns and low uptime, with \nnearly all maintenance resources devoted to crisis management, fire fighting, and \nrepair work. \nThe positive feedbacks Rl to R3 operate fairly quickly but are not the only \nvicious cycles that can drag a plant into the trap of low reliability and high costs. \nThe operational feedbacks in Figure 2-9 are embedded in a larger system shown in \nFigure 2- 10. \nA higher breakdown rate increases costs (due to overtime, the nonroutine and \noften hazardous nature of outages, the need to expedite parts procurement, col- \nlateral damage, etc.). The resulting pressure to cut costs leads to a reduction in \nthe quality of parts, increasing the stock of equipment defects and leading to \nstill more breakdowns and still higher costs (the Part Quality loop R4). Cost pres- \nsure also reduces investment in equipment upgrades and other design improve- \nments, so breakdowns increase further (the Design Improvement loop R5). As \ncosts rise training for maintenance workers is cut, particularly training in planned\n\nChapter 2 System Dynamics in Action \n71 \nFIGURE 2-1 0 \nAdditional positive feedbacks leading to a reactive maintenance culture \nThe contents of the rounded rectangle represent the structure in Figure 2-9. \nI \n/ \nProductivity \n\\ \nPlanning and / 'mpL!!!ement \nScheduling \nEquipmenr \nn,+..,a, \nQuality \nmort \nCapability \nI - 4 \n\\ \nPlanned \nMaintenance \nSkills and Culture \nw \nT r s i n i n m  \n+ \nPressure \nto cut \ncosts \nnepuiari \n\\ \ncosts \nI \n~ \n\\ \nMaintenance \nBudget \n+\\ \nRevenue \nErosion \n. Revenue \nfor Delivery \n@ Reliability \nPrice \nw \n+ \nmaintenance techniques (the Training loop R6). Cost pressure also forces the main- \ntenance department to downsize. The first to go are the planners and sched- \nulers-unlike mechanics, they don't actually fix anything, and with less and less \nplanned maintenance going on there is less for them to do. Without advance plan- \nning, part kits, equipment histories, and engineering drawings for maintenance \nwork are less available, lowering the quality of work still more (the Planning \nCapability loop R7). \nA parallel set of sel",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 93
  },
  {
    "child_id": "3f1c709f-f0aa-4bab-974d-68bc99b18d9a",
    "parent_id": "0ef8507c-aa30-47a2-aef0-fb045b4b4fab",
    "text": "Training loop R6). Cost pressure also forces the main- \ntenance department to downsize. The first to go are the planners and sched- \nulers-unlike mechanics, they don't actually fix anything, and with less and less \nplanned maintenance going on there is less for them to do. Without advance plan- \nning, part kits, equipment histories, and engineering drawings for maintenance \nwork are less available, lowering the quality of work still more (the Planning \nCapability loop R7). \nA parallel set of self-reinforcing feedbacks operate to reduce the maintenance \nbudget even as costs rise. Lower uptime directly constrains production and \ntherefore revenue, forcing budget cuts throughout the organization. Worse, high\n\n72 \nPart I Perspective and Process \nbreakdown rates and low uptime mean the plant is less able to meet its delivery \ncommitments. As it develops a reputation for poor delivery reliability the price it \ncan charge and volume of business it attracts decline, further eroding revenue and \nprofit and forcing still more budget cuts. Cost pressure rises still further, accelerat- \ning the part quality, training, design improvement, and planning capability loops. \nThese loops are summarized as the Revenue Erosion and Reputation Erosion loops \n(R8 and R9). \nAfter years of cost pressure, Du Pont had developed a culture of reactive main- \ntenance. Unreliable equipment and frequent breakdowns had become an accepted \noccurrence. Organizational norms and routines for writing up work orders, sched- \nuling maintenance effort, and ordering parts had come to reflect a world of frequent \nbreakdowns. Mechanics spent most of their time fighting fires. Mechanics who \nwere scheduled for planned maintenance were routinely pulled off to do reactive \nwork. Mechanics knew they could work overtime on a regular basis and consid- \nered overtime pay a part of their regular income. The knowledge that equipment \nwas unreliable had even led to installation of backup pumps in many sites, embed- \nding the low-reliability culture in the physical layout and capital costs of the plants. \nAs the years passed the workforce increasingly consisted of people who had never \nexperienced anything other than the reactive regime. For them, the equipment was \nintrinsically unreliable, low uptime was normal, and reactive maintenance was \nbusiness as usual (the Reactive Culture loop RlO). \nAs the model developed they calibrated it to represent a typical plant. In the \nearly 1990s a typical Du Pont chemical plant was valued at $400 million and spent \nabout 3-3.5% of its value annually on maintenance, or $12 to $14 milliodyear. \nThe spare parts store stocked more than 60,000 parts. It employed about 90 main- \ntenance mechanics who might complete as many as 25,000 work orders per year. \nAverage uptime was 83.5%. Maintenance expenses accounted for 1.5-40% of \ndirect production costs, depending on the process and product. The amount of \nmoney Du Pont spent companywide on maintenance in the late 1980s ",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 93
  },
  {
    "child_id": "9f198e5f-398c-4caf-bbc7-1c90f9354673",
    "parent_id": "0ef8507c-aa30-47a2-aef0-fb045b4b4fab",
    "text": " plant was valued at $400 million and spent \nabout 3-3.5% of its value annually on maintenance, or $12 to $14 milliodyear. \nThe spare parts store stocked more than 60,000 parts. It employed about 90 main- \ntenance mechanics who might complete as many as 25,000 work orders per year. \nAverage uptime was 83.5%. Maintenance expenses accounted for 1.5-40% of \ndirect production costs, depending on the process and product. The amount of \nmoney Du Pont spent companywide on maintenance in the late 1980s was about \n$1 billiodyear, a significant fraction of net income. \nOnce the model was adequately calibrated to the historical data, the next step \nwas to design high leverage policies to escape from the reactive regime. The team \nsimulated the impact of different policies, including those that had been tried in the \npast and failed. Table 2-1 shows the results of selected simulations. \nOptimizing the use of scheduling alone, within the traditional cost-minimiza- \ntion mindset, had only a modest impact. Through better scheduling the plant could \nstill meet its traditional uptime of 83.5% with 10% fewer mechanics, generating \nsavings of $350,00O/year. Implementing a full suite of proactive maintenance poli- \ncies, including better planning systems, parts, reliability engineering, and so on, al- \nlowed the plant to achieve the traditional uptime with only 61 mechanics, saving \n$1.2 milliodyear. \nHowever, deploying the same suite of proactive policies without downsizing \nallowed uptime to rise above 93% and generated $9 milliodyear in additional \nprofit. Why the difference? The cost-minimization approach means any improve- \nment in productivity generated by the adoption of improved maintenance tech- \nniques is immediately harvested as headcount reduction. Resources for planned \nmaintenance remain constrained. The organization continues to fight fires and",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 93
  },
  {
    "child_id": "81da09a3-9fab-40e6-8b99-368f410f826e",
    "parent_id": "a00f6343-0cb6-4fa3-87c9-a8ad377e0d4e",
    "text": "Chapter 2 System Dynamics in Action \n73 \nTABLE 2-1 \nResults from \nselected policy \nsimulations \nCases 1 and 2: \nMinimize \nmaintenance \ncosts subject to \nuptime 2 initial \nuptime. \nCase 3: Maximize \nplant profit subject \nto mechanic \nheadcount 5 \ninitial headcount. \nPolicy Mix \n0. Typical plant under existing policies \n1. Use scheduling to minimize \nmaintenance costs \n2. Minimize costs via full suite of \nproactive maintenance policies \n3. Maximize plant profit via full suite of \nproactive maintenance policies \nChange in \nHead \nProfit \nCount Uptime ($ milliodyear) \n91 \n83.5 \n0.00 \n82 \n83.5 \n0.35 \n61 \n83.5 \n1.20 \n91 \n93.3 \n9.00 \nSource: Winston Ledet, Mark Paich, Tony Cardella, and Mark Downing (1991), \u201cThe Value of \nIntegrating the CMLT Key Pursuits,\u201d Du Pont internal report. \nfocus on reactive maintenance but does so more efficiently. In contrast, imple- \nmenting the new policies without downsizing frees up resources that can be rein- \nvested in still more planned maintenance. As breakdowns fall, still more mechanics \nare released from fire fighting and outages to do even more planned work. Main- \ntenance expenses drop, releasing resources that can be invested in training, parts \nquality, reliability engineering, planning and scheduling systems, and other activi- \nties that cut defects and breakdowns still more. Higher uptime yields more revenue \nand provides additional resources for still more improvement. For example, up- \ngrading to a more durable type of pump seal improves reliability, allowing main- \ntenance intervals to be lengthened and inventories of replacement seals to be cut. \nAll the positive loops that once acted as vicious cycles to drag reliability down \nbecome virtuous cycles, progressively and cumulatively reducing breakdowns and \nimproving uptime. The result is a tremendous synergy, with the combined effect of \nthe individual policies greatly exceeding the sum of their impacts when imple- \nmented individually. \nThe model also revealed an important insight about the transition path follow- \ning implementation of the new policies. The simulation results in Table 2-1 show \nthat proactive maintenance policies\u2019 with reinvestment of the results ultimately \nlowers maintenance costs and boosts uptime. Immediately after implementation, \nhowever, maintenance costs increase and uptime falls. Why? It takes time for the \nplanned work to cut the breakdown rate; in the short run the plant must bear the \ncost of both the repair work and the additional planned maintenance effort. Uptime \nfalls because additional operable equipment must be taken off-line so planned \nmaintenance can be performed. Only later, as the stock of latent defects starts to \nfall, does the breakdown rate drop. As it does, expenses fall and uptime rises. This \nworse-before-better behavior is quite common in complex systems. However, if \nmanagers do not understand why it occurs or how long it might last, they may in- \nterpret the short-run deterioration in performance as evid",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 98
  },
  {
    "child_id": "5a826ea3-fe6c-4edd-8ccb-84d50d00c2b3",
    "parent_id": "a00f6343-0cb6-4fa3-87c9-a8ad377e0d4e",
    "text": "nned maintenance effort. Uptime \nfalls because additional operable equipment must be taken off-line so planned \nmaintenance can be performed. Only later, as the stock of latent defects starts to \nfall, does the breakdown rate drop. As it does, expenses fall and uptime rises. This \nworse-before-better behavior is quite common in complex systems. However, if \nmanagers do not understand why it occurs or how long it might last, they may in- \nterpret the short-run deterioration in performance as evidence that the policies \ndon\u2019t work and then abandon them.\n\n74 \nPart I Perspective and Process \n2.4.2 The Implementation Challenge \nLedet and his colleagues felt that the new perspectives they developed on the \nmaintenance problem could improve the contribution of Du Pont\u2019s maintenance \nprogram to corporate profitability. Now their challenge was to implement the \nneeded changes. The team wrote a white paper detailing the results of the model- \ning study and gave presentations throughout the organization. The result? Nothing \nhappened. People would say, \u201cWe already know that planned maintenance is a \ngood idea,\u201d \u201cWe tried those policies and they didn\u2019t work,\u201d or \u201cYour model doesn\u2019t \naccount for x.\u201d \nLedet realized that the client group for the project-the group of people whose \nbehavior had to change for any results to be realized-was far broader than the \nmanagement team responsible for maintenance. Nothing could happen without the \ncooperation and willing participation of huge numbers of line managers, equip- \nment operators, and maintenance mechanics. The client group numbered in the \nthousands. Reflecting on their own learning process, modeling team members \nrealized that their views had changed radically because they had participated in an \niterative process of modeling. They had seen the model evolve, had challenged and \nquestioned it, had seen their concerns addressed, and had gone through the process \nof working out the feedback structures that explained the dynamics of the system. \nSomehow they had to recreate that learning process throughout the plants, from top \nmanagement to the lowest-grade mechanics. \nIt was obviously impossible for the thousands of people they had to reach to \nparticipate in modeling workshops or even to give them the model so they could \nwork with it themselves. None had training in system dynamics or computer mod- \neling. Line supervisors and maintenance mechanics are action oriented and have \nlittle patience for presentations with lots of charts and graphs. \nLedet was familiar with the Beer Distribution Game, a role-playing manage- \nment flight simulator of a manufacturing supply chain developed by the MIT Sys- \ntem Dynamics Group as an introduction to systems thinking.14 Working with his \nson, Ledet converted the maintenance model into an interactive role-play simula- \ntion that they called the Manufacturing Game (see Ledet 1999). The game was \nembedded in a 2-day workshop or learning laboratory designed to be highly inter",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 98
  },
  {
    "child_id": "2f2f4ad7-acef-4b10-bc08-8d5f6739a603",
    "parent_id": "a00f6343-0cb6-4fa3-87c9-a8ad377e0d4e",
    "text": "ts of charts and graphs. \nLedet was familiar with the Beer Distribution Game, a role-playing manage- \nment flight simulator of a manufacturing supply chain developed by the MIT Sys- \ntem Dynamics Group as an introduction to systems thinking.14 Working with his \nson, Ledet converted the maintenance model into an interactive role-play simula- \ntion that they called the Manufacturing Game (see Ledet 1999). The game was \nembedded in a 2-day workshop or learning laboratory designed to be highly inter- \nactive, to put people at ease, and to create an environment for learning that ad- \ndressed emotional as well as cognitive issues. \nThe game simulates a typical plant. There are three roles: operations manager, \nmaintenance manager, and spare parts stores manager. The operations manager is \ncharged with meeting demand and has equipment, represented by chips, to do so. \nAs production proceeds, red markers representing latent defects are placed on the \nequipment chips. When enough red markers accumulate, the equipment breaks \ndown and capacity falls. The maintenance manager must then allocate mechanics \nto repair the equipment and must go to the spare parts store to see if the needed \nI4The Beer Distribution Game is an enjoyable and effective introduction not only to supply \nchain management but also to the principles of systems thinking in general (see chapter 17; also \nSterman 1989b, 1992 and Senge 1990 for descriptions, but not until after you have played the \ngame).\n\nChapter 2 System Dynamics in Action \n75 \nparts (determined by a roll of the dice) are available. If the parts are in stock, the \nequipment is repaired. If not, the mechanics must wait until they are available or \npay to have delivery expedited. Alternatively, the maintenance manager can sched- \nule planned work, ordering the needed parts and allocating mechanics in advance. \nPlanned maintenance can only be done, however, if the operations manager agrees \nto take operating equipment out of service. Each round the participants make deci- \nsions such as how much equipment to take down for planned maintenance, how to \nallocate mechanics and maintenance resources, and how many spare parts to order. \nRevenue and cost are recorded, along with production, uptime, inventories, and so \non. While the game is highly simplified compared to real plants, and even com- \npared to the original simulation model, it realistically captures the time delays, \ncosts, and other parameters characterizing a plant. \nDespite its many simplifications the game rapidly becomes in many ways a \nreal plant, with real emotions and conflicts among players. Initialized with high \nbreakdowns and low uptime, the maintenance manager's attempts to increase \nplanned maintenance are often rebuffed by the operations manager, who faces in- \ntense pressure to meet demand, just as in the real world. \nTeams who stick with the prevailing cost-minimization, reactive maintenance \npolicies are able to keep costs low for a while. But as defec",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 98
  },
  {
    "child_id": "3e966aa2-78c2-48d2-b6ae-8d897285f2f7",
    "parent_id": "a00f6343-0cb6-4fa3-87c9-a8ad377e0d4e",
    "text": "s many simplifications the game rapidly becomes in many ways a \nreal plant, with real emotions and conflicts among players. Initialized with high \nbreakdowns and low uptime, the maintenance manager's attempts to increase \nplanned maintenance are often rebuffed by the operations manager, who faces in- \ntense pressure to meet demand, just as in the real world. \nTeams who stick with the prevailing cost-minimization, reactive maintenance \npolicies are able to keep costs low for a while. But as defects build up they find \ntheir uptime slowly sinking and costs gradually rising. Teams who do follow \nthrough with a planned maintenance strategy immediately find costs rising and up- \ntime falling as equipment is taken off line for planned maintenance. Soon, how- \never, costs begin to fall and uptime rises. By compressing time the game allows \npeople to experience the worse-before-better dynamic in a few hours instead of a \nfew months. \nTwo members of the implementation team at Du Pont's Washington Works \ncomplex in Parkersburg, West Virginia, described how they used the game to cat- \nalyze a broad-based improvement program: \nThe team was initiated with a two-day learning lab . . . learning the concepts of de- \nfect elimination and experiencing the Manufacturing Game . . . The basic concepts \nare presented in different manners so that all learning modes are utilized-visual, \nauditory and kinesthetic. The material is presented in the form of lectures, skits and \nparticipative exercises in an off-site environment. Posters and music are used. The \natmosphere is much different than routine plant meetings or training, to open up \ntheir thinking . . . Through interactive exercises, the team develops their personal \naspirations for improving the area where they have chosen to work . . . [Then] \nthey . . . develop an action plan to immediately start ~ 0 r k i n g . l ~  \nThe game and learning laboratory proved popular throughout the company. But \nplaying it once with a small group of managers wasn't enough. The team found \nthat they had to run several workshops for a given plant before a critical mass of \npeople emerged to lead action teams that put proactive maintenance policies into \npractice. Often the plant needed to develop its own capability to run the game and \nworkshop so it could be done on demand by local people, with their site-specific \n'STewksbury, R., and R. Steward (1997) Improved Production Capability Program at \nDu Pont's Washington Works, Proceedings of the 1997 Society for Maintenance and Reliability \nannual conference.",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 98
  },
  {
    "child_id": "168531b5-c420-4da6-a11d-c1a19f839b33",
    "parent_id": "ece100cc-90e2-438a-9eb0-39405e0ea474",
    "text": "76 \nFIGURE 2-11 \nWorse-before- \nbetter behavior of \nmaintenance costs \nat a typical plant \nGraph shows \ndirect cost \nsavings after \nimplementation \nof the learning \nlaboratory and \nnew maintenance \npolicies at a \nparticular plant. \nVertical axis \ndisguised. \nPart I Perspective and Process \nexperience and authority. Ledet\u2019s team thus had to develop a group of trained fa- \ncilitators and a training process so that the quality of the workshop could be main- \ntained as it spread into the plants. The demand for the workshop grew slowly at \nfirst, but as favorable word of mouth about the experience and results spread, more \nand more plants asked Ledet\u2019s group to run the program for them. The surge in de- \nmand stressed the number of skilled facilitators, which lagged behind. By the end \nof 1992 some 1200 people had participated in the workshop and more than 50 fa- \ncilitators had been certified. \n2.4.3 Results \nBy 1994 a number of plants throughout the Gulf Coast region had adopted the \nlearning lab and associated policies. Figure 2-1 1 shows the direct maintenance cost \nsavings for a particular plant after implementation of the program. Just as seen in \nthe model and the game, the first effect of the new policies is an increase in costs. \nOnly after several months did the cost savings begin to accumulate. \nAmong plants that implemented the program by the end of 1993, the mean \ntime between failure (MTBF) for pumps (the focus of the program) rose by an av- \nerage of 12% each time cumulative operating experience doubled, while direct \nmaintenance costs had fallen an average of 20%. In 23 comparable plants not im- \nplementing the program the learning rate averaged just 5% per doubling of cumu- \nlative experience and costs were up an average of 7% (Carroll, Sterman, and \nMarcus 1998). The program at Washington Works boosted net production capabil- \nity 20%, improved customer service 9096, and cut delivery lead time by 5070, all \nwith minimal capital investment and a reduction in maintenance costs. It is diffi- \ncult to estimate the total benefit of the program for the company as a whole, but \nconservative estimates exceed $350 milliodyear in avoided maintenance costs. \nThe story does not end here, however. Success creates its own challenges. \nWhat happens to a plant after it succeeds in improving MTBFs and cutting main- \ntenance expenditures? One issue related to the persistence of the cost-saving \n$ \n30 \nE \n.- SS \nfJ4 \n20 \nQ z :  \n- \nz g  \nc .- \nr n =  \n10 \n.? u \n0 \n=I \n0 \n-10 -I \nI \nI \n11/92 \n12/92 \n1 193 \n2/93 \n3/93 \nSource: Allen (1 993).\n\nChapter 2 System Dynamics in Action \n77 \nmentality. A member of the modeling team commented, \u201cAs soon as you get the \nproblems down, people will be taken away from the effort and the problems will \ngo back up.\u201d In fact, cost-cutting programs mandated by corporate headquarters \ndid cause significant downsizing throughout the entire company and limited their \nability to expand the program. \nAnother problem for Du Pont",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 101
  },
  {
    "child_id": "1e3d4a03-345f-4823-b0f7-97dea5b77ba3",
    "parent_id": "ece100cc-90e2-438a-9eb0-39405e0ea474",
    "text": "0 \n=I \n0 \n-10 -I \nI \nI \n11/92 \n12/92 \n1 193 \n2/93 \n3/93 \nSource: Allen (1 993).\n\nChapter 2 System Dynamics in Action \n77 \nmentality. A member of the modeling team commented, \u201cAs soon as you get the \nproblems down, people will be taken away from the effort and the problems will \ngo back up.\u201d In fact, cost-cutting programs mandated by corporate headquarters \ndid cause significant downsizing throughout the entire company and limited their \nability to expand the program. \nAnother problem for Du Pont was rewarding the modeling team. Ledet be- \nlieved the game and learning laboratory had great potential to stimulate improve- \nment in a wide range of companies and industries. He began to receive inquiries \nfrom other firms interested in using the game. Ledet acquired the rights to the game \nfrom Du Pont, took early retirement, and became an entrepreneur, working with \nother companies to implement the approach. These firms include other chemicals \nmanufacturers along with firms in the energy, automotive, and high-tech sectors. \n2.4.4 \nTransferring the Learning: \nThe Lima Experience \nOne of the organizations that adopted the maintenance game and other system dy- \nnamics tools was British Petroleum (BP).16 BP\u2019s Lima, Ohio, refinery was built in \n1886 by John D. Rockefeller to supply fuel and petrochemicals to the Midwest. \nOnce the \u201cQueen of the Fleet,\u201d cost cutting during the 1980s had led to the same \nspiral of increasing breakdowns, declining performance, and still more cost cutting \nthat had plagued Du Pont. By the early 1990s it was a poor performer and lagged \nwell behind other US refineries. A number of improvement programs were tried, \nwith little success, and BP began to think about selling or closing the facility while \ntrying to cut costs. \nIn 1994 the Lima facility introduced the maintenance learning lab and game \nalong with some other tools of system dynamics such as the Beer Distribution \nGame. This was not a top management intervention: The game was initially cham- \npioned by an equipment specialist, a maintenance training supervisor, and an engi- \nneer, Paul Monus, then working in continuous improvement. Successful pilot \nprojects led refinery management to run 80% of all employees through the pro- \ngram. Soon dozens of improvement teams were in place. During the first 6 months \nmaintenance costs ballooned by 30%. Management was prepared for this worse- \nbefore-better dynamic, however, and focused on the improvements generated by \nthe action teams. Momentum began to build. \nIn January 1996 BP announced that it intended to sell the Lima refinery and \nstepped up its cost cutting and downsizing. A few months later BP stunned the em- \nployees by announcing that it could not find a buyer at a satisfactory price and \nwould therefore close the refinery. \nThe announcement was a deep blow to the workers and the city. The Lima \nfacility was one of the most important employers in the community, occupying \n650 acres of prime real estate and generating ",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 101
  },
  {
    "child_id": "42822a99-eefe-455c-8284-8c1d7d86fe40",
    "parent_id": "ece100cc-90e2-438a-9eb0-39405e0ea474",
    "text": "omentum began to build. \nIn January 1996 BP announced that it intended to sell the Lima refinery and \nstepped up its cost cutting and downsizing. A few months later BP stunned the em- \nployees by announcing that it could not find a buyer at a satisfactory price and \nwould therefore close the refinery. \nThe announcement was a deep blow to the workers and the city. The Lima \nfacility was one of the most important employers in the community, occupying \n650 acres of prime real estate and generating 400 jobs with payroll, utility, \nand other payments pumping more than $60 milliodyear into Lima\u2019s depressed \neconomy. \n16BP merged with Amoco in 1998, after the work described here was done.\n\n78 \nPart I Perspective and Process \nSome employees became discouraged and questioned the value of continuing \nthe program of defect elimination and proactive maintenance. A few transferred to \nother BP facilities or left altogether. Winston Ledet described what happened next: \nFor those who decided to stay with the ship, a new spirit emerged. They realized \nthat they needed a future in Lima and should take responsibility for creating that \nfuture. The first step was to ensure that the exit of many experienced people did not \nthrow them back in the reactive mode. This heightened the sense of urgency to do \ndefect elimination. It actually created a clearer focus for the people who remained. \nThey were all there because they had chosen to be there.17 \nSoon the cumulative impact of the new maintenance policies and attitudes was \nclearly visible in the performance of the plant. Table 2-2 highlights some of the \nresults. \nThe dramatic improvements in the refinery did not go unnoticed. On July 2, \n1998, the banner headline of the Lima News announced \u201cOil Refinery Rescued.\u201d \nClark USA, a privately held Fortune 500 company with refining and distribution \ninterests, agreed to buy the Lima refinery from BP for $215 million and keep it op- \nerating as a refinery. Many people and organizations contributed to the rescue of \nthe refinery. Yet without the dramatic improvements in refinery operations stimu- \nlated by the systems thinking intervention it is unlikely Clark, or any buyer, would \nhave offered enough for the facility to keep it running. \n1. Lima Refinery pump MTBF up from 12 to 58 months (pump failures \ndown from more than 640 in 1991 to 131 in 1998). Direct savings: \nTABLE 2-2 \nimprovement at \nthe Lima refinery \n$1.8 million/year. \n2. Total flare-off of hydrocarbon down from 1.5% to 0.35%. Direct savings: \n$0.27/barrel. Improved environmental quality. \n3. On-line analyzer uptime improvement from 75% and not trusted to 97% \nand trusted, permitting real-time optimization of product flow. Savings: \n$0.10-0.12/barrel. \n4. Thirty-four production records set. \n5. Safety incidents and lost hours cut by factor of 4. \n6. Cash margin improved by $0.77 per barrel of oil processed. \n7. Total new value created: $43 million/year. Total cost: $320,00O/year. \n8. BP wide learning initiati",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 101
  },
  {
    "child_id": "843e949c-42fe-441a-9f09-278f426a43a7",
    "parent_id": "ece100cc-90e2-438a-9eb0-39405e0ea474",
    "text": "o 0.35%. Direct savings: \n$0.27/barrel. Improved environmental quality. \n3. On-line analyzer uptime improvement from 75% and not trusted to 97% \nand trusted, permitting real-time optimization of product flow. Savings: \n$0.10-0.12/barrel. \n4. Thirty-four production records set. \n5. Safety incidents and lost hours cut by factor of 4. \n6. Cash margin improved by $0.77 per barrel of oil processed. \n7. Total new value created: $43 million/year. Total cost: $320,00O/year. \n8. BP wide learning initiative under way for all other refineries and plants. \nRatio: 143:l. \nOver 2000 people from sites in the US, UK, Australia, North Sea, Alaska, \nand Europe had participated in the workshop and game by 1998. \nSource: Paul Monus, personal communication; Monus, P. (1997) \u201cProactive Manufacturing at BP\u2019s \nLima Oil Refinery,\u201d presented at National Petroleum Refiners Association Maintenance Conference, \n20-23 May 1997, New Orleans; and Griffith, J., D. Kuenzli, and P. Monus (1998) \u201cProactive Manufac- \nturing: Accelerating Step Change Breakthroughs in Performance,\u201d NPRA Maintenance Conference, \nMC-98-92. \nI7TMG News, 15 September 1998.\n\nChapter 2 System Dynamics in Action \n79 \nThe success of the learning laboratory and maintenance game illustrates the \nreal purpose of the modeling process. The model, game, and workshop don\u2019t teach \nanyone how to maintain a pump better or how to do vibration monitoring. Du Pont, \nBP, and other organizations already have plenty of technical tools and knowledge. \nInstead, the game and learning laboratory enable people to experience the long- \nterm organizationwide consequences of their actions, to enact a future in which old \nways of behaving are changed, and to experience emotionally as well as cogni- \ntively what it might be like to make the transition to a high-performing plant. \nThe Lima experience illustrates the power of a shift in mental models. The BP \nteam reduced butane flare-off to zero, generating annual savings of $1.5 million/ \nyear and reducing pollution as well. The effort took 2 weeks and cost $5000, a \nreturn on investment of 30,00O%/year. What had stopped them from implementing \nthis improvement long ago? Members of the team knew about the problem and \nhow to solve it for 8 years. They already had all the engineering know-how they \nneeded to solve the problem and most of the equipment and materials were \nalready on site. The only barriers were the mental models through which employ- \nees came to believe that they were powerless, that the problem was imposed by \nexternal forces beyond their control, and that a few people could never make a \ndifference. \nThese entrenched mental models changed in four essential ways. The belief \nthat the problem was out there had to change from \u201cour equipment is lousy and \nthere\u2019s nothing we can do about it\u201d to \u201cour equipment performs poorly as a result \nof our own past policies-if we change our behavior, the equipment will respond.\u201d \nThe focus on defect correction through repairs had to ",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 101
  },
  {
    "child_id": "99c460ec-e19e-481c-af44-fbb9c74a6200",
    "parent_id": "ece100cc-90e2-438a-9eb0-39405e0ea474",
    "text": " that the problem was imposed by \nexternal forces beyond their control, and that a few people could never make a \ndifference. \nThese entrenched mental models changed in four essential ways. The belief \nthat the problem was out there had to change from \u201cour equipment is lousy and \nthere\u2019s nothing we can do about it\u201d to \u201cour equipment performs poorly as a result \nof our own past policies-if we change our behavior, the equipment will respond.\u201d \nThe focus on defect correction through repairs had to shift to a focus on defect pre- \nvention and elimination. The focus on minimizing maintenance costs had to shift \nto maximizing overall organizational performance. And they had to realize that es- \ncaping the trap of reactive maintenance necessarily involved a worse-before-better \ntradeoff. \nThe formal model was essential, as it led to the initial insights into the dynam- \nics of process improvement and the synergistic effects of high leverage policies. \nThe model also allowed the modeling team to develop the game and helped make \nit realistic. Ultimately implementation success required the modeling team to em- \nbed their insights into a learning environment that involved the active participation \nof the people on the front lines, that enabled people to discover those insights for \nthemselves, and that spoke not only to their heads but also to their hearts. \nSUMMARY: PRINCIPLES FOR SUCCESSFUL USE OF \nSYSTEM DYNAMICS \nThough the projects described above differed in many ways, they all illustrate a \nnumber of principles for effective development and implementation of system dy- \nnamics models (see chapter 3; see also Forrester 1961; Roberts 1977/1978; and \nMorecroft and Sterman 1994): \n1. Develop a model to solve a particular problem, not to model the system. \nA model must have a clear purpose and that purpose must be to solve the \nproblem of concern to the client. Modelers must exclude all factors not",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 101
  },
  {
    "child_id": "e613e8f9-3486-40b4-a7d3-a91753772d0e",
    "parent_id": "48ff5d9a-359f-49c2-902e-572156ed4a44",
    "text": "80 \nPart I Perspective and Process \n2. \n3. \n4. \n5. \n6. \n7. \nrelevant to the problem to ensure the project scope is feasible and the results \ntimely. The goal is to improve the performance of the system as defined by \nthe client. Focus on results. \nModeling should be integrated into a project from the beginning. \nThe value of the modeling process begins early on, in the problem \ndefinition phase. The modeling process helps focus diagnosis on the \nstructure of the system rather than blaming problems on the people making \ndecisions in that structure. \nBe skeptical about the value of modeling and force the \u201cwhy do we \nneed it\u201d discussion at the start of the project. \nThere are many problems for which system dynamics is not useful. \nCarefully consider whether system dynamics is the right technique for the \nproblem. Modelers should welcome difficult questions from the clients \nabout how the process works and how it might help them with their \nproblem. The earlier these issues are discussed, the better. \nSystem dynamics does not stand alone. Use other tools and methods as \nappropriate. \nMost modeling projects are part of a larger effort involving traditional \nstrategic and operational analysis, including benchmarking, statistical work, \nmarket research, etc. Effective modeling rests on a strong base of data and \nunderstanding of the issues. Modeling works best as a complement to other \ntools, not as a substitute. \nFocus on implementation from the start of the project. \nImplementation must start on the first day of the project. Constantly ask, \nHow will the model help the client make decisions? Use the model to set \npriorities and determine the sequence of policy implementation. Use the \nmodel to answer the question, How do we get there from here? Carefully \nconsider the real world issues involved in pulling various policy levers. \nQuantify the full range of costs and benefits of policies, not only those \nalready reported by existing accounting systems. \nModeling works best as an iterative process of joint inquiry between \nclient and consultant. \nModeling is a process of discovery. The goal is to reach new understanding \nof how the problem arises and then use that understanding to design high \nleverage policies for improvement. Modeling should not be used as a tool \nfor advocacy. Don\u2019t build a client\u2019s prior opinion about what should be \ndone into a model. Use workshops where the clients can test the model \nthemselves, in real time. \nAvoid black box modeling. \nModels built out of the sight of the client will never lead to change in \ndeeply held mental models and therefore will not change client behavior. \nInvolve the clients as early and as deeply as possible. Show them the model. \nEncourage them to suggest and run their own tests and to criticize the \nmodel. Work with them to resolve their criticisms to their satisfaction.\n\nChapter 2 System Dynamics in Action \n8 \n8. \n9. \n10. \n11. \n12. \nValidation is a continuous process of testing and building confidenc",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 105
  },
  {
    "child_id": "e65a0b7b-9233-4ef8-ac2b-6ce11038ad71",
    "parent_id": "48ff5d9a-359f-49c2-902e-572156ed4a44",
    "text": "els built out of the sight of the client will never lead to change in \ndeeply held mental models and therefore will not change client behavior. \nInvolve the clients as early and as deeply as possible. Show them the model. \nEncourage them to suggest and run their own tests and to criticize the \nmodel. Work with them to resolve their criticisms to their satisfaction.\n\nChapter 2 System Dynamics in Action \n8 \n8. \n9. \n10. \n11. \n12. \nValidation is a continuous process of testing and building confidence in \nthe model. \nModels are not validated after they are completed nor by any one test such \nas their ability to fit historical data. Clients (and modelers) build confidence \nin the utility of a model gradually, by constantly confronting the model with \ndata and expert opinion-their own and others\u2019. Through this process both \nmodel and expert opinions will change and deepen. Seek out opportunities \nto challenge the model\u2019s ability to replicate a diverse range of historical \nexperiences. \nGet a preliminary model working as soon as possible. Add detail only \nas necessary. \nDevelop a working simulation model as soon as possible. Don\u2019t try to \ndevelop a comprehensive conceptual model prior to the development of a \nsimulation model. Conceptual models are only hypotheses and must be \ntested. Formalization and simulation often uncover flaws in conceptual \nmaps and lead to improved understanding. The results of simulation \nexperiments inform conceptual understanding and help build confidence in \nthe results. Early results provide immediate value to clients and justify \ncontinued investment of their time. \nA broad model boundary is more important than a great deal of detail. \nModels must strike a balance between a useful, operational representation \nof the structures and policy levers available to the clients while capturing \nthe feedbacks generally unaccounted for in their mental models. In general, \nthe dynamics of a system emerge from the interactions of the components \nin the system-capturing those feedbacks is more important than a lot of \ndetail in representing the components themselves. \nUse expert modelers, not novices. \nWhile the software available for modeling is easily mastered by a high \nschool student or CEO, modeling is not computer programming. You cannot \ndevelop a qualitative diagram and then hand it off to a programmer for \ncoding into a simulation model. Modeling requires a disciplined approach \nand an understanding of business, skills developed through study and \nexperience. Get the expert assistance you need. Use the project as an \nopportunity to develop the skills of others on the team and in the client \norganization. \nImplementation does not end with a single project. \nIn all three cases the modeling work continued to have impact long after \nthe initial project was over. Models and management flight simulators were \napplied to similar issues in other settings. The modelers developed expertise \nthey applied to related problems and clients mov",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 105
  },
  {
    "child_id": "ce9020d1-a546-41ee-a5cf-2c98f209e4ea",
    "parent_id": "48ff5d9a-359f-49c2-902e-572156ed4a44",
    "text": "tudy and \nexperience. Get the expert assistance you need. Use the project as an \nopportunity to develop the skills of others on the team and in the client \norganization. \nImplementation does not end with a single project. \nIn all three cases the modeling work continued to have impact long after \nthe initial project was over. Models and management flight simulators were \napplied to similar issues in other settings. The modelers developed expertise \nthey applied to related problems and clients moved into new positions and \nnew organizations, taking the insights they gained and, sometimes, a new \nway of thinking, with them. Implementation is a long-term process of \npersonal, organizational, and social change.\n\n3 \nThe Modeling Process \nPerhaps the fault (for the poor implementation record for models] lies in the \norigins of managerial model-making-the translation of methods and prin- \nciples of the physical sciences into wartime operations research . , . If \nhypothesis, data, and analysis lead to proof and new knowledge in science, \nshouldn\u2019t similar processes lead to change in organizations? The answer is \nobvious-NO! Organizational changes (or decisions or policies) do not \ninstantly Pow from evidence, deductive logic, and mathematical optimization. \n-Edward B. Roberts\u2019 \nIn chapter 1 the concept of a virtual world was introduced as a way to speed the \nlearning process, and chapter 2 showed how models became virtual worlds to help \nsolve problems in three different situations. How can virtual worlds (models) be \nused most effectively? How can useful virtual worlds be created? Modeling takes \nplace in the context of real world problem solving, with all its messiness, ambi- \nguity, time pressure, politics, and interpersonal conflict. The purpose is to solve a \nproblem, not only to gain insight (though insight into the problem is required to \ndesign effective policies). Modeling, as a part of the learning process, is iterative, \na continual process of formulating hypotheses, testing, and revision, of both formal \nand mental models. Experiments conducted in the virtual world inform the design \nand execution of experiments in the real world; experience in the real world then \nleads to changes and improvements in the virtual world and in participants\u2019 mental \n\u2018Roberts, E. (1977), \u201cStrategies for effective implementation of complex corporate models,\u201d \nInterfaces 7(5); also chapter 4 in Roberts (1978). The paper remains a succinct and still relevant \nstatement of the need for an implementation focus from the very start of any modeling project. \n83\n\n84 \nPart I Perspective and Process \n3.1 \n3.2 \nmodels. This chapter discusses the purpose of modeling, describes the process of \nsystem dynamics modeling, the role of the client, and the modeler\u2019s professional \nand ethical responsibilities. \nTHE PURPOSE OF MODELING: \nMANAGERS AS ORGANIZATION DESIGNERS \nJay Forrester often asks, Who are the most important people in the safe operation \nof an aircraft? Most people re",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 105
  },
  {
    "child_id": "0d180d71-cc51-4d0d-9c5f-8a2cbe967cc8",
    "parent_id": "48ff5d9a-359f-49c2-902e-572156ed4a44",
    "text": " need for an implementation focus from the very start of any modeling project. \n83\n\n84 \nPart I Perspective and Process \n3.1 \n3.2 \nmodels. This chapter discusses the purpose of modeling, describes the process of \nsystem dynamics modeling, the role of the client, and the modeler\u2019s professional \nand ethical responsibilities. \nTHE PURPOSE OF MODELING: \nMANAGERS AS ORGANIZATION DESIGNERS \nJay Forrester often asks, Who are the most important people in the safe operation \nof an aircraft? Most people respond, The pilots. In fact, the most important people \nare the designers. Skilled, well-trained pilots are critical, but far more important is \ndesigning an aircraft that is stable, robust under extreme conditions, and that ordi- \nnary pilots can fly safely even when stressed, tired, or in unfamiliar conditions. In \nthe context of social and business systems, managers play both roles. They are pi- \nlots, malung decisions (who to hire, what prices to set, when to launch the new \nproduct) and they are designers, shaping the organizational structures, strategies, \nand decision rules that influence how decisions are made. The design role is the \nmost important but usually gets the least attention. Too many managers, especially \nsenior managers, spend far too much time acting as pilots-making decisions, tak- \ning control from subordinates-rather than creating an organizational structure \nconsistent with their vision and values and which can be managed well by ordinary \npeople (see Forrester 1965). \nToday designing a new aircraft is impossible without modeling and simulation. \nManagers seeking to enhance their organizational design skills, however, continue \nto design by trial and error, by anecdote, and by imitation of others, though the \ncomplexity of their organizations rivals that of an aircraft. Virtual worlds provide \nan important tool for managers in both the operation and especially the design of \ntheir organizations. \nThere is clearly a role for models that help managers pilot their organizations \nbetter, and system dynamics is often useful for these purposes. But the real value \nof the process comes when models are used to support organizational redesign. In \nIndustrial Dynamics, Forrester calls for courage in the selection of problems, say- \ning, \u201cThe solutions to small problems yield small rewards. . . The goal should be \nto find management policies and organizational structures that lead to greater suc- \ncess.\u201d Focus your modeling work on the important issues, on the problems where \nyour work can have lasting benefit, on the problems you care most deeply about. \nTHE CLIENT AND THE MODELER \nModeling does not take place in splendid isolation. It is embedded in an organi- \nzation and social context. Even before the modeling process per se begins, the \nmodeler must gain access to the organization and identify the client. The client is \nnot the person who brings you in to an organization or champions your work, nor \neven the person who pays for the model",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 105
  },
  {
    "child_id": "bfc6a8f6-2f61-434d-a208-6d6d71b25e3b",
    "parent_id": "48ff5d9a-359f-49c2-902e-572156ed4a44",
    "text": ", on the problems where \nyour work can have lasting benefit, on the problems you care most deeply about. \nTHE CLIENT AND THE MODELER \nModeling does not take place in splendid isolation. It is embedded in an organi- \nzation and social context. Even before the modeling process per se begins, the \nmodeler must gain access to the organization and identify the client. The client is \nnot the person who brings you in to an organization or champions your work, nor \neven the person who pays for the modeling study, though it is helpful to have \ncontacts, champions, and cash. Your clients are the people you must influence for \nyour work to have impact. They are those people whose behavior must change to \nsolve the problem. Your client can be a CEO or a machine operator on the factory \nfloor. Clients can be individuals, groups, or entire communities. The client for a",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 105
  },
  {
    "child_id": "52c630f9-6151-4c3a-87f3-25c12fee7c89",
    "parent_id": "f6a067f7-1e2d-40ed-8296-d46e19203882",
    "text": "Chapter 3 The Modeling Process \n85 \nmodeling study can be your academic colleagues, the public at large, or even your- \nself. In the discussion that follows, I will focus on modeling projects conducted for \norganizations. The process, however, is similar for these other contexts as well. \nTo be effective the modeling process must be focused on the clients\u2019 needs. \nThe clients for a modeling project are busy. They are embroiled in organizational \npolitics. They are looking out for their own careers. Their concern is solving a \nproblem and taking action in the real world. They care little for the elegance of \nyour theory or cleverness of your model. Modeling is done to help the client, not \nfor the benefit of the modeler. The client context and real world problem determine \nthe nature of the model, and the modeling process must be consistent with the \nclients\u2019 skills, capabilities, and goals. The purpose is to help the clients solve their \nproblem. If the clients perceive your model does not address their concerns or lose \nconfidence in it, you will have little impact. Focus your modeling work on the \nproblems that keep the clients up at night. \nThe political context of modeling and the need to focus on the clients\u2019 problem \ndoes not mean modelers should be hired guns, willing to do whatever the clients \nwant. Modelers should not automatically accede to clients\u2019 requests to include \nmore detail or to focus on one set of issues while ignoring others, just to keep the \nclients on board. A good modeling process challenges the clients\u2019 conception of the \nproblem. Modelers have a responsibility to require their clients to justify their \nopinions, ground their views in data, and consider new viewpoints. When the \nclients ask you to do something you think is unnecessary or misguided, you must \nwork with them to resolve the issue. \nUnfortunately, far too many clients are not interested in learning but in using \nmodels to support conclusions they\u2019ve already reached or as instruments to gain \npower in their organizations. Sadly, far too many consultants and modelers are \nonly too eager to oblige. As a modeler you have an ethical responsibility to carry \nout your work with rigor and integrity. You must be willing to let the modeling \nprocess change your mind. You must \u201cspeak truth to power,\u201d telling the clients that \ntheir most cherished beliefs are wrong, if that is what the modeling process reveals, \neven if it means you will be fired. If your clients push you to generate a result \nthey\u2019ve selected in advance or that is not supported by the analysis, push back. If \nyour clients\u2019 minds are closed, if you can\u2019t convince them to use modeling hon- \nestly, you must quit. Get yourself a better client.2 \n3.3 STEPS OF THE MODELING PROCESS \nIn practice, as a modeler you are first brought into an organization by a contact \nwho thinks you or your modeling tools might be helpful. Your first step is to find \nout what the real problem is and who the real client is. Your ",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 110
  },
  {
    "child_id": "3ac59de4-8faa-4a6f-94ac-5708c6cdf49c",
    "parent_id": "f6a067f7-1e2d-40ed-8296-d46e19203882",
    "text": "erate a result \nthey\u2019ve selected in advance or that is not supported by the analysis, push back. If \nyour clients\u2019 minds are closed, if you can\u2019t convince them to use modeling hon- \nestly, you must quit. Get yourself a better client.2 \n3.3 STEPS OF THE MODELING PROCESS \nIn practice, as a modeler you are first brought into an organization by a contact \nwho thinks you or your modeling tools might be helpful. Your first step is to find \nout what the real problem is and who the real client is. Your initial contact may not \nbe the client, but only serve as a gatekeeper who can introduce you to the client. \nAs the modeling project proceeds, you may find the client group expands or \nchanges. Assume that you\u2019ve successfully negotiated entry to the organization and \n2Wallace (1994) provides a good collection of articles addressing the ethical issues facing \nmodelers.\n\n86 \nPart I Perspective and Process \nTABLE 3-1 \nSteps of the \nmodeling process \n1. Problem Articulation (Boundary Selection) \nTheme selection: What is the problem? Why is it a problem? \nKey variables: What are the key variables and concepts we must \nconsider? \nTime horizon: How far in the future should we consider? How far back in \nthe past lie the roots of the problem? \nDynamic problem definition (reference modes): What is the historical \nbehavior of the key concepts and variables? What might their behavior \nbe in the future? \n2. Formulation of Dynamic Hypothesis \nInitial hypothesis generation: What are current theories of the problem- \natic behavior? \nEndogenous focus: Formulate a dynamic hypothesis that explains the \ndynamics as endogenous consequences of the feedback structure. \nMapping: Develop maps of causal structure based on initial hypotheses, \nkey variables, reference modes, and other available data, using tools \nsuch as \nModel boundary diagrams, \nSubsystem diagrams, \nCausal loop diagrams, \nStock and flow maps, \nPolicy structure diagrams, \nOther facilitation tools. \n3. Formulation of a Simulation Model \nSpecification of structure, decision rules. \nEstimation of parameters, behavioral relationships, and initial conditions. \nTests for consistency with the purpose and boundary. \nComparison to reference modes: Does the model reproduce the prob- \nRobustness under extreme conditions: Does the model behave realis- \nSensitivity: How does the model behave given uncertainty in parame- \n. . . Many other tests (see chapter 21). \nScenario specification: What environmental conditions might arise? \nPolicy design: What new decision rules, strategies, and structures might \nbe tried in the real world? How can they be represented in the model? \n\u201cWhat if. . .\u201d analysis: What are the effects of the policies? \nSensitivity analysis: How robust are the policy recommendations under \nInteractions of policies: Do the policies interact? Are there synergies or \n4. Testing \nlem behavior adequately for your purpose? \ntically when stressed by extreme conditions? \nters, initial conditions, model boundary, and aggre",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 110
  },
  {
    "child_id": "a8c1306e-93a5-4f10-b471-129c6c6eee58",
    "parent_id": "f6a067f7-1e2d-40ed-8296-d46e19203882",
    "text": "esign: What new decision rules, strategies, and structures might \nbe tried in the real world? How can they be represented in the model? \n\u201cWhat if. . .\u201d analysis: What are the effects of the policies? \nSensitivity analysis: How robust are the policy recommendations under \nInteractions of policies: Do the policies interact? Are there synergies or \n4. Testing \nlem behavior adequately for your purpose? \ntically when stressed by extreme conditions? \nters, initial conditions, model boundary, and aggregation? \n5. Policy Design and Evaluation \ndifferent scenarios and given uncertainties? \ncompensatorv responses?\n\nChapter 3 The Modeling Process \na7 \n3.4 \nidentified the (initial) clients. How do you proceed to develop a model which can \nbe helpful to them?3 \nThere is no cookbook recipe for successful modeling, no procedure you can \nfollow to guarantee a useful model. Modeling is inherently creative. Individual \nmodelers have different styles and approaches. Yet all successful modelers follow \na disciplined process that involves the following activities: (1) articulating the \nproblem to be addressed, (2) formulating a dynamic hypothesis or theory about the \ncauses of the problem, (3) formulating a simulation model to test the dynamic hy- \npothesis, (4) testing the model until you are satisfied it is suitable for your purpose, \nand (5) designing and evaluating policies for improvement. Table 3-1 lists these \nsteps along with some of the questions each step addresses and the principal tools \nused in each (see also Randers 1980). \nMODELING Is ITERATIVE \nFIGURE 3-1 \nThe modeling \nprocess is \niterative. \nResults of any \nstep can yield \ninsights that lead \nto revisions in \nany earlier step' \n(indicated by the \nlinks in the center \nof the diagram). \nBefore discussing each of these steps in more detail, it is important to place the \nmodeling process in context with the ongoing activities of the people in the system. \nModeling is a feedback process, not a linear sequence of steps. Models go through \nconstant iteration, continual questioning, testing, and refinement. Figure 3- 1 re- \ncasts the modeling process shown in Table 3-1 more accurately as an iterative \ncycle. The initial purpose dictates the boundary and scope of the modeling effort, \nbut what is learned from the process of modeling may feed back to alter our basic \nunderstanding of the problem and the purpose of our effort. Iteration can occur \nfrom any step to any other step (indicated by the interconnections in the center of \nthe diagram). In any modeling project one will iterate through these steps many \ntimes.4 \n(Boundary Selection) \n\\\". \nTesting \n/ \n3. Formulation \n3There is a huge literature on methods for planned organizational change and group interven- \ntions. See particularly Argyris and Schon (1996), Beckhard and Harris (1987), Dyer (1995), \nMichael (1997), and Schein (1987, 1988). \n4Homer (1996) provides an excellent discussion of the value of iteration and rigor in system \ndynamics, not only in",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 110
  },
  {
    "child_id": "5ef768e4-a821-4de5-8551-7b8695424303",
    "parent_id": "f6a067f7-1e2d-40ed-8296-d46e19203882",
    "text": " center of \nthe diagram). In any modeling project one will iterate through these steps many \ntimes.4 \n(Boundary Selection) \n\\\". \nTesting \n/ \n3. Formulation \n3There is a huge literature on methods for planned organizational change and group interven- \ntions. See particularly Argyris and Schon (1996), Beckhard and Harris (1987), Dyer (1995), \nMichael (1997), and Schein (1987, 1988). \n4Homer (1996) provides an excellent discussion of the value of iteration and rigor in system \ndynamics, not only in academic research but also in consulting work, with a variety of examples.\n\n88 \nPart I Perspective and Process \nFIGURE 3-2 \nModeling is \nembedded in \nthe dynamics \nof the system. \nEffective modeling \ninvolves constant \niteration between \nexperiments and \nlearning in the \nvirtual world and \nexperiments \nand learning in \nthe real world. \nMost importantly, modeling is embedded in the larger cycle of learning and ac- \ntion constantly taking place in organizations (and described in chapter 1). Pilots \nstep into an aircraft flight simulator and learn more quickly, effectively, and safely \nhow to operate the real aircraft, then put these skills to use in the real thing. They \nfeed back what they learn flying the real thing to the simulator designers so the \nsimulators can be continually improved. What pilots and designers learn in the \nsimulator is used in the real world. And what they learn in the real world is used to \nchange and improve the virtual world of the simulator. So it is with management \nflight simulators and system dynamics models. Figure 3-2 shows the modeling \nprocess embedded in the single- and double-loop learning feedbacks discussed in \nchapter 1. Simulation models are informed by our mental models and by informa- \ntion gleaned from the real world. Strategies, structures, and decision rules used in \nthe real world can be represented and tested in the virtual world of the model. The \nexperiments and tests conducted in the model feed back to alter our mental models \nand lead to the design of new strategies, new structures, and new decision rules. \nThese new policies are then implemented in the real world, and feedback about \ntheir effects leads to new insights and further improvements in both our formal and \nReal \nWorld \nDecisions \n(Organizational \nExperiments) \nInformation \nFeedback \nFormulatibn /=#* \n3. Formulation \nStrategy, \nMental \nStructure, \nDecision \nRules \\ \n/ \nWorld",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 110
  },
  {
    "child_id": "00faec17-f8c7-4517-b24a-b482c087e0f0",
    "parent_id": "762c357b-f15c-4431-b22b-55bcf7eadf0c",
    "text": "Chapter 3 \nThe Modeling Process \n89 \nmental models. Modeling is not a one-shot activity that yields The Answer, but an \nongoing process of continual cycling between the virtual world of the model and \nthe real world of action. \n3.5 \nOVERVIEW OF THE MODELING PROCESS \n3.5.1 \nProblem Articulation: \nThe Importance of Purpose \nThe most important step in modeling is problem articulation. What is the issue the \nclients are most concerned with? What problem are they trying to address? What is \nthe real problem, not just the symptom of difficulty? What is the purpose of the \nmodel? \nA clear purpose is the single most important ingredient for a successful mod- \neling study. Of course, a model with a clear purpose can still be misleading, un- \nwieldy, and difficult to understand. But a clear purpose allows your clients to ask \nquestions that reveal whether a model is useful in addressing the problem they care \nabout. \nBeware the analyst who proposes to model an entire business or social system \nrather than a problem. Every model is a representation of a system-a group of \nfunctionally interrelated elements forming a complex whole. But for a model to be \nuseful, it must address a specific problem and must simplify rather than attempt to \nmirror an entire system in detail. \nWhat is the difference? A model designed to understand how the business cy- \ncle can be stabilized is a model of a problem. It deals with a specific policy issue. \nA model designed to explore policies to slow fossil fuel use and mitigate global \nwarming is also a model of a problem; it too addresses only a limited set of issues. \nA model that claims to be a representation of the entire economy is a model of a \nwhole system. Why does it matter? The usefulness of models lies in the fact that \nthey simplify reality, creating a representation of it we can comprehend. A truly \ncomprehensive model would be just as complex as the system itself and just as in- \nscrutable. Von Clausewitz famously cautioned that the map is not the territory. It\u2019s \na good thing it isn\u2019t: A map as detailed as the territory would be of no use (as well \nas being hard to fold). \nThe art of model building is knowing what to cut out, and the purpose of the \nmodel acts as the logical knife. It provides the criteria to decide what can be ig- \nnored so that only the essential features necessary to fulfill the purpose are left. In \nthe example above, since the purpose of the comprehensive model would be to rep- \nresent the entire economic system, nothing could be excluded. To answer all con- \nceivable questions about the economy, the model would have to include an \noverwhelming array of variables. Because its scope and boundary are so broad, the \nmodel could never be completed. If it were, the data required to use it could never \nbe compiled. If they were, the model\u2019s underlying assumptions could never be \nexamined or tested. If they were, the model builders could never understand its \nbehavior and the clients\u2019 confidence in i",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 114
  },
  {
    "child_id": "2685f8e3-95fa-4086-a939-f64488daf9c4",
    "parent_id": "762c357b-f15c-4431-b22b-55bcf7eadf0c",
    "text": "ic system, nothing could be excluded. To answer all con- \nceivable questions about the economy, the model would have to include an \noverwhelming array of variables. Because its scope and boundary are so broad, the \nmodel could never be completed. If it were, the data required to use it could never \nbe compiled. If they were, the model\u2019s underlying assumptions could never be \nexamined or tested. If they were, the model builders could never understand its \nbehavior and the clients\u2019 confidence in it would depend on the authority of the \nmodeler and other nonscientific grounds. Mihailo Mesarovic, a developer of early\n\n90 \nPart I Perspective and Process \nglobal simulations, captured the impossibility of building models of systems when \nhe said, \u201cNo matter how many resources one has, one can envision a complex \nenough model to render resources insufficient to the task.\u201d (Meadows, Richardson, \nand Bruckmann 1982, p. 197). \nA model designed for a particular purpose such as understanding the business \ncycle or global climate change would be much smaller, since it would be limited to \nthose factors believed to be relevant to the question at hand. For example, the busi- \nness cycle model need not include long-term trends in population growth, resource \ndepletion, or climate change. The global warming model could exclude short-term \ndynamics related to interest rates, employment, and inventories. The resulting \nmodels could be simple enough so that their assumptions could be examined. The \nrelation of these assumptions to the most important theories regarding the business \ncycle and climate change could then be assessed to determine how useful the mod- \nels were for their intended purposes. Of course even models with well-defined pur- \nposes can be too large. But without a clear purpose, there is no basis to say \u201cwe \ndon\u2019t need to include that\u201d when a member of the client team makes a suggestion. \nIn sum: Always model a problem. Never model a system. \nUsually the modeler develops the initial characterization of the problem \nthrough discussion with the client team, supplemented by archival research, data \ncollection, interviews, and direct observation or participation. There are many \nmethods available to work with a group to elicit the information needed to define \nthe problem dynamically while still keeping the conversation focused firmly on the \nclients and their pr~blem.~ \nTwo of the most useful processes are establishing refer- \nence modes and explicitly setting the time horizon. \nReference Modes \nSystem dynamics modelers seek to characterize the problem dynamically, that is, \nas a pattern of behavior, unfolding over time, which shows how the problem arose \nand how it might evolve in the future. You should develop a reference mode, liter- \nally a set of graphs and other descriptive data showing the development of the \nproblem over time. Reference modes (so-called because you refer back to them \nthroughout the modeling process) help you and your clients b",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 114
  },
  {
    "child_id": "d117b3c6-523e-440e-9ab9-b9274c3cc025",
    "parent_id": "762c357b-f15c-4431-b22b-55bcf7eadf0c",
    "text": "he time horizon. \nReference Modes \nSystem dynamics modelers seek to characterize the problem dynamically, that is, \nas a pattern of behavior, unfolding over time, which shows how the problem arose \nand how it might evolve in the future. You should develop a reference mode, liter- \nally a set of graphs and other descriptive data showing the development of the \nproblem over time. Reference modes (so-called because you refer back to them \nthroughout the modeling process) help you and your clients break out of the short- \nterm event-oriented worldview so many people have. To do so you and the clients \nmust identify the time horizon and define those variables and concepts you \nconsider to be important for understanding the problem and designing policies to \nsolve it. \nTime Horizon \nThe time horizon should extend far enough back in history to show how the prob- \nlem emerged and describe its symptoms. It should extend far enough into the \nfuture to capture the delayed and indirect effects of potential policies. Most people \ndramatically underestimate the length of time delays and select time horizons that \n5See the references in note 9 for modeling tools that are effective for real time modeling with \norganizations and teams including eliciting and structuring the mental models of a group to define \nthe problem.\n\nChapter 3 The Modeling Process \n91 \n0 \nare far too short. A principal deficiency in our mental models is our tendency to \nthink of cause and effect as local and immediate. But in dynamically complex sys- \ntems, cause and effect are distant in time and space. Most of the unintended effects \nof decisions leading to policy resistance involve feedbacks with long delays, far re- \nmoved from the point of decision or the problem symptom. Work with your clients \nto think about the possible reactions to policies and how long they might take to \nplay out and then increase the time horizon even further. A long time horizon is a \ncritical antidote to the event-oriented worldview so crippling to our ability to iden- \ntify patterns of behavior and the feedback structures generating them. \nThe choice of time horizon dramatically influences your perception of the \nproblem. Figure 3-3 shows production, consumption, and imports of petroleum in \nthe United States from 1986 to 1996. The historical time horizon is 10 years, al- \nready a long time relative to most discussion of energy policy (the oil shocks of \nthe 1970s are considered ancient history in most policy debate today). The graphs \nshow production slowly trending down, consumption trending slowly up, and \ntherefore imports growing modestly. Prices fluctuate in a narrow band between \n$14 and $23 per barrel, lower than any time since the first oil crisis in 1973 (though \nprices did spike to $40/barrel after the Iraqi invasion of Kuwait, they soon fell \nback). The energy system appears to be relatively stable; there is little evidence of \na long-term problem. \nProduction, \nLower 48 States \nI \nFIGURE 3-3 \nUS ",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 114
  },
  {
    "child_id": "89c8fb28-995e-4b23-9673-a51739933ba6",
    "parent_id": "762c357b-f15c-4431-b22b-55bcf7eadf0c",
    "text": "day). The graphs \nshow production slowly trending down, consumption trending slowly up, and \ntherefore imports growing modestly. Prices fluctuate in a narrow band between \n$14 and $23 per barrel, lower than any time since the first oil crisis in 1973 (though \nprices did spike to $40/barrel after the Iraqi invasion of Kuwait, they soon fell \nback). The energy system appears to be relatively stable; there is little evidence of \na long-term problem. \nProduction, \nLower 48 States \nI \nFIGURE 3-3 \nUS oil production, \nconsumption, \n5. \nimports, and price \n. \nzi \nu) - \n2! z \nm \nover a 1 0-year \ntime horizon \n1 8 ;  \nt \nImports \n'p; \n, \n, \n, \n, \n, \n, \n, \n. i \n0 \n1986 \n1988 \n1990 \n1992 \n1994 \n1996 \nSource: EIA (US Energy Information Agency) Annual Energy Review.\n\n92 \n- \u2018 i  \nConsumption \n+ \nPart I Perspective and Process \nConsumption \n+ \nImports \nFIGURE 3-4 \nUS oil production, \nconsumption, \nimports, and price \nover a 130-year \ntime horizon \nL \nNow consider Figure 3-4, showing the same variables from near the beginning \nof the oil era (the petroleum industry began in earnest in 1859 with Colonel \nDrake\u2019s famous well in Titusville, Pennsylvania). The impression is completely \ndifferent. The history of the oil industry in the United States is divided into two \nregimes. From 1920 through 1973, consumption grew exponentially at an average \nrate of 4.3%/year. Production nearly kept pace, as exploration and better drilling \ntechniques more than offset depletion. Starting in the 1950s, imports grew slightly, \nstimulated by the availability of cheap foreign oil. Prices fluctuated, often dramat- \nically, but along a slowly declining trend as technology improved. All this changed \nin 1970. In 1970, domestic production of oil peaked. It\u2019s been falling ever since, \ndespite the intense exploration stimulated by the much higher prices of the 1970s \nand early 1980s. US production from the lower 48 states and adjacent offshore area \nin 1996 stood at only 54% of its peak level. Even the addition of Prudhoe Bay and \nthe trans-Alaska pipeline did not halt the slide, and Alaskan production peaked in \n1988. Higher prices following the 1970s oil shocks, along with the deepest reces- \nsions since the Great Depression, cut the growth of consumption, but imports nev- \nertheless reached 61% of total oil consumption by 1996. \nChanging the time horizon completely changes the assessment of the problem. \nViewed with a time scale consistent with the life of the resource, it is clear that the \npetroleum problem wasn\u2019t solved in the 1980s but has been steadily getting worse. \n>\n.\n \nr5 2 12- \n2 \nm \n- \nL \nm \nC \n6 -  \n- \n.- \n, \n, \n, \n185 \n#\ni\n \nI \n5 \n4 \n1 \nImports \nLower 40 States \nI \nI \nI \n1870 \n1890 \n1910 \n1930 \n1950 \n1970 \n1990 \n0-I \nt \n1870 \n1890 \n1910 \n1930 \n1950 \n1970 \n1990 \nI \nSource: Production & consumption: 1870-1 949, Davidsen (1 988); 1950-1 966, EIA Annual Energy \nReview, Price: 1880-1 968, Davidsen (1 988); 1968-1 996, EIA Annual Energy Review, Refiners \nAcquisition Cost.",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 114
  },
  {
    "child_id": "2cefc1f1-f6f3-46f3-abac-d10c6ac7350e",
    "parent_id": "85214983-ee78-467d-bf00-d6904e715436",
    "text": "Chapter 3 The Modeling Process \n.- 8 \n4- 0 \nQ\n-\n \n2 \nn \n% ; \nw\n-\n \nm \nln \nLL \n- \n.- \n93 \n,\n.\n,\n,\n,\nI\n,\n,\n,\n.\n \nI,\\ , \n, \nFIGURE 3-5 \nThe fossil fuel \nera shovvn with a \ntime horizon of \n151,000 years \nPetroleum is a finite nonrenewable resource. In the US, depletion began to domi- \nnate finding rates in the 1960s, leading to an inevitable decline in production, a de- \ncline that began in 1970. The United States is the most heavily explored and \ndensely drilled region of the world. The very success of early wildcatters in find- \ning oil means there is less left to find now. While not all the petroleum in the US \nhas been found or recovered, consumption continues to exceed the rate at which \nwhat remains is found. Consequently, imports continue to grow, leading to still \ngreater dependency on the unstable Persian Gulf region, still more political and \neconomic power for the oil exporting countries and less for the US, and, eventu- \nally, higher oil prices, either at the pump or in the defense budget.6 \nThe oil industry illustrates the dangers of selecting a time horizon too short to \ncapture the important dynamics and feedbacks creating them. Of course, one can \nerr too far in the other direction. Figure 3-5 shows a graph developed by the late \npetroleum geologist M. King Hubbert. Hubbert invented the most successful tech- \nnique for forecasting fossil fuel production ever created. In 1956 he estimated the \nultimate recoverable petroleum resources of the US to be between 150 and 200 bil- \nlion barrels and forecast that \u201cthe peak in production should probably occur within \nthe interval 1966-1971\u201d (Hubbert 1975, p. 371). His prediction of decline came at \na time when the US Geological Survey projected ultimate recoverable resources \nnearly three times as large and claimed \u201cthe size of the resource base would not \nlimit domestic production capacity \u2018in the next 10 to 20 years at least, and proba- \nbly [not] for a much longer time\u2019 \u201d (Gillette 1974). The actual peak occurred in \n1970 at almost the precise value Hubbert had predicted, one of the most accurate \nlong-term forecasts on record. Hubbert\u2019s success lay in explicitly modeling oil as \na nonrenewable resource. Production could grow exponentially in the early phases \n6There is a large literature of energy modeling in system dynamics, originating with work in \nMeadows et al. (1974). See, e.g., Backus (1996), Bunn and Larsen (1997), Fiddaman (1997), \nFord (1990, 1997, 1999), Ford and Bull (1989), Naill (1977, 1992), and Naill et al. (1992) for \nwork on national and global energy markets, electric utilities, global climate change, and other \nenergy policy issues.\n\n94 \nPart I Perspective and Process \nof its life cycle but had to fall to zero as it was depleted, forcing a transition to re- \nnewable energy source~.~ \nTo emphasize the transitory nature of fossil fuel civiliza- \ntion, Hubbert showed the production of fossil fuels on a time scale from the \nbeginning of the agricultural revolution 10,000 ye",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 118
  },
  {
    "child_id": "134ec93b-3440-418f-8a68-f80a339f1cd3",
    "parent_id": "85214983-ee78-467d-bf00-d6904e715436",
    "text": " 1992), and Naill et al. (1992) for \nwork on national and global energy markets, electric utilities, global climate change, and other \nenergy policy issues.\n\n94 \nPart I Perspective and Process \nof its life cycle but had to fall to zero as it was depleted, forcing a transition to re- \nnewable energy source~.~ \nTo emphasize the transitory nature of fossil fuel civiliza- \ntion, Hubbert showed the production of fossil fuels on a time scale from the \nbeginning of the agricultural revolution 10,000 years ago to 5000 years in the fu- \nture. Against this backdrop, the fossil fuel era is seen as a transitory spike-a \nunique period during which humanity lives extravagantly off a rich inheritance of \nirreplaceable natural capital. The picture is sobering. But Hubbert\u2019s pimple, as it \nwas called by critics, takes a time horizon too long to be useful to policy makers \nwho influence public policy or corporate strategy affecting energy prices, regula- \ntions, capital investment, and R&D. \nThe choice of time horizon can dramatically influence the evaluation of \npolicies. In the early 1970s a US government agency concerned with foreign aid \nsponsored a model focused on the Sahel region of sub-Saharan Africa. The Sahel \nwas then experiencing rapid population growth at the same time the desert was \nexpanding southward, reducing grazing land for the nomadic herders\u2019 cattle. The \npurpose of the model was to identify high leverage policies to spur economic \ndevelopment in the region. The model was used to assess the effects of many of \nthe policies then in use, such as drilling bore holes to increase the water supply for \ncattle by tapping deep aquifers or subsidizing crops such as sorghum and ground \nnuts. Running the model to the year 2000, a round number several decades in the \nfuture at the time, showed that the policies led to improvement. Subsidies in- \ncreased agricultural output. Bore holes permitted cattle stocks to grow, increasing \nthe supply of milk and meat and the wealth of the herders. However, running the \nmodel into the first decades of the 21 st century showed a different outcome: larger \nstocks of cattle began to outstrip the carrying capacity of the region. As the cattle \noverbrowsed and trampled the grasslands, erosion and desertification increased. \nThe cattle population dropped sharply, creating a food deficit in the region. Select- \ning a time horizon too short to capture these feedbacks favored adoption of poli- \ncies counter to the long-term interests of the region\u2019s people and the mission of the \nclient organization.* \nModelers must guard against accepting the client\u2019s initial assessment of the ap- \npropriate time frame. Often these are based on milestones and round numbers hav- \ning little to do with the dynamics of the problem, such as the end of the fiscal year, \nor the next 5-year planning cycle. A good rule of thumb is to set the time horizon \nseveral times as long as the longest time delays in the system, and then some. \n3.5.2 \nFormula",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 118
  },
  {
    "child_id": "73f23341-625e-48d1-b26e-e5d5ff556091",
    "parent_id": "85214983-ee78-467d-bf00-d6904e715436",
    "text": "of the region\u2019s people and the mission of the \nclient organization.* \nModelers must guard against accepting the client\u2019s initial assessment of the ap- \npropriate time frame. Often these are based on milestones and round numbers hav- \ning little to do with the dynamics of the problem, such as the end of the fiscal year, \nor the next 5-year planning cycle. A good rule of thumb is to set the time horizon \nseveral times as long as the longest time delays in the system, and then some. \n3.5.2 \nFormulating a Dynamic Hypothesis \nOnce the problem has been identified and characterized over an appropriate time \nhorizon, modelers must begin to develop a theory, called a dynamic hypothesis, to \n7Sterman and Richardson (1985), Sterman et al. (1988), and Sterman, Richardson, and Davidsen \n(1990) model the world and US petroleum life cycles and study the evolution of estimates of the \nresource base, showing why Hubbert was so accurate while other estimation methods proved so \nwildly overoptimistic. \n*Picadi and Seifert (1976) describe one of several models of the Sahel region (the model \ndescribed above was not published).\n\nChapter 3 The Modeling Process \n95 \naccount for the problematic behavior. Your hypothesis is dynamic because it must \nprovide an explanation of the dynamics characterizing the problem in terms of the \nunderlying feedback and stock and flow structure of the system. It is a hypothesis \nbecause it is always provisional, subject to revision or abandonment as you learn \nfrom the modeling process and from the real world. \nA dynamic hypothesis is a working theory of how the problem arose. It guides \nmodeling efforts by focusing you and your clients on certain structures. Much of \nthe remainder of the modeling process helps you to test the dynamic hypothesis, \nboth with the simulation model and by experiments and data collection in the real \nworld. \nIn practice, discussion of the problem and theories about the causes of the \nproblem are jumbled together in conversation with client teams. Each member of \na team likely has a different theory about the source of the problem; you need to \nacknowledge and capture them all. Many times the purpose of the model is to solve \na critically important problem that has persisted for years and generated great \nconflict and not a little animosity among members of the client team. All will \ntenaciously advocate their positions while deriding the views of others in the \ngroup. Early in the modeling process, the modeler needs to act as a facilitator, cap- \nturing these mental models without criticizing or filtering them. Clarifying and \nprobing questions are often useful, but the modeler\u2019s role during this early phase is \nto be a thoughtful listener, not a content expert. A variety of elicitation techniques \nand diagramming tools have been developed to assist you in facilitating a produc- \ntive conversation to elicit people\u2019s theories about the causes of the pr~blem.~ \nYour \ngoal is to help the client develop an endoge",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 118
  },
  {
    "child_id": "f0762cbf-a95b-4344-b970-98a0c65e4aad",
    "parent_id": "85214983-ee78-467d-bf00-d6904e715436",
    "text": " act as a facilitator, cap- \nturing these mental models without criticizing or filtering them. Clarifying and \nprobing questions are often useful, but the modeler\u2019s role during this early phase is \nto be a thoughtful listener, not a content expert. A variety of elicitation techniques \nand diagramming tools have been developed to assist you in facilitating a produc- \ntive conversation to elicit people\u2019s theories about the causes of the pr~blem.~ \nYour \ngoal is to help the client develop an endogenous explanation for the problematic \ndynamics. \nEndogenous Explanation \nSystem dynamics seeks endogenous explanations for phenomena. The word \u201cen- \ndogenous\u201d means \u201carising from within.\u201d An endogenous theory generates the dy- \nnamics of a system through the interaction of the variables and agents represented \nin the model. By specifying how the system is structured and the rules of interac- \ntion (the decision rules in the system), you can explore the patterns of behavior cre- \nated by those rules and that structure and explore how the behavior might change \nif you alter the structure and rules. In contrast, a theory relying on exogenous vari- \nables (those \u201carising from without,\u201d that is, from outside the boundary of the \nmodel) explains the dynamics of variables you care about in terms of other vari- \nables whose behavior you\u2019ve assumed. Exogenous explanations are really no ex- \nplanation at all; they simply beg the question, What caused the exogenous \nvariables to change as they did? The focus in system dynamics on endogenous ex- \nplanations does not mean you should never include any exogenous variables in \nyour models. But the number of exogenous inputs should be small, and each can- \ndidate for an exogenous input must be carefully scrutinized to consider whether \n9The literature on group model building is growing rapidly. Reagan-Cirincione et al. (1991), \nMorecroft and Sterman (1994), Vennix (1996), and Vennix et al. (1997) provide good overviews of \ntools and techniques to elicit and capture the mental models of teams and client groups.",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 118
  },
  {
    "child_id": "41313aac-c927-4caa-84e4-0e807d3c592a",
    "parent_id": "1cbe9079-aa63-4a4d-a51c-3b879012854a",
    "text": "96 \nPart I Perspective and Process \nthere are in fact any important feedbacks from the endogenous elements to the can- \ndidate. If so, the boundary of the model must be expanded and the variable must be \nmodeled endogenously. \nThe consequences of narrow model boundaries and reliance on exogenous \nvariables are often serious. A typical example is provided by the Project Indepen- \ndence Evaluation System (PIES) model, a hybrid model based on linear program- \nming, econometrics, and input/output analysis used in the 1970s by the US Federal \nEnergy Administration (FEA) and later by the US Department of Energy. As de- \nscribed by the FEA, the purpose of the model was to evaluate different energy poli- \ncies according to the following criteria: their impact on the development of \nalternative energy sources; their impact on economic growth, inflation, and unem- \nployment; their regional and social impacts; their vulnerability to import disrup- \ntions; and their environmental effects. \nSurprisingly, considering the stated purpose, the PIES model treated the econ- \nomy as exogenous. The model economy (including economic growth, interest \nrates, inflation, world oil prices, and the costs of unconventional fuels) was com- \npletely unaffected by the energy situation (including prices, policies, and produc- \ntion). In the model, even a full embargo of imported oil or a doubling of oil prices \nwould have no impact on the economy. \nTreating the economy exogenously made the PIES model inherently contra- \ndictory. Because it assumed high rates of economic growth and low price elastici- \nties, it projected huge increases in energy demand, requiring even greater increases \nin the capital requirements of the energy sector as cheap domestic oil was con- \nsumed. In the model, these huge investments in energy production were satisfied \nwithout reducing investment or consumption in the rest of the economy and with \nno impact on interest rates or inflation. In effect, the model let the economy have \nits pie and eat it too. \nIn part because it ignored the feedbacks between the energy sector and the rest \nof the economy, the PIES model consistently proved to be overoptimistic. In 1974 \nthe model projected that by 1985 the US would be well on the way to energy \nindependence: energy imports would be only 3.3 million barrels per day and \nproduction of shale oil would be 250,000 barrels per day. Furthermore, these \ndevelopments would be accompanied by oil prices of about $22 per barrel (1984 \ndollars) and by vigorous economic growth. It didn\u2019t happen. Imports in the late \n1980s were about 5.5 million barrels per day and grew to more than half of oil con- \nsumption by the mid 1990s. Shale oil and other exotic synfuels never materialized. \nThis situation prevailed despite huge reductions in oil demand caused by oil prices \nin the early 1980s greater than $30/bbl and the most serious recession since the \nGreat Depression. \nA broad model boundary that captures important feedbacks ",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 121
  },
  {
    "child_id": "4a08d879-1e5b-488a-af09-4dc021bc113d",
    "parent_id": "1cbe9079-aa63-4a4d-a51c-3b879012854a",
    "text": "(1984 \ndollars) and by vigorous economic growth. It didn\u2019t happen. Imports in the late \n1980s were about 5.5 million barrels per day and grew to more than half of oil con- \nsumption by the mid 1990s. Shale oil and other exotic synfuels never materialized. \nThis situation prevailed despite huge reductions in oil demand caused by oil prices \nin the early 1980s greater than $30/bbl and the most serious recession since the \nGreat Depression. \nA broad model boundary that captures important feedbacks is more impor- \ntant than a lot of detail in the specification of individual components. It is worth \nnoting that the PIES model provided a breakdown of supply, demand, and price for \ndozens of fuels in each region of the country yet its,aggregate projections \nweren\u2019t even close. What purpose was served by the effort devoted to forecasting \nthe demand for jet fuel or naphtha in the Pacific Northwest when the basic as- \nsumptions were so palpably inadequate and the main results were so woefully \nerroneous?\n\nChapter 3 The Modeling Process \n97 \nMapping System Structure \nSystem dynamics includes a variety of tools to help you communicate the bound- \nary of your model and represent its causal structure. These include model bound- \nary diagrams, subsystem diagrams, causal loop diagrams, and stock and flow \nmaps. \nModel boundary chart. A model boundary chart summarizes the scope of the \nmodel by listing which key variables are included endogenously, which are exoge- \nnous, and which are excluded from the model. \nTo illustrate, Table 3-2 shows a model boundary diagram for a model designed \nto study the feedbacks between the energy system and the economy (Sterman \n1983). Partly in reaction to the limitations of existing models such as PIES, the De- \npartment of Energy in the late 1970s sought to develop dynamic models with a \nbroader boundary (Nail1 1977, 1992). The purpose of the model was to explore the \nimpact of higher energy prices on economic growth, unemployment, inflation, and \ninterest rates and how these macroeconomic considerations might constrain the de- \nvelopment of new energy sources. The time horizon of the model was quite long \n(1950-2050) to capture the full transition from fossil fuels to renewable or other \nenergy sources and consistent with the long time delays in the development, con- \nstruction, and useful life of energy-producing and energy-consuming capital \nstocks. \nIn contrast to nearly all models used to address these issues at the time, the \nmodel had a broad boundary, with all major macroeconomic variables generated \nendogenously. Unlike the PIES model, the capital, labor, and energy requirements \nTABLE 3-2 \nModel boundary \nEndogenous \nExogenous \nExcluded \nchart for a long- \nGNP \n.. \nConsumption \nInvestment \nterm model of \nenergy-economy \ninteractions \nSavings \nPrices (real and nominal) \nWages (real and nominal) \nInflation rate \nLabor force participation \nEmployment \nUnemployment \nInterest rates \nMoney supply \nDebt \nEnergy production \n",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 121
  },
  {
    "child_id": "f477f35f-6281-4cfe-ae4b-c1454a86a180",
    "parent_id": "1cbe9079-aa63-4a4d-a51c-3b879012854a",
    "text": "l had a broad boundary, with all major macroeconomic variables generated \nendogenously. Unlike the PIES model, the capital, labor, and energy requirements \nTABLE 3-2 \nModel boundary \nEndogenous \nExogenous \nExcluded \nchart for a long- \nGNP \n.. \nConsumption \nInvestment \nterm model of \nenergy-economy \ninteractions \nSavings \nPrices (real and nominal) \nWages (real and nominal) \nInflation rate \nLabor force participation \nEmployment \nUnemployment \nInterest rates \nMoney supply \nDebt \nEnergy production \nEnergy demand \nEnergy imports \nPopulation \nInventories \nTechnological change \nInternational trade \nTax rates \n(except with OPEC) \nEnergy policies \nEnvironmental constraints \nNonenergy resources \nInterfuel substitution \nDistributional equity \nSource: Sterman (1 983).\n\n98 \nPart I Perspective and Process \nof the energy industries were endogenous and the energy industry had to compete \nagainst other sectors for these resources. The model still contained several exoge- \nnous variables. These include population, the rate of overall technological \nprogress, and the price of imported oil. Were these exogenous variables accept- \nable? Population growth and the overall rate of technical progress might be af- \nfected by changes in energy prices and consequent changes in the rate of economic \ngrowth. However, these feedbacks seemed likely to be small. The decision to \nmodel the price of imported oil exogenously is more problematic. Clearly the price \nof oil affects both the demand for and supply of energy in the United States, deter- \nmining the quantity imported. As a major importer, changes in US oil imports can \ndramatically alter the supply/demand balance of the oil exporting nations, feeding \nback to the price of oil in the world market. Treating import prices exogenously \ncuts an important feedback loop. In discussing the boundary of the model I argued \nthat there were in fact important feedbacks between the US energy system and the \nworld oil market. But I also argued that the dynamics of the world price were so \ncomplex that incorporating them endogenously was beyond the scope and purpose \nof the project. I had previously helped build a model of the world oil market for the \nUS Department of Energy and hoped that ultimately the two models could be \njoined. The model boundary chart alerted the clients to a questionable assumption \nso they could evaluate what the effect of the missing feedback might be. \nThe list of excluded concepts also provides important warnings to the model \nuser. The model omitted inventories of goods and materials (and hence short-term \nbusiness cycles)-no problem in such a long-term model. International trade was \nexcluded, except for the flows of oil, goods, capital, and money between the US \nand the oil exporting nations. The petrodollars flowing to OPEC and their recy- \ncling as exports or foreign investment had to be included, but to include nonenergy \ntrade would have expanded the model into a global macroeconomic system, and I \nwou",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 121
  },
  {
    "child_id": "30a9ae53-22b0-4671-84f5-a5a602f3cb8b",
    "parent_id": "1cbe9079-aa63-4a4d-a51c-3b879012854a",
    "text": "e model \nuser. The model omitted inventories of goods and materials (and hence short-term \nbusiness cycles)-no problem in such a long-term model. International trade was \nexcluded, except for the flows of oil, goods, capital, and money between the US \nand the oil exporting nations. The petrodollars flowing to OPEC and their recy- \ncling as exports or foreign investment had to be included, but to include nonenergy \ntrade would have expanded the model into a global macroeconomic system, and I \nwould probably still be working on it. Environmental constraints and nonenergy \nresources such as water that might limit new energy sources like synfuels were ex- \ncluded, meaning conclusions about the rate of development of these exotic energy \nsources would be overoptimistic. The model also treated the energy system in a \nfairly aggregate fashion, so interfuel substitution (oil vs. gas, for example), was not \nconsidered, another optimistic assumption. Finally, the model did not consider \nincome distribution, even though some energy policies such as gasoline taxes are \nregressive unless offset by changes in the income tax code. The purpose of listing \nall these omissions from the model was to help model users decide for themselves \nwhether the model was appropriate for their purpose. \nModel boundary diagrams are surprisingly useful and shockingly rare. Often, \nmodels are used not as tools of inquiry but as weapons in a war of advocacy. \nIn such cases modelers seek to hide the assumptions of their models from potential \ncritics. But even when the modelers\u2019 motives are benign, many feel uncomfortable \nlisting what they\u2019ve left out, see the omissions as flaws and prefer to stress the \nstrengths of their model. While this tendency is natural, it undercuts the utility of \nyour model and weakens the ability of people to learn from and improve your \nwork. By explicitly listing the concepts you have chosen not to include, at least \nfor now, you provide a visible reminder of the caveats to the results and limitations \nof the model. Without a clear understanding of the boundary and assumptions,\n\nChapter 3 The Modeling Process \n99 \nFIGURE 3-6 \nPatterns of \ncorporate growth \nmodels constructed for one purpose are frequently used for another for which they \nare ill-suited7 sometimes producing absurd results. All too often models with com- \npletely inappropriate and even bizarre assumptions about exogenous and excluded \nvariables are used in policy making because the model users are unable to exam- \nine the boundary of the models themselves and the modelers have not provided \nthat information for them (chapter 21 provides examples; see also Meadows and \nRobinson 1985). \nSubsystem diagram. A subsystem diagram shows the overall architecture of \na model. Each major subsystem is shown along with the flows of material, money, \ngoods, information, and so on coupling the subsystems to one another. Subsystems \ncan be organizations such as the firm and the customer or organization",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 121
  },
  {
    "child_id": "163e2978-e0b9-4066-b386-e23a101dcd84",
    "parent_id": "1cbe9079-aa63-4a4d-a51c-3b879012854a",
    "text": "e unable to exam- \nine the boundary of the models themselves and the modelers have not provided \nthat information for them (chapter 21 provides examples; see also Meadows and \nRobinson 1985). \nSubsystem diagram. A subsystem diagram shows the overall architecture of \na model. Each major subsystem is shown along with the flows of material, money, \ngoods, information, and so on coupling the subsystems to one another. Subsystems \ncan be organizations such as the firm and the customer or organizational subunits \nsuch as operations, marketing, and product development. Subsystem diagrams \nconvey information on the boundary and level of aggregation in the model by \nshowing the number and type of different organizations or agents represented. \nThey also communicate some information about the endogenous and exogenous \nvariables. \nIn the 1960s Jay Forrester served on the boards of several successful high-tech \ncompanies and became interested in the dynamics of corporate growth. To help \nhim think about the strategic issues facing these firms, Forrester (1964, p. 32) \ncreated a model designed \u201cto show how the differing kinds of corporate growth \npatterns can be created by different corporate policies and management attitudes \nand by the interactions between a company and its market.\u201d Figure 3-6 shows the \nreference mode. Forrester (pp. 32-33) explained: \nThe very rare company grows smoothly, as in curve A, and eventually reaches \na healthy sustained plateau of mature life. More frequently, the company follows a \npattern, as in curve B, where it appears to succeed at first and then encounters a \nsevere crisis that leads to bankruptcy or merger. Often, the pattern is growth stag- \nnation, as in curve C, marked by neither success nor failure. Of those companies \nwhich do show a long-term growth trend, the most common pattern is that in \ncurve D, where growth is accompanied by repeated crisis. \nTime \nSource: Adapted from Forrester (1 964).",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 121
  },
  {
    "child_id": "865f20da-fc53-4648-a2dc-cd2785d96579",
    "parent_id": "508492e6-3053-45dc-97ae-b6f4669fed98",
    "text": "100 \nPart I Perspective and Process \nFIGURE 3-7 \nSubsystem \ndiagram for \nForrester\u2019s \ncorporate growth \nmodel \nForrester argued that \u201ccontrary to first impressions, one cannot explain these \ndifferences on the basis of the particular industry or the type and design of prod- \nucts.. . One must therefore look deeper into the structure of information flows and \nthe policies which guide operating decisions\u201d (p. 33). To do so the model consisted \nof two subsystems, the company and the market (Figure 3-7). \nThe two subsystems are coupled by the obvious flows of orders, product, and \nmoney: The firm receives orders from the market, ships product, and receives pay- \nment. But in addition, the firm sends signals to the market including the price of \nthe product, its availability (measured by the delivery delay), its functionality, \nquality, suitability to customer needs, and other intangible attributes of the com- \npany\u2019s reputation. The market responds to these signals through the order rate and \nthrough customer feedback about price, quality, service, product features, and so \non. The diagram elegantly presents the essential feedback processes coupling a \nfirm to its market, stresses that orders depend on much more than price, and begins \nto suggest the structure which must be captured within each subsystem. Forrester \nreflected on the importance of this conceptual framework in his thinking: \nDefining the system boundary and the degree of aggregation are two of the most \ndifficult steps in successful modeling. In this particular study, part-time effort for \nabout two years was devoted to false starts before arriving at the point shown in \n[Figure 3-71. Thereafter, only eight weeks were required to create the entire system \nof some 200 equations. \nChapter 15 presents a simple version of this model, Forrester\u2019s \u201cmarket growth \nmodel,\u201d and shows how different management policies can create the patterns of \ngrowth described in Figure 3-6. \nA more detailed subsystem diagram is shown in Figure 3-8. The diagram \nshows the architecture for a model of a semiconductor manufacturer (Sterman, \nRepenning, and Kofman 1997). The purpose of the model was to explore the \ndynamics of process improvement programs. The firm had implemented a very \nProduct Suitability \n/Delivery \nof Product \nCompany \nMarket \n\\Payment-/ \nMkt. Response to Price \nMkt. Response to Quality \nSource: Adapted from Forrester (1 964). \n3\n\u2019\n\nChapter 3 The Modeling Process \n101 \nsuccessful quality improvement program. However, despite dramatic improve- \nments in quality, productivity, and customer responsiveness, operating profit \nand the stock price fell, leading to layoffs. Exploring this paradox required a \nmodel with a broad boundary both within the representation of the firm and in \ninteractions of the firm with its environment. Besides the usual subsystems for \nmanufacturing, product development, and accounting, the model includes a \nprocess improvement sector and a sector labeled \u201cFinancial Stre",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 125
  },
  {
    "child_id": "9d0853fa-e662-4151-a607-861960919fee",
    "parent_id": "508492e6-3053-45dc-97ae-b6f4669fed98",
    "text": "ogram. However, despite dramatic improve- \nments in quality, productivity, and customer responsiveness, operating profit \nand the stock price fell, leading to layoffs. Exploring this paradox required a \nmodel with a broad boundary both within the representation of the firm and in \ninteractions of the firm with its environment. Besides the usual subsystems for \nmanufacturing, product development, and accounting, the model includes a \nprocess improvement sector and a sector labeled \u201cFinancial Stress.\u201d The Financial \nStress subsystem is not an organizational subunit but represents top manage- \nment decisions regarding layoffs, investment, and the attention given to process \nFIGURE 3-8 Subsystem diagram for model of a semiconductor firm and its quality \nProcess \nimprovement \nimprovement \nimprovement \ncommitment \n\u20188 Quality \nI* Process \n\u2018e Workforce \ni rnp rovemen t Cp rog ram \n\u2018 \nMarket \u2019-\nCompeting \nProducts \nMarket \nshare \nPotential \nmarket \nCompetitor \nt \nNew \nProducts \nA \nPrice \nr \n\\ \n+ \n[New-Product Development\u2019 \nDefects \nPricing \nOrders \nBreakthrough products \n0 Line extensions \nDevelolpment projects \n1 \nManagement \nAccounting \nManufacturing \ne Management \nsupport \n4 \nCost of goods sold \nCapital \n- \nc y ~ ~ ~ ; m e  4 \nLabor \nInventory \nt p g z t t d  Budget variances \nHiring/Firing \nInvestment \nOperating income \nLabor variances \nTakeover threat \nForecasted revenue \nI Desired fraction to R&D \nThe \nFirm \nFinancial \u2019 \nAccounting \nIncome statement \nBalance sheet \nFlow of funds \n7 \n/ \nd \nMarket Value \nFinancial Markets \nSource: Adapted from Sterman, Repenning, and Kofman (1 997).\n\n102 \nPart I Perspective and Process \nimprovement. These decisions were affected by the firm\u2019s financial health and the \nthreat of takeover (as influenced by the market value of the firm relative to book \nvalue and cash flow). The diagram also shows that the firm\u2019s sales and market \nshare are endogenous, as is competitor behavior (note that competitors respond not \nonly to the firm\u2019s price but also to its quality improvement efforts). The stock price \nand market valuation of the firm are also endogenous. \nSubsystem diagrams are overviews and should not contain too much detail. \nThe diagram in Figure 3-8 is quite complex; subsystem diagrams should generally \nbe simpler. Multiple subsystem diagrams can be used to convey the hierarchical \nstructure of large models. \nCausal loop diagrams. Model boundary charts and subsystem diagrams \nshow the boundary and architecture of the model but don\u2019t show how the variables \nare related. Causal loop diagrams (CLDs) are flexible and useful tools for dia- \ngramming the feedback structure of systems in any domain. Causal diagrams are \nsimply maps showing the causal links among variables with arrows from a cause \nto an effect. Chapter 2 provides examples; chapter 5 covers the rules for their con- \nstruction and interpretation in depth. \nStock and flow maps. Causal loop diagrams emphasize the feedback struc- \nture of a system. Stock and flow ",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 125
  },
  {
    "child_id": "98b55e9a-8a3b-4df5-a87f-c238d7c7e66e",
    "parent_id": "508492e6-3053-45dc-97ae-b6f4669fed98",
    "text": "on\u2019t show how the variables \nare related. Causal loop diagrams (CLDs) are flexible and useful tools for dia- \ngramming the feedback structure of systems in any domain. Causal diagrams are \nsimply maps showing the causal links among variables with arrows from a cause \nto an effect. Chapter 2 provides examples; chapter 5 covers the rules for their con- \nstruction and interpretation in depth. \nStock and flow maps. Causal loop diagrams emphasize the feedback struc- \nture of a system. Stock and flow diagrams emphasize their underlying physical \nstructure. Stocks and flows track accumulations of material, money, and informa- \ntion as they move through a system. Stocks include inventories of product, popu- \nlations, and financial accounts such as debt, book value, and cash. Flows are the \nrates of increase or decrease in stocks, such as production and shipments, births \nand deaths, borrowing and repayment, investment and depreciation, and receipts \nand expenditures. Stocks characterize the state of the system and generate the in- \nformation upon which decisions are based. The decisions then alter the rates of \nflow, altering the stocks and closing the feedback loops in the system. Chapter 2 \nshows examples; chapters 6 and 7 discuss the mapping and behavior of stocks and \nflows. \nPolicy structure diagrams. These are causal diagrams showing the informa- \ntion inputs to a particular decision rule. Policy structure diagrams focus attention \non the information cues the modeler assumes decision makers use to govern the \nrates of flow in the system. They show the causal structure and time delays in- \nvolved in particular decisions rather than the feedback structure of the overall sys- \ntem. Chapter 15 provides examples; see Morecroft (1982) for details. \n3.5.3 \nFormulating a Simulation Model \nOnce you\u2019ve developed an initial dynamic hypothesis, model boundary, and con- \nceptual model, you must test them. Sometimes you can test the dynamic hypothe- \nsis directly through data collection or experiments in the real system. Most of the \ntime, however, the conceptual model is so complex that its dynamic implications \nare unclear. As discussed in chapter 1, our ability to infer correctly the dynamics of \na complex model is extremely poor. Further, in many situations, especially human \nsystems, it is difficult, dangerous, unethical, or simply impossible to conduct the\n\nChapter 3 The Modeling Process \n1 03 \nreal world experiments that might reveal the flaws in a dynamic hypothesis. In the \nmajority of cases, you must conduct these experiments in a virtual world. To do so, \nyou must move from the conceptual realm of diagrams to a fully specified formal \nmodel, complete with equations, parameters, and initial conditions. \nActually, formalizing a conceptual model often generates important insight \neven before it is ready to be simulated. Formalization helps you to recognize vague \nconcepts and resolve contradictions that went unnoticed or undiscussed during the \nconceptua",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 125
  },
  {
    "child_id": "e8305729-7447-46f5-ad36-557a67c66a39",
    "parent_id": "508492e6-3053-45dc-97ae-b6f4669fed98",
    "text": "is. In the \nmajority of cases, you must conduct these experiments in a virtual world. To do so, \nyou must move from the conceptual realm of diagrams to a fully specified formal \nmodel, complete with equations, parameters, and initial conditions. \nActually, formalizing a conceptual model often generates important insight \neven before it is ready to be simulated. Formalization helps you to recognize vague \nconcepts and resolve contradictions that went unnoticed or undiscussed during the \nconceptual phase. Formalization is where the real test of your understanding oc- \ncurs: computers accept no hand waving arguments. Indeed, the most experienced \nmodelers routinely write some equations and estimate parameters throughout the \nmodeling process, even in the earliest phases of problem articulation and concep- \ntualization-often with the clients-as a way to resolve ambiguity and test initial \nhypotheses. System dynamics practice includes a large variety of tests one can \napply during the formulation stage to identify flaws in proposed formulations and \nimprove your understanding of the system. \n3.5.4 \nTesting \nTesting begins as soon as you write the first equation. Part of testing, of course, is \ncomparing the simulated behavior of the model to the actual behavior of the sys- \ntem. But testing involves far more than the replication of historical behavior. Every \nvariable must correspond to a meaningful concept in the real world. Every equa- \ntion must be checked for dimensional consistency (so you aren\u2019t adding apples and \noranges). The sensitivity of model behavior and policy recommendations must be \nassessed in light of the uncertainty in assumptions, both parametric and structural. \nModels must be tested under extreme conditions, conditions that may never \nhave been observed in the real world. What happens to the GDP of a simulated \neconomy if you suddenly reduce energy supplies to zero? What happens in a model \nof an automaker if you raise the price of its cars by a factor of one billion? What \nhappens if you suddenly increase dealer inventories by 1000%? Even though these \nconditions have never and could never be observed, there is no doubt about what \nthe behavior of the system must be: Without energy, the GDP of a modern econ- \nomy must fall nearly to zero; with a price one billion times higher, the demand for \nthe firm\u2019s cars must fall to zero; with a huge surplus of cars on dealer lots, produc- \ntion should soon fall to zero but cannot become negative. You might imagine that \nmodels would never fail to pass such obvious tests, that production without energy, \ndemand for goods that cost more than the total wealth of many nations, and nega- \ntive production would never arise. But you\u2019d be wrong. Many widely used models \nin economics, psychology, management, and other disciplines violate basic laws of \nphysics, even though they may replicate historical behavior quite well (see section \n9.3.2 and chapter 21). Extreme conditions tests, along with oth",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 125
  },
  {
    "child_id": "cb54d21c-efca-450d-94d1-6f9fa1bdb970",
    "parent_id": "508492e6-3053-45dc-97ae-b6f4669fed98",
    "text": "u might imagine that \nmodels would never fail to pass such obvious tests, that production without energy, \ndemand for goods that cost more than the total wealth of many nations, and nega- \ntive production would never arise. But you\u2019d be wrong. Many widely used models \nin economics, psychology, management, and other disciplines violate basic laws of \nphysics, even though they may replicate historical behavior quite well (see section \n9.3.2 and chapter 21). Extreme conditions tests, along with other tests of model be- \nhavior, are critical tools to discover the flaws in your model and set the stage for \nimproved understanding. \n3.5.5 \nPolicy Design and Evaluation \nOnce you and the client have developed confidence in the structure and behavior \nof the model, you can use it to design and evaluate policies for improvement.",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 125
  },
  {
    "child_id": "75e44cae-fa87-42b6-a6e8-5fb556f9672a",
    "parent_id": "4bec0f95-4120-489f-925e-f4cc227c5c6d",
    "text": "104 \nPart I Perspective and Process \nPolicy design is much more than changing the values of parameters such as a tax \nrate or markup ratio. Policy design includes the creation of entirely new strategies, \nstructures, and decision rules. Since the feedback structure of a system determines \nits dynamics, most of the time high leverage policies will involve changing the \ndominant feedback loops by redesigning the stock and flow structure, eliminating \ntime delays, changing the flow and quality of information available at key decision \npoints, or fundamentally reinventing the decision processes of the actors in the sys- \ntem. \nThe robustness of policies and their sensitivity to uncertainties in model para- \nmeters and structure must be assessed, including their performance under a wide \nrange of alternative scenarios. The interactions of different policies must also be \nconsidered: Because real systems are highly nonlinear, the impact of combination \npolicies is usually not the sum of their impacts alone. Often policies interfere \nwith one another; sometimes they reinforce one another and generate substantial \nsynergies. \n3.6 SUMMARY \nThis chapter described the modeling process. While there are certain steps all mod- \nelers go through, modeling is not a cookbook procedure. It is fundamentally cre- \native. At the same time, modeling is a disciplined, scientific, and rigorous process, \nchallenging the modeler and client at every step to surface and test assumptions, \ngather data, and revise their models-both formal and mental. \nModeling is iterative. No one ever built a model by starting with step 1 and \nprogressing in sequence through a list of activities. Modeling is a continual process \nof iteration among problem articulation, hypothesis generation, data collection, \nmodel formulation, testing, and analysis. There are revisions and changes, blind al- \nleys and backtraclung. Effective modeling continually cycles between experiments \nin the virtual world of the model and experiments and data collection in the real \nworld. \nModels must be clearly focused on a purpose. Never build a model of a sys- \ntem. Models are simplifications; without a clear purpose, you have no basis for ex- \ncluding anything from your model and your effort is doomed to failure. Therefore \nthe most important step in the modeling process is working with your client to ar- \nticulate the problem-the real problem, not the symptoms of the problem, the lat- \nest crisis, or the most recent fad. Of course, as the modeling process leads you to \ndeeper insight, your definition and statement of the problem may change. Indeed, \nsuch radical reframings are often the most important outcome of modeling. \nThe purpose of modeling is to help the clients solve their problem. Though the \nmodeling process often challenges the clients\u2019 conception of the problem, ulti- \nmately, if the client perceives that your model does not address their concern, you \ncan have little impact. The modeler must not grow",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 129
  },
  {
    "child_id": "ef1e75ef-901a-44c4-b4e4-57138b89875b",
    "parent_id": "4bec0f95-4120-489f-925e-f4cc227c5c6d",
    "text": "f course, as the modeling process leads you to \ndeeper insight, your definition and statement of the problem may change. Indeed, \nsuch radical reframings are often the most important outcome of modeling. \nThe purpose of modeling is to help the clients solve their problem. Though the \nmodeling process often challenges the clients\u2019 conception of the problem, ulti- \nmately, if the client perceives that your model does not address their concern, you \ncan have little impact. The modeler must not grow attached to a model, no matter \nhow elegant or how much time has been invested in it. If it doesn\u2019t help the clients \nsolve their problem, it needs to be revised until it does. \nModeling takes place in an organizational and social context. The setting may \nbe a business but can also be a government agency, a scientific community, a pub- \nlic policy debate, or any other organization. Modelers are inevitably caught up in\n\nChapter 3 The Modeling Process \n105 \nthe politics of the community and personalities of its members. Modelers require \nboth first-rate analytical skills and excellent interpersonal and political skills. \nFinally, modelers have an ethical responsibility to pursue the modeling process \nwith rigor and integrity. The fact that modeling is embedded in an organizational \ncontext and subject to political pressures does not relieve you of your responsibil- \nity to carry out your work with the highest standards of scientific inquiry and pro- \nfessional conduct. If your client is not willing to pursue the modeling process \nhonestly, quit and find yourself a better client.\n\n4 \nStructure and Behavior of \nDynamic Systems \nLike all systems, the complex system is an interlocking structure of feedback \nloops . . . This loop structure surrounds all decisions public or private, \nconscious or unconscious. The processes of man and nature, of psychology and \nphysics, of medicine and engineering all fall within this structure. \n-Jay W. Forrester, Urban Dynamics (1969), p. 107. \nThe behavior of a system arises from its structure. That structure consists of the \nfeedback loops, stocks and flows, and nonlinearities created by the interaction of \nthe physical and institutional structure of the system with the decision-making \nprocesses of the agents acting within it. This chapter provides an overview of dy- \nnamics focusing on the relationship between structure and behavior. The basic \nmodes of behavior in dynamic systems are identified along with the feedback \nstructures generating them. These modes include growth, created by positive feed- \nback; goal seeking, created by negative feedback; and oscillations (including \ndamped oscillations, limit cycles, and chaos), created by negative feedback with \ntime delays. More complex modes such as S-shaped growth and overshoot and col- \nlapse arise from the nonlinear interaction of these basic structures. The chapter also \nillustrates the concept of reference modes to capture dynamic behavior and causal \nloop diagrams as a",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 129
  },
  {
    "child_id": "650a6876-ab37-429d-8ff0-fdb0573dee6e",
    "parent_id": "4bec0f95-4120-489f-925e-f4cc227c5c6d",
    "text": "nerating them. These modes include growth, created by positive feed- \nback; goal seeking, created by negative feedback; and oscillations (including \ndamped oscillations, limit cycles, and chaos), created by negative feedback with \ntime delays. More complex modes such as S-shaped growth and overshoot and col- \nlapse arise from the nonlinear interaction of these basic structures. The chapter also \nillustrates the concept of reference modes to capture dynamic behavior and causal \nloop diagrams as a method to represent feedback structure. \n1 07\n\n108 \nPart I Perspective and Process \n4.1 \nFUNDAMENTAL MODES OF DYNAMIC BEHAVIOR \nChange takes many forms, and the variety of dynamics around us is astounding. \nYou might imagine that there must be a correspondingly huge variety of different \nfeedback structures to account for such a rich array of dynamics. In fact, most dy- \nnamics are instances of a fairly small number of distinct patterns of behavior, such \nas exponential growth or oscillation. Figure 4-1 shows the most common modes of \nbehavior. \nThe most fundamental modes of behavior are exponential growth, goal seek- \ning, and oscillation. Each of these is generated by a simple feedback structure: \ngrowth arises from positive feedback, goal seeking arises from negative feedback, \nand oscillation arises from negative feedback with time delays in the loop. Other \ncommon modes of behavior, including S-shaped growth, S-shaped growth with \novershoot and oscillation, and overshoot and collapse, arise from nonlinear inter- \nactions of the fundamental feedback structures. \n4.1 .I \nExponential Growth \nExponential growth arises from positive (self-reinforcing) feedback. The larger the \nquantity, the greater its net increase, further augmenting the quantity and leading to \never-faster growth (Figure 4-2). The paradigm cases are compound interest and the \ngrowth of populations. The more money you have invested, the more interest you \nearn, so the greater your balance and the greater still the next interest payment will \nbe. The larger the population, the bigger the net birth rate, adding to the population \nand eventually leading to still more births, in an ever-accelerating spiral. Pure ex- \nponential growth has the remarkable property that the doubling time is constant: \nthe state of the system doubles in a fixed period of time, no matter how large. \nFIGURE 4-1 \nCommon modes of behavior in dynamic systems \nSoal Seeking \nI S-shaDed Growth \n- \nTime - \nI Oscillation \nGrowth with Overshoot \nOvershoot and Collapse\n\nChapter 4 Structure and Behavior of Dynamic Systems \n109 \nIt takes the same length of time to grow from one unit to two as it does to grow \nfrom one million to two million. This property is a direct consequence of positive \nfeedback: the net increase rate depends on the size of the state of the system (see \nchapter 8). Positive feedback need not always generate growth. It can also create \nself-reinforcing decline, as when a drop in stock prices erodes investo",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 129
  },
  {
    "child_id": "8731989a-42cb-4077-8485-395862cf8bc5",
    "parent_id": "4bec0f95-4120-489f-925e-f4cc227c5c6d",
    "text": "h Overshoot \nOvershoot and Collapse\n\nChapter 4 Structure and Behavior of Dynamic Systems \n109 \nIt takes the same length of time to grow from one unit to two as it does to grow \nfrom one million to two million. This property is a direct consequence of positive \nfeedback: the net increase rate depends on the size of the state of the system (see \nchapter 8). Positive feedback need not always generate growth. It can also create \nself-reinforcing decline, as when a drop in stock prices erodes investor confidence \nwhich leads to more selling, lower prices, and still lower confidence. \nWhat about linear growth? Linear growth is actually quite rare. Linear growth \nrequires that there be no feedback from the state of the system to the net increase \nrate, because the net increase remains constant even as the state of the system \nchanges. What appears to be linear growth is often actually exponential, but \nviewed over a time horizon too short to observe the acceleration. \nFigure 4-3 shows some examples of exponential growth. Growth is never per- \nfectly smooth (due to variations in the fractional growth rates, cycles, and pertur- \nbations), but in each case exponential growth is the dominant mode of behavior. \nThough the doubling times vary widely (from about 40 years for world population \nto about 2 years for semiconductor performance), these systems all exhibit the \nsame enormous acceleration caused by positive feedback. \nProcess Point: When a Rate Is Not a Rate \nIn dynamic modeling, the term \u201crate\u201d generally refers to the absolute rate of \nchange in a quantity. The population growth example above states, \u201cthe larger the \nFIGURE 4-2 \nExponential growth: structure and behavior \nThe causal loop diagram in the bottom half \nof the figure shows the feedback structure \nthat generates (exponential growth. Arrows \nindicate the direction of causal influences. \nHere, State of the System determines Net \nIncrease Rate (the lower arrow), and Net \nIncrease Rate adds to State of the System \n(the upper arrow). Signs at arrow heads \n(f or -) indicate the polarity of the \nrelationship. A positive polarity, indicated \nby f ,  means an increase in the \nindependent va.riable causes the \ndependent variable to rise above what it \nwould have been (and a decrease causes \na decrease). Negative signs (see Figure \n4-4) mean an increase (decrease) in \nthe independent variable causes the \ndependent variable to decrease (increase) \nbeyond what it would have been. Loop \nidentifiers show the polarity of the loop, \neither positive (self-reinforcing, denoted \nby R) or negative (balancing, denoted \nby B; see Figure 4-4). Chapter 5 \ndiscusses causal loop diagrams in depth. \nf+ \n/ \nNet \nRate \nState of the \nIncrease \nSystem\n\nFIGURE 4-3 Exponential growth: examples \n6 \n. \na \nQ\n-\n \nE\n.\n \n1 3 -  \n2\n-\n \n.- \n- \nr \n0 - \n.- \nI- \ns\n-\n \n.- \n-\n.\n \n- \ns\n-\n \n0 -  \nUS Real \n,\n,\n,\n.\nI\n,\n I \n,\n,\n I\n~\n.\n,\n.\nI\n~\n,\n,\n,\n~\n,\n,\n,\n,\n \nAverage growth rate: \n34%/year (doubling time = 2 years) \n. \nAverage growth rate ",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 129
  },
  {
    "child_id": "29b7d984-b19f-4d75-af2f-81cee369f72f",
    "parent_id": "4bec0f95-4120-489f-925e-f4cc227c5c6d",
    "text": "ity of the loop, \neither positive (self-reinforcing, denoted \nby R) or negative (balancing, denoted \nby B; see Figure 4-4). Chapter 5 \ndiscusses causal loop diagrams in depth. \nf+ \n/ \nNet \nRate \nState of the \nIncrease \nSystem\n\nFIGURE 4-3 Exponential growth: examples \n6 \n. \na \nQ\n-\n \nE\n.\n \n1 3 -  \n2\n-\n \n.- \n- \nr \n0 - \n.- \nI- \ns\n-\n \n.- \n-\n.\n \n- \ns\n-\n \n0 -  \nUS Real \n,\n,\n,\n.\nI\n,\n I \n,\n,\n I\n~\n.\n,\n.\nI\n~\n,\n,\n,\n~\n,\n,\n,\n,\n \nAverage growth rate: \n34%/year (doubling time = 2 years) \n. \nAverage growth rate 3.45Y0/year \nDoubling time = 20 years \nGDP \n------I \n0 I\n1850 \n1900 \n1950 \n2000 \nWorld Population \n6 \n1900-1950: 0.86Yo/year (doubling time = 80 years) \n1950-2000: 1.76Yo/year (doubling time = 40 years) \n0 \n0 \n400 \n800 \n1200 \n1600 \n2000 \nUS Prison Population \nAverage growth rate: \n1926 - 1995: 3.5Yo/year (doubling time = 20 years) \n1970 - 1995: 6.8%/year (doubling time = 10 years) \nn \no ~ , , , . , , , , , , , , , , , . , , , , , , , , , , , , , , , , . , , ,\n1920 \n1940 \n1960 \n1980 \n2000 \nPentium \nPro \n4004 \n~~~~ \n8080 \n8086 \n286 . \u2019r \n,, \nExponential \n1 05 \n1 0\u2018 \n, \ni o 3  \u2018 \nPentium \n1 02 \n486 , \u2019 \\  \n./ \nBest Fit \n1970 \n2000 \nI\n,\n,\n,\n(\n,\n,\n,\n,\n(\n,\n~\nl\nl\nZ\n \n1970 \n1975 \n1980 \n1985 \n1990 \n1995 \n200C \nSources: Real GNP: Prior to 1929, Historical Statistics of the US. Real GDP, 1929-present: Survey of Current Business, Bureau of Economic Analysis. State and Federal \nAdult Prison Population: 1926-1970, Historical Statistics of the US; 1970-1 980, Kurian (1 994); 1980-1 995, US Dept. of Justice. World Population: Prior to 1950, \nUS Census Bureau summary of various estimates; 195O-present, US Census Bureau. Inset shows 1900-1996. Microprocessor performance: Joglekar (1996). Curve is \nbest fit exponential function. Inset shows performance on semi-log scale.",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 129
  },
  {
    "child_id": "1ec71894-96be-42ef-b781-1bda49795432",
    "parent_id": "28181f8f-7427-4ed9-89c8-49d540862be2",
    "text": "Chapter 4 Structure and Behavior of Dynamic Systems \n111 \nFIGURE 4-4 \nGoal seeking: \nstructure and \nbehavior \npopulation, the greater the birth rate.\u201d The term \u201cbirth rate\u201d here refers to the num- \nber of people born per time period. For example, the birth rate in a city of one mil- \nlion people might be 20,000 people per year. Often, however, the term \u201crate\u201d is \nused as shorthand for thefractional rate of change of a variable. For example, the \nbirth rate is often interpreted as the number of births per year per thousand people \n(also known as the crude birth rate). The crude birth rate in the city of one million \nwould be 20 births per year per thousand people, or 2%/year. Similarly, we com- \nmonly speak of the interest rate or the unemployment rate. The word \u201crate\u201d in \nthese cases actually means \u201cratio\u201d: the interest rate is the ratio of the interest pay- \nments you must make each period to the principal outstanding; the unemployment \nrate is the ratio of the number of unemployed workers to the labor force. \nYou must carefully distinguish between absolute and fractional rates of change \nand between rates of change and ratios. Select variable names that minimize the \nchance for confusion. Be sure to check the units of measure for your rates. The \nunits of measure for rates of flow are unitskime period; the units of measure for \nfractional rates of flow are units per unit per time period = l/time periods. For ex- \nample, the interest rate on your credit card is not, say, 12%, but 12% per yea6 or, \nequivalently, 1% per month (0.12/year or O.Ol/month). The economy doesn\u2019t grow \nat, say, 3.5%, but at a fractional rate of 3.5%/year. \n4.1.2 \nGoal Seeking \nPositive feedback loops generate growth, amplify deviations, and reinforce \nchange. Negative loops seek balance, equilibrium, ,and stasis. Negative feedback \nloops act to bring the state of the system in line with a goal or desired state. They \ncounteract any disturbances that move the state of the system away from the goal. \nAll negative feedback loops have the structure shown in Figure 4-4. The state of \nGoal \n- \nTime- \n+ Stateof the \nGoal \nf l  System \\ \n(Desired \nState of System) \nDiscrepancy + \n\\ \nCorrective J \nAction \n+\n\n112 \nPart I Perspective and Process \nthe system is compared to the goal. If there is a discrepancy between the desired \nand actual state, corrective action is initiated to bring the state of the system back \nin line with the goal. When you are hungry, you eat, satisfying your hunger; when \ntired, you sleep, restoring your energy and alertness. When a firm\u2019s inventory \ndrops below the stock required to provide good service and selection, production \nincreases until inventory is once again sufficient. \nEvery negative loop includes a process to compare the desired and actual con- \nditions and take corrective action. Sometimes the desired state of the system and \ncorrective action are explicit and under the control of a decision maker (e.g., the \ndesired level of inventory). Somet",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 136
  },
  {
    "child_id": "e05b59b0-e0d4-4df3-88a4-08e4ce1891b4",
    "parent_id": "28181f8f-7427-4ed9-89c8-49d540862be2",
    "text": "en \ntired, you sleep, restoring your energy and alertness. When a firm\u2019s inventory \ndrops below the stock required to provide good service and selection, production \nincreases until inventory is once again sufficient. \nEvery negative loop includes a process to compare the desired and actual con- \nditions and take corrective action. Sometimes the desired state of the system and \ncorrective action are explicit and under the control of a decision maker (e.g., the \ndesired level of inventory). Sometimes the goal is implicit and not under conscious \ncontrol, or under the control of human agency at all. The amount of sleep you need \nto feel well rested is a physiological factor not under your conscious control. The \nequilibrium surface temperature of the earth depends on the flux of solar energy \nand the concentration of greenhouse gases in the atmosphere, among other physi- \ncal parameters. And a cup of coffee cools via negative feedback until it reaches \nroom temperature. \nIn most cases, the rate at which the state of the system approaches its goal di- \nminishes as the discrepancy falls. We do not often observe a constant rate of ap- \nproach that suddenly stops just as the goal is reached. The gradual approach arises \nbecause large gaps between desired and actual states tend to generate large re- \nsponses, while small gaps tend to elicit small responses. The flow of heat from \nyour coffee cup to the air in the room is larger when the temperature gap between \nthem is large and diminishes as the gap falls. When coffee and room temperatures \nare equal, there is no net heat flow between them. \nWhen the relationship between the size of the gap and the corrective action is \nlinear, the rate of adjustment is exactly proportional to the size of the gap and the \nresulting goal-seeking behavior is exponential decay. As the gap falls, so too does \nthe adjustment rate. And just as exponential growth is characterized by its doubling \ntime, pure exponential decay is characterized by its halflife-the time it takes for \nhalf the remaining gap to be eliminated (see chapter 8). \nFigure 4-5 shows examples of goal-seeking behavior. The top left panel shows \nthe rate of defect generation in the wafer fabrication process of a major semi- \nconductor manufacturer. In 1987, the company began a process improvement \nprogram using principles of Total Quality Management. The goal of the program \nwas zero defects. In 4 years the defect rate declined from 1500 ppm to about 150 \nppm. Note that as the defect rate fell, the rate of improvement declined. The top \nright panel shows the average load factor (up time) for two Finnish nuclear power \nplants started up in 1978. The fraction of the year the plants operated increased \nrapidly at first, then more slowly, until a maximum of about 94% was reached. The \nbottom left panel shows the share of all advertising dollars spent on television in \nthe US. Growth was rapid in the 1950s, but reached a fairly steady level of about \n20-25% by 19",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 136
  },
  {
    "child_id": "929970ba-c008-4085-96d7-21091217a893",
    "parent_id": "28181f8f-7427-4ed9-89c8-49d540862be2",
    "text": "at as the defect rate fell, the rate of improvement declined. The top \nright panel shows the average load factor (up time) for two Finnish nuclear power \nplants started up in 1978. The fraction of the year the plants operated increased \nrapidly at first, then more slowly, until a maximum of about 94% was reached. The \nbottom left panel shows the share of all advertising dollars spent on television in \nthe US. Growth was rapid in the 1950s, but reached a fairly steady level of about \n20-25% by 1980. The bottom right panel shows the roughly exponential decline in \nautomobile-related fatalities in the US per 100 million vehicle miles driven. De- \nspite the substantial decline in death risk per mile, the number of miles driven has \ngrown exponentially, so the total number killed on the roads each year has fluctu- \nated between about 30 and 50 thousand since the 1930s.\n\nFIGURE 4-5 Goal-seeking behavior: examples \nSemi co n ci u cto r Fabrication Defect Rate \nu) 2 5 . ' ' >  \n\"\n.\n\"\n'\n\"\n\"\n'\n\"\n'\n \n~. \nl\n'\n\"\n'\nl\n'\n'\n'\n'\nl\n'\nl\n'\n'\n\"\n'\n'\n'\n.\n \n25 \n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ \nQ - \n.- I \n2 0 -  \n- \n0 20- \n0 \nc \n.- \n1 5 -  \n3 15- \nC \n0 .- - \n8\n:\n \n1 0 -  \ng 10- \n5 -  \n5 5: \n0 , , , , , / / , , , , , , I , I , . , I , I I  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  \nO\n.\n,\n,\n~\n.\n,\n.\n,\n.\n.\n,\n,\n,\n,\n,\n~\n,\n,\n,\n,\n,\n,\n,\n.\n,\n,\n,\n,\n,\n,\n~\n,\n \nI \nI \nI\n,\n,\n I \nI I 1  \n0 \n0 \nc, \nm \nQ) \n]\\ ' \nStart of TQM Program \n- \nv \n~ E l O O O j  \\ \nNuciear Piant Load Factor \n1001 \n'\nI\n '\nI\n '\nI\n '\nI\n '\n1\n '\nI\n '\nI\n \no\n/\n,\n,\n,\n,\n,\n,\n,\n,\n,\n,\n.\n,\n,\n.\n.\n~\n \n1987 \n1988 \n1989 \n1990 \n1991 \no r  \nI\n,\n I\n,\n,\n , \n. \n, \nI\n,\n I \nI\n,\n I \n1978 \n1980 \n1982 \n1984 \n1986 \n1988 \n1990 \n1992\n\n114 \nFIGURE 4-6 \nOscillation: \nstructure and \nbehavior \nDelays can exist \nin any of the \ncausal links in a \nnegative feedback \nloop. Oscillation \ncan occur if there \nare delays in at \nleast one of \nthe links in a \nnegative loop. \nPart I Perspective and Process \n4.1.3 Oscillation \nOscillation is the third fundamental mode of behavior observed in dynamic sys- \ntems. Like goal-seeking behavior, oscillations are caused by negative feedback \nloops. The state of the system is compared to its goal, and corrective actions are \ntaken to eliminate any discrepancies. In an oscillatory system, the state of the sys- \ntem constantly overshoots its goal or equilibrium state, reverses, then undershoots, \nand so on. The overshooting arises from the presence of significant time delays in \nthe negative loop. The time delays cause corrective actions to continue even after \nthe state of the system reaches its goal, forcing the system to adjust too much, and \ntriggering a new correction in the opposite direction (Figure 4-6). \nOscillations are among the most common modes of behavior in dynamic sys- \ntems. There are many types of oscillation, including damped oscillations, limit cy- \ncles, and chaos (see section 4.3.3). Each variant is caused by a particular feedback \nstruct",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 136
  },
  {
    "child_id": "347de927-dc29-4c1b-856b-44a345e219cd",
    "parent_id": "28181f8f-7427-4ed9-89c8-49d540862be2",
    "text": "elays in \nthe negative loop. The time delays cause corrective actions to continue even after \nthe state of the system reaches its goal, forcing the system to adjust too much, and \ntriggering a new correction in the opposite direction (Figure 4-6). \nOscillations are among the most common modes of behavior in dynamic sys- \ntems. There are many types of oscillation, including damped oscillations, limit cy- \ncles, and chaos (see section 4.3.3). Each variant is caused by a particular feedback \nstructure and set of parameters determining the strengths of the loops and the \nlengths of the delays. But every type of oscillation has, at its core, a negative feed- \nback loop with delays. \nOscillations can arise if there is a significant delay in any part of the negative \nloop. As shown in Figure 4-6, there may be delays in any of the information links \nmaking up the loop. There may be delays in perceiving the state of the system \ncaused by the measurement and reporting system. There may be delays in initiat- \ning corrective actions after the discrepancy is perceived due to the time required \nState of the \nSystem \nTime - \nMeasurement, \nReporting, and \nPerception \nDelays \n+ Stateof the / \nGoal \nAction , /r sg \nDelays \nState of System) \n~ (Desired \nDiscrepancy + \n' \nDelay \nAdministrative and \nDelays \nCorrective \nAction \n+ \nDecision-Ma king",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 136
  },
  {
    "child_id": "fcce4a59-b32a-41d8-b5a2-58352253509f",
    "parent_id": "c7074b36-49d1-4c9b-b238-9fc99ecc7b51",
    "text": "Chapter 4 Structure and Behavior of Dynamic Systems \n115 \nto reach a decision. And there may be delays between the initiation of a corrective \naction and its effect on the state of the system. It takes time for a company to mea- \nsure and report inventory levels, time for management to meet and decide how \nmuch to produce, and more time while raw materials procurement, the labor force, \nand other needed resources respond to the new production schedule. Sufficiently \nlong delays at any one of these points could cause inventory to oscillate. \nFigure 4-3 showed real GDP in the US. The dominant mode of behavior in the \ndata is exponential growth. But the growth is not smooth. Output fluctuates around \nthe growth trend. In the top panel of Figure 4-7 these oscillations are revealed by \ndetrending the GDP data (removing the best fit exponential function). After the ex- \nponential growth is removed, the business cycle is clearly visible as a fluctuation \naveraging about 5% in amplitude and with an average period of about 4 years. A \nlonger and larger fluctuation in real production is also apparent, with peaks relative \nto trend around 1910 and 1970-the so-called economic long wave.l The bottom \npanels of Figure 4-7 show two critical business cycle indicators--capacity utiliza- \ntion in the US manufacturing sector and the civilian unemployment rate. The am- \nplitude of the business cycle in these important variables is quite large. Utilization \ntypically fluctuates 15 points from peak to trough (nearly 20% of its average \nvalue), while unemployment during the postwar period in the US has ranged from \nunder 3% to nearly 11% of the labor force, with much higher values in Europe. \nNote that the business cycle (and most real world oscillations) is not perfectly \nregular. You should not expect it to be. Many people think a cycle must be as pre- \ndictable as the dawn, as regular as the orbits of the planets, as smooth and sym- \nmetric as the swing of a pendulum clock. But these paradigms of periodicity are \nspecial systems. The planets interact mainly with the sun and only weakly with one \nanother.2 A pendulum clock has been carefully designed to generate a regular mo- \ntion by isolating its components from the environment. Biological, social, and eco- \nnomic systems, in contrast, involve huge numbers of interactions among tightly \ncoupled elements. They are continuously bombarded by perturbations that cause \ntheir motion to be somewhat irregular, a (usually nonlinear) combination of their \nendogenous dynamics and these exogenous shocks (see section 4.3.2). \n\u2018The long wave, or Kondratiev cycle, has an average period of about 60 years and, as seen in the \ndata, an amplitude much larger than the short-term business cycle. Sterman (1986) and Forrester \n(1977, 1983) present theory and evidence for the existence and feedback structure generating the \nlong wave. Sterman (1985b) presents a simple model of the long wave; Sterman 1989a reports an \nexperimental test of ",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 140
  },
  {
    "child_id": "83943daf-db68-40cd-8cb4-2545b06358f5",
    "parent_id": "c7074b36-49d1-4c9b-b238-9fc99ecc7b51",
    "text": "combination of their \nendogenous dynamics and these exogenous shocks (see section 4.3.2). \n\u2018The long wave, or Kondratiev cycle, has an average period of about 60 years and, as seen in the \ndata, an amplitude much larger than the short-term business cycle. Sterman (1986) and Forrester \n(1977, 1983) present theory and evidence for the existence and feedback structure generating the \nlong wave. Sterman (1985b) presents a simple model of the long wave; Sterman 1989a reports an \nexperimental test of the model, and Sterman (1989~) shows that many of the decision rules charac- \nterizing human subjects in the experiment generate chaotic dynamics. \ning as tidal and frictional forces dissipate the earth\u2019s rotational energy. Recent research shows that \nthe orbits of most of the planets are chaotic and that chaotic resonances among the planets can hurl \nmeteorites and asteroids from distant orbits into trajectories that cross the earth\u2019s orbit, perhaps ac- \ncounting for the impacts now believed to have caused the major extinctions. It is only our short (by \nheavenly standards) record of observations that causes us to perceive the solar system to be stable \nand predictable. Peterson (1993) provides an excellent nontechnical treatment of chaotic dynamics \nin the solar system; Diacu and Holmes (1996) cover the origins of chaos in theories of celestial me- \nchanics. Jack Wisdom of MIT pioneered computer simulations that revealed the chaotic character \nof the solar system (see Wisdom 1987 for a review). See section 4.3.3 for more on chaos. \n2Actually, the apparent regularity of the solar system is illusory. The length of the day is increas-\n\n116 \nFIGURE 4-7 \nOscillation: \nexamples \nThe business \ncycle in the \nUnited States. \nTop: Deviation \nof real GDP \nfrom long-term \nexponential trend. \nMiddle: Capacity \nutilization. \nBottom: Civilian \nunemployment. \nPart I Perspective and Process \nUS Real GDP Deviation from Trend \n.- \nI \n2000 \n-0.41 \nI \n8 \nI \nI \n, \n, \nI \nI \n, \n, \n. \n, \n, \n, \nI \n1850 \n1900 \n1950 \nCapacity Utilization, US Manufacturing \n1945 \n1955 \n1965 \n1975 \n1985 \n1995 \nUS Unemployment Rate \n1 2  '\n'\n'\n'\n\"\n'\n~\n'\n'\nI\n~\n \n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n \n\" I  \nSource: Historical Statistics of the United States, US Bureau of Economic Analysis. \n4.1.4 Process Point \nThe connection between structure and behavior provides a useful heuristic for the \nconceptualization process. Any time you observe exponential growth in a variable, \nyou know there is at least one positive feedback in which the variables of interest \nparticipate (and possibly more). There will, of course, be many negative loops \npresent as well. However, if the system is exhibiting exponential growth, then you \nknow that positive loops are dominant (at least during the regime in which growth\n\nChapter 4 Structure and Behavior of Dynamic Systems \n117 \noccurs). You can then guide the discussion among the client group toward the iden- \ntification of self-reinforcing pro",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 140
  },
  {
    "child_id": "2eab90a4-9f1e-4198-88c1-4ce30be088ae",
    "parent_id": "c7074b36-49d1-4c9b-b238-9fc99ecc7b51",
    "text": " there is at least one positive feedback in which the variables of interest \nparticipate (and possibly more). There will, of course, be many negative loops \npresent as well. However, if the system is exhibiting exponential growth, then you \nknow that positive loops are dominant (at least during the regime in which growth\n\nChapter 4 Structure and Behavior of Dynamic Systems \n117 \noccurs). You can then guide the discussion among the client group toward the iden- \ntification of self-reinforcing processes. Typically, the group will be able to identify \nmany positive loops involving the variables of interest. Of course, it is not possi- \nble to tell which of these candidate loops are active and contributing to the behav- \nior, nor their relative strengths, without recourse to data and/or model simulations. \nBut focusing on the connection between structure and behavior helps generate \nfruitful hypotheses about the key loops. \nSimilarly, any time you observe the other core modes of behavior, you imme- \ndiately know what types of loop must be dominant, guiding your initial search for \nthe structures responsible. Oscillation, for example, must mean there is an impor- \ntant negative feedback with significant time delays. You can then ask about the de- \ncision processes by which the variable is regulated and the time delays in the \nperception of the state of the system, in the decision process, and in the response \nof the system to the corrective actions of the decision makers. \nA caveat: This heuristic helps in the identification of the feedback structures \nresponsible for the observed behavior. In addition, it is essential to consider what \nstructures exist but have not yet played a significant role in the history of the sys- \ntem or left a trace in the available data. As the system evolves these latent feed- \nbacks may become dominant, dramatically changing the dynamics, shifting trends \nand patterns, and altering the system\u2019s response to policies. Identifying potential \nshifts in loop dominance arising from latent structures is a valuable function of \nmodeling. \nTo illustrate, return to the case of exponential growth. No real quantity can \ngrow forever. Eventually, one or more negative loops will become dominant as \nvarious limits to growth are approached. Immediately after identifying some posi- \ntive loops potentially responsible for observed growth, you should ask, What neg- \native loops might stop the growth? Most people can easily generate a wide range \nof potential limits and constraints to the growth of the system. Identifying the po- \ntential constraints to growth is a powerful way to identify possible future bottle- \nnecks and limits, even if there is no evidence of a slowdown in the data. As with \nthe identification of positive loops, empirical investigation and modeling are re- \nquired to determine which negative loops are strongest, what limits to growth they \nreflect, and whether those limits can be relaxed or tightened by other feedbacks o",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 140
  },
  {
    "child_id": "360b221f-441b-4291-9147-b5c5fb8c74fe",
    "parent_id": "c7074b36-49d1-4c9b-b238-9fc99ecc7b51",
    "text": "otential limits and constraints to the growth of the system. Identifying the po- \ntential constraints to growth is a powerful way to identify possible future bottle- \nnecks and limits, even if there is no evidence of a slowdown in the data. As with \nthe identification of positive loops, empirical investigation and modeling are re- \nquired to determine which negative loops are strongest, what limits to growth they \nreflect, and whether those limits can be relaxed or tightened by other feedbacks or \nthrough policy interventions (see section 4.2.1). \nIdentifying Feedback Structure from System Behavior \n1. Identify the positive loops responsible for the growth in the examples \nshown in Figure 4-3. Sketch a causal loop diagram to capture the loops you \nidentify. Identify as many negative feedbacks that might halt growth in \nthese systems as you can. \n2. Identify the negative loops that might be responsible for the goal-seeking \nbehaviors shown in Figure 4-5. Identify the state of the system, the goal, \nand the corrective action(s) for each case. What counterforces might \nprevent the state of the system from reaching its goal?\n\n118 \nPart I Perspective and Process \n3. Identify the negative loops and time delays that might be responsible for the \noscillations in economic affairs illustrated by Figure 4-7. Identify the state \nof the system, the goal, the corrective action, and delays. Estimate the \nlength of the time delays you identify. \n4.2 INTERACTIONS OF THE FUNDAMENTAL MODES \nFIGURE 4-8 \nS-shaped growth: \nstructure and \nbehavior \nThe three basic modes of behavior-exponential growth, goal seeking, and oscil- \nlation-are caused by three basic feedback structures: positive feedback, negative \nfeedback, and negative feedback with delays. Other, more complex patterns of be- \nhavior arise through the nonlinear interaction of these structures with one another. \n4.2.1 \nS-shaped Growth \nAs discussed above, no real quantity can grow (or decline) forever: eventually one \nor more constraints halt the growth. A commonly observed mode of behavior in \ndynamic systems is S-shaped growth-growth is exponential at first, but then grad- \nually slows until the state of the system reaches an equilibrium level. The shape of \nthe curve resembles a stretched-out \u201cS\u201d (Figure 4-8). To understand the structure \nunderlying S-shaped growth it is helpful to use the ecological concept of carrying \ncapuci~. The carrying capacity of any habitat is the number of organisms of a \nparticular type it can support and is determined by the resources available in the \nCarrying Capacity \nTime- \n/-----%+ \nState of the \nNet \nIn::. \n@ System \nResource \nCarrying \nCapacity \nFractional \nNet Increase \nAdequacy",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 140
  },
  {
    "child_id": "ece09ff4-021e-497b-9890-6a180f95df81",
    "parent_id": "934c8629-5c0c-4297-9bda-971178471f20",
    "text": "Chapter 4 Structure and Behavior of Dynamic Systems \n119 \nenvironment and the resource requirements of the population. As a population \napproaches its carrying capacity, resources per capita diminish thereby reducing \nthe fractional net increase rate until there are just enough resources per capita to \nbalance births and deaths, at which point the net increase rate is zero and the pop- \nulation reaches equilibrium. Any real quantity undergoing exponential growth can \nbe interpreted as a population drawing on the resources in its environment. As the \ncapacity of the environment is approached, the adequacy of the required resources \ndiminishes, and the fractional net increase rate must decline. The state of the sys- \ntem continues to grow, but at a slower rate, until resources are just scarce enough \nto halt growth. In general, a population may depend on many resources, each cre- \nating a negative loop which might limit growth. The constraint that is most bind- \ning determines which of the negative loops will be most influential as the state of \nthe system grows. \nThe carrying capacity concept is subtle and complex. While it is appropriate to \nconsider the carrying capacity of an environment to be constant in some situations, \nin general the carrying capacity of an environment is intimately intertwined with \nthe evolution and dynamics of the species it supports. We humans alter the carry- \ning capacity of the planet in ways both intended and unintended, through the de- \nvelopment of technology enabling greater utilization of resources, through changes \nin cultural practices and norms for consumption of resources per capita, and \nthrough consumption, depletion, and erosion of the various resources upon which \nwe depend. Even so-called lower species interact with their environment to alter \nthe carrying capacity. The co-evolution of flowers and pollinating insects permit- \nted greater population densities for both. Similarly, all businesses and organiza- \ntions grow in the context of a market, society, and physical environment that \nimposes limits to their growth. As with natural populations, these limits can in- \ncrease or decrease, both exogenously and, more importantly, endogenously, as the \norganization interacts with its customers, competitors, suppliers, regulators, and \nother entities in the system. In general, one must model the various resources that \ntogether determine the carrying capacity-for a species or an organization-as an \nendogenous element of the system. \nDespite the dynamic character of the carrying capacity, there is, at any mo- \nment, a limit to the size of the population (the current carrying capacity), which, if \nexceeded, causes the population to fall. Further, the carrying capacity itself cannot \ngrow forever. The laws of thermodynamics dictate an absolute limit to the carrying \ncapacity of the earth, though there is no agreement among scholars as to what that \nlevel is, how it is changing, whether population should grow to ",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 144
  },
  {
    "child_id": "0e44a7bc-51ad-421c-aa67-8769bbd1cd23",
    "parent_id": "934c8629-5c0c-4297-9bda-971178471f20",
    "text": "f the system. \nDespite the dynamic character of the carrying capacity, there is, at any mo- \nment, a limit to the size of the population (the current carrying capacity), which, if \nexceeded, causes the population to fall. Further, the carrying capacity itself cannot \ngrow forever. The laws of thermodynamics dictate an absolute limit to the carrying \ncapacity of the earth, though there is no agreement among scholars as to what that \nlevel is, how it is changing, whether population should grow to the carrying ca- \npacity or be voluntarily stabilized below it, or whether a population as large as the \ncarrying capacity would enable a reasonable quality of life or provide only the bare \nminimum for ~ubsistence.~ \nA system generates S-shaped growth only if two critical conditions are met. \nFirst, the negative loops must not include any significant time delays (if they did, \nthe system would overshoot and oscillate around the carrying capacity; see section \n3For good discussion of the uncertainty in definitions and estimates of the earth\u2019s carrying \ncapacity, see Cohen (1995). For system dynamics models in which the carrying capacity of the \nearth is treated endogenously and dynamically, see Meadows, Meadows, and Randers (1992).\n\n120 \nPart I Perspective and Process \n100 \n1 \n7 5 -  \n5 0 -  \n2 5 -  \n0 \nFIGURE 4-9 \nS-shaped growth: \nexamples \n\" \" \" \" \" \" \" \" \" \" \" \"  \n% of Households with TV \nCable Subscribers \n(Million Households) \n,- \nI \nI \nI \n, \n, . \n, \n, \n, \n, \nI \nI \n, \nI \n, \nI \n* \nI \nGrowth of Sunflowers \n300 1 \nI \n, \nI \n0 \n1 4  \n2 8  \n4 2  \n5 6  \n7 0  \n8 4  \nDays \nAdoption of Cardiac Pacemaker by Physicians \ni \nI \nF \n0 \n1960 \n1962 \n1964 \n1966 \n1968 \n1970 \n1972 \nSource: Sunflowers: Lotka (1 956, p. 74); Cable TV: Kurian (1 994), Statistical Abstract of the US; \nPacemaker adoption: Homer (1 983, 1987). \n2000 \n100 \nc \ns \n2 5  \n4.2.2). Second, the carrying capacity must be fixed. It cannot be consumed by the \ngrowth of the population, lest the population exhaust its resources and force itself \ninto extinction, as a population of yeast consumes the sugar in a cask of wine, ul- \ntimately causing fermentation to stop (see section 4.2.3).\n\nChapter 4 Structure and Behavior of Dynamic Systems \n121 \nFIGURE 4-10 \nS-shaped grow1:h \nwith overshoot \nand oscillation: \nstructure and \nbehavior \nA key aspect of the structure generating S-shaped growth is that the interaction \nof the positive and negative loops must be nonlinear. At first, when the state of the \nsystem is small relative to the resource base, the limits to growth are distant and the \npositive loops dominate. An additional unit added to the state of the system con- \ntributes more to the net increase rate than it decreases the fractional net increase \nrate by reducing resource adequacy. The state of the system grows exponentially. \nHowever, as a direct consequence of that growth, the adequacy of the resource \nbase falls. As the limits to growth are approached, the negative loops grow stronger \nand stronger",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 144
  },
  {
    "child_id": "b7a3689e-ce80-46d5-b50e-42556deba017",
    "parent_id": "934c8629-5c0c-4297-9bda-971178471f20",
    "text": "elative to the resource base, the limits to growth are distant and the \npositive loops dominate. An additional unit added to the state of the system con- \ntributes more to the net increase rate than it decreases the fractional net increase \nrate by reducing resource adequacy. The state of the system grows exponentially. \nHowever, as a direct consequence of that growth, the adequacy of the resource \nbase falls. As the limits to growth are approached, the negative loops grow stronger \nand stronger, until they begin to dominate the dynamics. The inflection point in the \ncurve is the point where the system, though still growing, shifts from acceleration \nto deceleration. The inflection marks the point at which there is a shift in loop \ndominance. It is the point at which an additional unit added to the state of the sys- \ntem reduces the fractional net increase rate more than it adds to the total population \ndriving the growth. \nFigure 4-9 shows some examples of S-shaped growth. Whether the growth of \na plant, the diffusion of a new product or service such as cable television, or the \nadoption of a new idea or technology like the cardiac pacemaker, growth always \nconfronts limits. \n4.2.2 \nS-Shaped Growth with Overshoot \nS-shaped growth requires the negative feedbacks that constrain growth to act \nswiftly as the carrying capacity is approached. Often, however, there are signifi- \ncant time delays in these negative loops. Time delays in the negative loops lead to \nthe possibility that the state of the system will overshoot and oscillate around the \ncarrying capacity (Figure 4-10). Figure 4-11 shows some examples of S-shaped \ngrowth with overshoot and oscillation. \nCarrying Capacity \nState of the \nSystem \nTime - \nNet p+ \nIncrease \nState of the \n ate @ System \n@ \nResource \nCarrying \nFractional \nNet Increase \nRate \nAdequacy \nCapacity \n+y-f \n-F u\n\n122 \n5000 \nz \n5 I \n+ \n0 .- \n2500- \nI \nU \nm \na \nc \n+ \nFIGURE 4-1 1 \nS-shaped growth \nwith overshoot \nand oscillation: \nexamples \n,\n,\n,\nI\n,\n,\n \nI \n1\n.\n1\n,\n \n1\n,\ns\n \ni\n,\n,\n,\n,\n~\n \n,\n/\n,\n 1\n1\n1\n \n, \no-,-, \n, ,-\n,  \n, ,  , , ,  , , ,  , , ,  , \nPart I Perspective and Process \nPopulation of London \n1 0 '  \" \n' \" \n' \n\" \n' \n1 \n' \n1\n'\n I \n\" \" \n1 \n1800 \n1850 \n1900 \n1950 \n2000 \nIdentifying the Limits to Growth \nWhat are the limits to growth for the population of a city and the rise in production \nof commodities such as aluminum? Identify the negative feedbacks that halt the \ngrowth in each case. Identify the time delays responsible for the overshoot and \n41n Urban Dynamics, Forrester (1969) presents a model of urban growth and stagnation, show- \ning how many urban renewal policies actually accelerate the decay of the inner city. Mass (1975) \nand Schroeder, Sweeney, and Alfeld (1975) extend and apply the results of Urban Dynamics, and \nAlfeld and Graham (1976) build up a simplified version of the Urban Dynamics model suitable for \nteaching.\n\nChapter 4 Structure and Behavior of Dynamic Systems \n123 \n4.2.3 \nOvershoot and Collap",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 144
  },
  {
    "child_id": "0b7c9d31-7860-4f98-ab77-a89288b8a03d",
    "parent_id": "934c8629-5c0c-4297-9bda-971178471f20",
    "text": "r the overshoot and \n41n Urban Dynamics, Forrester (1969) presents a model of urban growth and stagnation, show- \ning how many urban renewal policies actually accelerate the decay of the inner city. Mass (1975) \nand Schroeder, Sweeney, and Alfeld (1975) extend and apply the results of Urban Dynamics, and \nAlfeld and Graham (1976) build up a simplified version of the Urban Dynamics model suitable for \nteaching.\n\nChapter 4 Structure and Behavior of Dynamic Systems \n123 \n4.2.3 \nOvershoot and Collapse \nThe second critical assumption underlying S-shaped growth is that the carrying \ncapacity is fixed. Often, however, the ability of the environment to support a \ngrowing population is eroded or consumed by the population itself. For example, \nthe population of deer in a forest can grow so large that they overbrowse the \nvegetation, leading to starvation and a precipitous decline in the population. Figure \n4-12 shows the feedback structure and typical behavior for the overshoot and col- \nlapse behavior mode. \nConsumption or erosion of the carrying capacity by the population creates a \nsecond negative feedback limiting growth. Population growth now cuts resource \nadequacy two ways: by reducing the resources available per capita and by reduc- \ning total resources. As in the S-shaped growth case, when resources are initially \nample the positive growth loop dominates and the state of the system grows expo- \nnentially. As it grows, resource adequacy drops. The negative loops gradually gain \nin strength. At some point, the net increase rate falls to zero, and the population \nreaches its maximum. But unlike the S-shaped growth case, the system does not \nreach equilibrium. When the population reaches its peak, the rate of decline of the \ncarrying capacity is at its maximum. The carrying capacity continues to drop, re- \nsources per capita fall further, and the net increase rate of the population becomes \nnegative. The state of the system declines. Even as it declines, the remaining pop- \nulation continues to consume the carrying capacity, so resources per capita remain \nFIGURE 4-1 2 \nOvershoot and \ncollapse: structure \nand behavior \n/-------+ \n-+ \nConsumption/ \nErosion of \nCarrying Capacity \nState of the \nNet \nIncrease \nr- w\n)\n \n1- \nResource \nCarrying \nAdequacy \nCapacity \nFractional @ \nNet Increase \nRate \n+ u \n+\n-\n\nc \n0 \nN \n0 \nQ, \n-Q, ' \n0 \nQ, \n_ E o  ' \n0 \nIC \n- Q ,  ' \n0 \nW \n-Q, ' \n0 \n0 \n0 \n0 \n0\n'\n \nd \nm \nN \n' \nieaHMw puesnoyl \n0 \n0 \n0 \n0 \n0 7  \nd \ncc) \nN \n' \n'20 AOJI/$ \nI '  \n4 ,\n,\n,\n,\n,\n,\n,\n,\nI\n ,\n,\n,\n,\n,\n,\n 1 \n0 \nco \nco \n0 \n0 \n0' \n0 \nv) \n4- \nw\no\n \nE\nm\n \nU \nS \nm \n124",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 144
  },
  {
    "child_id": "6e68a75b-a972-4fa2-8201-c23915053a85",
    "parent_id": "a985a764-0394-47fd-a363-58e6e8b14b6c",
    "text": "Chapter 4 Structure and Behavior of Dynamic Systems \n125 \ninsufficient and the population keeps falling. If there is no regeneration of the car- \nrying capacity (if it is strictly nonrenewable), the equilibrium of the system is ex- \ntinction: any nonzero population continues to consume the resource base, forcing \nit to zero, and with it, the population. If the carrying capacity can be regenerated or \nsupplemented with renewable resources, a nonzero equilibrium can be sustained. \nFigure 4-13 shows some examples of overshoot and collapse. The New Eng- \nland Haddock fishery collapsed due to overfishing of Georges Bank, once one of \nthe world\u2019s richest fishing areas. Overfishing has also shut down the Canadian and \nUS cod fishery, and similar overexploitation is common in fisheries around the \nworld.5 Nuclear power construction ground to a halt in the 1980s as high-level \nwaste-and public concern over safety-accumulated and as the costs of nuclear \npower steadily escalated. The Atari Corporation was the leader of the first wave of \nhome and arcade video games in the late 1970s. Sales doubled roughly every year \nfrom 1976 through 1982. Abrupt saturation of the market-depletion of the stock \nof potential customers-led to a precipitous drop in sales from $2 billion per year \nin 1982 to $100 million per year in 1984. The company lost about $600 million \nduring the collapse. Silver experienced a classic speculative bubble in the late \n1970s, with prices rising tenfold in a year, then collapsing even more precipitously. \nThe interplay between population and carrying capacity leading to overshoot \nand collapse is illustrated in Figure 4-14, which shows the population of Easter \nIsland (Rapa Nui in the local language) and a measure of the carrying capacity de- \nrived from pollen cores indicating the extent of tree cover. \nEaster Island, one of the most remote spots on earth, is a small island of about \n160 km2 located in the eastern Pacific. Easter Island is most famous for the giant \nstone statues, known as moai, that dot the island. Radiocarbon dating puts the ar- \nrival of the first settlers, intrepid sailors of Polynesian origin, at about the year 400 \nand not later than 690. Population is estimated to have grown slowly until about \n1 100, when growth accelerated dramatically, perhaps doubling about every cen- \ntury, until about the year 1400. Pollen counts from soil cores and other records \nshow that prior to the arrival of the first humans, Easter Island was lushly forested \nand supported a diverse set of fauna, particularly birds (Bahn and Flenley 1992; \nSteadman 1995). However, as the human population grew, the forests were pro- \ngressively cut to provide wood and fiber for boats, structures, ropes, and tools, as \nwell as to provide firewood. The Polynesian rat, which arrived with the original \nsettlers, hastened the decline by killing birds and eating the seeds and nuts of the \nnative palm. \nBy about the year 1400, deforestation was nearly complete.",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 150
  },
  {
    "child_id": "cc51c4b1-6bd3-4c0c-a855-35a03fefbe45",
    "parent_id": "a985a764-0394-47fd-a363-58e6e8b14b6c",
    "text": "hly forested \nand supported a diverse set of fauna, particularly birds (Bahn and Flenley 1992; \nSteadman 1995). However, as the human population grew, the forests were pro- \ngressively cut to provide wood and fiber for boats, structures, ropes, and tools, as \nwell as to provide firewood. The Polynesian rat, which arrived with the original \nsettlers, hastened the decline by killing birds and eating the seeds and nuts of the \nnative palm. \nBy about the year 1400, deforestation was nearly complete. The loss of tree \ncover dramatically reduced the island\u2019s carrying capacity. There is clear strati- \ngraphic evidence that soil erosion increased with deforestation as rain washed \naway the unprotected soil. Without tree cover, wind speeds at ground level in- \ncreased, carrying still more valuable soil into the sea. The erosion was so severe \n5The \u201cFishbanks\u201d simulation (Meadows, Fiddaman, and Shannon 1993) is a wonderful role-play \nmanagement flight simulator illustrating the dynamics of renewable resources such as fisheries.\n\n126 \nFIGURE 4-1 4 \nEstimated \npopulation and \ntree cover of \nEaster Island \nTop: Population \nestimates for \nEaster Island are \nhighly uncertain. \nThe graph shows \nthe likely range of \npopulation based \non data in Bahn \nand Flenley (1 992, \npp. 80, 178ff). \nBottom: Pollen \nrecords from soil \ncore at Rano Kau, \nEaster Island, \nshowing decline \nin the fraction of \npollen from trees \nand shrubs, \nindicating the \ndeforestation \nof the island \n(remainder of \npollen from \ngrasses, sedges, \nherbs, and ferns). \nDeforestation \nwas essentially \ncomplete by \nabout 1400. \nPart I Perspective and Process \n10000 \nS \n0 .- \n4- 4 5000 \nZT \n0 \nn \n0 \nPopulation of Easter Island \n400 \n0 \n800 \n1200 \nTree Cover \n1600 \n2000 \n100 \nI \nI \nI \nI \n1400 \nYear \n590 \n910 950 \n+50 \nf60 f70 \n+60 \n0 \nDepth \n10 \n(meters) \nNote: Time axes for top and bottom graphs differ. \nSource: Bahn and Flenley (1992, p. 174). \nthat sediment washed from the higher elevations eventually covered many of the \nmoai, so that European visitors thought the giant statues were just heads, when in \nfact they were complete torsos averaging 20 feet in height. Deforestation also in- \ncreased evaporation from the soil and may have reduced rainfall. The few streams \non the island dried up, further reducing food production and the fresh water supply. \nEventually, fishing, the other main source of food, also fell, as boats, lines, and \nhooks, all made from wood, could no longer be replaced. When the first Europeans \narrived, the islanders prized wood above all other items offered in trade. Most of \nthe bird species living on Easter Island became at least locally extinct. Only 1 of \nabout 25 indigenous species still nests on the island today (Steadman 1995).\n\nChapter 4 Structure and Behavior of Dynamic Systems \n127 \nAs the carrying capacity declined, population growth slowed, reaching a peak \ngenerally estimated to be between 6000 and 10,000 people around the year 1600. \nA precipitous decline in popul",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 150
  },
  {
    "child_id": "ee57305e-ef16-42ed-96ac-a52575a84d08",
    "parent_id": "a985a764-0394-47fd-a363-58e6e8b14b6c",
    "text": "peans \narrived, the islanders prized wood above all other items offered in trade. Most of \nthe bird species living on Easter Island became at least locally extinct. Only 1 of \nabout 25 indigenous species still nests on the island today (Steadman 1995).\n\nChapter 4 Structure and Behavior of Dynamic Systems \n127 \nAs the carrying capacity declined, population growth slowed, reaching a peak \ngenerally estimated to be between 6000 and 10,000 people around the year 1600. \nA precipitous decline in population had set in by about 1680, accompanied by \nmajor changes in social, political, and religious structures. Spear points and other \ntools of war appeared for the first time, and there is evidence of large battles \namong competing groups. Some scholars believe there is evidence of cannibalism \nduring this period. The first Europeans known to visit Easter Island arrived in 1722 \nand found a small and poor population. Scholars generally accept an estimate of \n2000 people in 1786. After Peruvian slave raids and a subsequent smallpox epi- \ndemic the population fell to 111 in 1877. The population recovered to about 2100 \nby the early 1990s, largely the result of immigration and settlement from Chile, \nwhich has governed the island since 1888. \nThe overshoot and collapse of Easter Island is but one of many similar \nepisodes documented in the history of island biogeography (see Kirch 1997). In \neach case, population growth led to deforestation, the extinction of native species, \nand unfavorable changes in local climate, rainfall, and agricultural productivity, \nfollowed by starvation, conflict, and, often, population collapse.6 \n4.3 \nOTHER MODES OF BEHAVIOR \nGrowth, goal seeking, oscillation, and their combinations: are these the only pat- \nterns of behavior systems can exhibit? No, but they cover the vast majority of dy- \nnamics. There are other patterns, for example: (1) stasis, or equilibrium, in which \nthe state of the system remains constant over time; and (2) random variation. \n4.3.1 \nStasis, or Equilibrium \nConstancy arises either because dynamics affecting the state of the system are so \nslow that change is imperceptible or because there are powerful negative feedback \nprocesses keeping the state of the system nearly constant even in the face of envi- \nronmental disturbances. In the former case, change is too slow relative to your time \nhorizon to be meaningful. In the latter case, constancy is an example of highly ef- \nfective goal-seeking behavior. The firmness and reliability with which you remain \nin contact with the ground when standing reflects the equilibrium caused by a \npowerful negative feedback loop: as gravity causes you to sink into the earth, the \nelectrons in the atoms of the ground exert greater and greater upward force on \nthe electrons in the atoms of your feet until the force of their mutual electrostatic \nrepulsion just offsets the force of gravity, at which point you come to rest. \n4.3.2 \nRandomness \nMany variables appear to vary ran",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 150
  },
  {
    "child_id": "395c2578-146b-4c79-883f-17fc0bcd8775",
    "parent_id": "a985a764-0394-47fd-a363-58e6e8b14b6c",
    "text": "and reliability with which you remain \nin contact with the ground when standing reflects the equilibrium caused by a \npowerful negative feedback loop: as gravity causes you to sink into the earth, the \nelectrons in the atoms of the ground exert greater and greater upward force on \nthe electrons in the atoms of your feet until the force of their mutual electrostatic \nrepulsion just offsets the force of gravity, at which point you come to rest. \n4.3.2 \nRandomness \nMany variables appear to vary randomly. In most situations, randomness is a mea- \nsure of our ignorance, not intrinsic to the system. (Except in quantum mechanics, \n6The Easter Island data above are drawn primarily from Bahn and Flenley (1992), Kirch (1984), \nand Van Tilburg (1994). These works, along with Kirch (1997) and Steadman (1995), provide a \ngood survey of recent research on the biological and human history of Rapa Nui and other island \necosystems.",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 150
  },
  {
    "child_id": "c2a2714b-3ec1-467e-ac92-e61c29001656",
    "parent_id": "5e0ba8cb-f5cc-4172-8a36-b5d8be0343b9",
    "text": "128 \nPart I Perspective and Process \nwhere Einstein\u2019s famous lament \u201cGod does not play dice with the universe!\u201d \nappears to be wrong. However, the random behavior of elementary particles near \nthe Planck scale has little if any bearing on the dynamics of macroscopic systems \nsuch as a company). When we say there are \u201crandom\u201d variations in, say, the de- \nmand for a firm\u2019s product, what we actually mean is that we don\u2019t know the rea- \nsons for these variations. We are revealing the limitations of our understanding, not \ncharacterizing a feature of reality. The demand for a firm\u2019s product may be grow- \ning and may also experience a seasonal cycle. The firm may understand and can \nperhaps even forecast the trend and seasonal cycle with some accuracy. But after \naccounting for these sources of change, people tend to call the residual variation \nrandom as if the customers were somehow rolling dice to decide whether to buy \nthe product. People generally have reasons for behaving as they do, but the man- \nagers of the firm are not aware of either their decision rules or the information they \nuse to make their decisions. The managers\u2019 model of customer behavior is im- \nperfect. If the firm could, through additional modeling and fieldwork, discover \nthose rules and their inputs, they could explain more of the total variation in de- \nmand, and some of what was formerly deemed random would now be resolved \ninto their theory of the system structure. \nAs a practical matter, no one can never know all the local conditions and idio- \nsyncrasies causing a customer to place an order today or wait until tomorrow or \ncause a machine to break down now instead of 3 hours from now. The aggregate \nimpact of the individual deviations from average behavior means systems are \nbathed in a continuous rain of random shocks. Engineers term these random per- \nturbations \u201cnoise,\u201d after the distortion heard on telephone lines caused by thermal \nfluctuations of the atoms in the wires. Of course, the rain of random shocks in- \ncludes the occasional downpour, or even flood (for example, note the impact of \nWWII on economic output in the US, Figure 4-3). \nThe rain of random noise falling on our systems does play an important role in \ndynamics, however. By constantly knocking systems away from their current tra- \njectory, noise can excite modes of behavior that otherwise would lie dormant. A \npendulum swinging in the air will tend towards equilibrium as friction dissipates \nits energy; eventually the bob of the pendulum comes to rest, straight down. How- \never, perturb the bob with small, random jolts, and soon it will begin swinging, \nsomewhat irregularly, with a rhythm close to its natural frequency. The structure of \nthe system has the potential to oscillate, but energy from some external source such \nas high-frequency random noise is required to excite its latent dynamics (chapters \n18-20 provide examples). Random noise can also unfreeze systems that are stuck \non local optima, sen",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 153
  },
  {
    "child_id": "fff3d026-39d3-4741-b068-e7e18d5e6b71",
    "parent_id": "5e0ba8cb-f5cc-4172-8a36-b5d8be0343b9",
    "text": "y the bob of the pendulum comes to rest, straight down. How- \never, perturb the bob with small, random jolts, and soon it will begin swinging, \nsomewhat irregularly, with a rhythm close to its natural frequency. The structure of \nthe system has the potential to oscillate, but energy from some external source such \nas high-frequency random noise is required to excite its latent dynamics (chapters \n18-20 provide examples). Random noise can also unfreeze systems that are stuck \non local optima, sending them into a new neighborhood where the dynamics are \nquite different, and can determine which of many equally attractive paths a system \ntakes, contributing to path dependence (see chapter 10). These disturbances can be \nmodeled as random variations around the average behavior given by the equations \ncapturing the feedback structure of the system. Other times it is more appropriate \nto model the individual elements and actors in the system, in which case nonaver- \nage behavior arises from the heterogeneity of the population of agents. These roles \nfor random perturbations will be explored in later chapters.\n\nChapter 4 Structure and Behavior of Dynamic Systems \n129 \n4.3.3 Chaos \nIn recent years chaos has become a ubiquitous buzz word in the popular press and \nmanagement literature. Books and articles by a host of new age management gu- \nrus warn companies to \u201cmanage at the edge of chaos\u201d or be overtaken by more \nnimble competitors. Extravagant claims have been made that chaos is a new and \nradically different science, one which is fundamentally nonlinear and complex, one \nthat can\u2019t be explained without some mysterious new theory. Actually, the term \n\u201cchaos\u201d has a narrow and precise technical meaning in dynamical theory. Unfortu- \nnately, the hunger for the latest fad in the business world, reinforced by marketing \nhype attending the development of chaos and complexity theory, has led to the \nmisappropriation and dilution of the term. To explain chaos I first describe some \nmore common types of oscillations. \nDamped Oscillations: Local Stability \nOne important characteristic of oscillations is damping: if an oscillatory system is \nperturbed once and then left undisturbed, will the fluctuations die out? If so, the cy- \ncle is damped. Many systems are damped oscillators. The classic example is a pen- \ndulum like a child\u2019s swing: Given a single push, the arc traversed by the swing \nsteadily diminishes as friction dissipates its energy, until it eventually comes to \nrest. If you could reduce the frictional energy losses of the pendulum, damping \nwould be weaker and it would take longer and longer for equilibrium to be reestab- \nlished after a shock. In the (unattainable) limit of zero friction, a single shock \nwould cause a perpetual oscillation at a constant amplitude. \nThe equilibrium of the damped pendulum is said to be locally stable: pertur- \nbations will cause the system to oscillate, but it will eventually return to the same \nequilibrium. The qualif",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 153
  },
  {
    "child_id": "2128b0a3-ec32-449a-b9a7-e57e5cd942c6",
    "parent_id": "5e0ba8cb-f5cc-4172-8a36-b5d8be0343b9",
    "text": "\nrest. If you could reduce the frictional energy losses of the pendulum, damping \nwould be weaker and it would take longer and longer for equilibrium to be reestab- \nlished after a shock. In the (unattainable) limit of zero friction, a single shock \nwould cause a perpetual oscillation at a constant amplitude. \nThe equilibrium of the damped pendulum is said to be locally stable: pertur- \nbations will cause the system to oscillate, but it will eventually return to the same \nequilibrium. The qualifier \u201clocally\u201d is important. Real systems are nonlinear, \nmeaning that the feedback loops and parameters governing the dynamics vary de- \npending on the state of the system (where the system is operating in state space- \nthe space created by the state variables of the ~ystem).~ \nLocal stability means the \nperturbations have to be small relative to nonlinearities that might cause other dy- \nnamics to emerge, as when the pendulum is swung so hard it breaks. \nMany real world oscillators are damped, but the oscillations never die away \nbecause the systems are continually bombarded with noise. Many models suggest \nthat the short-term business cycle (Figure 4-7) is a damped, locally stable oscilla- \ntion (chapter 19). The oscillatory structure is a set of negative feedback loops \nthrough which firms adjust production to control their inventories of products and \nraw materials. These loops are oscillatory because of the lags in the adjustment of \nproduction to changes in demand and inventory, particularly delays in hiring and \n71n a simple pendulum, there are two state variables: the position of the pendulum and its mo- \nmentum. These two states define a two-dimensional space, and the state of the system is defined at \nany time by the point in that space corresponding to the position and momentum of the pendulum. \nAs the pendulum swings through its arc, its trajectory traces out a curve in state space. More com- \nplex systems have high-dimensional state spaces, but the concept of a trajectory in state space re- \nmains the same.\n\n130 \nFIGURE 4-1 5 \nDamped \noscillation in a \nmodel of the Beer \nDistribution Game \nNote the \nnonlinearity: \nbetween weeks \n30 and 45 there \nis a large surplus \nof inventory but \norders are \nconstrained to be \nnonnegative. \nPart I Perspective and Process \nmaterials acquisition (Forrester 1961; Mass 1975). In these models, both the per- \nsistence and irregularity of the business cycle are caused by the excitation of the \neconomy by random shocks, just as the simple pendulum discussed above fluctu- \nates somewhat irregularly when perturbed by noise. \nFigure 4-15 shows an example of damped oscillation in a simple model of a \nfirm based on the Beer Distribution Game (Sterman 1989b, chap. 17). The game \nrepresents the supply chain in a typical manufacturing industry. The supply chain \nhas four sectors: a retailer, wholesaler, distributor, and factory. Each stage is iden- \ntical and managed by a different person. The managers strive to minimize t",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 153
  },
  {
    "child_id": "c9314b71-7bc2-46d8-bf01-956a180fa9d3",
    "parent_id": "5e0ba8cb-f5cc-4172-8a36-b5d8be0343b9",
    "text": " as the simple pendulum discussed above fluctu- \nates somewhat irregularly when perturbed by noise. \nFigure 4-15 shows an example of damped oscillation in a simple model of a \nfirm based on the Beer Distribution Game (Sterman 1989b, chap. 17). The game \nrepresents the supply chain in a typical manufacturing industry. The supply chain \nhas four sectors: a retailer, wholesaler, distributor, and factory. Each stage is iden- \ntical and managed by a different person. The managers strive to minimize their \ncosts by controlling inventories as they seek to meet incoming demand. The simu- \nlation shows the response of the factory order rate to a one-time change in cus- \ntomer orders. The decision rule used by each agent in the simulation was estimated \nfrom the behavior of actual players. In response to the shock in demand, factory or- \nders exhibit a damped oscillation which returns the system to equilibrium after \nabout 70 weeks. Here the negative loop is the process by which each stage in the \nsupply chain manages its inventory: ordering more when inventories are inade- \nquate and less when they are high. The delays arise from the time required to \nprocess orders and produce and deliver the beer. \nExpanding Oscillations and Limit Cycles \nWhile many oscillatory systems are damped, the equilibria of other systems are \nlocally unstable, meaning that small disturbances tend to move the system farther \naway from the equilibrium point. Imagine a ball balanced on top of a hill. As long \nas the ball is exactly balanced on the hilltop, it remains in equilibrium. But the \nslightest breeze pushes the ball down the hill ever so slightly, leading to a still \ngreater force downhill, in a positive feedback. The equilibrium is unstable. While \nan equilibrium may be locally unstable, any real system must be globally stable. \nGlobal stability means the trajectories of the system do not diverge to infinity: \nthe trajectories are bounded because the positive feedbacks leading to the accel- \nerating flight from the balance point must ultimately be limited by various nega- \ntive loops. The ball cannot accelerate indefinitely, but will come to rest at the \nbottom of the hill.",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 153
  },
  {
    "child_id": "1b7a9d69-87c4-434a-9f70-9c20dd5b35f4",
    "parent_id": "e34b6437-a310-4160-b85a-c7d186ac1192",
    "text": "Chapter 4 Structure and Behavior of Dynamic Systems \n131 \nIf an oscillatory system with a locally unstable equilibrium is given a slight \nnudge off its equilibrium point, its swings grow larger and larger until they are con- \nstrained by various nonlinearities. Such oscillations are known as limit cycles, to \ndenote the nonlinear limits restricting their amplitude. In limit cycles, the states of \nthe system remain within certain ranges (they are limited to a certain region of state \nspace). In the steady state, after the effects of any initial perturbations have died \nout, a limit cycle follows a particular orbit (closed curve) in state space. The steady \nstate orbit is known as an attractor, since trajectories near enough to it will move \ntoward it, just as the bob of the damped pendulum is attracted to its stable equilib- \nrium point. \nFigure 4-16 shows an example of a limit cycle from the Beer Distribution \nGame. The situation in the figure is the same as described above for the damped \noscillation except that the parameters of the ordering decision rule are slightly dif- \nferent. As in the case of the damped oscillation, the parameters characterize the be- \nhavior of an actual player. Again, there is a one-time change in customer demand. \nInstead of dying out, the cycle persists indefinitely, even though the environment \nis completely unchanging. The figure shows the cycle both as a time series and as \na so-called phase plot with orders on the vertical axis and inventory on the hori- \nzontal axis, showing the closed orbit perpetually traced by the system. \nOf course, limit cycles are not perpetual motion machines. The energy re- \nquired to maintain the cycle must be provided from a source outside the oscillator. \nLimit cycles are quite common. Your life depends on them-your heartbeat and \nrespiration are limit cycles. The circadian rhythms (daily fluctuations in alertness, \nhormone production, and a host of other physiological parameters) observed in al- \nmost all organisms, from bacteria to people, are limit cycles. Many cycles in the bi- \nological world also appear to be limit cycles, including cycles in predator-prey \npopulations, cycles in the mass fruiting of certain plant species such as Piiion pines \nand some bamboos, and the periodic population explosions of certain insects such \nas the 17-year cicada (see Murray 1993). Many models suggest that very long-term \nFIGURE 4-1 6 \nLe,ft Time series of factory orders. The cycle repeats indefinitely without any external variation. \nRight: The orbit of the system is a closed curve, shown here with factory orders plotted against net \nfactory inventory (inventory less backlog). \nA limit cycle generated in the Beer Distribution Game \n600 \n700 \n800 \n900 \n1000 \nWeeks \n0 \n-30 -20 \n-10 \n0 \n1 0  \n2 0  \nFactory Net Inventory\n\n132 \nPart I Perspective and Process \nfluctuations in the world economy known as \u201clong waves\u201d are self-perpetuating \nlimit cycles (Sterman 1985; Forrester 1983). Sterman (1989a) rep",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 156
  },
  {
    "child_id": "38e1b1bd-dd90-4c9c-8479-e4dbc4fd20b0",
    "parent_id": "e34b6437-a310-4160-b85a-c7d186ac1192",
    "text": "hout any external variation. \nRight: The orbit of the system is a closed curve, shown here with factory orders plotted against net \nfactory inventory (inventory less backlog). \nA limit cycle generated in the Beer Distribution Game \n600 \n700 \n800 \n900 \n1000 \nWeeks \n0 \n-30 -20 \n-10 \n0 \n1 0  \n2 0  \nFactory Net Inventory\n\n132 \nPart I Perspective and Process \nfluctuations in the world economy known as \u201clong waves\u201d are self-perpetuating \nlimit cycles (Sterman 1985; Forrester 1983). Sterman (1989a) reports an experi- \nment in which people managed a simple economic model; the vast majority gener- \nated long waves much like the behavior of the model. Sterman (1989~) shows that \nmany of the decision rules\u2019characterizing the human subjects generate chaos and \nvarious forms of limit cycle. \nChaotic Oscillations \nChaos, like damped fluctuations and limit cycles, is a form of oscillation. How- \never, unlike limit cycles, a chaotic system fluctuates irregularly, never exactly re- \npeating, even though its motion is completely deterministic. The irregularity arises \nendogenously and is not created by external, random shocks. Like a limit cycle, the \npath of a chaotic system is bounded to a certain region of state space. Because \nchaotic systems are bounded, chaos, like limit cycles, can only arise in nonlinear \nsystems. However, unlike linear systems or limit cycles, chaotic dynamics do not \nhave a well-defined period, as does the simple pendulum discussed above. The mo- \ntion of a chaotic system never repeats; instead, the orbits of the system approach \nwhat is known as a strange attractor-a set of closely related but slightly different \norbits rather than a single closed curve. Furthermore, chaotic systems have the \nproperty known as sensitive dependence on initial conditions. Two nearby tra- \njectories, no matter how close, will diverge exponentially until the state of one \nprovides no more information about the state of the other than any randomly cho- \nsen trajectory. Sensitive dependence means that the prediction horizon for chaotic \nsystems-the length of time over which forecasts of future behavior are accurate- \nis likely to be short even if our model of the system structure and parameter esti- \nmates are perfect. Further, the cost of increasing the prediction horizon a fixed \namount by improving our knowledge of the current state of the system increases \nexponentially. \nFigure 4-17 shows chaotic behavior in a simulation of the Beer Distribution \nGame. Only the parameters of the decision rule for orders have been altered; again, \nFIGURE 4-17 Chaos in the Beer Distribution Game \nLeft: Time series showing factory orders. Right: Phase plot showing orders vs. net factory inventory \n(inventory less backlog). \n8 o  t \n8\n6 0  \nE 6 0  \n2 2  \nQ \nh \n2 2  \nLL \nE \n0 \n2. 40 \n0 \n0 \nm \nz% 40 \n+ \n8 c \n- c  \n0 \n2 0  \n2 0  \n0 \n0 \n600 \n7 0 0  \n800 \n900 \n1000 \n-100 \n-50 \n0 \n5 0  \n100 \nFactory Net Inventory \nWeeks\n\nChapter 4 Structure and Behavior of Dynamic Systems \n133 \nth",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 156
  },
  {
    "child_id": "4fa450cd-a9b9-41ce-b728-a22d948df1cc",
    "parent_id": "e34b6437-a310-4160-b85a-c7d186ac1192",
    "text": "rameters of the decision rule for orders have been altered; again, \nFIGURE 4-17 Chaos in the Beer Distribution Game \nLeft: Time series showing factory orders. Right: Phase plot showing orders vs. net factory inventory \n(inventory less backlog). \n8 o  t \n8\n6 0  \nE 6 0  \n2 2  \nQ \nh \n2 2  \nLL \nE \n0 \n2. 40 \n0 \n0 \nm \nz% 40 \n+ \n8 c \n- c  \n0 \n2 0  \n2 0  \n0 \n0 \n600 \n7 0 0  \n800 \n900 \n1000 \n-100 \n-50 \n0 \n5 0  \n100 \nFactory Net Inventory \nWeeks\n\nChapter 4 Structure and Behavior of Dynamic Systems \n133 \nthese parameters were estimated from the behavior of an actual player. Like the \nlimit cycle, orders fluctuate indefinitely, in this case with an amplitude ranging \nfrom 0 to about 50 units per week and an average period of about 20 weeks. Un- \nlike the limit cycle, the oscillation does not have a regular amplitude, periodicity, \nor shape, even though the environment is completely constant and the system is \ncompletely free of random shocks. The trajectory of the system in state space fol- \nlows a well-defined path, but one which never closes on itself.8 \nIn all three of these cases, damped oscillation, limit cycle, and chaos, the feed- \nback structure and decision rules are the same. The only differences are in the pa- \nrameters of the ordering rule such as the size of desired inventory and the \naggressiveness with which managers react to the discrepancy between desired and \nactual inventory. \n4.4 SUMMARY \nThe feedback structure of a system generates its behavior. Most dynamics ob- \nserved in the real world are examples of a small set of basic patterns or modes of \nbehavior. Three of these modes are fundamental: exponential growth, goal seeking, \nand oscillation. Each of these modes is generated by a particular underlying feed- \nback structure. Exponential growth is generated by positive feedback processes, \ngoal seeking is generated by negative feedback, and oscillation is generated \nby negative feedback with delays. More complex patterns of behavior such as \nS-shaped growth, growth with overshoot, and overshoot and collapse result from \nthe nonlinear interaction of these basic feedback structures. \nThe principle that the structure of a system generates its behavior leads to a \nuseful heuristic to help modelers discover the feedback loop structure of a system. \nWhenever a particular pattern of behavior is observed, you know which of the \nbasic feedback structures must have been dominant during the period covered by \nthe data. Observing that a variable of interest has been fluctuating, for example, \nimplies the existence of (at least) one negative feedback loop with significant time \ndelays, which helps to guide the search for the particular structures, decision \nprocesses, and time delays that comprise the negative loop. While this heuristic is \nuseful as an aid to the initial conceptualization process, modelers must also take \ncare to search for and include in their models the feedback loops and structures that \nhave not been important in generating the d",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 156
  },
  {
    "child_id": "c6b9fb0c-fe89-44ff-8ebb-41cfd83839ed",
    "parent_id": "e34b6437-a310-4160-b85a-c7d186ac1192",
    "text": "s been fluctuating, for example, \nimplies the existence of (at least) one negative feedback loop with significant time \ndelays, which helps to guide the search for the particular structures, decision \nprocesses, and time delays that comprise the negative loop. While this heuristic is \nuseful as an aid to the initial conceptualization process, modelers must also take \ncare to search for and include in their models the feedback loops and structures that \nhave not been important in generating the dynamics to date but that may become \nactive as the system evolves. \nsMosekilde (1996) provides an excellent treatment of chaotic and other nonlinear dynamics in \nthe Beer Distribution Game and a wide variety of other physical, technical, and biological systems. \nStrogatz (1994) provides an excellent mathematical introduction to nonlinear dynamics and chaos.\n\nCausal Loop Diagrams \nWe shape our buildings; thereaffer; our buildings shape us. -Winston Churchill \nFeedback is one of the core concepts of system dynamics. Yet our mental models \noften fail to include the critical feedbacks determining the dynamics of our \nsystems. In system dynamics we use several diagramming tools to capture the \nstructure of systems, including causal loop diagrams and stock and flow maps. \nThis chapter focuses on causal loop diagrams, including guidelines, pitfalls, and \nexamples. \n5.1 \nCAUSAL DIAGRAM NOTATION \nCausal loop diagrams (CLDs) are an important tool for representing the feedback \nstructure of systems. Long used in academic work, and increasingly common in \nbusiness, CLDs are excellent for \nQuickly capturing your hypotheses about the causes of dynamics; \nEliciting and capturing the mental models of individuals or teams; \nCommunicating the important feedbacks you believe are responsible for a \nproblem. \nThe conventions for drawing causal diagrams are simple but should be followed \nfaithfully. Think of causal diagrams as musical scores. Neatness counts, and idio- \nsyncratic symbols and styles make it hard for fellow musicians to read your score. \nAt first, you may find it difficult to construct and interpret these diagrams. With \npractice, however, you will soon be sight-reading. \n137\n\n138 \nPart I1 Tools for Systems Thinking \nFIGURE 5-1 \nCausal loop \ndiagram notation \nA causal diagram consists of variables connected by arrows denoting the \ncausal influences among the variables. The important feedback loops are also iden- \ntified in the diagram. Figure 5-1 shows an example and key to the notation. \nVariables are related by causal links, shown by arrows. In the example, the \nbirth rate is determined by both the population and the fractional birth rate. Each \ncausal link is assigned a polarity, either positive (+) or negative (-) to indicate \nhow the dependent variable changes when the independent variable changes. The \nimportant loops are highlighted by a loop identifier which shows whether the \nloop is a positive (reinforcing) or negative (balancing) feedback. Note that th",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 156
  },
  {
    "child_id": "c87ab804-a360-426e-b231-88cb536b8568",
    "parent_id": "e34b6437-a310-4160-b85a-c7d186ac1192",
    "text": "o the notation. \nVariables are related by causal links, shown by arrows. In the example, the \nbirth rate is determined by both the population and the fractional birth rate. Each \ncausal link is assigned a polarity, either positive (+) or negative (-) to indicate \nhow the dependent variable changes when the independent variable changes. The \nimportant loops are highlighted by a loop identifier which shows whether the \nloop is a positive (reinforcing) or negative (balancing) feedback. Note that the loop \nidentifier circulates in the same direction as the loop to which it corresponds. In the \nexample, the positive feedback relating births and population is clockwise and so \nis its loop identifier; the negative death rate loop is counterclockwise along with its \nidentifier. \nTable 5-1 summarizes the definitions of link polarity. \nExample \nn+ \n-\n-\n \nDeath Rate \n(3 \nPopulation \ntil \nBirth Rate \nFractional \nBirth Rate \nAverage \nLifetime \nCausal Link \n-\n+\n \nLink Polarity \nBirth Rate \nVariable \nPopulation \nVariable \nLoop Identifier: Positive (Reinforcing) Loop \n0 \nor +iJ \nLoop Identifier: Negative (Balancing) Loop",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 156
  },
  {
    "child_id": "b7f347af-ad0b-4ae7-b58a-5b048a7329f7",
    "parent_id": "10bc0959-c29f-4f35-becd-a667042987da",
    "text": "Chapter 5 Causal Loop Diagrams \n139 \nA positive link means that if the cause increases, the effect increases above \nwhat it would otherwise have been, and if the cause decreases, the effect de- \ncreases below what it would otherwise have been. In the example in Figure 5-1 an \nincrease in the fractional birth rate means the birth rate (in people per year) will \nincrease above what it would have been, and a decrease in the fractional birth rate \nmeans the birth rate will fall below what it would have been. That is, if average \nfertility rises, the birth rate, given the population, will rise; if fertility falls, the \nnumber of births will fall. When the cause is a rate of flow that accumulates into a \nstock then it is also true that the cause adds to the stock. In the example, births add \nto the population (see chapter 6 for more on stocks and flows). \nA negative link means that if the cause increases, the effect decreases below \nwhat it would otherwise have been, and if the cause decreases, the effect increases \nabove what it would otherwise have been. In the example, an increase in the aver- \nage lifetime of the population means the death rate (in people per year) will fall \nbelow what it would have been, and a decrease in the average lifetime means the \ndeath rate will rise above what it would have been. That is, if life expectancy \nincreases, the number of deaths will fall; and if life expectancy falls, the death rate \nwill rise. \nLink polarities describe the structure of the system. They do not describe the \nbehavior of the variables. That is, they describe what would happen IF there were \na change. They do not describe what actually happens. The fractional birth rate \nmight increase; it might decrease-the causal diagram doesn\u2019t tell you what will \nhappen. Rather, it tells you what would happen if the variable were to change. \nNote the phrase above (or below) what it otherwise would have been in the \ndefinition of link polarity. An increase in a cause variable does not necessarily \nmean the effect will actually increase. There are two reasons. First, a variable of- \nten has more than one input. To determine what actually happens you need to know \nhow all the inputs are changing. In the population example, the birth rate depends \nTABLE 5-1 \nLink polarity: definitions and examples \nSymbol \nInterpretation \nMathematics \nExamples \n+ \nProduct - \nQuality \nEffort -Results \nSales \ndY/dX > 0 \n+ \n(decreases) above (below) \nIn the case of \naccumulations, \nAll else equal, if X increases \n(decreases), then Y increases \nwhat it would have been. \n+ \nx - 2 - y  \nIn the case of accumulations, \ny = \n+ . . .)ds + ytO \nX adds to Y. \nBirths \n+ \nt \nPopulation \nSales \nProduct- \ndY/dX < 0 \nIn the case of \naccumulations, \nAll else equal, if X increases \n(increases) below (above) \nwhat it would have been. \nX subtracts from Y. \n(decreases), then Y decreases \nPrice - \nFrustration \nResults - \nx -y \nIn the case of accumulations, \nY = (-x + . . .)ds + Yt0 \nDeaths \nPopulation\n",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 164
  },
  {
    "child_id": "6112c1bd-a8ca-4b12-9cae-5d3ea244dc32",
    "parent_id": "10bc0959-c29f-4f35-becd-a667042987da",
    "text": "qual, if X increases \n(decreases), then Y increases \nwhat it would have been. \n+ \nx - 2 - y  \nIn the case of accumulations, \ny = \n+ . . .)ds + ytO \nX adds to Y. \nBirths \n+ \nt \nPopulation \nSales \nProduct- \ndY/dX < 0 \nIn the case of \naccumulations, \nAll else equal, if X increases \n(increases) below (above) \nwhat it would have been. \nX subtracts from Y. \n(decreases), then Y decreases \nPrice - \nFrustration \nResults - \nx -y \nIn the case of accumulations, \nY = (-x + . . .)ds + Yt0 \nDeaths \nPopulation\n\n140 \nPart I1 Tools for Systems Thinking \non both the fractional birth rate and the size of the population (that is, Birth Rate = \nFractional Birth Rate * Population). You cannot say whether an increase in the \nfractional birth rate will actually cause the birth rate to rise; you also need to know \nwhether the population is rising or falling. A large enough drop in the population \nmay cause the birth rate to fall even if the fractional birth rate rises. When assess- \ning the polarity of individual links, assume all other variables are constant (the fa- \nmous assumption of ceteris pavibus). When assessing the actual behavior of a \nsystem, all variables interact simultaneously (all else is not equal) and computer \nsimulation is usually needed to trace out the behavior of the system and determine \nwhich loops are dominant. \nSecond, and more importantly, causal loop diagrams do not distinguish be- \ntween stocks and flows-the accumulations of resources in a system and the rates \nof change that alter those resources (see chapter 6). In the population example, the \npopulation is a stock-it accumulates the birth rate less the death rate. An increase \nin the birth rate will increase the population, but a decrease in the birth rate does \nnot decrease the population. Births can only increase the population, they can \nnever reduce it. The positive link between births and population means that the \nbirth rate adds to the population. Thus an increase in the birth rate increases the \npopulation above what it otherwise would have been and a decrease in the birth \nrate decreases population below what it otherwise would have been. \nSimilarly, the negative polarity of the link from the death rate to population in- \ndicates that the death rate subtracts from the population. A drop in the death rate \ndoes not add to the population. A drop in deaths means fewer people die and more \nremain alive: the population is higher than it would otherwise have been. Note that \nyou cannot tell whether the population will actually be increasing or decreasing: \nPopulation will be falling even if the birth rate is rising if the death rate exceeds \nbirths. To know whether a stock is increasing or decreasing you must know its net \nrate of change (in this case, births less deaths). It is always true, however, that if the \nbirth rate rises, population will rise above what it would have been in the absence \nof the change in births, even if the population continues to fall. Population will be \nfalli",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 164
  },
  {
    "child_id": "4e316423-d0a7-40d6-a75a-2037798a0fcc",
    "parent_id": "10bc0959-c29f-4f35-becd-a667042987da",
    "text": "r the population will actually be increasing or decreasing: \nPopulation will be falling even if the birth rate is rising if the death rate exceeds \nbirths. To know whether a stock is increasing or decreasing you must know its net \nrate of change (in this case, births less deaths). It is always true, however, that if the \nbirth rate rises, population will rise above what it would have been in the absence \nof the change in births, even if the population continues to fall. Population will be \nfalling at a slower rate than it otherwise would. Chapters 6 and 7 discuss the struc- \nture and behavior of stocks and flows. \nProcess Point: A Note on Notation \nIn some of the system dynamics literature, especially the systems thinking tradition \n(see, e.g., Senge et al. 1994 and Kim 1992), an alternate convention for causal dia- \ngrams has developed. Instead of + or - the polarity of a causal link is denoted \nby s or 0, respectively (denoting the same or opposite relationship between inde- \npendent and dependent variables): \nX\nA\nY\n \nX\nA\nY\n \ninsteadof X d\nY\n \ninsteadof X \nY\n\nChapter 5 \nCausal Loop Diagrams \n141 \nThe link denoted with an s is read as \u201cX and Y move in the same direction\u201d \nwhile the link denoted with an o is read as \u201cX and Y move in the opposite direc- \ntion.\u201d Thus Product Quality and Sales tend to move in the same direction while \nProduct Price and Sales tend to move in the opposite direction. \nThe s and o notation was motivated by a desire to make causal diagrams even \neasier to understand for people with little mathematical background. Which nota- \ntion is better is hotly debated. Richardson (1997) provides strong arguments \nagainst the use of s and 0. He notes that the statement \u201cX and Y move in the same \ndirection\u201d is not in general correct, for the reasons stated above. The correct state- \nment is, \u201cIf X increases, Y increases above what it would have been.\u201d That is, a \ncausal link is a contingent statement of the individual effect of a hypothesized \nchange. The variables X and Y may be positively linked and yet Y may fall even as \nX increases, as other variables also affect Y. The s and o definitions also don\u2019t \nwork for stock and flow relationships. Births and population do not move in the \nsame direction: a decrease in births does not cause population to decrease because \nthe birth rate is an inflow to the stock of population. The correct definition is given \nin Table 5-1: for positive link polarity, if X increases, Y will always be higher than \nit would have been; for negative polarity, if X increases, Y will always be lower \nthan it would have been. In this book I will use the + and - signs to denote link \npolarity. As a modeler you should know how to interpret the s and o notation when \nyou see it, but you should use the + and - notation to denote link polarity. \n5.2 \nGUIDELINES FOR CAUSAL LOOP DIAGRAMS \n5.2.1 \nCausation versus Correlation \nEvery link in your diagram must represent (what you believe to be) causal rela- \ntionships betw",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 164
  },
  {
    "child_id": "29b5efdd-0161-481e-acc9-dd64f8fdf1cd",
    "parent_id": "10bc0959-c29f-4f35-becd-a667042987da",
    "text": "t would have been; for negative polarity, if X increases, Y will always be lower \nthan it would have been. In this book I will use the + and - signs to denote link \npolarity. As a modeler you should know how to interpret the s and o notation when \nyou see it, but you should use the + and - notation to denote link polarity. \n5.2 \nGUIDELINES FOR CAUSAL LOOP DIAGRAMS \n5.2.1 \nCausation versus Correlation \nEvery link in your diagram must represent (what you believe to be) causal rela- \ntionships between the variables. You must not include correlations between vari- \nables. The Latin root of the word simulate, sirnulare, means \u201cto imitate.\u201d A system \ndynamics model must mimic the structure of the real system well enough that the \nmodel behaves the same way the real system would. Behavior includes not only \nreplicating historical experience but also responding to circumstances and policies \nthat are entirely novel. Correlations among variables reflect the past behavior of a \nsystem. Correlations do not represent the structure of the system. If circumstances \nchange, if previously dormant feedback loops become dominant, if new policies \nare tried, previously reliable correlations among variables may break down. Your \nmodels and causal diagrams must include only those relationships you believe cap- \nture the underlying causal structure of the system. Correlations among variables \nwill emerge from the behavior of the model when you simulate it. \nThough sales of ice cream are positively correlated with the murder rate, you \nmay not include a link from ice cream sales to murder in your models. Instead, as \nshown in Figure 5-2, both ice cream sales and murder rise in summer and fall in \nwinter as the average temperature fluctuates. Confusing correlation with causality \ncan lead to terrible misjudgments and policy errors. The model on the left side of \nFigure 5-2 suggests that cutting ice cream consumption would slash the murder \nrate, save lives, and allow society to cut the budget for police and prisons.\n\n142 \nPart I1 Tools for Systems Thinking \nFIGURE 5-2 \nCausal diagrams \nmust include \nonly (what you \nbelieve to be) \ngenuine causal \nrelationships. \nIncorrect - \nIce Cream \nMurder \nSales \nRate \nCorrect \nIce Cream \nSales \nMurder \nRate \n/c\u2019 \nAverage / \nTemperature \nWhile few people are likely to attribute murders to the occasional double-dip \ncone, many correlations are more subtle, and it is often difficult to determine the \nunderlying causal structure. A great deal of scientific research seeks the genuine \ncausal needles in a huge haystack of correlations: Does vitamin C cure the com- \nmon cold? Can eating oat bran reduce cholesterol, and if it does, will your risk of \na heart attack drop? Does economic growth lead to lower birth rates, or is the lower \nrate attributable to literacy, education for women, and increasing costs of child \nrearing? Do companies with serious quality improvement programs earn superior \nreturns for stockholders? Scientists have lear",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 164
  },
  {
    "child_id": "7ebdce05-1a0e-428d-aa58-bc81a9636f0d",
    "parent_id": "10bc0959-c29f-4f35-becd-a667042987da",
    "text": " scientific research seeks the genuine \ncausal needles in a huge haystack of correlations: Does vitamin C cure the com- \nmon cold? Can eating oat bran reduce cholesterol, and if it does, will your risk of \na heart attack drop? Does economic growth lead to lower birth rates, or is the lower \nrate attributable to literacy, education for women, and increasing costs of child \nrearing? Do companies with serious quality improvement programs earn superior \nreturns for stockholders? Scientists have learned from bitter experience that reli- \nable answers to such questions are hard to come by and require dedication to the \nscientific method-controlled experiments, randomized, double-blind trials, large \nsamples, long-term follow-up studies, replication, statistical inference, and so on. \nIn the social and human systems we often model, such experiments are difficult, \nrare, and often impossible. Modelers must take extra care to consider whether the \nrelationships in their models are causal, no matter how strong the correlation, how \nhigh the R2, or how great the statistical significance of the coefficients in a re- \ngression may be. As the English economist Phelps-Brown (1972, p. 6) noted, \n\u201cWhere, as so often, the fluctuations of different series respond in common to the \npulse of the economy, it is fatally easy to get a good fit, and get it for quite a num- \nber of different equations . . . Running regressions between time series is only \nlikely to deceive.\u201d \n5.2.2 \nLabeling Link Polarity \nBe sure to label the polarity of every link in your diagrams. Label the polarity of \nthe important feedback loops in your diagrams, using the definitions in Table 5-1 \nto help you determine whether the links are positive or negative. Positive feed- \nback loops are also called reinforcing loops and are denoted by a + or R, while \nnegative loops are sometimes called balancing loops and are denoted by a - or B \n(Figure 5-3).",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 164
  },
  {
    "child_id": "fc9a5792-c5ac-4cc4-9bc7-085fbb4409a8",
    "parent_id": "2f056204-3dee-4f8d-b223-2fa6fc1063da",
    "text": "Chapter 5 Causal Loop Diagrams \n143 \nFIGURE 5-3 \nLabel link and loop \npolarities. \nNote that all linlks \nare labeled and \nloop polarity \nidentifiers show \nwhich loops are \npositive and which \nare negative. \nLoop identifiers \nare clockwise \nfor the clockwise \nloops (and vice \nversa). \nIncorrect \nnn \nCustomer \nCustomer \nSales from \nWord of \nBase \nLoss Rate \nMou\nu \nCorrect \nCustomer \nLoss Rate \nAssigning Link Polarities \nConsider the attractiveness of a product to customers as it depends on various at- \ntributes of the product (Figure 5-4). Assign link polarities. What feedback loops \nmight be created as product attractiveness changes the demand for the firm\u2019s prod- \nuct? Add these to the diagram, labeling the link and loop polarities. \nQuality \nPrice \nProduct \nAttractiveness \nDelay \nDelivery \u2019/ \nFunctionality \n5.2.3 \nDetermining Loop Polarity \nThere are two methods for determining whether a loop is positive or negative: the \nfast way and the right way.\n\n144 \nPart I1 Tools for Systems Thinking \nThe Fast Way: Count the Number of Negative Links \nThe fast way to tell if a loop is positive or negative is to count the number of \nnegative links in the loop. If the number of negative links is even, the loop is posi- \ntive; if the number is odd, the loop is negative. The rule works because positive \nloops reinforce change while negative loops are self-correcting; they oppose dis- \nturbances. Imagine a small disturbance in one of the variables. If the disturbance \npropagates around the loop to reinforce the original change, then the loop is posi- \ntive. If the disturbance propagates around the loop to oppose the original change, \nthen the loop is negative. To oppose the disturbance, the signal must experience a \nnet sign reversal as it travels around the loop. Net reversal can only occur if the \nnumber of negative links is odd. A single negative link causes the signal to reverse: \nan increase becomes a decrease. But another negative link reverses the signal \nagain, so the decrease becomes an increase, reinforcing the original disturbance. \nSee \u201cMathematics of Loop Polarity\u201d below for a formal derivation of this rule. \nThe fast method always works . . . except when it doesn\u2019t. Why might it fail? \nIn a complex diagram it is all too easy to miscount the number of negative links in \na loop. And it is easy to mislabel the polarity of links when you first draw the dia- \ngram. Counting the number of negative signs is unlikely to reveal these errors. The \nright method, carefully tracing the effect of a disturbance around the loop, will of- \nten reveal a wrongly labeled polarity and will help you and your audience to grasp \nthe meaning and mechanism of the loop. Assigning loop polarity the right way \nrather than the fast way saves time in the long run. \nThe Right Way: Trace the Effect of a Change around the Loop \nThe right way to determine the polarity of a loop is to trace the effect of a small \nchange in one of the variables as it propagates around the loop. If the",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 168
  },
  {
    "child_id": "b27a9f4c-0781-441a-9555-be4001669712",
    "parent_id": "2f056204-3dee-4f8d-b223-2fa6fc1063da",
    "text": "lly tracing the effect of a disturbance around the loop, will of- \nten reveal a wrongly labeled polarity and will help you and your audience to grasp \nthe meaning and mechanism of the loop. Assigning loop polarity the right way \nrather than the fast way saves time in the long run. \nThe Right Way: Trace the Effect of a Change around the Loop \nThe right way to determine the polarity of a loop is to trace the effect of a small \nchange in one of the variables as it propagates around the loop. If the feedback ef- \nfect reinforces the original change, it is a positive loop; if it opposes the original \nchange, it is a negative loop. You can start with any variable in the loop; the result \nmust be the same. In the market loops shown in Figure 5-3, assume sales from \nword of mouth increase. Because the link from sales from word of mouth to the \ncustomer base is positive, the customer base increases. Because the link from the \ncustomer base back to sales from word of mouth is positive, the signal propagates \naround the loop to increase sales from word of mouth still further. The feedback ef- \nfect reinforces the original change, so the loop is positive. Turning to the other \nloop, assume a small increase in the customer loss rate. If customer losses increase, \nthe customer base falls. With a lower customer base, there are fewer customers \nwho can drop out. The feedback effect opposes the original change, so the loop is \nnegative. \nThis method works no matter how many variables are in a loop and no matter \nwhich variable you start with. (Identify the loop polarities for the example starting \nwith customer base instead of sales from word of mouth: you should get the same \nresult). You may also assume an initial decrease in a variable rather than an initial \nincrease.\n\nChapter 5 Causal Loop Diagrams \n145 \nIdentifying Link and Loop Polarity \nIdentify and label the polarity of the links and loops in the examples shown in \nFigure 5-5. \nAttractiveness \nf Of Market \nProfits \n4 \nNumber of \nCompetitors \n1 \nP r i c e d  \n?Pressure to Clean \nUp Environment \nEnvironmental \nCleanuD \nCumulative \nr \nProduction A \nP r i c e J  \nMarket \nUnit \nShare \ncosts \nI \nPerceived \nSolvency of \nNet \nQuality \nWithdrawals L \nBank \nMathematics of Loop Polarity \nWhen you determine loop polarity, you are calculating what is known in control \ntheory as the sign of the open loop gain of the loop. The term \u201cgain\u201d refers to the \nstrength of the signal returned by the loop: a gain of two means a change in a vari- \nable is doubled each cycle around the loop; a gain of negative 0.5 means the dis- \nturbance propagates around the loop to oppose itself with a strength half as large. \nThe term \u201copen loop\u201d means the gain is calculated for just one feedback cycle by \nbreaking-opening-the loop at some point. Consider an arbitrary feedback loop \nconsisting of n variables, xl, . . . , x,. You can calculate the open loop gain at any \npoint; let x1 denote the variable you choose. When you break the loop, x1 ",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 168
  },
  {
    "child_id": "acc391bb-dd12-4685-b8ce-74dd0fc476f3",
    "parent_id": "2f056204-3dee-4f8d-b223-2fa6fc1063da",
    "text": " a vari- \nable is doubled each cycle around the loop; a gain of negative 0.5 means the dis- \nturbance propagates around the loop to oppose itself with a strength half as large. \nThe term \u201copen loop\u201d means the gain is calculated for just one feedback cycle by \nbreaking-opening-the loop at some point. Consider an arbitrary feedback loop \nconsisting of n variables, xl, . . . , x,. You can calculate the open loop gain at any \npoint; let x1 denote the variable you choose. When you break the loop, x1 splits into \nan input, xll, and output, xl0 (Figure 5-6). The open loop gain is defined as the \n(partial) derivative of xl0 with respect to xll, that is, the feedback effect of a small \nchange in the variable as it returns to itself. The polarity of the loop is the sign of \nthe open loop gain: \nPolarity of loop = SGN(dx,O/dxll) \n(5- 1) \nwhere SGN() is the signum or sign function, returning + 1 if its argument is posi- \ntive and -1 if the argument is negative (if the open loop gain is zero, the SGN \nfunction = 0: there is no loop). The open loop gain is calculated by the chain rule \nfrom the gains of the individual links, dxi/dxi-,:\n\n146 \nFIGURE 5-6 \nCalculating the \nopen-loop gain \nof a loop \nPart I1 Tools for Systems Thinking \n'1 \\ \nBreak \natany \nthe \npoint \nloop /*I \n'1' 1 \nx2 \nand trace the effect \nof a change around \nthe loop. \nPolarity = SGN(~X~O/~X,I) \nSince the sign of a product is the product of the signs, loop polarity is also \ngiven by: \nSGN(dx1O/dx,') = SGN(dx,'/dx,) * SGN(dxn/dx,_1) * SGN(~X,-,/~X,_~) \n* . . - * SGN(dx2/dxI1) \n(5-3) \nUsing the right method to determine loop polarity by tracing the effect of a \nsmall change around a loop is equivalent to calculating equation (5-3). Equation \n(5-3) also explains why the fast method works: Since the product of two negative \nsigns is a positive sign, negative open loop polarity requires an odd number of neg- \native links in the loop. \nAll Links Should Have Unambiguous Polarities \nSometimes people say a link can be either positive or negative, depending on other \nparameters or on where the system is operating. For example, people often draw \nthe diagram on the left side of Figure 5-7 relating a firm's revenue to the price of \nits product and then argue that the link between price and company revenue can be \neither positive or negative, depending on the elasticity of demand. If demand is \nhighly elastic, a higher price means less revenue because a 1% increase in price \ncauses demand to fall more than 1 %. The link would have negative polarity. If de- \nmand is inelastic, then a l % increase in price causes demand to drop less than l %, \nso revenues rise. The link would be positive. It appears no single polarity can be \nassigned. \nWhen you have trouble assigning a clear and unambiguous polarity to a link it \nusually means there is more than one causal pathway connecting the two variables. \nYou should make these different pathways explicit in your diagram. In the exam- \nple, price has at least two effec",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 168
  },
  {
    "child_id": "2de80341-5aa2-4753-8758-05fff2bd4d1b",
    "parent_id": "2f056204-3dee-4f8d-b223-2fa6fc1063da",
    "text": "link would have negative polarity. If de- \nmand is inelastic, then a l % increase in price causes demand to drop less than l %, \nso revenues rise. The link would be positive. It appears no single polarity can be \nassigned. \nWhen you have trouble assigning a clear and unambiguous polarity to a link it \nusually means there is more than one causal pathway connecting the two variables. \nYou should make these different pathways explicit in your diagram. In the exam- \nple, price has at least two effects on revenue: (1) it determines how much revenue \nis generated per unit sold and (2) it affects the number of units sold. That is, Reve- \nnue = Price * Sales, and (Unit) Sales depend on Price (presumably the demand \ncurve is downward sloping: Higher prices reduce sales). The proper diagram is\n\nChapter 5 Causal Loop Diagrams \n147 \nFIGURE 5-7 \nCausal links \nmust have \nunambiguous \npolarity. \nApparently \nambiguous \npolarities usually \nindicate the \npresence of \nmultiple causal \npathways that \nshould be \nrepresented \nseparately. \nIncorrect \nCorrect \nPrice \nRevenue \nPrice \nRevenue \nSales 2 \n+ \nshown on the right side of Figure 5-7. There is now no ambiguity about the polar- \nity of any of the links. \nThe price elasticity of demand determines which causal pathway dominates. If \ndemand is quite insensitive to price (the elasticity of demand is less than one), then \nthe lower path in Figure 5-7 is weak, price raises unit revenue more than it de- \ncreases sales, and the net effect of an increase in price is an increase in revenue. \nConversely, if customers are quite price sensitive (the elasticity of demand is \ngreater than one), the lower path dominates. The increase in revenue per unit is \nmore than offset by the decline in the number of units sold, so the net effect of a \nprice rise is a drop in revenue. Separating the pathways also allows you to specify \ndifferent delays, if any, in each. In the example above, there is likely to be a long \ndelay between a change in price and a change in sales, while there is little or no de- \nlay in the effect of price on revenue. \nSeparating links with apparently ambiguous polarity into the underlying mul- \ntiple pathways is a fruitful method to deepen your understanding of the causal \nstructure, delays, and behavior of the system. \nEmployee Motivation \nYour client team is worried about employee motivation and is debating the best \nways to generate maximum effort from their people. They have drawn a diagram \n(Figure 5-8) and are arguing about the polarity of the links. One group argues that \nthe greater the performance shortfall (the greater the gap between Required Per- \nformance and Actual Performance), the greater the motivation of employees will \nbe. They argue that the secret of motivation is to set aggressive, even impossible \ngoals (so-called stretch objectives) to elicit maximum motivation and effort. The \nother group argues that too big a performance shortfall simply causes frustration as \npeople conclude there is no",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 168
  },
  {
    "child_id": "fc5f6e4f-82dd-4460-9cbd-5c234e49ee56",
    "parent_id": "2f056204-3dee-4f8d-b223-2fa6fc1063da",
    "text": "g about the polarity of the links. One group argues that \nthe greater the performance shortfall (the greater the gap between Required Per- \nformance and Actual Performance), the greater the motivation of employees will \nbe. They argue that the secret of motivation is to set aggressive, even impossible \ngoals (so-called stretch objectives) to elicit maximum motivation and effort. The \nother group argues that too big a performance shortfall simply causes frustration as \npeople conclude there is no chance to accomplish the goal, so the link to employee \nmotivation should be negative. Expand the diagram to resolve the apparent conflict \nby incorporating both theories. Discuss which links dominate under different cir- \ncumstances. Can you give some examples from your own experience where these \ndifferent pathways were dominant? How can a manager tell which pathway is \nlikely to dominate in any situation? What are the implications for goal setting in or- \nganizations? Actual and required performance are not exogenous but part of the \nfeedback structure. How does motivation feed back to performance, and how \nmight actual performance affect the goal? Indicate these loops in your diagram and \nexplain their importance.",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 168
  },
  {
    "child_id": "724cbe3d-4d77-4540-90fa-f17e8aa9342a",
    "parent_id": "2e7e479d-cfb2-4929-9cbe-c3281d13fcf5",
    "text": "148 \nPart I1 Tools for Systems Thinking \nActual \nRequired \nPerformance \n+/ \nPerformance \nPerformance \nShortfall \nEm p I oyee \nMotivation \n5.2.4 Name Your Loops \nWhether you use causal diagrams to elicit the mental models of a client group or to \ncommunicate the feedback structure of a model, you will often find yourself trying \nto keep track of more loops than you can handle. Your diagrams can easily over- \nwhelm the people you are trying to reach. To help your audience navigate the net- \nwork of loops, it\u2019s helpful to give each important feedback a number and a name. \nNumbering the loops R1, R2, B1, B2, and so on helps your audience find each loop \nas you discuss it. Naming the loops helps your audience understand the function of \neach loop and provides useful shorthand for discussion. The labels then stand in for \na complex set of causal links. When working with a client group, it\u2019s often possi- \nble to get them to name the loop. Many times, they will suggest a whimsical phrase \nor some organization-specific jargon for each loop. \nFigure 5-9 shows a causal diagram developed by engineers and managers in a \nworkshop designed to explore the causes of late delivery for their organization\u2019s \ndesign work. The diagram represents the behavior of the engineers trying to \ncomplete a project against a deadline. The engineers compare the work remaining \nto be done against the time remaining before the deadline. The larger the gap, the \nmore Schedule Pressure they feel. When schedule pressure builds up, engineers \nhave several choices. First, they can work overtime. Instead of the normal 50 hours \nper week, they can come to work early, skip lunch, stay late, and work through the \nweekend. By burning the Midnight Oil, they increase the rate at which they com- \nplete their tasks, cut the backlog of work, and relieve the schedule pressure (bal- \nancing loop B l). However, if the workweek stays too high too long, fatigue sets in \nand productivity suffers. As productivity falls, the task completion rate drops, \nwhich increases schedule pressure and leads to still longer hours: the reinforcing \nBurnout loop R1 limits the effectiveness of overtime. Another way to complete the \nwork faster is to reduce the time spent on each task. Spending less time on each \ntask boosts the number of tasks done per hour (productivity) and relieves schedule \npressure, thus closing the balancing loop B2. Discussion of the name for this loop \nwas heated. The managers claimed the engineers always gold-plated their work; \nthey felt schedule pressure was needed to squeeze out waste and get the engineers \nto focus on the job. The engineers argued that schedule pressure often rose so high \nthat they had no choice but to cut back quality assurance and skip documentation\n\nChapter 5 Causal Loop Diagrams \n149 \nFIGURE 5-9 \nName and number \nyour loops to \nincrease diagraim \nclarity and provide \nmemorable lablels \nfor important \nfeedbacks. \nTime \nRemaining \n/ \nWork \nError Rate \nof their work. The",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 173
  },
  {
    "child_id": "67d1b0be-7cb7-4e7d-8d1c-fe43c3631481",
    "parent_id": "2e7e479d-cfb2-4929-9cbe-c3281d13fcf5",
    "text": "s gold-plated their work; \nthey felt schedule pressure was needed to squeeze out waste and get the engineers \nto focus on the job. The engineers argued that schedule pressure often rose so high \nthat they had no choice but to cut back quality assurance and skip documentation\n\nChapter 5 Causal Loop Diagrams \n149 \nFIGURE 5-9 \nName and number \nyour loops to \nincrease diagraim \nclarity and provide \nmemorable lablels \nfor important \nfeedbacks. \nTime \nRemaining \n/ \nWork \nError Rate \nof their work. They called it the Corner Cutting loop (B2). The engineers then ar- \ngued that corner cutting is self-defeating because it increases the error rate, which \nleads to rework and lower productivity in the long run: \u201cHaste makes waste,\u201d they \nsaid, and schedule pressure rises further, leading to still more pressure to cut cor- \nners (loop R2). \nThe full model included many more loops (section 5.1 provides a closely re- \nlated example; see also section 2.3). The names given to the loops by one group \n(engineers) communicated their attitudes and the rationale for their behavior to the \nmanagers in a clear and compelling way. The conversation did not degenerate into \nad hominem arguments between managers shouting that engineers just need to \nhave their butts kicked and engineers griping that getting promoted to management \nturns your brain to [fertilizer]-the mode of discourse most common in the orga- \nnization prior to the intervention. Participants soon began to talk about the Burnout \nLoop kicking in and the nonlinear relationships between schedule pressure, over- \ntime, fatigue, and errors. The names for the loops made it easy to refer to complex \nchunks of feedback structure. The concepts captured by the names gradually began \nto enter the mental models and decision making of the managers and engineers in \nthe organization and led to change in deeply ingrained behaviors.\n\n150 \nPart I1 Tools for Systems Thinking \nFIGURE 5-10 \nRepresenting \ndelays in causal \ndiagrams \n5.2.5 \nIndicate Important Delays in Causal Links \nDelays are critical in creating dynamics. Delays give systems inertia, can create os- \ncillations, and are often responsible for trade-offs between the short- and long-run \neffects of policies. Your causal diagrams should include delays that are important \nto the dynamic hypothesis or significant relative to your time horizon. As shown in \nchapter 11, delays always involve stock and flow structures. Sometimes it is im- \nportant to show these structures explicitly in your diagrams. Often, however, it is \nsufficient to indicate the presence of a time delay in a causal link without explic- \nitly showing the stock and flow structure. Figure 5-10 shows how time delays are \nrepresented in causal diagrams. \nWhen the price of a good rises, supply will tend to increase, but often only af- \nter significant delays while new capacity is ordered and built and while new firms \nenter the market. See also the time delays in the Burnout and Haste Makes Waste \nloops i",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 173
  },
  {
    "child_id": "57d2a610-070c-43fc-9a92-8191ce21292a",
    "parent_id": "2e7e479d-cfb2-4929-9cbe-c3281d13fcf5",
    "text": "tly in your diagrams. Often, however, it is \nsufficient to indicate the presence of a time delay in a causal link without explic- \nitly showing the stock and flow structure. Figure 5-10 shows how time delays are \nrepresented in causal diagrams. \nWhen the price of a good rises, supply will tend to increase, but often only af- \nter significant delays while new capacity is ordered and built and while new firms \nenter the market. See also the time delays in the Burnout and Haste Makes Waste \nloops in Figure 5-9. \nExample: Energy Demand \nThe response of gasoline sales to price involves long delays. In the short run, gaso- \nline demand is quite inelastic: if prices rise, people can cut down on discretionary \ntrips somewhat, but most people still have to drive to work, school, and the super- \nmarket. As people realize that prices are likely to stay high they may organize car- \npools or switch to public transportation, if it is already available. Over time high \nprices induce other responses. First, consumers (and the auto companies) wait to \nsee if gas prices are going to stay high enough and long enough to justify buying \nor designing more efficient cars (a perceptual and decision-making delay of per- \nhaps a year or more). Once people have decided that the price won\u2019t drop back \ndown any time soon, the auto companies must then design and build more efficient \ncars (a delay of several years). Even after more efficient cars become available, the \nvast majority of cars on the road will be inefficient, older models which are only \nreplaced as they wear out and are discarded, a delay of about 10 years. If prices \nstay high, eventually the density of settlement patterns will increase as people \nabandon the suburbs and move closer to their jobs. Altogether, the total delay in the \nlink between price and demand for gasoline is significantly more than a decade. As \nthe stock of cars on the road is gradually replaced with more efficient cars, and as \n(perhaps) new mass transit routes are designed and built, the demand for gasoline \nwould fall substantially-long-run demand is quite elastic. Figure 5-1 1 makes \nthese different pathways for the adjustment of gasoline demand explicit. \nExplicitly portraying the many delays between a change in price and the \nresulting change in demand makes it easier to see the worse-before-better behavior \nof expenditures on gasoline caused by a price increase. The bottom of Figure \n5-1 1 shows the response of gasoline demand and expenditures to a hypothetical\n\nChapter 5 Causal Loop Diagrams \n151 \nunanticipated step increase in the price of gasoline. In the short run gasoline \ndemand is rather inflexible, so the first response to an increase in the price of gas \nis an increase in gasoline expenditures. As the high price persists, efficiency \nFIGURE 5-11 \nTop: The short run response to higher prices is weak, while the long run response is substantial as the \nstock of cars is gradually replaced with more efficient models, and as life",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 173
  },
  {
    "child_id": "dd82c860-7e7e-4528-a1db-36deb26e33f4",
    "parent_id": "2e7e479d-cfb2-4929-9cbe-c3281d13fcf5",
    "text": "s to a hypothetical\n\nChapter 5 Causal Loop Diagrams \n151 \nunanticipated step increase in the price of gasoline. In the short run gasoline \ndemand is rather inflexible, so the first response to an increase in the price of gas \nis an increase in gasoline expenditures. As the high price persists, efficiency \nFIGURE 5-11 \nTop: The short run response to higher prices is weak, while the long run response is substantial as the \nstock of cars is gradually replaced with more efficient models, and as lifestyles change. \nBottom: Resporise to a hypothetical permanent unanticipated increase in gasoline price. Consumption \nslowly declines 'due to the long delays in adjusting the efficiency of automobiles and in changing \nsettlement patterns and mass transit routes. Expenditures therefore immediately rise and only later fall \nbelow the initial level: a worse-before-better trade-off for consumers. Of course, as demand falls, there \nwould be downvvard pressure on price, possibly lowering expenditures still more, but also discouraging \nfurther efficiency improvements. The feedback to price is deliberately ignored in the diagram. \nDifferent time delays in the response of gasoline demand and expenditures to price \nGasoline \nExpenditures \nPrice \nDiscretionary \nTrips \nDemand for \nShort-Term \nPrice \n-\n>\nI\n\u20ac\n\u20ac\n-\n \n+ \nper Year \nGasoline \nUse of Existing \n+ \nMass Transit \nDensity of \nSettlement Patterns, \n+ \nDevelopment of New \nMass Transit Routes \n+ \nPrice \n+ \\4 Efficiency \nEfficiency of \nCars on Road \nof Carson 2_1 Delay \nMarket \nGasoline Price \nL \nTime\n\n152 \nFIGURE 5-1 2 \nVariable names \nshould be nouns \nor noun phrases. \nFIGURE 5-1 3 \nVariable names \nshould have a \nclear sense of \ndirection. \nPart I1 Tools for Systems Thinking \nimprovements gradually cut consumption of gasoline per vehicle mile, and even- \ntually, settlement patterns and mass transit availability will adjust to reduce the \nnumber of vehicle miles driven per year. In the long run, demand adjustments more \nthan offset the price increase and expenditures fall. From the point of view of the \nconsumer, this is a worse-before-better situation. The time delays and the trade-off \nthey create help explain why it has proven so difficult, in the United States at least, \nto increase gasoline taxes. Although the long-run benefits outweigh the short-run \ncosts, even in net present value terms, they only begin to accrue after many years. \nGovernment officials focused on the next reelection campaign judge the short-run \ncosts to be politically unacceptable. In turn, they make this judgment because the \npublic is unwilling to sacrifice a little today for larger benefits tomorrow. \n5.2.6 \nVariable Names \nVariable Names Should Be Nouns or Noun Phrases \nThe variable names in causal diagrams and models should be nouns or noun \nphrases. The actions (verbs) are captured by the causal links connecting the vari- \nables. A causal diagram captures the structure of the system, not its behavior-not \nwhat has actually happened but",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 173
  },
  {
    "child_id": "f1364e5d-3c36-454b-ad12-744ccd237aa5",
    "parent_id": "2e7e479d-cfb2-4929-9cbe-c3281d13fcf5",
    "text": "to be politically unacceptable. In turn, they make this judgment because the \npublic is unwilling to sacrifice a little today for larger benefits tomorrow. \n5.2.6 \nVariable Names \nVariable Names Should Be Nouns or Noun Phrases \nThe variable names in causal diagrams and models should be nouns or noun \nphrases. The actions (verbs) are captured by the causal links connecting the vari- \nables. A causal diagram captures the structure of the system, not its behavior-not \nwhat has actually happened but what would happen if other variables changed in \nvarious ways. Figure 5- 12 shows examples of good and bad practice. \nThe correct diagram states: If costs rise, then price rises (above what it would \nhave been), but if costs fall, then price will fall (below what it would have been). \nAdding the verb \u201crises\u201d to the diagram presumes costs will only rise, biasing the \ndiscussion towards one pattern of behavior (inflation). It is confusing to talk of a \ndecrease in costs rising or a fall in price increases-are prices rising, rising at a \nfalling rate, or falling? \nVariable Names Must Have a Clear Sense of Direction \nChoose names for which the meaning of an increase or decrease is clear, variables \nthat can be larger or smaller. Without a clear sense of direction for the variables \nyou will not be able to assign meaningful link polarities. \nOn the left side of Figure 5-13 neither variable has a clear direction: If feed- \nback from the boss increases, does that mean you get more comments? Are these \nIncorrect \nn+ \nCosts Rise \nPrice Rises \nIncorrect \nCorrect \nn+\ncosts \nPrice \nCorrect \n-+ \nn+\nMorale \nMental \nPraise from \nAttitude \nthe Boss \nFeedback \nfrom the \nBoss",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 173
  },
  {
    "child_id": "a20c7b4e-fca6-4d37-9e16-a955b21b39a1",
    "parent_id": "eea91f74-42bc-4eba-8aaf-dbe053a77553",
    "text": "Chapter 5 Causal Loop Diagrams \n153 \nFIGURE 5-1 4 \nChoose variables \nwhose normal \nsense of direction \nis positive. \nIncorrect \ncosts \nLosses \nCorrect \ncosts \nProfit \nm- \nHappiness \nn+ \nCriticism \nUnhappiness \nCriticism \ncomments from the boss good or bad? And what does it mean for mental attitude \nto increase? The meaning of the right side is clear: More praise from the boss \nboosts morale; less praise erodes it (though you should probably not let your self- \nesteem depend so much on your boss\u2019 opinion). \nChoose Variables Whose Normal Sense of Direction Is Positive \nVariable names should be chosen so their normal sense of direction is positive. \nAvoid the use of variable names containing prefixes indicating negation (non, un, \netc.; Figure 5-14). \nStandard accounting practice is Profit = Revenue - Costs, so the better vari- \nable name is Profit, which falls when costs rise and rises when costs fall. Likewise, \ncriticism may make you unhappy, but it is confusing to speak of rising un- \nhappiness; a better choice is the positive happiness, which may fall when you are \ncriticized and rise when criticism drops. Though there are occasional excep- \ntions, decreasing noncompliance with this principle will diminish your audience\u2019s \nincomprehension. \n5.2.7 \nTips for Causal Loop Diagram Layout \nTo maximize the clarity and impact of your causal diagrams, you should follow \nsome basic principles of graphic design. \n1. Use curved lines for information feedbacks. Curved lines help the reader \nvisualize the feedback loops. \n2. Make important loops follow circular or oval paths. \n3. Organize your diagrams to minimize crossed lines. \n4. Don\u2019t put circles, hexagons, or other symbols around the variables in causal \ndiagrams. Symbols without meaning are \u201cchart junk\u201d and serve only to \nclutter and distract. An exception: You will often need to make the stock \nand flow structure of a system explicit in your diagrams. In these cases the \nrectangles and valves around the variables tell the reader which are stocks \nand which are flows-they convey important information (see chapter 6). \n5. Iterate. Since you often won\u2019t know what all the variables and loops will be \nwhen you start, you will have to redraw your diagrams, often many times, \nto find the best layout.\n\n154 \nFIGURE 5-1 5 \nMake intermediate \nlinks explicit to \nclarify a causal \nrelationship. \nPart I1 Tools for Systems Thinking \nIf your audience was confused by \n-- \nMarket \nUnit \nShare \ncosts \nyou might make the intermediate concepts explicit as follows: \n+ Cumulative \n/ \nPytruccm d \nProduction \nExperience \nMarket \nShare \nUnit \ncosts \n5.2.8 \nChoose the Right Level of Aggregation \nCausal loop diagrams are designed to communicate the central feedback structure \nof your dynamic hypothesis. They are not intended to be descriptions of a model at \nthe detailed level of the equations. Having too much detail makes it hard to see the \noverall feedback loop structure and how the different loops interact. Having too lit- \n",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 178
  },
  {
    "child_id": "991d90ad-907b-4e59-a454-e8cb6ab82289",
    "parent_id": "eea91f74-42bc-4eba-8aaf-dbe053a77553",
    "text": "ate concepts explicit as follows: \n+ Cumulative \n/ \nPytruccm d \nProduction \nExperience \nMarket \nShare \nUnit \ncosts \n5.2.8 \nChoose the Right Level of Aggregation \nCausal loop diagrams are designed to communicate the central feedback structure \nof your dynamic hypothesis. They are not intended to be descriptions of a model at \nthe detailed level of the equations. Having too much detail makes it hard to see the \noverall feedback loop structure and how the different loops interact. Having too lit- \ntle detail makes it hard for your audience to grasp the logic and evaluate the plau- \nsibility and realism of your model. \nIf your audience doesn\u2019t grasp the logic of a causal link, you should make \nsome of the intermediate variables more explicit. Figure 5-15 shows an example. \nYou might believe that in your industry, market share gains lead to lower unit costs \nbecause higher volumes move your company down the learning curve faster. The \ntop panel compresses this logic into a single causal link. If your audience found \nthat link confusing, you should disaggregate the diagram to show the steps of your \nreasoning in more detail, as shown in the bottom panel. \nOnce you\u2019ve clarified this logic to the satisfaction of all, you often can \n\u201cchunk\u201d the more detailed representation into a simple, more aggregate form. The \nsimpler diagram then serves as a marker for the richer, underlying causal structure. \n5.2.9 \nDon\u2019t Put All the Loops into \nOne Large Diagram \nShort-term memory can hold 7 t 2 chunks of information at once. This puts a \nrather sharp limit on the effective size and complexity of a causal map. Presenting \na complex causal map all at once makes it hard to see the loops, understand which \nare important, or understand how they generate the dynamics. Resist the tempta- \ntion to put all the loops you and your clients have identified into a single compre- \nhensive diagram. Such diagrams look impressive-My, what a lot of work must \nhave gone into it! How big and comprehensive your model must be!-but are not \neffective in communicating with your audience. A large, wall-filling diagram may \nbe perfectly comprehensible to the person who drew it, but to the people with\n\nChapter 5 Causal Loop Diagrams \n155 \nwhom the author seeks to communicate, it is indistinguishable from a Jackson \nPollock and considerably less valuable. \nHow then do you communicate the rich feedback structure of a system without \noversimplifying? Build up your model in stages, with a series of smaller causal \nloop diagrams. Each diagram should correspond to one part of the dynamic story \nbeing told. Few people can understand a complex causal diagram unless they have \na chance to digest the pieces one at a time. Develop a separate diagram for \neach important loop. These diagrams can have enough detail in them to show how \nthe process actually operates. Then chunk the diagrams into a simpler, high- \nlevel overview to show how they interact with one another. In presentations, build \nup your dia",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 178
  },
  {
    "child_id": "5ba5c051-b24e-4d56-9c82-57b26dfd5130",
    "parent_id": "eea91f74-42bc-4eba-8aaf-dbe053a77553",
    "text": " causal \nloop diagrams. Each diagram should correspond to one part of the dynamic story \nbeing told. Few people can understand a complex causal diagram unless they have \na chance to digest the pieces one at a time. Develop a separate diagram for \neach important loop. These diagrams can have enough detail in them to show how \nthe process actually operates. Then chunk the diagrams into a simpler, high- \nlevel overview to show how they interact with one another. In presentations, build \nup your diagram piece by piece from the chunks (see sections 5.4 and 5.6 for \nexamples). \n5.2.10 \nMake the Goals of Negative Loops Explicit \nAll negative feedback loops have goals. Goals are the desired state of the system, \nand all negative loops function by comparing the actual state to the goal, then ini- \ntiating a corrective action in response to the discrepancy. Make the goals of your \nnegative loops explicit. Figure 5-16 shows two examples. The top panel shows a \nnegative loop affecting the quality of a company\u2019s product: the lower the quality, \nthe more quality improvement programs will be started, and (presumably) the de- \nficiencies in quality will be corrected. Making goals explicit encourages people to \nask how the goals are formed. The goals in most systems are not given exoge- \nnously but are themselves part of the feedback structure. Goals can vary over time \nand respond to pressures in the environment. In the example, what determines the \nFIGURE 5-16 \nMake the goals of \nnegative loops \nexplicit. \nHuiman agency or \nnatural processes \ncan determine \ngoals. \nTop: The goal alf \nthe loop is \ndetermined by \nmanagement \ndecision. \nThe \nBottom: \nlaws of \nthermodynamics \ndetermine the goal \nof the loop. \n( i e G t u r e 1  \nCoffee \nCooling Rate + \nIncorrect \n+ Product \nImprovement \nPrograms \nCorrect \nDesired \n+ \nProduct \nQuality \nQuality \nImprovement \nPrograms \n+ \nCoffee \nRoom \nTemperature \nTemperature \n4 B) \nTemperature \nDifference \nCooling \nRate \n+\n\n156 \nPart I1 Tools for Systems Thinking \ndesired level of product quality? The CEO\u2019s edict? Benchmarking studies of com- \npetitor quality? Customer input? The company\u2019s own past quality levels? When the \ngoal is explicit these questions are more likely to be asked and hypotheses about \nthe answers can be quickly incorporated in the model. \nMaking the goals of negative loops explicit is especially important when the \nloops capture human behavior. But often it is important to represent goals explic- \nitly even when the loop does not involve people at all. The second example por- \ntrays the negative feedback by which a cup of coffee cools to room temperature. \nThe rate of cooling (the rate at which heat diffuses from the hot coffee to the sur- \nrounding air) is roughly proportional to the difference between the coffee temper- \nature and room temperature. The cooling process stops when the two temperatures \nare equal. This basic law of thermodynamics is made clear when the goal is shown \nexplicitly. \nThere are except",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 178
  },
  {
    "child_id": "491f1608-7130-4adc-9f6c-e5f7305ec7ee",
    "parent_id": "eea91f74-42bc-4eba-8aaf-dbe053a77553",
    "text": "does not involve people at all. The second example por- \ntrays the negative feedback by which a cup of coffee cools to room temperature. \nThe rate of cooling (the rate at which heat diffuses from the hot coffee to the sur- \nrounding air) is roughly proportional to the difference between the coffee temper- \nature and room temperature. The cooling process stops when the two temperatures \nare equal. This basic law of thermodynamics is made clear when the goal is shown \nexplicitly. \nThere are exceptions to the principle of showing the goals of negative loops. \nConsider the death rate loop in Figure 5- 1. The goal of the death rate loop is im- \nplicit (and equal to zero: in the long run, we are all dead). Your models should not \nexplicitly portray the goal of the death loop or the goals of similar decay processes \nsuch as the depreciation of capital equipment. \n5.2.11 \nDistinguish between Actual and \nPerceived Conditions \nOften there are significant differences between the true state of affairs and the \nperception of that state by the actors in the system. There may be delays caused by \nreporting and measurement processes. There may be noise, measurement error, \nbias, and distortions. In the quality management example shown in Figure 5-16, \nthere may be significant delays in assessing quality and in changing management\u2019s \nopinion about product quality. Separating perceived and actual conditions helps \nprompt questions such as How long does it take to measure quality? To change \nmanagement\u2019s opinion about quality even after the data are available? To im- \nplement a quality improvement program? To realize results? Besides the long time \ndelays, there may be bias in the reporting system causing reported quality to differ \nsystematically from quality as experienced by the customer. Customers don\u2019t file \nwarranty claims for all problems or report all defects to their sales representative. \nSales and repair personnel may not report all customer complaints to the home \noffice. There may be bias in senior management\u2019s quality assessment because sub- \nordinates filter the information that reaches them. Some auto executives are pro- \nvided with the latest models for their personal use; these cars are carefully selected \nand frequently serviced by company mechanics. Their impression of the quality of \ntheir firm\u2019s cars will be higher than that of the average customer who buys off the \nlot and keeps the car for 10 years. The diagram might be revised as shown in \nFigure 5-17. The diagram now shows how management, despite good inten- \ntions, can come to hold a grossly exaggerated view of product quality, and you are \nwell positioned for a discussion of ways to shorten the delays and eliminate the \ndistortions.",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 178
  },
  {
    "child_id": "78db32f8-dc74-4c63-be6d-e61d83619c4d",
    "parent_id": "a290512b-c7b3-4b8e-9038-e4dd2cc196e6",
    "text": "Chapter 5 Causal Loop Diagrams \n157 \nFIGURE 5-17 \nDistinguish \nbetween actual \nand perceived \nconditions. \nBias in \nReporting \nSystem \nManagement \nBias Toward \nProduct \nQuality \n+ 6High \nQuality \nQuality \nProduct \nManagement \nPerception of \nDelay \nProduct Quality \nDesired \nProduct \nQuality \nQuality \nPrograms \nImprovement \nShortfall \n+ \n5.3 \nPROCESS POINT: \nDEVELOPING CAUSAL DIAGRAMS FROM INTERVIEW DATA \nMuch of the data a modeler uses to develop a dynamic hypothesis comes from in- \nterviews and conversations with people in organizations. There are many tech- \nniques available to gather data from members of organizations, including surveys, \ninterviews, participant observation, archival data, and so on. Surveys generally do \nnot yield data rich enough to be useful in developing system dynamics models. In- \nterviews are an effective method to gather data useful in formulating a model, ei- \nther conceptual or formal. Semistructured interviews (where the modeler has a set \nof predefined questions to ask but is free to depart from the script to pursue av- \nenues of particular interest) have proven to be particularly effective. \nInterviews are almost never sufficient alone and must be supplemented by \nother sources of data, both qualitative and quantitative. People have only a local, \npartial understanding of the system, so you must interview all relevant actors, at \nmultiple levels, including those outside the organization (customers, suppliers, \netc.). Interview data is rich, including descriptions of decision processes, internal \npolitics, attributions about the motives and characters of others, and theories to ex- \nplain events, but these different types of information are mixed together. People \nboth know more than they will tell you and can invent rationales and even inci- \ndents to justify their beliefs, providing you with \u201cdata\u201d they can\u2019t possibly know \n(Nisbett and Wilson 1977). The modeler must triangulate by using as many sources \nof data as possible to gain insight into the structure of the problem situation and the \ndecision processes of the actors in it. An extensive literature provides guidance in \ntechniques for qualitative data collection and analysis; see, for example, Argyris et \nal. (1985), Emmerson et al. (1995), Glaser and Strauss (1967), Kleiner and Roth \n(1997), March et al. (1991), Morecroft and Sterman (1994), Van Maanen (1988), \nand Yin (1994).\n\n158 \nPart I1 Tools for Systems Thinking \nOnce you\u2019ve done your interviews, you must be able to extract the causal \nstructure of the system from the statements of the interview subjects. Formulate \nvariable names so that they correspond closely to the actual words used by the per- \nson you interviewed, while still adhering to the principles for proper variable name \nselection described above (noun phrases, a clear and positive sense of direction). \nCausal links should be directly supported by a passage in the transcript. Typically, \npeople will not describe all the links you may see a",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 182
  },
  {
    "child_id": "889a7d94-a8e5-41e5-ae20-e0202fe60b8b",
    "parent_id": "a290512b-c7b3-4b8e-9038-e4dd2cc196e6",
    "text": "e to extract the causal \nstructure of the system from the statements of the interview subjects. Formulate \nvariable names so that they correspond closely to the actual words used by the per- \nson you interviewed, while still adhering to the principles for proper variable name \nselection described above (noun phrases, a clear and positive sense of direction). \nCausal links should be directly supported by a passage in the transcript. Typically, \npeople will not describe all the links you may see and will not explicitly close \nmany feedback loops. Should you add these additional links? It depends on the \npurpose of your diagram. \nIf you are trying to represent a person\u2019s mental model, you must not include \nany links that cannot be grounded in the person\u2019s own statements. However, you \nmay choose to show the initial diagram to the person and invite him or her to elab- \norate or add any missing links. People will often mention the motivation for a de- \ncision they made, with the feedback effect on the state of the system implicitly \nunderstood. For example, \u201cOur market share was slipping, so we fired the market- \ning VP and got ourselves a new ad agency.\u201d Implicit in this description is the be- \nlief that a new VP and agency would lead to better ads and an increase in market \nshare, closing the negative loop. \nIf the purpose of your interviews is to develop a good model of the problem \nsituation, you should supplement the links suggested by the interviews with other \ndata sources such as your own experience and observations, archival data, and so \non. In many cases, you will need to add additional causal links not mentioned in \nthe interviews or other data sources. While some of these will represent basic phys- \nical relationships and be obvious to all, others require justification or explanation. \nYou should draw on all the knowledge you have from your experience with the \nsystem to complete the diagram1 \nProcess Improvement \nThe following two quotes are actual interview transcripts developed in fieldwork \ncarried out in an automobile company in the United States. The managers, from \ntwo different component plants in the same division of the company, describe why \nthe yield of their lines was persistently low and why it had been so difficult to get \nprocess improvement programs off the ground (Repenning and Sterman 1999): \nIn the minds of the [operations team leaders] they had to hit their pack counts [daily \nquotas]. This meant if you were having a bad day and your yield had fallen . . . you \nhad to run like crazy to hit your target. You could say, \u201cYou are making 20% \ngarbage, stop the line and fix the problem,\u201d and they would say, \u2018\u2018I can\u2019t hit my \npack count without running like crazy.\u201d They could never get ahead of the game. \nSupervisors never had time to make improvements or do preventive maintenance \non their lines . . . they had to spend all their time just trying to keep the line going, \n-Manager at Plant A \n\u2018Burchill and Fine (1997) illustr",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 182
  },
  {
    "child_id": "f6b2acbb-7bde-4404-8700-f27155854ce2",
    "parent_id": "a290512b-c7b3-4b8e-9038-e4dd2cc196e6",
    "text": "d your yield had fallen . . . you \nhad to run like crazy to hit your target. You could say, \u201cYou are making 20% \ngarbage, stop the line and fix the problem,\u201d and they would say, \u2018\u2018I can\u2019t hit my \npack count without running like crazy.\u201d They could never get ahead of the game. \nSupervisors never had time to make improvements or do preventive maintenance \non their lines . . . they had to spend all their time just trying to keep the line going, \n-Manager at Plant A \n\u2018Burchill and Fine (1997) illustrate how causal diagrams can be developed from interview data \nin a product development context.\n\nChapter 5 Causal Loop Diagrams \n159 \nbut this meant it was always in a state of flux . . . because everything was so unpre- \ndictable. It was a kind of snowball effect that just kept getting worse. \n-Supervisor ut Plant B \nDevelop a single causal diagram capturing the dynamics described by the inter- \nviews. Name your loops using terms from the quotes where possible. Explain in a \nparagraph or two how the loops capture the dynamics described. Build your dia- \ngram around the basic physical structure shown in Figure 5-18. The Net Through- \nput of a process (the number of usable parts produced per time period, for example, \nthe number of usable parts produced per day) equals Gross Throughput (the total \nnumber produced per time period) multiplied by the process Yield (the fraction of \ngross throughput that passes inspection and is usable). The remainder, Gross \nThroughput * (1 - Yield), are defective. \n5.4 CONCEPTUALIZATION CASE STUDY: \nMANlAGlNG YOUR WORKLOAD \nThis section illustrates the use of causal diagrams to model an issue. The example \nshows how causal diagramming can be an aid to the development of a dynamic hy- \npothesis, along with identifying variables and developing a reference mode show- \ning the dynamics of the variables over the relevant time horizon. \n5.4.1 \nProblem Definition \nConsider the process of managing your workload. You might be an engineer in a \nproduct development organization, a consultant, or a CEO. To keep it concrete, fo- \ncus on a student managing his or her workload. A student (imagine yourself) must \nbalance classes and assignments with outside activities, a personal life, and sleep. \nDuring the semester you attend classes, do the readings, and hand in assignments \nas they are due, at least occasionally. You probably try to work harder if you think \nyour grades are lower than you desire and take more time off when you are sleep- \ndeprived and your energy level falls. There are two basic policies you can follow: \n(1) The ant strategy-never put off until tomorrow what you can do today; or \n(2) the grasshopper strategy-never do today what can be put off until tomorrow. \nThe ant works steadily throughout the semester as work is assigned and never \nbuilds up a large backlog of assignments. As a result, the ant avoids the end of se- \nmester crunch, keeps the workweek under control, and is able to stay well rested. \nBecause the ant get",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 182
  },
  {
    "child_id": "9c1cbe45-a5bf-442a-913c-edecb9188b3f",
    "parent_id": "a290512b-c7b3-4b8e-9038-e4dd2cc196e6",
    "text": " and your energy level falls. There are two basic policies you can follow: \n(1) The ant strategy-never put off until tomorrow what you can do today; or \n(2) the grasshopper strategy-never do today what can be put off until tomorrow. \nThe ant works steadily throughout the semester as work is assigned and never \nbuilds up a large backlog of assignments. As a result, the ant avoids the end of se- \nmester crunch, keeps the workweek under control, and is able to stay well rested. \nBecause the ant gets enough sleep, productivity is high, and the ant has plenty of\n\n160 \nPart I1 Tools for Systems Thinking \ntime to participate in outside activities. The ant\u2019s grades improve steadily through- \nout the term. \nThe grasshopper, in contrast, defers the work until the last minute. The \ngrasshopper\u2019s workweek is low at the beginning of the term, providing lots of time \nfor parties and outside activities. The grasshopper can stay reasonably well rested \ndespite a heavy social schedule because the workweek is low. But because the \ngrasshopper doesn\u2019t do the work as fast as it is assigned, the assignment backlog \nsteadily builds up. Eventually, it\u2019s crunch time, and the grasshopper starts putting \nin long hours, perhaps pulling a few all-nighters. Unfortunately, as sleep suffers, \nenergy and productivity fall. The rate and quality of work suffers. Grades plummet, \nand the term ends before the grasshopper can finish all the work, perhaps leading \nthe grasshopper to plead for extensions from the faculty. \n5.4.2 \nIdentifying Key Variables \nThe description above suggests several variables important in a model of student \nworkload management (units of measure are given in parentheses): \nAssignment rate: the rate at which professors assign work throughout the \nterm (taskdweek). \nWork completion rate: the rate at which tasks are completed (taskdweek). \nAssignment backlog: the number of tasks that have been assigned but not \nyet completed (tasks). \nGrades: the grade received for work handed in (0-100 scale). \nWorkweek: the number of hours spent on academic work, including \nclasses, reading, homework, projects, etc. (hourdweek). \nEnergy level: measures how well rested the student is. Arbitrary scale from \n0-100% where 100% = fully rested and 0 = comatose). \nOther variables could be added, but this set provides a reasonable starting point for \nconceptualization of the feedback structure governing the dynamics. As you pro- \nceed, you may find you need to revise the list. \n5.4.3 Developing the Reference Mode \nFigure 5- 19 translates the written descriptions of the ant\u2019s behavior into graphical \nform (Figure 5-20 shows the grasshopper strategy). These graphs constitute the ref- \nerence mode characterizing the problem. Some items to note: \n1. The time horizon is explicitly stated. Here, the semester is 13 weeks long. \n2. Several different graphs are used to avoid clutter. The time axes of each \ngraph are aligned so that the timing of events can be directly compared. \n3. Variable",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 182
  },
  {
    "child_id": "1d6619d3-09ca-489e-a650-a37575777c45",
    "parent_id": "a290512b-c7b3-4b8e-9038-e4dd2cc196e6",
    "text": "ing the Reference Mode \nFigure 5- 19 translates the written descriptions of the ant\u2019s behavior into graphical \nform (Figure 5-20 shows the grasshopper strategy). These graphs constitute the ref- \nerence mode characterizing the problem. Some items to note: \n1. The time horizon is explicitly stated. Here, the semester is 13 weeks long. \n2. Several different graphs are used to avoid clutter. The time axes of each \ngraph are aligned so that the timing of events can be directly compared. \n3. Variables with the same units are plotted on the same axis. For example, the \nassignment and completion rates are both measured in taskdweek and are \nplotted together. \n4. You don\u2019t need quantitative data to capture the dynamics in the reference \nmodes. When numerical data are unavailable you should estimate the\n\nChapter 5 \nCausal Loop Diagrams \n161 \nFIGURE 5-1 9 \nReference mode \nfor the ant strat\u2019egy \nAssignment Rate \nWork Completion Rate \n0 \nTime (weeks of the semester) \n13 \nAssignment Bac..log \n0 \nTime (weeks of the semester) \n13 \n100 \nh \n___--- \ng \n/------ \nO\nh\n \nGrades \ng g  \n/------ \nU \n- &  \nQ ) u  \n__ _-_____ - \n\\I \n0 \nTime (weeks of the semester) \n13- \nbehavior of the variables from the written description and other qualitative \ninformation. Scales and rough magnitudes are provided where possible, as \nthey are for the workweek, grades, and energy level. Of course, when \nquantitative data are available, they should be used. But don\u2019t omit \nimportant variables simply because they haven\u2019t been measured yet or \nbecause the data aren\u2019t readily available. An important goal of the modeling",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 182
  },
  {
    "child_id": "245ef54b-c694-4792-ac0f-35d2052c19ba",
    "parent_id": "ac3f264b-2115-4c74-945f-1060493be1a7",
    "text": "162 \nPart I1 Tools for Systems Thinking \nFIGURE 5-20 \nReference \nmode for the \ngrasshopper \nstrategy \n0 \nTime (weeks of the semester) \n13 \n0 \nTime (weeks of the semester) \n13 \n100 \nn \nY \n8 \n8 3 \nE \nG \nGrades \n3 \nE \n0\n\u2019\n \n\\ \n3 ----------_I----- \n----- I_ \n_____\nY \nQ, \nQ, \nP \n13 \n0 \nTime (weeks of the semester) \nprocess is the identification of variables that should be measured so the \nnecessary empirical work can be done. \n5. There should be a basis in the data (numerical or written) for each feature of \nthe reference mode. For example, the graph of the ant\u2019s grades rises because \nthe description of the ant strategy states that the ant\u2019s grades improve \nsteadily throughout the term. Likewise, for the grasshopper the \u201cterm ends\n\nChapter 5 Causal Loop Diagrams \n163 \nbefore the grasshopper can finish all the work\" so the assignment backlog, \nthough falling, remains positive even as the term ends. \n6. The magnitudes and timing of variables should be consistent with your \nknowledge of the system even if the description available does not specify \nthese features. Details matter. For example, consider the grasshopper \nstrategy. The work completion rate must depend on the student's work \neffort (workweek), so these move together. However, because energy and \nproductivity are falling at the end, the completion rate does not rise as much \nas the workweek during the end of semester crunch. To make this even \nmore obvious, you might define the variable Productivity explicitly (try \nsketching its dynamics from the description above). \n7. Make sure your graphs are consistent with any stock and flow relationships \namong the variables. Since the assignment backlog accumulates the rate of \nassignments less the rate of work completion, it must be rising whenever \nthe assignment rate exceeds the completion rate, and vice versa. The \nrelationship between the backlog and its flows is most clearly seen in \nthe grasshopper strategy. Until week 10, the assignment rate exceeds the \ncompletion rate, so the backlog builds up. At week 10, the grasshopper \nis handing in work just as fast as new work is assigned, and the backlog \nreaches its peak. After week 10, the completion rate exceeds the assignment \nrate and the backlog falls. \n5.4.4 \nDeveloping the Causal Diagrams \nNext you must use the description of the system and reference modes to develop a \ncausal map of the feedback processes you believe are responsible for the dynamics. \nConsider Figure 5-21. The Assignment Rate is assumed to be exogenous: Once \na student has signed up for a set of courses, the assignment rate is determined. \nClasses can sometimes be dropped, but this possibility is ignored for now. The As- \nsignment Backlog is increased by the Assignment Rate and decreased by the Com- \npletion Rate. Completion Rate (taskdweek) is Workweek (hours per week) times \nProductivity (tasks completed per hour of effort) times the Effort Devoted to As- \nsignments. Effort Devoted to Assignments is the effort put in by the ",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 187
  },
  {
    "child_id": "4154d9b8-ec48-4a34-8ad7-ea6fe0862606",
    "parent_id": "ac3f264b-2115-4c74-945f-1060493be1a7",
    "text": " to be exogenous: Once \na student has signed up for a set of courses, the assignment rate is determined. \nClasses can sometimes be dropped, but this possibility is ignored for now. The As- \nsignment Backlog is increased by the Assignment Rate and decreased by the Com- \npletion Rate. Completion Rate (taskdweek) is Workweek (hours per week) times \nProductivity (tasks completed per hour of effort) times the Effort Devoted to As- \nsignments. Effort Devoted to Assignments is the effort put in by the student com- \npared to the effort required to complete the assignment with high quality. If work \npressure is high, the student may choose to cut corners, skim some reading, skip \nclasses, or give less complete answers to the questions in assignments. For exam- \nple, if a student works 50 hours per week and can do one task per hour with high \nquality but only does half the work each assignment requires for a good job, then \nthe completion rate would be (50)( 1)(.5) = 25 task equivalents per week. \nWork Pressure determines the workweek and effort devoted to assignments. \nWork pressure depends on the assignment backlog and the Time Remaining to \ncomplete the work: The bigger the backlog or the less time remaining, the higher \nthe workweek needs to be to complete the work on time. Time remaining is of \ncourse simply the difference between the Due Date and the current Calendar Time. \nThe two most basic options available to a student faced with high work pressure \nare to (1) work longer hours, thus increasing the completion rate and reducing the\n\n164 \nPart I1 Tools for Systems Thinking \nFIGURE 5-21 \nBasic control loops for the assignment backlog \nWork \nCompletion + \n* \nAssign men t \nRate \nAssignment \nBacklog \nC a I e n d a r \nTime \\ \nCutting \nEffort Devoted \nProductivity \nc \nTime \\ \nWork \nPressure \n\\to \nAssignments \nDue \nDate \nMidnight \nOil \nbacklog (the Midnight Oil loop B l), or (2) work faster by spending less time on \neach task, speeding the completion rate and reducing the backlog (the Corner Cut- \nting loop B2). Both are negative feedbacks whose goal is to reduce work pressure \nto a tolerable level. \nHowever, each of these negative feedbacks has side effects. Consider Figure \n5-22. Sustained high workweeks cut into sleep and the satisfaction of other needs \n(eating, exercise, human companionship, etc.), causing the student\u2019s Energy Level \nto fall. As energy level falls, so too do concentration and focus. Errors rise. Pro- \nductivity drops, reducing the completion rate-a tired student must spend longer \nthan a well-rested one to complete a task with a given level of quality. As the com- \npletion rate falls, the backlog remains higher than it would otherwise be and work \npressure intensifies, leading to still higher workweeks and still lower energy and \nproductivity. If the self-reinforcing Burnout loop, R1, dominates the balancing \nMidnight Oil loop, an increase in workweek would actually lower the completion \nrate as the extra hours are more than offset b",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 187
  },
  {
    "child_id": "d926b38f-83c6-491c-8a01-236ae7be8c3b",
    "parent_id": "ac3f264b-2115-4c74-945f-1060493be1a7",
    "text": "ate-a tired student must spend longer \nthan a well-rested one to complete a task with a given level of quality. As the com- \npletion rate falls, the backlog remains higher than it would otherwise be and work \npressure intensifies, leading to still higher workweeks and still lower energy and \nproductivity. If the self-reinforcing Burnout loop, R1, dominates the balancing \nMidnight Oil loop, an increase in workweek would actually lower the completion \nrate as the extra hours are more than offset by the increase in errors and reduction \nin productivity. \nReducing the effort devoted to each assignment also has side effects. Putting \nless effort into each task does allow assignments to be completed in less time \nbut reduces the Quality of Work, lowering the student\u2019s Grades. When grades fall\n\nChapter 5 \nCausal Loop Diagrams \n165 \nFIGURE 5-22 The burnout loop \nWork \nCompletion + \n3 \nAssignment \nRate \nAssign men t \nCalendar \nTime -x \nEffort Devoted \nProductivity \n+ \nTime \nP m a i n i n g  \\ \nWork \n/ \nPressure \nDue \nDate \nBurnout \nrelative to the student\u2019s aspirations, there is pressure to boost the effort put into \neach task. The negative Quality Control loop B3 prevents effort and quality from \nfalling too far even when work pressure is high (Figure 5-23). However, the effort \nto maintain quality also creates an insidious positive feedback. As work pressure \nforces the workweek up, energy level eventually falls (note the delay), reducing \ngrades. The student responds by increasing the effort put into each task in an at- \ntempt to boost grades back up through the quality control loop. But increasing the \ntime spent on each task lowers the completion rate. The backlog of work rises, in- \ntensifying work pressure and leading to still more overtime, still lower energy, and \nstill lower grades. When the exhausted student is Too Tired to Think, the positive \nloop R2 operates as a vicious cycle-efforts to boost grades only succeed in creat- \ning more work pressure, longer hours, even lower energy, and still lower quality \nwork. \nYou may wonder why anyone would keep working when their efforts not only \nyielded diminishing returns but negative returns. Wouldn\u2019t the grasshoppers real- \nize their efforts were actually counterproductive? It is precisely when people \nare exhausted that their judgment is most impaired. How many times have you \ncontinued to work on a project when, at least in retrospect, you should have called \nit a day?\n\n166 \nPart I1 Tools for Systems Thinking \nFIGURE 5-23 The \u201ctoo tired to think\u2019 loop \nWork \nCompletion + \n- \nAssignment \nRate \nAssignment \nCalendar \nTime \\ \nF \nWork \nTime \nRemaining \nDue \nDate \nIf all else fails, the exhausted student can appeal to the faculty for relief, gen- \nerating Requests for Extensions (Figure 5-24). Usually, such requests are accom- \npanied by stories of bad luck and hardship beyond the student\u2019s control: \u201cMy dog \nate my homework,\u201d \u201cMy hard disk crashed,\u201d \u201cMy roommate had a nervous break- \ndown.\u201d If the facult",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 187
  },
  {
    "child_id": "c9ce9950-6015-4803-8a9c-106783ea29e8",
    "parent_id": "ac3f264b-2115-4c74-945f-1060493be1a7",
    "text": "g \nFIGURE 5-23 The \u201ctoo tired to think\u2019 loop \nWork \nCompletion + \n- \nAssignment \nRate \nAssignment \nCalendar \nTime \\ \nF \nWork \nTime \nRemaining \nDue \nDate \nIf all else fails, the exhausted student can appeal to the faculty for relief, gen- \nerating Requests for Extensions (Figure 5-24). Usually, such requests are accom- \npanied by stories of bad luck and hardship beyond the student\u2019s control: \u201cMy dog \nate my homework,\u201d \u201cMy hard disk crashed,\u201d \u201cMy roommate had a nervous break- \ndown.\u201d If the faculty are moved by these tales of tragedy and woe (a big if), the \ndue date is slipped, making more time available and reducing work pressure. Be- \ncause faculty rarely give extensions unless there are genuine extenuating circum- \nstances, the negative My Dog Ate My Homework loop B4 is quite weak. Note that \nslipping the deadline, because it lowers work pressure, may actually cause the \nworkweek to fall and the effort devoted to each assignment to rise, both reducing \nthe completion rate and causing work pressure to build up again. These feedbacks \nare responsible for Parkinson\u2019s (1957) famous law: \u201cWork expands to fill the time \navailable for its completion.\u201d \nWhile there are many other loops you could add to the framework, these six \nfeedbacks jointly explain most of the dynamics created by the ant and grasshopper \nstrategies. \n5.4.5 Limitations of the Causal Diagram \nCausal diagrams can never be comprehensive (and you shouldn\u2019t try: modeling is \nthe art of simplification). They are also never final, but always provisional. The\n\nChapter 5 Causal Loop Diagrams \n167 \nFIGURE 5-24 My dog ate my homework-Parkinson's Law 7 \nWork \nCompletion + \n3 \nAssignment \nRate \nAssignment \nCalendar \nMy Dog Ate \nMy Homework \nDate \nmaps evolve as your understanding improves and as the purpose of the modeling \neffort evolves. The account of workload management above is far from perfect. \nHere are some issues to consider: \nFirst, the diagram does not distinguish between stocks and flows. In particular, \nit would be helpful to show the stock and flow structure of the assignment backlog. \nWhat other variables in this model are stocks? \nSecond, some loops could be specified in more detail. For example, the qual- \nity control loop assumes that effort increases when grades fall relative to the stu- \ndent's aspirations. It would be clearer to specify those aspirations explicitly, for \nexample, by creating a variable Desired Grade Point Average (GPA). Effort would \nthen be affected by the student's Satisfaction with Grades, which measures the gap \nbetween desired and actual grades. An explicit goal for grades makes it easier to \nexplore the dynamics for students with different aspirations and attitudes about the \nimportance of grades. Making the goal explicit also motivates questions such as \nWhat determines aspirations for academic achievement?-that is, what feedback \nprocesses might cause the desired GPA to vary over time? \nA variety of pressures for achievement, external to the workloa",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 187
  },
  {
    "child_id": "ef3a821c-95ed-4914-9ea3-c4c81e9de92e",
    "parent_id": "ac3f264b-2115-4c74-945f-1060493be1a7",
    "text": " Satisfaction with Grades, which measures the gap \nbetween desired and actual grades. An explicit goal for grades makes it easier to \nexplore the dynamics for students with different aspirations and attitudes about the \nimportance of grades. Making the goal explicit also motivates questions such as \nWhat determines aspirations for academic achievement?-that is, what feedback \nprocesses might cause the desired GPA to vary over time? \nA variety of pressures for achievement, external to the workload management \nmodel, put upward pressure on grade aspirations. Such pressures arise from obser- \nvations of the grades your peers receive (or claim to have received), from parents,",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 187
  },
  {
    "child_id": "d9163197-1f97-4709-b599-5e48a0ba51d3",
    "parent_id": "b7b30ae0-f801-4e04-86ed-211edcb9eea6",
    "text": "168 \nPart I1 Tools for Systems Thinking \nFIGURE 5-25 \nMaking the goal of \na loop explicit \nAdding the desired \nGPA and its \ndeterminants. \nCHALLENGE \nWork Pressure \nI- \nEffort Devoted \nto Assignments \\ \nQuality Control \nSatisfaction \n@ \nwith Grades \nGoal Erosion \nGrades \nQuality of \nWork \n+ \nDesired \nGPA \nPressure for \nAchievement \nEnergy Level \n+ \nor from the (perceived) requirements of future employers or graduate school ad- \nmissions officers. Figure 5-25 shows another important determinant of student \ngoals: Aspirations adjust to past actual achievement, forming the negative Goal \nErosion loop. Many people judge what is possible, at least in part, from what has \nbeen achieved. Eroding your goals in the face of a persistent discrepancy between \naspiration and achievement is a common way to reduce what Festinger (1957) \ncalled \u201ccognitive dissonance\u201d and has been amply documented in many situations. \nThe goal erosion loop can be an important learning process or may create a harm- \nful self-fulfilling prophecy. For example, most students admitted to elite universi- \nties were at the top of their high school class. Once enrolled in the Ivy League or \nMIT, however, half of them will be in the bottom half of their class. The adjust- \nment of grade aspirations to a new situation prevents perpetual disappointment, \nstress, and self-doubt. On the other hand, overly flexible goals can lead to under- \nachievement. Some grasshoppers, reflecting on how much midnight oil they \nburned at the end of the term and the disappointing grades those hours led to, may \nconclude they aren\u2019t A or even B students and lower their aspirations to relieve the \ndissonance between expectations and achievement. Sadly, this lesson may be en- \ntirely erroneous: Fewer hours of effort, if they were well rested, may easily have \nled to higher grades. \nPolicy Analysis with Causal Diagrams \nThe boundary of the student workload model could be extended to include many \nother feedback processes. Modify the student workload diagram to include the \nfollowing issues: \n1. Dropping classes in response to high work pressure, low grades, or low energy. \n2. Drinking coffee or taking stimulants to stay awake when energy level is low.\n\nChapter 5 \nCausal Loop Diagrams \n169 \n3. Cheating on assignments to boost the completion rate and raise grades. \n4. Other loops you believe to be important. \nAs you expand the boundary of the model, ask yourself Does the ability of the \nmodel to explain the dynamics change? Does the response of the model to policies \nchange? Are the conclusions of the earlier analysis robust to changes in the bound- \nary of the model? \n5.5 \nADAM SMITH\u2019S INVISIBLE HAND AND THE \nFEEDBACK STRUCTURE OF MARKETS \nAdam Smith\u2019s invisible hand is one of the most famous metaphors in the English \nlanguage. Smith realized that a free market creates powerful negative feedback \nloops that cause prices and profits to be self-regulating. While Smith lacked mod- \nem tools such as causal diagrams an",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 193
  },
  {
    "child_id": "55026e0a-ab2d-4eb8-b3c6-28b4aeb14966",
    "parent_id": "b7b30ae0-f801-4e04-86ed-211edcb9eea6",
    "text": "Does the response of the model to policies \nchange? Are the conclusions of the earlier analysis robust to changes in the bound- \nary of the model? \n5.5 \nADAM SMITH\u2019S INVISIBLE HAND AND THE \nFEEDBACK STRUCTURE OF MARKETS \nAdam Smith\u2019s invisible hand is one of the most famous metaphors in the English \nlanguage. Smith realized that a free market creates powerful negative feedback \nloops that cause prices and profits to be self-regulating. While Smith lacked mod- \nem tools such as causal diagrams and simulation models, the feedback loops in his \ndescription of the functioning of markets are clear. In The Wealth ofNations Smith \nargued that for any commodity there was a \u201cnatural\u201d price which is just \u201csufficient \nto pay the rent of the land, the wages of the labour, and the profits of the [capital] \nstock employed in raising, preparing, and bringing [the commodity] to market . . .\u201d \nAt the natural price, a \u201ccommodity is then sold precisely for what it is worth, or for \nwhat it really costs the person who brings it to market . . .\u201d In contrast, the actual \nmarket price \u201cmay either be above, or below, or exactly the same with its natural \nprice\u201d-that is, markets may at any time be out of equilibrium. \nSmith then noted how prices respond to the balance between demand and \nsupply: \nThe market price of every particular commodity is regulated by the proportion \nbetween the quantity which is actually brought to market, and the demand of those \nwho are willing to pay the natural price of the commodity . . . When the quantity of \nany commodity which is brought to market falls short of the effectual demand, all \nthose who are willing to pay the whole value . . . cannot be supplied with the quan- \ntity which they want. Rather than want it altogether, some of them will be willing \nto give more. A competition will immediately begin among them, and the market \nprice will rise more or less above the natural price. \nSimilarly, when supply exceeds demand, \u201c[tlhe market price will sink more or less \nbelow the natural price.\u201d \nBut supply in turn responds to the market price: \nIf. . . the quantity brought to market should at any time fall short of the effectual \ndemand, some of the component parts of its price must rise above their natural rate. \nIf it is rent, the interest of all other landlords will naturally prompt them to prepare \nmore land for the raising of this commodity; if it is wages or profit, the interest of \nall other labourers and dealers will soon prompt them to employ more labour and \nstock in preparing and bringing it to market. The quantity brought thither will soon \nbe sufficient to supply the effectual demand. All the different parts of its price will \nsoon sink to their natural rate, and the whole price to its natural price.\n\n170 \nFIGURE 5-26 \nThe invisible hand: \nthe feedback \nstructure of \nmarkets \nDemand responds \nto the relative \nvalue of the com- \nmodity compared \nto substitutes; \nhigher relative \nvalue increases \ndemand, bidding \nprices up and \n",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 193
  },
  {
    "child_id": "5af91ef6-a3b7-4682-bdc4-a31cee59ce63",
    "parent_id": "b7b30ae0-f801-4e04-86ed-211edcb9eea6",
    "text": "oy more labour and \nstock in preparing and bringing it to market. The quantity brought thither will soon \nbe sufficient to supply the effectual demand. All the different parts of its price will \nsoon sink to their natural rate, and the whole price to its natural price.\n\n170 \nFIGURE 5-26 \nThe invisible hand: \nthe feedback \nstructure of \nmarkets \nDemand responds \nto the relative \nvalue of the com- \nmodity compared \nto substitutes; \nhigher relative \nvalue increases \ndemand, bidding \nprices up and \nlowering relative \nvalue. Supply \nexpands when \nprofits rise; profit \ndepends on price \nrelative to pro- \nduction costs \nincludina the re- \n\u201c \nquired return on \ncapital. Greater \nsupply bids prices \ndown, lowering \nprofits. The price \nof substitutes and \nthe cost of produc- \ntion determine \nwhat Adam Smith \ncalled the \u201cnatural \nprice\u201d of the com- \nmodity-the equi- \nlibrium price at \nwhich supply and \ndemand are equal. \nPart I1 Tools for Systems Thinking \n+ \nDemand \nPrice of \nSubstitutes \\i / \nRelative \n+ f  \nProfits \ncost of \nProduction \nA simple representation of the feedback structure Smith describes is shown in Fig- \nure 5-26. When the price of a commodity rises above the natural price, fewer buy- \ners \u201cwill be willing to give more\u201d and more will be forced to \u201cwant it altogether.\u201d \nThat is, as price rises relative to the price of substitutes, including all substitute \nuses for the funds available to the buyer, consumers will seek substitutes or find \nthemselves simply priced out of the market. As demand falls prices will be bid \ndown, forming a negative loop. At the same time, higher prices increase the profit \nsuppliers can realize, which attracts new entrants to the market and encourages \nexisting producers to increase output. As the supply increases, prices are bid down- \nwards. These two negative feedback loops cause price to adjust until, in the ab- \nsence of further external shocks, the market reaches equilibrium, with production \nequal to consumption and price equal to its natural level. Smith concludes: \nThe natural price, therefore, is, as it were, the central price, to which the prices of \nall commodities are continually gravitating. Different accidents may sometimes \nkeep them suspended a good deal above it, and sometimes force them down even \nsomewhat below it. But whatever may be the obstacles which hinder them from \nsettling in this centre of repose and continuance, they are constantly tending \ntowards it. \nSmith\u2019s great insight was to realize that when prices rise above the natural level, \nproducers who seek to maximize their own gain will continue to enter the market \nuntil the price is bid down to the point where the return on their capital is no higher \n(today we would add \u201con a risk adjusted basis\u201d) than that available elsewhere, re- \nsulting in competitive prices and an efficient allocation of resources throughout so- \nciety. He famously concludes: \nEvery individual endeavors to employ his capital so that its produce may be of \ngreat",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 193
  },
  {
    "child_id": "b6500247-cca8-46fb-80ba-1fba195a296e",
    "parent_id": "b7b30ae0-f801-4e04-86ed-211edcb9eea6",
    "text": "when prices rise above the natural level, \nproducers who seek to maximize their own gain will continue to enter the market \nuntil the price is bid down to the point where the return on their capital is no higher \n(today we would add \u201con a risk adjusted basis\u201d) than that available elsewhere, re- \nsulting in competitive prices and an efficient allocation of resources throughout so- \nciety. He famously concludes: \nEvery individual endeavors to employ his capital so that its produce may be of \ngreatest value. He generally neither intends to promote the public interest, nor \nknows how much he is promoting it. He intends only his own security, only his \nown gain. And he is in this led by an invisible hand to promote an end which was \nno part of his intention. By pursuing his own interest he frequently promotes that of \nsociety more effectually than when he really intends to promote it.",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 193
  },
  {
    "child_id": "2fb3bac7-8c94-4b1f-ac3f-0f2924c3e0fb",
    "parent_id": "137fffb7-8a97-4bf2-8d73-faf90da2ab4c",
    "text": "Chapter 5 Causal Loop Diagrams \n171 \nSmith was thus one of the first systems thinkers to show how the local, intendedly \nrational self-interested behavior of individual people could, through the feedback \nprocesses created by their interactions, lead to unanticipated side effects for all. \nOf course, Smith\u2019s concept of the invisible hand is far more famous as the \ncredo of modern free market capitalism. It is the core of the faith that markets \nknow best. Smith himself, however, was careful to note the limits of the market \nfeedbacks in equilibrating demand and supply at the natural price. \u201cThis at least \nwould be the case\u201d Smith notes, \u201cwhere there was perfect liberty\u201d-that is, under \nconditions of perfect competition (free entry and exit, free mobility of the factors \nof production, and free exchange of information on demand, supply, costs, and \nprofits). Where there are monopolies, trade secrets, government regulations, barri- \ners to trade, restrictions on immigration and capital mobility, or other feedbacks \noutside the simple negative loops coupling supply and demand, Smith notes that \nprices and profits may rise above the natural level for many years, even decades. \nThe feedback structure for competitive markets shown in Figure 5-26 is quite \nuseful. Beginning with the general framework, one can disaggregate to show the \nspecific adjustment processes at work in any particular market for both demand \nand supply. Additional feedbacks besides the demand and supply loops can be \nadded, both positive and negative, and their implications assessed. The time de- \nlays, if any, in the reaction of demand and supply to higher prices can be estimated, \nand the implications for the stability of the market explored. If either the demand \nor supply loop operates strongly and swiftly (high short-run elasticities), then the \nmarket will rapidly return to equilibrium if perturbed. However, if there are long \ndelays or weak responses in the loops (low short-run elasticity and high long-run \nelasticity), then the market will be prone to persistent disequilibrium and instabil- \nity; random shocks in demand or production will excite the latent oscillatory be- \nhavior of the market (see chapters 4 and 20). \nNot all markets clear through price alone. Few products are pure commodities \nfor which price is the only consideration: Products and services are increasingly \ndifferentiated and companies compete to offer the best availability, delivery relia- \nbility, service, functionality, terms of payment, aftermarket support, and so on. In \nmany markets prices do not change fast enough to equilibrate supply and demand \nand other competitive variables such as availability become important in clearing \nthe market. Prices may be sluggish due to government regulation, the costs and ad- \nministrative burden of frequent price changes, or considerations of fairness. For \nexample, most people consider it unfair for hardware stores to raise the price of \nsnow shovels after a st",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 196
  },
  {
    "child_id": "ce48fcb7-5e77-4554-93f7-3bff10cfabbf",
    "parent_id": "137fffb7-8a97-4bf2-8d73-faf90da2ab4c",
    "text": "ionality, terms of payment, aftermarket support, and so on. In \nmany markets prices do not change fast enough to equilibrate supply and demand \nand other competitive variables such as availability become important in clearing \nthe market. Prices may be sluggish due to government regulation, the costs and ad- \nministrative burden of frequent price changes, or considerations of fairness. For \nexample, most people consider it unfair for hardware stores to raise the price of \nsnow shovels after a storm, even though demand may have increased (see Kahne- \nman, Knetsch, and Thaler 1986; Thaler 1991). \nIn many institutional settings price does not mediate markets at all. Most \norganizations, for example, have no price-mediated markets for offices, parking \nspaces, senior management attention, and many other scarce resources. In these \ncases, supply and demand are still coupled via negative feedbacks, but resources \nare allocated on the basis of availability, politics, perceived fairness, lottery, \nor other administrative procedures. Figure 5-27 shows examples of non-price- \nmediated markets. In each case the feedback structure is a set of coupled negative \nloops which regulate the demand for and supply of a resource. As in the case of \nprice-mediated markets, there may be substantial delays in the adjustments, lead- \ning to persistent disequilibria.\n\n172 \nPart I1 Tools for Systems Thinking \nFIGURE 5-27 \nLeft: Availability is an important competitive variable in many product markets, and firms regulate \nproduction in response to inventory adequacy and delivery delay. \nRight: In service settings, higher service quality stimulates demand, but greater demand erodes service \nquality as waiting time increases, and accuracy, friendliness, and other experiential aspects of the \nservice encounter deteriorate. \nFeedback structure of non-price-mediated resource allocation systems \nProduct \nBacklog of \nAttractiveness @ Unfilled Orders \nProduct \nAvailability \n+ \nI \nDesired \nb \nI \n@ \nProduction \nInventory \n+ \n+ \nProduction \n+ Customer \n+ \nService \nRequests \nCustomer \nSatisfaction \n+ \nService \nService \n@ \nAdequacy \nResources \nof Service \nThe Oil Crises of the 1970s \nIn 1973 the first OPEC oil shock stunned the industrial world. Oil prices more than \ntripled in a matter of months as many Arab oil producers embargoed shipments to \nwestern nations to retaliate for their support of Israel in the Yom Kippur war. Many \nanalysts believed market forces would bring the price of oil back to pre-embargo \nlevels in a matter of months, or at most a year or two, as demand and supply re- \nacted. Instead, prices remained high, then rose even higher as Iranian production \nfell in the wake of the 1979 revolution. By the early 1980s, many analysts pre- \ndicted that oil prices were headed even higher and would never return to the low \nlevels of the early 1970s. But after reaching nearly $50 per barrel (in 1990 dollars), \nthe price of oil collapsed in the mid 1980s. Many oil exploration an",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 196
  },
  {
    "child_id": "78459484-a862-4186-a3ca-5588ae8d689e",
    "parent_id": "137fffb7-8a97-4bf2-8d73-faf90da2ab4c",
    "text": "to pre-embargo \nlevels in a matter of months, or at most a year or two, as demand and supply re- \nacted. Instead, prices remained high, then rose even higher as Iranian production \nfell in the wake of the 1979 revolution. By the early 1980s, many analysts pre- \ndicted that oil prices were headed even higher and would never return to the low \nlevels of the early 1970s. But after reaching nearly $50 per barrel (in 1990 dollars), \nthe price of oil collapsed in the mid 1980s. Many oil exploration and alternative \nenergy projects were canceled; bankruptcy was common. In the US, gasoline \nprices in real terms fell below their pre-embargo level-gasoline in the late 1990s \nwas often one-fourth the price of designer water. \nStarting with the basic market feedback structure (Figure 5-26), develop a \ncausal diagram to explain (1) the failure of market forces to bring prices back to \nequilibrium soon after the first oil shock (that is, How could prices remain so high \nso long?) and (2) why prices collapsed in the mid 1980s and remained below the \nequilibrium level for so long (that is, Why didn\u2019t prices stay high?). To help, Figure \n5-11 shows some of the causal links on the demand side of the market. Figure 3-4 \nshows US petroleum production, consumption, and real prices over the relevant\n\nChapter 5 Causal Loop Diagrams \n173 \ntime horizon. Keep your diagram simple and follow the guidelines for causal loop \ndiagrams. \nUse your diagram to sketch the pattern of behavior you would expect for the \nrate of oil production and the rate of drilling of new wells from 1970 to 1990. Also \nplot capacity utilization for both activities (that is, what fraction of existing wells \nare pumping, and what fraction of existing drill rigs are operating, at any given \ntime). What does your diagram suggest about the likely dynamics of the world oil \nprice over the next few decades? \nSpeculative Bubbles \nNot all markets consist of negative feedbacks alone. In many markets the locally \nrational behavior of individual entrepreneurs creates positive feedbacks as they in- \nteract with one another and with the physical structure of the system. One common \nexample is the speculative bubble. There have been many dozens of major specu- \nlative bubbles in the past few centuries, from the infamous tulip mania of 1636 and \nSouth Sea bubble of 1720 to the manias and crashes of the past few decades, in- \ncluding gold, silver, real estate, impressionist paintings, and internet stocks.2 \nJohn Stuart Mill distilled the essence of the dynamics of speculation in the fol- \nlowing passage from his famous text Principles of Political Economy, originally \npublished in 1848: \nWhen there is a general impression that the price of some commodity is likely to \nrise, from an extra demand, a short crop, obstructions to importation, or any other \ncause, there is a disposition among dealers to increase their stocks, in order to profit \nby the expected rise. This disposition tends in itself to produce the effect ",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 196
  },
  {
    "child_id": "82a16a49-b625-4411-ba22-7028e2815018",
    "parent_id": "137fffb7-8a97-4bf2-8d73-faf90da2ab4c",
    "text": "istilled the essence of the dynamics of speculation in the fol- \nlowing passage from his famous text Principles of Political Economy, originally \npublished in 1848: \nWhen there is a general impression that the price of some commodity is likely to \nrise, from an extra demand, a short crop, obstructions to importation, or any other \ncause, there is a disposition among dealers to increase their stocks, in order to profit \nby the expected rise. This disposition tends in itself to produce the effect which it \nlooks forward to, a rise of price: and if the rise is considerable and progressive, \nother speculators are attracted, who, so long as the price has not begun to fall, are \nwilling to believe that it will continue rising. These, by further purchases, produce a \nfurther advance: and thus a rise of price for which there were originally some ratio- \nnal grounds, is often heightened by merely speculative purchases, until it greatly \nexceeds what the original grounds will justify. After a time this begins to be per- \nceived; the price ceases to rise, and the holders, thinking it time to realize their \ngains, are anxious to sell. Then the price begins to decline: the holders rush into \nmarket to avoid a still greater loss, and, few being willing to buy in a falling mar- \nket, the price falls much more suddenly than it rose. \nDevelop a reference mode for Mill\u2019s description of a speculative bubble. Begin- \nning with the basic two-loop structure for a market (Figure 5-26), develop a causal \ndiagram grounded in Mill\u2019s text which explains the dynamics he describes. Explain \nbriefly how the feedback structure corresponds to Mill\u2019s description and how it ex- \nplains the behavior. Give examples of the phenomenon. \n2Perhaps the best treatment of speculative bubbles is Charles Kindleberger\u2019s (1978) Manias, \nPanics, and Crushes. See also Galbraith\u2019s (1988) The Great Crush on the 1929 stock market crash.\n\n174 \nPart I1 Tools for Systems Thinking \nThe Thoroughbred Horse Market \nFigure 5-28 shows the price of top yearling thoroughbreds in the US from 1965 \nthrough 1990. From 1974 to 1984 nominal prices for these elite horses increased \nby almost a factor of 10, to about $450,000. Even after removing the effects of in- \nflation, the real price of a top thoroughbred increased by more than a factor of 4. \nPrices then collapsed, falling by nearly 50% in just 4 years (in real terms). Adapt \nyour diagram of speculative bubbles to the thoroughbred horse market. Add suffi- \ncient detail to specify the particular biological and institutional features of the mar- \nket. For example, what are the motivations for owning a top race horse? (You can \nconsider a race horse to be an investment like a common stock, with an uncertain \nfuture payoff depending on the horse's performance on the track, but this is only \none of the reasons people own race horses, and expected cash flow rarely justifies \nsuch a risky investment). How is the supply of horses increased? What time delays \nare inv",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 196
  },
  {
    "child_id": "b2a8a1d5-0c4e-4e8d-af32-80312e54f621",
    "parent_id": "137fffb7-8a97-4bf2-8d73-faf90da2ab4c",
    "text": "l to specify the particular biological and institutional features of the mar- \nket. For example, what are the motivations for owning a top race horse? (You can \nconsider a race horse to be an investment like a common stock, with an uncertain \nfuture payoff depending on the horse's performance on the track, but this is only \none of the reasons people own race horses, and expected cash flow rarely justifies \nsuch a risky investment). How is the supply of horses increased? What time delays \nare involved? \nUse your causal diagram to explain the dynamics of the thoroughbred price \nduring the 1970s and 80s. Why did the market rise so dramatically? Why did it \ncrash even faster? In 1965 about 18,000 thoroughbreds were born in North Amer- \nica. Using your model, sketch the likely behavior of the birth rate of North Amer- \nican thoroughbreds through 1990. \n400- \n69 = 300- \nm \n3 \n+ \nc\" 200: \ni n n  \n1965 \n1970 \n1975 \n1980 \n1985 \n1 \n~ 990 \nSource: Hermann and Link (1990). \n5.5.1 \nMarket Fai I ure, Adverse Selection, \nand the Death Spiral \nMany real world markets are imperfect due to limitations of information, costs of \nentry and exit, and inflexibility of resources. These imperfections create feedbacks \nthat sometimes overwhelm the negative loops normally balancing supply and de- \nmand, leading to inefficiency or even the complete failure of the market. One \nsource of market failure is adverse selection. \nAdverse selection can arise when sellers and buyers in a market have different \ninformation. A classic example, first developed by Akerlof (1970), considers the",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 196
  },
  {
    "child_id": "74a5bd51-d494-40da-8286-fcd1e0d12bcf",
    "parent_id": "48196b9a-d0a4-419f-82c9-4551447a3f37",
    "text": "Chapter 5 Causal Loop Diagrams \n175 \nused car market. To illustrate how adverse selection works, Akerlof assumed that \nthe owners of used cars know the true quality of their cars while potential buyers \ndo not. At any given market price, owners, knowing the true quality of their cars, \nwill offer for sale only those cars actually worth less than the market price (the \n\u201clemons\u201d) while keeping any car actually worth more (the \u201cpeaches\u201d). Therefore, \nthe only cars offered for sale will be lemons. Potential buyers, realizing this, refuse \nto buy. Akerlof showed that in equilibrium no one will be willing to buy a used \ncar-the market will not exist, even though there are buyers and sellers who would \nbe willing to trade if both knew which were lemons and which were pea~hes.~ \nEach person, behaving rationally given the information available to them, causes \nan outcome undesirable for all. Akerlof\u2019s result was a breakthrough in economics. \nNot only did his model form the foundation for the important field of information \neconomics, a field of immense importance in economics today, but he also demon- \nstrated that the workings of free markets were not always benign, even without \nmonopoly power or collusive agreements among producers. Adam Smith cele- \nbrated market forces for creating an invisible hand leading individuals to \u201cpromote \nan end which was no part of [their] intention,\u201d an end which \u201cfrequently promotes \n[the interests] of society.\u201d Akerlof showed that rational self-interest could lead \nindividuals to promote, though unintentionally, an end harmful to the interests of \nsociety-and themselves. \nHowever, Akerlof\u2019s theory, like most economic models, is an equilibrium \nmodel and does not address the dynamics of the process. To examine the dynam- \nics of adverse selection in an important public policy context, consider the market \nfor health insurance. \nSince the 1950s, health care costs in the US have grown much faster than GDP \nand have long been the highest in the world, both in absolute expenditures per \ncapita and as a percent of national income. As costs rose, so too did health insur- \nance premiums. Federal programs such as Medicare (for the elderly) and Medicaid \n(for the poor) were created to provide a safety net for these groups. But rising \nhealth care costs soon outstripped federal benefits, and forced the elderly to seek \nprivate insurance to supplement Medicare. As the costs of private insurance rose, \nhowever, many were frozen out of the market. To prevent health care from bank- \nrupting them, many states required health insurers to offer so-called medigap in- \nsurance to senior citizens in return for the privilege of underwriting other business \nin their state. In Massachusetts, insurers were required to offer at least one medi- \ngap plan providing unlimited coverage for prescription drugs, one of the highest \ncosts for the elderly. At first, the program was very successful. In the 1980s, a wide \nrange of insurers offered medigap ",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 200
  },
  {
    "child_id": "10ef9436-d967-463a-b939-b90e835e481e",
    "parent_id": "48196b9a-d0a4-419f-82c9-4551447a3f37",
    "text": "ket. To prevent health care from bank- \nrupting them, many states required health insurers to offer so-called medigap in- \nsurance to senior citizens in return for the privilege of underwriting other business \nin their state. In Massachusetts, insurers were required to offer at least one medi- \ngap plan providing unlimited coverage for prescription drugs, one of the highest \ncosts for the elderly. At first, the program was very successful. In the 1980s, a wide \nrange of insurers offered medigap coverage in Massachusetts, capturing a large \nshare of the total senior citizen market. The largest program, Medex, offered by \n30f course, there is a used car market. Akerlof\u2019s assumption that buyers have no knowledge of \nquality was a simplifying assumption to make the example clear. The real used car market has \nevolved various means to prevent market failure. Buyers can gain some information on quality \nthrough test drives and by having their own mechanic look at the car, and regulations such as lemon \nlaws and implied warranty doctrine reduce the buyer\u2019s risk. Information on the past quality of cars \noffered by used car dealers deters some from selling lemons to unwitting buyers. The cost (in time \nand money) of these activities is a measure of the impact of the adverse selection problem in the \nused car market.\n\n176 \nPart I1 Tools for Systems Thinking \nBlue Cross/Blue Shield of Massachusetts, covered about one-third of all senior cit- \nizens in the state in 1987. Premiums were low, about $50/month. In the late 1980s, \nhealth care cost inflation accelerated, and underwriters had to raise premiums, in- \ncluding the premiums for medigap and Medex. In response, some of the elderly \nwere forced to drop their medigap coverage. Others found they could get lower \nrates with other carriers or by signing up for plans offering fewer benefits or which \ncapped benefits for items such as prescriptions. However, only the healthiest se- \nniors were eligible for these other, cheaper plans. The sickest of the elderly, those \nsuffering from chronic illnesses, those with a history putting them at high risk- \nthose with so-called pre-existing conditions-were not eligible for less expensive \ncoverage or health maintenance organizations (HMOs) and had no choice but to \nstay with medigap. In many cases, the cost of prescriptions alone for those elderly \ncovered by Medex exceeded their premiums by hundreds of dollars each year. As \nmedigap losses mounted, premiums grew. But higher premiums forced still more \nof the comparatively healthy elderly to opt out of medigap as they found coverage \nelsewhere or simply did without, bearing the risk of illness themselves. Those re- \nmaining with the plan were, on average, sicker and costlier, forcing premiums up \nfurther. Figure 5-29 shows the evolution of the Medex subscriber base and premi- \nums. Total subscribers fell from nearly 300,000 in 1988 to about 158,000 in 1997, \nwhile subscribers of the premium Medex Gold option, which pro",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 200
  },
  {
    "child_id": "f00aab24-03d6-4cd3-b96f-fad7d10eb526",
    "parent_id": "48196b9a-d0a4-419f-82c9-4551447a3f37",
    "text": "miums forced still more \nof the comparatively healthy elderly to opt out of medigap as they found coverage \nelsewhere or simply did without, bearing the risk of illness themselves. Those re- \nmaining with the plan were, on average, sicker and costlier, forcing premiums up \nfurther. Figure 5-29 shows the evolution of the Medex subscriber base and premi- \nums. Total subscribers fell from nearly 300,000 in 1988 to about 158,000 in 1997, \nwhile subscribers of the premium Medex Gold option, which provided unlimited \ncoverage for prescriptions, fell even faster, from about 250,000 in 1988 to about \n65,000 in 1997. Over the same 10 years premiums rose from about $50/month to \n$228/month, with further increases projected. As the customer base shrank and \nlosses grew, underwriters began to withdraw from the market. In the early 1990s \nhalf a dozen insurers wrote medigap coverage in Massachusetts; by 1997 only \nMedex remained. A consumer activist lamented, \u201cAs healthier people continue to \ndrop out and sicker people stay in, premiums continue to go up, and you create a \ndeath spiral.\u201d (Boston Globe, 20 January 1998, A12). \n1. Develop a causal loop diagram capturing the death spiral as depicted in \nsection 5.5.1. Your diagram should explain not only the dynamics of the \nsubscriber base and premiums, but also the profitability of the medigap \nmarket, the number of carriers offering coverage, and the health status of \nthose in the program. Note any important delays in your diagram. Use your \ndiagram to analyze the impact of the following policies: \na. Requiring all carriers doing business in the state to insure all qualified \napplicants, regardless of age or health. \nb. \nRequiring all medigap plans (all the versions of Medex) to provide \nunlimited coverage for prescription drugs. The goal is to pool healthier \nseniors who generally use fewer drugs and choose the less expensive \nMedex plans with the sicker seniors who use more drugs and opt for \nMedex Gold. \nProvide a subsidy to lower medigap premiums, funded by the state. \nc.\n\nChapter 5 \nCausal Loop Diagrams \n177 \nd. Allowing BC/BS to drop Medex, effectively eliminating all medigap \ncoverage in the state of Massachusetts. \nIn assessing the impact of the policies, consider their effects on the insurers, on \nthe elderly (insured and uninsured), and on society at large. \n2. What assumptions about information availability and consumer behavior \nunderlie the theory captured in your causal loop diagram of the health \ninsurance market? How might the validity of these assumptions be altered, \nfor example, by advances in information technology which might make a \nperson's entire health history available to insurers, or advances in genetic \nscreening which might reveal which people were at increased risk for the \ndevelopment of particular illnesses? \n3. What other examples of adverse selection can you identify? Map their \nfeedback structure. \ndeath spiral: subscribers and premiums for medigap insurance \nnsurance for th",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 200
  },
  {
    "child_id": "9c9ecc67-93ec-4f5a-963a-d2a70c495dbf",
    "parent_id": "48196b9a-d0a4-419f-82c9-4551447a3f37",
    "text": "ce market? How might the validity of these assumptions be altered, \nfor example, by advances in information technology which might make a \nperson's entire health history available to insurers, or advances in genetic \nscreening which might reveal which people were at increased risk for the \ndevelopment of particular illnesses? \n3. What other examples of adverse selection can you identify? Map their \nfeedback structure. \ndeath spiral: subscribers and premiums for medigap insurance \nnsurance for the elderly offered by Blue Cross/Blue Shield of Massachusetts. \nunlimited prescription drugs with a small copayment. Other Medex plans limit total \ne for December 1 of each year. * indicates proposed rate for 1998 of $278/month. \nuuscriuers \n* \n,:\" - 250 \n200 \n-150 \n5 \n3 \n-100 3 \n- 50 \n-\nn\n \n\" \n1988 1989 1990 1991 1992 1993 1994 1995 1996 1997 \nSource: Boston Globe, 20 January 1998, A1 \n5.6 \nEX P [.AI N I NG Po L I CY R ES I STAN c E : TR A FFI c CON G ESTI o N \nBy showing the network of feedback loops in which policies are embedded, causal \ndiagrams are often an effective way to show how event-oriented, open-loop men- \ntal models lead to policy resistance. Consider the problem of traffic congestion. \nAmerica's roads are choked with traffic. In 1995 there were nearly 200 million ve- \nhicles registered in the US. The 1990 census reported that about 100 million peo- \nple, 87% of all workers, traveled to work by motor vehicle, 85% of them alone. \nOnly 5% used public transportation. In 1960 64% commuted by motor vehicle. \nSince 1970 the number of registered vehicles grew by 70% and annual vehicle \nmiles grew by 90%, both much faster than the growth in population or households,\n\n178 \n3 \n2 -  \n1 -  \n0 -  \nPart I1 Tools for Systems Thinking \n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n \n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n.\n \n, \nI\nS\n I \nFIGURE 5-30 \nMore roads, \nmore traffic \nwhile public transportation stagnated (Figure 5-30). More and more of the average \nperson's day is spent inside a car: The government estimates Americans spend \n8 billion hours per year stuck in traffic. The cost of driving includes about $6000 \nper car per year in direct costs and up to another $9400 in indirect, externalized \ncosts. Estimates of lost productivity due to traffic congestion range from $43 to \n$168 billion per year. The economy and culture of the US (and of other auto-rich \nnations) have adapted themselves to the dominance of the auto, from the $40 bil- \nlion spent annually in the US to market automobiles to the rise of drive-through \nfast foods, especially foods you can eat with one hand (while the other steers). \nRoad rage is increasingly recognized as a common mental disorder, and frustrated \ndrivers have taken to shooting those who cut them off on the so-called freeway. \nWhat went wrong?4 \n5.6.1 \nMental Models of the Traffic Problem \nThe traditional solution to traffic jams and congestion has been road building. Fig",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 200
  },
  {
    "child_id": "dc0a00ec-4cd3-4c80-89e9-1009325b2458",
    "parent_id": "48196b9a-d0a4-419f-82c9-4551447a3f37",
    "text": " auto, from the $40 bil- \nlion spent annually in the US to market automobiles to the rise of drive-through \nfast foods, especially foods you can eat with one hand (while the other steers). \nRoad rage is increasingly recognized as a common mental disorder, and frustrated \ndrivers have taken to shooting those who cut them off on the so-called freeway. \nWhat went wrong?4 \n5.6.1 \nMental Models of the Traffic Problem \nThe traditional solution to traffic jams and congestion has been road building. Fig- \nure 5-3 1 shows the open-loop perspective on the problem: The problem is highway \ncongestion; the solution is to build more roads. \nTotal Passengers on US Public Transit Systems \nO\nS\nO i  ,\n.\n,\n.\n,\n.\n,\n,\n.\n,\n.\n.\n,\n.\n.\n.\n,\n.\n.\n,\n.\n.\n.\n.\n,\n.\n,\n.\n.\n,\n.\n.\n,\n,\n.\n,\n.\n.\n.\n~\n \n1920 \n1940 \n1960 \n1980 \n2000 \nSources: Historical Statistics of the US; Kurian (1994). \n4Some of these data appear in Kay (1997), whose book Asphalt Nation discusses a broad range \nof social, cultural, economic, and environmental effects of automobile addiction. See also Downs \n(1992), Hansen (1995), and Gibbs (1997).",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 200
  },
  {
    "child_id": "a1511311-f370-4e3d-93b2-c1c6765097a4",
    "parent_id": "456e8112-cbb7-4e1c-8809-6fba241fc932",
    "text": "Chapter 5 Causal Loop Diagrams \n179 \nFIGURE 5-31 \nOpen-loop view of \ntraffic congestion \nFIGURE 5-32 \nDeterminants of \ntravel time \nCongestion \nBuild New \nand Delays - \nRoads \nBut what happens when new roads are built? And where should you begin the \ndevelopment of a causal diagram to show the feedback effects of road construc- \ntion? It\u2019s usually best to begin by capturing the physical structure of the system. \nSystems consist of both a physical structure and the decision rules used by the peo- \nple in the system (the behavioral structure). The physical structure is often easier \nto visualize and represent than the decision-making structure. Additionally, con- \nceptualization is often part of a group process in which people must share their \nown mental models and reach agreement over a single representation. It is usually \neasier to gain agreement about the physical structure. The behavioral structure is \noften more controversial; if you start there your group process may grind to a halt \nbefore you\u2019ve really begun. \nA good place to start for the traffic congestion case is congestion itself. A good \nmodel requires a variable that has operational meaning and can be measured. One \ngood summary measure of congestion is average travel time (for the typical trip in \na particular region). What determines travel time? Travel time depends on the bal- \nance between the capacity of the highways to handle traffic and the number of ve- \nhicles using the roads, denoted Traffic Volume in Figure 5-32. \nAs the number of vehicles on the roads increases, given the highway capacity, \nthe average trip will take longer. As highway capacity rises, given the vehicle vol- \nume, the average travel time will fall. Highway capacity is altered by construction \nof new roads. Road construction here includes not only new roads but also im- \nprovements to existing roads such as adding lanes or increasing capacity by chang- \ning the flow of traffic, for example by converting a four-way intersection into a \ncloverleaf. Any project that augments the capacity of the roads to carry traffic \nwould be included in the notion of road construction, at least in this first version of \n+I \nHighway \nCapacity \nTraffic \nVolume\n\n180 \nPart I1 Tools for Systems Thinking \nFIGURE 5-33 \nCongestion \nleads to political \npressure to build \nmore roads, \nreducing con- \ngestion via the \nnegative Capacity \nExpansion \nfeedback. \nthe model (later you could disaggregate the construction of new roads from widen- \ning of existing roads, if that was deemed to be necessary for the purpose). Since \nhighway projects take time, the delay between the initiation of a construction proj- \nect and the increase in highway capacity is explicitly noted. \nWhen developing a causal map it is helpful to consider the units of measure for \nthe constructs in your diagram. Having consistent units is often a great aid to clear \nthinking about the definitions of and relationships among the variables. Specifying \nunits and checking f",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 204
  },
  {
    "child_id": "a1026b28-e53e-4c79-9c0e-60edbd03e67b",
    "parent_id": "456e8112-cbb7-4e1c-8809-6fba241fc932",
    "text": "f existing roads, if that was deemed to be necessary for the purpose). Since \nhighway projects take time, the delay between the initiation of a construction proj- \nect and the increase in highway capacity is explicitly noted. \nWhen developing a causal map it is helpful to consider the units of measure for \nthe constructs in your diagram. Having consistent units is often a great aid to clear \nthinking about the definitions of and relationships among the variables. Specifying \nunits and checking for dimensional consistency is useful even when your model is \npurely conceptual and you do not intend to develop a formal simulation. Travel \ntime would be measured in minutes per trip (for the average trip in the region). \nHighway Capacity and Traffic Volume are measured in vehicle-miles per day (a \nvehicle mile is one mile traveled by one vehicle). \nHaving specified the physical structure of road building and highway con- \nstruction, next ask what drives highway construction programs. The primary moti- \nvation is congestion: as travel time rises, as traffic jams become the norm, as the \nrush hour expands from dawn through dusk, political pressure to build will build. \nFigure 5-33 adds the link from travel time to road construction. \nCongestion creates pressure for new roads; after the new capacity is added, \ntravel time falls, relieving the pressure. The Capacity Expansion loop (B 1) acts to \nreduce travel time to acceptable levels. Note that the goal of the loop, the desired \ntravel time, has been made explicit. Desired travel time is the travel time driv- \ners consider acceptable (on average), perhaps 20 minutes for the commute from \nhome to work. The 1990 census found average one-way commuting times for all \nmodes and all workers of about 22 minutes, though more than 17 million people \nspent more than 40 minutes getting to work and nearly 2 million spent more than \n90 minutes. \nConstruction \nPressure to \nReduce \nCongestion \n+I \nHighway \nCapacity \nCapacity \nExpansion \nTraffic \nVolume\n\nChapter 5 Causal Loop Diagrams \n181 \n5.6.2 \nCompensating Feedback: \nThe Response to Decreased Congestion \nSo far traffic volume is considered to be exogenous. This assumption is an accu- \nrate reflection of the mental models of many politicians, city planners, and trans- \nportation officials, for whom traffic volume grows as the population of the region \ngrows and as the local economy develops. They see their job as building enough \nroads to keep travel time at the acceptable level, so political pressure stays low, so \nthey can be reelected, and so they can serve special interests such as construction \nfirms, real estate developers, and the business community who benefit from road \nbuilding and who often provide lucrative jobs for them when they leave office. \nIf the capacity expansion loop were the only feedback operating in the system, \nthen the policy of road building to relieve congestion would work well: whenever \ntraffic volume rose, leading to congestion and pressu",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 204
  },
  {
    "child_id": "bd02eb87-f412-4f50-8180-e926f1b52d64",
    "parent_id": "456e8112-cbb7-4e1c-8809-6fba241fc932",
    "text": ", so political pressure stays low, so \nthey can be reelected, and so they can serve special interests such as construction \nfirms, real estate developers, and the business community who benefit from road \nbuilding and who often provide lucrative jobs for them when they leave office. \nIf the capacity expansion loop were the only feedback operating in the system, \nthen the policy of road building to relieve congestion would work well: whenever \ntraffic volume rose, leading to congestion and pressure from the community, a road \nbuilding program would be started and highway capacity would expand until the \npressure was relieved. \nHowever, traffic volume is not exogenous. To formulate the causal structure \ndetermining traffic flow it is again helpful to consider the physics of the system \nand the units of measure for the variables. What determines the volume of traffic? \nTo have traffic, there must be. . . cars. No cars, no traffic. So the number of cars in \nthe region must be a determinant of traffic volume. Traffic volume is measured in \nvehicle-miles per day. Total traffic volume must therefore equal the number of \nvehicles in the region multiplied by the number of miles each vehicle travels per \nday. In turn, the number of miles each vehicle travels per day is the product of \nthe number of trips each vehicle makes per day and the length of each trip. Thus, \naveraging over the vehicle population, \nTraffic Volume = Vehicles * Average Trips per Day * Average Trip Length \nVehicle Milesmay = Vehicles * \nTripsDay \n* \nMilesnrip \nThe number of trips per day and the average trip length are not constant but de- \npend on the level of congestion. If traffic is light, people are more likely to take ad- \nditional and longer trips. When congestion is heavy, people will forego or defer \ntrips and make shorter trips, skipping that quick run to the video shop and buying \nwhat they need at the closest store rather going on to the mall. Likewise, the num- \nber of cars in the region is not constant. The number of vehicles in the region can \nbe thought of as the product of the population of the region and the number of cars \nper person: The more people in the region (and the more businesses), the more ve- \nhicles there will be. The number of vehicles per person or business in turn is not \nconstant but depends on the attractiveness of driving. The attractiveness of driving \ndepends on the level of congestion (Figure 5-34). \nAdding these relationships to the model closes three negative feedback loops, \nall of which act to increase congestion whenever new roads are built. Suppose new \nroads are built to relieve congestion. In the short run, travel time falls-the num- \nber of cars in the region hasn\u2019t changed and people\u2019s habits haven\u2019t adjusted to the \nnew, shorter travel times. As people notice that they can now get around much \nfaster than before, they will take more Discretionary Trips (loop B2). They will\n\n182 \nPart I1 Tools for Systems Thinking \nFIGURE 5-34 Traffic v",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 204
  },
  {
    "child_id": "87098fef-a5ff-4365-b993-8bc9856a2543",
    "parent_id": "456e8112-cbb7-4e1c-8809-6fba241fc932",
    "text": "ative feedback loops, \nall of which act to increase congestion whenever new roads are built. Suppose new \nroads are built to relieve congestion. In the short run, travel time falls-the num- \nber of cars in the region hasn\u2019t changed and people\u2019s habits haven\u2019t adjusted to the \nnew, shorter travel times. As people notice that they can now get around much \nfaster than before, they will take more Discretionary Trips (loop B2). They will\n\n182 \nPart I1 Tools for Systems Thinking \nFIGURE 5-34 Traffic volume depends on congestion, closing several negative loops that cause traffic \nto increase whenever new roads are built. \nCapacity \nExpansion \nConstruction \n+ \nPressure to \nReduce \nCongestion \nHighway \nCapacity \nDesired \n& \nAdequacy of \nTraffic \nAttractiveness \nPublic Transit \nDiscretionary \nTrips \nof Driving \n+ \nPublic \nTransit \nPopulation \nExtra Miles \nActivity of \nRegion \nand Economic \nAverage \nFare \nTake the \nBus? \nTrip Length + \n\\ \nTransit \nCars per /Ridership \n\\ \nCars in \nRegion \nPerson \n- \n+ \n+ \nalso travel Extra Miles (loop B3). Over time, seeing that driving is now much more \nattractive than other modes of transport such as the public transit system, some \npeople will give up the bus or subway and buy a car. The number of cars per per- \nson (and business) rises as people ask why they should Take the Bus? (loop B4). \nAll three of these loops compensate for any new road construction by increas- \ning traffic flow. But road construction stimulates other long-term feedbacks. The \npopulation of the region is not exogenous but is affected by the accessibility of the \noutlying districts. As the road network expands, as new freeways and ring roads \nlink the countryside with the center city, the size of the region within a reasonable \ntravel time grows. Of course, average travel time has a negative effect on the size \nof the accessible region: The greater the congestion, the smaller the radius accessi- \nble within, say, a 30-minute drive of the city (Figure 5-35). \nThe links to the population of the region close two more feedbacks. People be- \ngin to Move to the Suburbs (B5). As the population of the suburbs grows, the auto \npopulation rises as well. The roads begin to fill. Traffic volume grows further and\n\nChapter 5 Causal Loop Diagrams \n183 \nFIGURE 5-35 Reduced travel time and an expanded highway network increase the size of the region \naccessible from the center, which expands the population and leads to still more traffic. \nPressure to \nReduce \nCongestion \n+t\u2018 \nHighway \nCapacity \nCapacity \nExpansion \nDesired \nDiscretionary \n& \nAdequacy of \nSize of Regiion \nTraffic \nTrips \nPublic Transit \nwithin Desired \nof Driving \nTravel Time @ + \nPublic \nF\u2019opulation \nExtra Miles \nTransit \nActivity of \nRegion \nand Economic \nFare \nTake the \nAverage \nBus? \nTrip Length + \nTransit \nCars per /Ridership \nCars in \nRegion \nPerson \n- \n+ \n+ \ntravel time rises until the resulting congestion makes the suburbs sufficiently unat- \ntractive to stop further inmigration and developme",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 204
  },
  {
    "child_id": "0bebee3a-4e55-494c-9632-12f0218bbd07",
    "parent_id": "456e8112-cbb7-4e1c-8809-6fba241fc932",
    "text": "\nHighway \nCapacity \nCapacity \nExpansion \nDesired \nDiscretionary \n& \nAdequacy of \nSize of Regiion \nTraffic \nTrips \nPublic Transit \nwithin Desired \nof Driving \nTravel Time @ + \nPublic \nF\u2019opulation \nExtra Miles \nTransit \nActivity of \nRegion \nand Economic \nFare \nTake the \nAverage \nBus? \nTrip Length + \nTransit \nCars per /Ridership \nCars in \nRegion \nPerson \n- \n+ \n+ \ntravel time rises until the resulting congestion makes the suburbs sufficiently unat- \ntractive to stop further inmigration and development. \nThe combined effect of the four negative feedbacks B2 through B5 is to com- \npensate strongly for any decrease in travel time caused by new roads. If new high- \nways were built and then all construction stopped, there would be an immediate \ndrop in travel time. But as people respond to their newfound ease of travel, more, \nlonger trips would be taken. More people would abandon the bus and buy cars to \ncommute to work. The population of the suburbs would grow. These adjustments \ncontinue until travel time rises enough to stop the expansion of the suburbs be- \ncause the commute required is too long. The delays in these negative loops could \ncause congestion to overshoot the desirable level. \nBut road construction doesn\u2019t stop. As new highways Open the Hinterlands \n(loop Rl), it becomes possible to live in the countryside and commute to work in \nthe town or city. What was once remote farm country or woods now becomes a \n20 minute drive from the city, with its jobs, culture, and nightlife. Whole new",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 204
  },
  {
    "child_id": "0e058d27-2670-4601-9bed-505c26700394",
    "parent_id": "b70192cb-8484-4be7-b96d-292f6ec57854",
    "text": "184 \nPart I1 Tools for Systems Thinking \ncommunities spring up, communities where the people have to drive not only to \nwork but also to the market, to school, to the homes of their friends and their chil- \ndren\u2019s friends. The burgeoning population brings new development. Shops, strip \nmalls, and other businesses spring up, turning countryside to condo development, \npasture to parking lot. All the while, the number of cars on the road grows. After \nsome years, traffic congestion in these formerly quiet towns becomes a terrible \nproblem. Political pressure grows and still more roads are built. \nRoute 128, a ring road around Boston built in the 1950s to relieve congestion \nby diverting long-haul traffic around the center city, rapidly attracted local drivers \nand soon proved inadequate. To relieve the congestion it was widened, from four \nto eight, and in places, even more lanes. In stretches the breakdown lane was \nopened to traffic during rush hour (not a few hapless motorists have been killed \nwhen they had the temerity to use the breakdown lane for a breakdown). Traffic \nsoon filled these new lanes, and today during rush hour the cars crawl along \nbumper to bumper through long stretches of route 128. A second ring road, Inter- \nstate 495, was then built another 15 to 20 miles farther out. The expanded network \nmade even more countryside accessible, and another round of population growth \nand economic development began. This self-reinforcing process leads to more and \nmore new roads, pushing ever farther into the countryside, in a vain attempt to ease \ncongestion. The story is similar for other cities in the US, including the paradigm \ncase of congestion-Los Angeles-as well as London, Paris, Istanbul, Cairo, \nTokyo, Bangkok, and countless other cities around the world. \nThe model clearly shows the futility of attempts to reduce traffic congestion \nthrough road building. It may take some years, but, in an automotive version of \nParkinson\u2019s Law, traffic always expands to fill the highways available for its travel. \nTraffic volume grows until congestion is just bad enough to deter people from tak- \ning that additional trip, from driving to work instead of riding public transit, or \nfrom moving just a little farther out into the ~uburbs.~ \nTraffic engineers call this re- \naction \u201croad generated traffic.\u201d Hansen\u2019s (1995) econometric study of US metro- \npolitan areas showed that the elasticity of traffic volume with respect to highway \ncapacity was 0.9 after just 5 years, that is, a 10% increase in capacity led to a 9% \nincrease in traffic within 5 years. Many of the feedbacks identified in the model \noperate over even longer periods, fully negating the effect of road construction on \ncongestion. Some analysts even argue that by \u201cadding capacity to a crowded [high- \nway] network you could actually slow things down\u201d (Kay 1997, p. 15), a phenom- \nenon known as Braess\u2019 Law after the operations research analyst who first coined \nit. For example, the M25, ",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 209
  },
  {
    "child_id": "a11b8a3d-5b5f-4fca-a4af-999a6f6447b9",
    "parent_id": "b70192cb-8484-4be7-b96d-292f6ec57854",
    "text": "st 5 years, that is, a 10% increase in capacity led to a 9% \nincrease in traffic within 5 years. Many of the feedbacks identified in the model \noperate over even longer periods, fully negating the effect of road construction on \ncongestion. Some analysts even argue that by \u201cadding capacity to a crowded [high- \nway] network you could actually slow things down\u201d (Kay 1997, p. 15), a phenom- \nenon known as Braess\u2019 Law after the operations research analyst who first coined \nit. For example, the M25, London\u2019s ring road, was designed to carry long distance \ntraffic around London. Instead, it is actually used primarily for short trips by local \nresidents and commuters. It soon became the busiest highway in Europe and has \nlong been known as \u2018the longest parking lot in the world\u2019, though commuters on \nthe Long Island Expressway, Paris\u2019 Peripherique, and the San Diego Freeway \nmight disagree. In response, the M25 has been steadily widened, all to no avail. \nStudies typically find, as the London Times reported (10 November 1997), that \n5The analogy with Parhnson\u2019s Law (\u201cwork expands to fill the time available for its comple- \ntion\u201d) is more than casual: Parhnson\u2019s Law arises through a negative feedback loop structure quite \nsimilar to that governing traffic congestion. See section 5.4.\n\nChapter 5 Causal Loop Diagrams \n185 \nTraffic congestion on a widened section of the M25 is now greater than before the \nimprovement took place, a motoring survey suggests. The widening of a stretch of \nthe motorway at junction 15, west of London, was intended to curb congestion, but \nthe survey showed that jams on the stretch were now commonplace, although last \nyear traffic was generally free-flowing. \n5.6.3 The Mass Transit Death Spiral \nStandard economic analysis suggests that a decline in the attractiveness of a good \nor service should lead people to switch to substitutes. Why, then, as congestion \nbuilds up, don\u2019t people turn to mass transit? Part of the answer is shown in Fig- \nure 5-36. \nAs lower travel time caused by new roads increases the attractiveness of driv- \ning, ridership and revenue of the public transit system fall. Costs don\u2019t fall very \nmuch, since most of the costs are the fixed costs of providing service: the buses \nmust run whether they are full or empty. If the transit authority tries to close its \ndeficit by Cost Cutting (loop B6), service and quality erode. Routes are closed and \nthe frequency of service is cut. The relative attractiveness of driving rises and mass \ntransit ridership falls still more. The deficit widens, leading to still more cuts in the \npublic transit network as the self-reinforcing Route Expansion loop R2 operates as \na vicious cycle of decreasing ridership, greater cuts, and still fewer riders. \nRaising fares to balance the transit authority budget is little better: Higher fares \nincrease the relative attractiveness of driving, and more people abandon mass tran- \nsit for cars. Ridership falls, and fares must be raised again, Cho",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 209
  },
  {
    "child_id": "6071f49e-8741-4e81-882b-d3bd5ab78ba0",
    "parent_id": "b70192cb-8484-4be7-b96d-292f6ec57854",
    "text": "d mass \ntransit ridership falls still more. The deficit widens, leading to still more cuts in the \npublic transit network as the self-reinforcing Route Expansion loop R2 operates as \na vicious cycle of decreasing ridership, greater cuts, and still fewer riders. \nRaising fares to balance the transit authority budget is little better: Higher fares \nincrease the relative attractiveness of driving, and more people abandon mass tran- \nsit for cars. Ridership falls, and fares must be raised again, Choking off Ridership \n(loop R3). Because mass transit systems have a high proportion of fixed costs, they \nare highly vulnerable to these self-reinforcing feedbacks. As road construction and \nauto use accelerated in America, particularly after the late 1940s, people aban- \ndoned trolleys, trains, and buses. These positive loops became a death spiral of \nhigher fares, reduced service, and declining quality until in many cities only the \npoorest people, those who cannot afford to move to the suburbs or own a car, are \nleft to ride the public transit system. Attempts to build up the mass transit network \nto offset the positive loops that erode ridership through Mass Transit Capacity Ex- \npansion (loop B7) often fight a losing battle due to their long delays and high costs. \nOne final positive feedback is worth adding: The adequacy of a public transit \nsystem depends not only on the scope of the network and the frequency of service \nbut also on the size and population density of the region. As the countryside is de- \nveloped, the locus of activity shifts away from the area served by existing mass \ntransit. As population density falls, fewer and fewer people live near a bus or sub- \nway route. Public transit becomes less and less useful because You Can\u2019t Get There \non the Bus, leading to still more driving and still lower mass transit ridership, in \nanother vicious cycle, loop R4 (Figure 5-37). The suburbs grow and the adequacy \nof public transit falls much faster than mass transit capacity can be added. \nThe model above is still incomplete (as all models always are). One could add \nmany more feedbacks. For example, the spread of population into the less densely \npopulated suburbs increases the average length of trips, forming additional chan- \nnels by which congestion rises to offset any gains caused by new highways. The \nmodel does not explore other side effects of the automobile\u2019s rise to dominance,\n\nFIGURE 5-36 The high fixed costs of mass transit lead to a death spiral. \nAs mass transit ridership falls, service must be cut and fares raised, further driving people to drive. \nConstruction \n\\ \nPressure to \nReduce \nCongestion \nH ig h way \nCapacity \nCapacity \nExpansion \nTravel Time \n2- \nAdequacy of \nTraffic \nAttractiveness \nVolume \nPublic \nPopulation \nExtra Miles \nChoke Off \nTransit \ncost \nCutting \nRidership \n+ \nand Economic \nActivity of \nRegion \nAverage \nBus? \nTrip Length + \nFare \nIncrease \nTransit \nTransit \n+ \nDeficit \n+ \nRegion \nCars per /Ridership \nPublic \nCa",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 209
  },
  {
    "child_id": "ac4bb65f-4f4b-45b2-b58c-feb1830fc38e",
    "parent_id": "b70192cb-8484-4be7-b96d-292f6ec57854",
    "text": "l. \nAs mass transit ridership falls, service must be cut and fares raised, further driving people to drive. \nConstruction \n\\ \nPressure to \nReduce \nCongestion \nH ig h way \nCapacity \nCapacity \nExpansion \nTravel Time \n2- \nAdequacy of \nTraffic \nAttractiveness \nVolume \nPublic \nPopulation \nExtra Miles \nChoke Off \nTransit \ncost \nCutting \nRidership \n+ \nand Economic \nActivity of \nRegion \nAverage \nBus? \nTrip Length + \nFare \nIncrease \nTransit \nTransit \n+ \nDeficit \n+ \nRegion \nCars per /Ridership \nPublic \nCars in \n+ \n+ \nPerson \n- \nRevenue\n\nFGURE 5-37 You can't get there on the bus. \nAs the size of the populated region expands, the adequacy of public transit declines. The result is more driving, more congestion, and \nstill more road construction rather than an expansion of the public transit network. \nRoad \nConstruction \n\\ \nPressure to \nReduce \n\\ \nCongestion \n+r' \nHigh way \nCapacity \nCapacity \n/ \nExpansion \nHinterlands \nOpenthe \n~ \nE <- \nTravel Time (7) \nMT Capacity \nExpansion \nAdequacy of \nwithin \nSize \n+ / G ? s c r e t i o n a r y  \nof Desired \nRegion \nTraffic \nTrips \nAttractiveness \nPublic Transit 7 \nPublic \nand Economic \nIncrease \nTransit \nCan't Get There",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 209
  },
  {
    "child_id": "37e15250-04c7-4218-a023-3b981b4037fb",
    "parent_id": "d58dbc16-abdb-4c19-b1b8-8aac6414bdae",
    "text": "188 \nPart I1 Tools for Systems Thinking \nincluding the deaths, injuries and costs of accidents, the health effects of smog and \nozone production, greenhouse gas generation, the solid waste problem posed by \nthe discard of millions of vehicles each year (see chapter 6), and the dependence of \nthe highly automotive nations on insecure supplies of imported oil. What other \nfeedbacks and side effects do you see? \n5.6.4 Policy Analysis: The Impact of Technology \nDespite its limitations and omissions, the model provides a rich explanation for the \npersistent failure of road-building programs to alleviate traffic congestion. You can \nnow use the model to assess the likely effect of other policies. \nIn the 1970s and 1980s, a popular solution was HOV lanes (high-occupancy \nvehicle, or carpool lanes). These lanes are restricted to cars with at least two occu- \npants (sometimes only during rush hour). The result? To the extent drivers joined \ncarpools, the number of trips per day fell, reducing traffic volume slightly. The re- \nsulting reduction in congestion, however, simply encouraged others to take to the \nroads instead of mass transit, to take additional trips they might otherwise have \nforegone, and to leave for work a little later. The total volume of traffic during rush \nhours didn\u2019t change and more people were now on the highways than before, fur- \nther eroding mass transit ridership. And some enterprising but immoral motorists \ntook to riding with inflatable dummies in the passenger seat to fool the police and \nillegally take advantage of the HOV lane. \nDespite the persistent failure of road building and innovations such as HOV \nlanes, many transportation planners continue to pin their hopes on technological \nsolutions to the congestion problem. The latest of these is so-called intelligent \nvehicle-highway systems. Many clever technologies are under development, from \nsensors to detect the distance to the car ahead and automatically adjust your car\u2019s \nspeed, to transponders or magnets embedded in the road surface to automatically \nsteer your car. Already sensors embedded in some highways transmit real time traf- \nfic data to cars equipped with special receivers. Technologists look forward to the \nday when the internet, GPS, and real time vehicle controls will allow your car to \npick the optimal route to your destination and drive you there while you relax or \nread a book. Some of these technologies are designed to increase highway safety. \nMany are motivated by the need to increase highway capacity in cities where \nbuilding new roads and adding new lanes is no longer possible: under computer \ncontrol, the technologists promise, cars could zip safely along at 70 miles per hour \nonly inches apart, greatly expanding the capacity of existing highways. \nThe model shows the futility of these hopes. There is no technological solution \nto the congestion problem. The more effectively these technologies increase high- \nway capacity, the more trips will be ta",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 213
  },
  {
    "child_id": "6c0679a0-ddb4-4a35-aa49-60a5d155d131",
    "parent_id": "d58dbc16-abdb-4c19-b1b8-8aac6414bdae",
    "text": " by the need to increase highway capacity in cities where \nbuilding new roads and adding new lanes is no longer possible: under computer \ncontrol, the technologists promise, cars could zip safely along at 70 miles per hour \nonly inches apart, greatly expanding the capacity of existing highways. \nThe model shows the futility of these hopes. There is no technological solution \nto the congestion problem. The more effectively these technologies increase high- \nway capacity, the more trips will be taken, the more people will buy cars, the less \nattractive public transit will be, and the more countryside will be developed into \nbedroom communities for commuters. The volume of traffic will swiftly rise to ab- \nsorb all the new capacity technology can yield. We might zip along the freeway at \nseventy, but we\u2019ll be stuck in much longer lines at the entrance ramp and on sec- \nondary routes. On the roadways of the future we may ride more safely and more \ncomfortably, but we won\u2019t ride more swiftly.\n\nChapter 5 \nCausal Loop Diagrams \n189 \nEconomists generally suggest the solution is to charge tolls that increase as \ncongestion rises (Downs 1992). While some regions are experimenting with time- \nof-day tolls and congestion-based pricing using real time sensing equipment, there \nis considerable political resistance to the notion of paying for the freeway, and \nsome concern over the regressive impact of tolls. Worse, drivers tend to switch to \nsecondary roads and city streets where tolls are infeasible. \nSome nations have come to understand these dynamics and are moving to \nreduce traffic and the attendant pollution, accidents, and destruction of open land \nit causes by increasing travel times. In September 1997 Sweden\u2019s parliament \nadopted \u201cVision Zero\u201d, a policy aimed at eliminating all traffic fatalities by per- \nmitting towns to reduce speed limits to 30 kilometers per hour and install speed \nbumps and other flow restricting devices. The model suggests these policies will, \nin addition to saving lives, encourage people to use other modes such as bus, train, \nand bicycle, thus reducing the pressure for road building and the growth in traffic. \n5.6.5 \nCompensating Feedback: \nThe Source of Policy Resistance \nThe feedbacks affecting traffic clearly show that attempts to control congestion \nthrough road building are vain. Any reduction in congestion leads to more trips and \nmore cars, swiftly building congestion back up. What road construction actually \ncontrols is the size of the metropolitan area and the number of cars on the road. \nRoad construction causes the dramatic expansion of the urbanized and suburban- \nized area, the growth of strip malls and parking lots, and the decline of farm, for- \nest, and field. \nThe causal structure of the traffic problem illustrates how policy resistance \narises in a wide range of complex systems. Road-building programs are typical of \npolicies directed at the symptom of difficulty. Policies directed at alleviating the \nsympto",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 213
  },
  {
    "child_id": "999ff9c9-eae7-45fc-bfb6-426fdec1159d",
    "parent_id": "d58dbc16-abdb-4c19-b1b8-8aac6414bdae",
    "text": "e of the metropolitan area and the number of cars on the road. \nRoad construction causes the dramatic expansion of the urbanized and suburban- \nized area, the growth of strip malls and parking lots, and the decline of farm, for- \nest, and field. \nThe causal structure of the traffic problem illustrates how policy resistance \narises in a wide range of complex systems. Road-building programs are typical of \npolicies directed at the symptom of difficulty. Policies directed at alleviating the \nsymptoms of a problem usually fail because they trigger compensating feedbacks, \nfeedbacks that undercut the intended effects of the policy. The compensating loops \narise because other actors, with their own goals, respond to changes in the state of \nthe system in such a way as to offset the intended effects of the policy. While each \nindividual loop may be weak, the combined effect can often compensate com- \npletely for any policy directed at a symptom of a problem. Directing policies at \nthe symptoms of a problem is like trying to squeeze a balloon to make it smaller. \nWhenever you squeeze, the air pressure increases, expanding some other part of \nthe balloon so its volume remains about the same. \nWhy then do so many policies focus on alleviating the symptoms of difficulty? \nWe focus on symptoms because so much of our experience is with simple systems \nin which cause and effect are closely related in time and space, in which symptom \nand cause are obvious. Most of our experience is with systems in which there is a \nsingle, dominant negative feedback, as when you reach out to grasp an object by \nassessing the gap between the position of the object and your hand. We then ex- \ntrapolate these everyday experiences with simple systems into the management of \ncomplex systems. But, as Jay Forrester (1969, pp. 9-10) notes\n\n190 \nPart I1 Tools for Systems Thinking \nIn the crrmplex system the cause of a difficulty may lie far back in time from \nthe symptoms, or in a completely different and remote part of the system. In fact, \ncauses are usually found, not in prior events, but in the structure and policies of the \nsystem . . . Conditioned by our training in simple systems, we apply the same intu- \nition to complex systems and are led into error. As a result we treat symptoms, not \ncauses. The outcome lies between ineffective and detrimental . . . If the attempted \nsolution intensifies the problem, wrongly attributed to another source, the organiza- \ntion likely will redouble its \u201ccorrective\u201d action, producing more difficulty and pres- \nsure for still more remedial action. A destructive spiral becomes established. \nIdentifying the Feedback Structure of \nPolicy Resistance \n1. Consider the failed Romanian population policy described in chapter 1. \nDevelop a causal loop diagram explaining the failure of the government\u2019s \nefforts to increase the birth rate. \n2. Table 1-1 lists a number of common examples of policy resistance in social, \nbusiness, and economic systems. Develop",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 213
  },
  {
    "child_id": "8b92cd36-e855-46a1-a57c-e41d97370376",
    "parent_id": "d58dbc16-abdb-4c19-b1b8-8aac6414bdae",
    "text": "corrective\u201d action, producing more difficulty and pres- \nsure for still more remedial action. A destructive spiral becomes established. \nIdentifying the Feedback Structure of \nPolicy Resistance \n1. Consider the failed Romanian population policy described in chapter 1. \nDevelop a causal loop diagram explaining the failure of the government\u2019s \nefforts to increase the birth rate. \n2. Table 1-1 lists a number of common examples of policy resistance in social, \nbusiness, and economic systems. Develop simple causal diagrams for each. \nUse your diagrams to explain why each policy failed. \n5.7 \nSUMMARY \nCausal diagrams are a powerful tool to map the feedback structure of complex sys- \ntems. Causal diagrams can be helpful to you in the early phases of a project, when \nyou need to work with the client team to elicit and capture their mental models. \nThey are helpful in presenting the results of your modeling work in a nontechnical \nfashion. To be effective, you should follow the rules for causal diagrams, including \nselection of variable names, layout, and assignment of link and loop polarities. It \nis best to build up diagrams in steps: resist the urge to create a single, comprehen- \nsive diagram. As in learning to read music, practice is everything. Develop your \nskills in mapping the feedback structure of systems by sketching causal diagrams \nto capture the feedbacks you recognize as you read the newspaper or the great \nworks of literature.\n\n6 \nStocks and Flows \nI\u2019m very good at integral and differential calculus, \nI know the scientific names of beings animalculous; \nIn short, in matters vegetable, animal, and mineral, \nI am the very model of a modem Major-General. \n-W. \nS. Gilbert, The Pirates of Penzance, Act 1. \nThis chapter introduces the concept of stocks and flows, a central idea in dynam- \nics. It presents the conceptual and mathematical definitions of stocks and flows, the \ndiagramming tools for mapping networks of stocks and flows, and case studies of \nthe use of stocks and flows in modeling projects including automobile recycling \nand the construction of pulp and paper mills. Developing facility in identifying, \nmapping, and interpreting the stock and flow networks of systems is a critical skill \nfor any modern systems modeler. \n6.1 STOCKS, FLOWS, AND ACCUMULATION \nCausal loop diagrams are wonderfully useful in many situations. They are well \nsuited to represent interdependencies and feedback processes. They are used ef- \nfectively at the start of a modeling project to capture mental models-both those \nof a client group and your own. They are also used to communicate the results of a \ncompleted modeling effort. \nHowever, causal loop diagrams suffer from a number of limitations and can \neasily be abused. Some of these are discussed in chapter 5. One of the most im- \nportant limitations of causal diagrams is their inability to capture the stock and \nflow structure of systems. Stocks and flows, along with feedback, are the two cen- \ntral concepts",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 213
  },
  {
    "child_id": "f8d1d9e4-cf52-4f09-9795-43383dd03f11",
    "parent_id": "d58dbc16-abdb-4c19-b1b8-8aac6414bdae",
    "text": "eling project to capture mental models-both those \nof a client group and your own. They are also used to communicate the results of a \ncompleted modeling effort. \nHowever, causal loop diagrams suffer from a number of limitations and can \neasily be abused. Some of these are discussed in chapter 5. One of the most im- \nportant limitations of causal diagrams is their inability to capture the stock and \nflow structure of systems. Stocks and flows, along with feedback, are the two cen- \ntral concepts of dynamic systems theory. \n191",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 213
  },
  {
    "child_id": "be70363b-13e4-4de5-b467-e587515d2e6c",
    "parent_id": "1a44b476-2754-44eb-9ebc-b63aa144e76e",
    "text": "192 \nPart I1 Tools for Systems Thinking \nStocks are accumulations. They characterize the state of the system and gener- \nate the information upon which decisions and actions are based. Stocks give sys- \ntems inertia and provide them with memory. Stocks create delays by accumulating \nthe difference between the inflow to a process and its outflow. By decoupling rates \nof flow, stocks are the source of disequilibrium dynamics in systems. \nStocks and flows are familiar to all of us. The inventory of a manufacturing \nfirm is the stock of product in its warehouses. The number of people employed by \na business is a stock. The balance in your checking account is a stock. Stocks are \naltered by inflows and outflows. A firm\u2019s inventory is increased by the flow of pro- \nduction and decreased by the flow of shipments (and possibly other outflows due \nto spoilage or shrinkage). The workforce increases via the hiring rate and decreases \nvia the rate of quits, layoffs, and retirements. Your bank balance increases with de- \nposits and decreases as you spend. Yet despite everyday experience of stocks and \nflows, all too often people fail to distinguish clearly between them. Is the US fed- \neral deficit a stock or a flow? Many people, including politicians responsible for \nfiscal policy, are unclear. Failure to understand the difference between stocks and \nflows often leads to underestimation of time delays, a short-term focus, and policy \nresistance. \n6.1.1 \nDiagramming Notation for Stocks and Flows \nSystem dynamics uses a particular diagramming notation for stocks and flows \n(Figure 6- 1 1. \n0 \nStocks are represented by rectangles (suggesting a container holding the \ncontents of the stock). \nInflows are represented by a pipe (arrow) pointing into (adding to) the \nstock. \nOutflows are represented by pipes pointing out of (subtracting from) \nthe stock. \nValves control the flows. \nClouds represent the sources and sinks for the flows. A source represents \nthe stock from which a flow originating outside the boundary of the model \narises; sinks represent the stocks into which flows leaving the model \nboundary drain. Sources and sinks are assumed to have infinite capacity and \ncan never constrain the flows they support. \nThe structure of all stock and flow structures is composed of these elements. \nAs the example in the figure shows, a firm\u2019s inventory is a stock that accumulates \nthe inflow of production and is reduced by the outflow of shipments. These are the \nonly flows considered in the model: unless explicitly shown, other possible flows \ninto or out of the stock, such as inventory shnnkage or spoilage, are assumed to be \nzero. The clouds indicate that the stock of raw materials never starves the produc- \ntion rate and the stock of product shipped to customers never grows so high that it \nblocks the shipment rate.\n\nChapter 6 Stocks and Flows \nL1 \nFlow of material \ninto stock \n193 \n~ \nL1 \nc3 \nStock \noutofstock \nFIGURE 6-1 \nStock and flow \ndiagramming \nnotation \nv ",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 217
  },
  {
    "child_id": "6038d869-b74d-445f-8151-829dc3a57dd1",
    "parent_id": "1a44b476-2754-44eb-9ebc-b63aa144e76e",
    "text": "idered in the model: unless explicitly shown, other possible flows \ninto or out of the stock, such as inventory shnnkage or spoilage, are assumed to be \nzero. The clouds indicate that the stock of raw materials never starves the produc- \ntion rate and the stock of product shipped to customers never grows so high that it \nblocks the shipment rate.\n\nChapter 6 Stocks and Flows \nL1 \nFlow of material \ninto stock \n193 \n~ \nL1 \nc3 \nStock \noutofstock \nFIGURE 6-1 \nStock and flow \ndiagramming \nnotation \nv \nL1 \nc3 \n+. \nGeneral Structure: \n~ \nInventory \nL1 \nmc3 \nv \n\\;7 \nc3 \nY 4 Stock \nOutflow \n- \nInflow \nKey: \nI \nStock \nFlow \nX \nc3 \nValve (Flow Regulator) \nSource or Sink \n(Stocks outside model boundary) \nt \\ \nf \n/ \n/ \n\\- Nameof , \n\\ \nflow \nExample: \n6.1.2 \nMathematical Representation of \nStocks and Flows \nThe stock and flow diagramming conventions (originated by Forrester 1961) were \nbased on a hydraulic metaphor-the flow of water into and out of reservoirs. \nIndeed, it is helpful to think of stocks as bathtubs of water. The quantity of water\n\n194 \nFIGURE 6-2 \nFour equivalent \nrepresentations \nof stock and \nflow structure \nEach \nrepresentation \ncontains \nprecisely the \nsame \ninformation. \nPart I1 Tools for Systems Thinking \nin your bathtub at any time is the accumulation of the water flowing in through the \ntap less the water flowing out through the drain (assume no splashing or evapora- \ntion). In exactly the same way, the quantity of material in any stock is the accumu- \nlation of the flows of material in less the flows of material out. Despite the prosaic \nmetaphor the stock and flow diagram has a precise and unambiguous mathemati- \ncal meaning. Stocks accumulate or integrate their flows; the net flow into the stock \nis the rate of change of the stock. Hence the structure represented in Figure 6-1 \nabove corresponds exactly to the following integral equation: \nStock(t) = \n[Inflow(s) - Outflow(s)]ds + Stock(t,) \n(6-1) \nJI,' \nwhere Inflow(s) represents the value of the inflow at any time s between the initial \ntime to and the current time t. Equivalently, the net rate of change of any stock, its \nderivative, is the inflow less the outflow, defining the differential equation \nd(Stock)/dt = Inflow(t) - Outflow(t). \nIn general, the flows will be functions of the stock and other state variables and pa- \nrameters. Figure 6-2 shows four equivalent representations of the general stock and \nflow structure. The bathtub and stock and flow diagrams may appear to be less rig- \norous than the integral or differential equation representations, but they are pre- \ncisely equivalent and contain exactly the same information. From any system of \nintegral or differential equations we can construct the corresponding stock and \nflow map; from any stock and flow map we can generate the corresponding inte- \ngral or differential equation system. \nHydraulic Metaphor: \nf \nStock and Flow Diagram: \nIntegral Equation: \nt \nStock(t) = 1 [Inflow(s) - Outflow(s)]ds + Stock (to) \nto \nDifferen",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 217
  },
  {
    "child_id": "89740de5-88c4-41cc-af3c-5ac99a5371d6",
    "parent_id": "1a44b476-2754-44eb-9ebc-b63aa144e76e",
    "text": "ous than the integral or differential equation representations, but they are pre- \ncisely equivalent and contain exactly the same information. From any system of \nintegral or differential equations we can construct the corresponding stock and \nflow map; from any stock and flow map we can generate the corresponding inte- \ngral or differential equation system. \nHydraulic Metaphor: \nf \nStock and Flow Diagram: \nIntegral Equation: \nt \nStock(t) = 1 [Inflow(s) - Outflow(s)]ds + Stock (to) \nto \nDifferential Equation: \nd(Stock)/dt = Net Change in Stock = Inflow(t) - Outflow(t)\n\nChapter 6 Stocks and Flows \n195 \nProcess Point: Notation for Accumulation \nThe traditional notation used in calculus and shown in Figure 6-2 is often con- \nfusing to many people. In this book, I will generally represent the process of accu- \nmulation with the INTEGRAL() function: \nStock = INTEGRAL(1nflow - Outflow, Stockh) \n(6-3) \nThe INTEGRAL() function is exactly equivalent to equation (6-1) and represents \nthe concept that the stock accumulates its inflows less its outflows, beginning with \nan initial value of Stockh. \n6.1.3 \nThe Contribution of Stocks to Dynamics \nStocks are critical in generating the dynamics of systems for the following reasons \n(Mass 1980): \n1. Stocks characterize the state of the system and provide the basis for \nactions. \nThe stocks in a system tell decision makers where they are, providing them \nwith the information needed to act. A pilot must know the state of the aircraft \nincluding position, heading, altitude, and fuel level. Without knowledge of \nthese states, the pilot is flying blind and won\u2019t survive long. Likewise, a \nfirm can\u2019t set its production schedule appropriately without knowledge of \nthe order backlog, the stock of inventory, the parts stocks, the labor force, \nand other stocks. A balance sheet characterizes the financial health of a \ncorporation by reporting the values of stocks such as cash, inventory, \npayables, and debt. Information about these stocks affects decisions such as \nissuing new debt, paying dividends, and controlling expenses via layoffs. \n2. Stocks provide systems with inertia and memory. \nStocks accumulate past events. The content of a stock can only change \nthrough an inflow or outflow. Without changes in these flows, the past \naccumulation into the stock persists. The stock of lead in the paint of \nAmerica\u2019s inner city housing remains high today even though lead paint was \nbanned in 1978. Once the stock of lead paint accumulated, the only way to \neliminate it is through expensive deleading or the eventual demolition of the \nhousing itself. Even then the lead remains, either safely sequestered or more \nlikely dispersed into the environment as dust, chips, or lead leaching from \nlandfills into water supplies. Likewise, the stock of ozone-destroying \nchlorine generated by CFCs will remain in the atmosphere for decades even \nafter the production rate of CFCs falls to zero because the rate at which \nchlorine is scrubbed from",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 217
  },
  {
    "child_id": "dab4937d-c48c-4d19-9c62-81e63d2bcce7",
    "parent_id": "1a44b476-2754-44eb-9ebc-b63aa144e76e",
    "text": " the only way to \neliminate it is through expensive deleading or the eventual demolition of the \nhousing itself. Even then the lead remains, either safely sequestered or more \nlikely dispersed into the environment as dust, chips, or lead leaching from \nlandfills into water supplies. Likewise, the stock of ozone-destroying \nchlorine generated by CFCs will remain in the atmosphere for decades even \nafter the production rate of CFCs falls to zero because the rate at which \nchlorine is scrubbed from the stratosphere is very low. Stocks don\u2019t have to \nbe tangible. Memories and beliefs are stocks that characterize your mental \nstates. Your beliefs persist over time, generating inertia and continuity in \nyour attitudes and behavior. If you have a bad experience on an airline and \nnever fly on that carrier again, your belief about the low quality of their \nservice remains even if they\u2019ve improved.\n\n196 \nPart I1 Tools for Systems Thinking \n3. Stocks are the source of delays. \nAll delays involve stocks. A delay is a process whose output lags behind its \ninput. The difference between the input and output accumulates in a stock of \nmaterial in process. There is a lag between the time you mail a letter and the \ntime it is received. During this interval, the letter resides in a stock of letters \nin transit. Even email accumulates in stocks of undelivered packets and \nmessages residing in the memory of various computers between the sender \nand receiver. There is a lag of several years between the decision to build \nnew office buildings and the time they are ready for occupancy. During this \ninterval there is a supply line of buildings under development, including a \nstock of proposed projects and a stock of buildings under construction. \nBy definition, when the input to a delay changes, the output lags behind \nand continues at the old rate for some time. During such adjustments, the \nstock accumulating the difference between input and output changes. If you \nmail wedding invitations to 1000 of your closest friends all at once, while the \nrate at which other mail is deposited remains constant, the stock of letters in \ntransit jumps by 1000 and remains at the new level as the letters make their \nway to their destinations. Only as the invitations begin to arrive does the \nstock of letters in transit start to fall. The delivery rate exceeds the mailing \nrate, shrinking the stock of mail in transit, until all the invitations have been \ndelivered, at which point the delivery rate once again equals the rate at which \nmail is deposited and the stock of letters in transit returns to its original level. \nPerception delays also involve stocks though these stocks do not involve \nany material flows. For example, the belief of managers in a company\u2019s \nTaiwan headquarters about the shipment rate from their Silicon Valley plant \nlags behind the true shipment rate due to measurement and reporting delays. \nMeasurement of a rate such as shipments always involves a stock. Due to \n",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 217
  },
  {
    "child_id": "f6f4f09a-4fad-49bc-9cf3-3c15f5d37c97",
    "parent_id": "1a44b476-2754-44eb-9ebc-b63aa144e76e",
    "text": "ate once again equals the rate at which \nmail is deposited and the stock of letters in transit returns to its original level. \nPerception delays also involve stocks though these stocks do not involve \nany material flows. For example, the belief of managers in a company\u2019s \nTaiwan headquarters about the shipment rate from their Silicon Valley plant \nlags behind the true shipment rate due to measurement and reporting delays. \nMeasurement of a rate such as shipments always involves a stock. Due to \nunpredictable variations in customer orders, product availability, and \ntransportation, shipments can vary significantly from hour to hour, day to \nday, or over even longer periods. Shipments must be accumulated for some \nperiod of time such as a day, week, or month to provide a meaningful \nmeasurement of the rate. If shipments are highly volatile, the firm will have \nto accumulate them over longer intervals to filter out the short-term noise and \nprovide a meaningful average managers can use to make decisions. In \naddition there are reporting delays involving a stock of shipment information \nwaiting to be uploaded to and downloaded from the firm\u2019s computer system. \nThere may be further delays in the adjustment of the executives\u2019 beliefs even \nafter they see the latest data. Chapter 11 describes the structure and dynamics \nof delays in detail. \n4. Stocks decouple rates of flow and create disequilibrium dynamics. \nStocks absorb the differences between inflows and outflows, thus permitting \nthe inflows and outflows to a process to differ. In equilibrium, the total \ninflow to a stock equals its total outflow so the level of the stock is \nunchanging. However, inflows and outflows usually differ because they are \noften governed by different decision processes. Disequilibrium is the rule \nrather than the exception.",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 217
  },
  {
    "child_id": "0161b508-8d30-41e3-884c-48c363aa40e8",
    "parent_id": "5a383b74-3043-47e4-8445-f8aab220107c",
    "text": "Chapter 6 Stocks and Flows \n197 \nThe production of grain depends on the yearly cycle of planting and \nharvest, along with unpredictable natural variations in weather, pest \npopulations, and so on. Consumption of grain depends on how many mouths \nthere are to feed. The difference between grain production and consumption \nrates accumulates in grain stocks, stored throughout the distribution system \nfrom field to grain elevator to processor inventories to market to kitchen \ncupboard. Without a stock of grain to buffer the differences between \nproduction and consumption, consumption would necessarily equal \nproduction at all times and people would starve between harvests. Thus \nJoseph advised Pharaoh to stockpile grain during the 7 good years in \nanticipation of the 7 lean years during which consumption would exceed \nharvests. While on average the production of grain balances consumption \n(and losses) as farmers respond to market prices and inventory conditions \nin determining how much to plant, and as consumers adjust consumption \nin response to prices and availability, production and consumption are \nrarely equal. \nmakers, involve different resources, and are subject to different random \nshocks, a buffer or stock between them must exist, accumulating the \ndifference. As these stocks vary, information about the size of the buffer \nwill feed back in various ways to influence the inflows and outflows. Often, \nbut not always, these feedbacks will operate to bring the stock into balance. \nWhether and how equilibrium is achieved cannot be assumed but is an \nemergent property of the whole system as its many feedback loops interact \nsimultaneously. Understanding the nature and stability of these dynamics \nis often the purpose of a system dynamics model. \nWhenever two coupled activities are controlled by different decision \n6.2 \nIdentifying Stocks and Flows \nThe distinction between stocks and flows is recognized in many disciplines. \nTable 6-1 shows some common terms used to distinguish between stocks and \nflows in various fields. In mathematics, system dynamics, control theory, and re- \nlated engineering disciplines, stocks are also known as integrals or state variables. \nFlows are also known as rates or derivatives. Chemists speak of reactants and \nreaction products (the stocks) and reaction rates (the flows). In manufacturing \nsettings, stocks and flows are also called bufSers and throughput. In economics, \nstocks are also known as levels and flows as rates. For example, the capital stock \nof an economy is its level of wealth (measured in, say, dollars) while the GDP is \nthe aggregate rate of national output (measured in $/year). In accounting, balance \nsheet items are stocks, such as cash, the book value of inventory, long-term debt, \nand shareholder equity (all measured in, e.g., dollars). Items appearing on the in- \ncome statement or flow of funds report are flows which alter the corresponding \nstocks on the balance sheet, such as net receipts, the co",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 222
  },
  {
    "child_id": "fe5ab23d-2176-44a9-808e-9ab3c0ce4de9",
    "parent_id": "5a383b74-3043-47e4-8445-f8aab220107c",
    "text": "xample, the capital stock \nof an economy is its level of wealth (measured in, say, dollars) while the GDP is \nthe aggregate rate of national output (measured in $/year). In accounting, balance \nsheet items are stocks, such as cash, the book value of inventory, long-term debt, \nand shareholder equity (all measured in, e.g., dollars). Items appearing on the in- \ncome statement or flow of funds report are flows which alter the corresponding \nstocks on the balance sheet, such as net receipts, the cost of goods sold, long-term \nborrowing, and the change in retained earnings. These flows are measured in \n$/year. Physiological models often lump different stocks into a small number of \ncompartments or boxes connected by diffusion rates (the flows). For example, the \nstock of glucose in a human can be represented by a three compartment model:\n\n198 \nPart I1 Tools for Systems Thinking \nField \nStocks \nFlows \nTABLE 6-1 \nTerminology used \nto distinguish \nMathematics, physics \nbetween stocks \nand engineering \nand flows in \ndifferent \ndisciplines \nChemistry \nManufacturing \nEconomics \nAccounting \nBiology, physiology \nMedicine, \nepidemiology \nIntegrals, states, state \nvariables, stocks \nReactants and reaction \nproducts \nBuffers, inventories \nLevels \nStocks, balance sheet \nitems \nCompartments \nPrevalence, reservoirs \nDerivatives, rates of \nchange, flows \nReaction rates \nThroughput \nRates \nFlows, cash flow or \nincome statement \nitems \nDiffusion rates, flows \nIncidence, infection, \nmorbidity and \nmortality rates \nglucose in the digestive system, glucose in the bloodstream, and glucose in the in- \ntracellular matrix. In epidemiology, prevalence measures the number or stock of \npeople who have a particular condition at any given time, while incidence is the \nrate at which people come down with the disease or condition. In December 1998 \nthe prevalence of HIV/AIDS worldwide was estimated by the United Nations \nAIDS program to be 33.4 million and the incidence of HIV infection was estimated \nto be 5.8 million/year. That is, a total of 33.4 million people were estimated to be \nHIV-positive or to have AIDS; the rate of addition to this stock was 5.8 million \npeople per year (16,000 new infections per day). The net change in the population \nof HIV-positive individuals was estimated to be 3.3 million people per year due to \nthe death rate from AIDS, estimated to be 2.5 million people per year in 1998. \nHow can you tell which concepts are stocks and which are flows? Stocks are \nquantities of material or other accumulations. They are the states of the system. \nThe flows are the rates at which these system states change. Imagine a river flow- \ning into a reservoir. The quantity of water in the reservoir is a stock (measured in, \nsay, cubic meters). If you drew an imaginary line across the point where the river \nenters the reservoir, the flow is the rate at which water passes the line-the rate of \nflow in cubic meters per second. \n6.2.1 \nUnits of Measure in Stock and Flow Networ",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 222
  },
  {
    "child_id": "99300caf-5106-49e1-b507-f47391d4967d",
    "parent_id": "5a383b74-3043-47e4-8445-f8aab220107c",
    "text": "ies of material or other accumulations. They are the states of the system. \nThe flows are the rates at which these system states change. Imagine a river flow- \ning into a reservoir. The quantity of water in the reservoir is a stock (measured in, \nsay, cubic meters). If you drew an imaginary line across the point where the river \nenters the reservoir, the flow is the rate at which water passes the line-the rate of \nflow in cubic meters per second. \n6.2.1 \nUnits of Measure in Stock and Flow Networks \nThe units of measure can help you distinguish stocks from flows. Stocks are \nusually a quantity such as widgets of inventory, people employed, or Yen in an \naccount. The associated flows must be measured in the same units per time period, \nfor example, the rate at which widgets are added per week to inventory, the hiring \nrate in people per month, or the rate of expenditure from an account in %/hour. Note \nthat the choice of time period is arbitrary. You are free to select any measurement \nsystem you like as long as you remain consistent. You can measure the flow of pro- \nduction into inventory as widgets per week, widgets per day, or widgets per hour. \nThe statement \u201cThe current rate of production is 1200 widgets per day\u201d is exactly\n\nChapter 6 Stocks and Flows \n199 \nequivalent to the statement that production is proceeding at a rate of 8400 widgets \nper week, 50 widgets per hour, 5/6 widgets per minute, or even 43,800,000 widgets \nper century. All are statements about how many widgets are being produced right \nnow-at this instant. Whether the cumulative number of widgets produced in any \ngiven interval such as a day, week, or century is equal to 1200,8400, or 43,800,000 \ndepends on whether the current rate stays constant over that interval (or averages \nout to the current rate). Most likely it won\u2019t. \n6.2.2 \nThe Snapshot Test \nStocks characterize the state of the system. To identify key stocks in a system, \nimagine freezing the scene with a snapshot. Stocks would be those things you \ncould count or measure in the picture, including psychological states and other in- \ntangible variables. You can estimate the stock of water in a reservoir from a set \nof satellite images and topographic data, but you cannot determine whether the \nwater level is rising or falling. Your bank statement tells you how much money is \nin your account but not the rate at which you are spending it now. If time stopped, \nit would be possible to determine how much inventory a company has or the price \nof materials but not the net rate of change in inventory or the rate of inflation in \nmaterials prices. The snapshot test applies also to less tangible stocks. The plant \nmanager\u2019s expectation of the customer order rate at any instant or perception of the \nsize of inventory are stocks, even though they are mental and not physical stocks. \nA snapshot of people\u2019s mental states, however, does not indicate how fast they are \nrevising their beliefs. \nFigure 6-3 lists some common concepts a",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 222
  },
  {
    "child_id": "f6aaacf4-b21f-46f9-9fcd-ee3d32a95ad8",
    "parent_id": "5a383b74-3043-47e4-8445-f8aab220107c",
    "text": "the price \nof materials but not the net rate of change in inventory or the rate of inflation in \nmaterials prices. The snapshot test applies also to less tangible stocks. The plant \nmanager\u2019s expectation of the customer order rate at any instant or perception of the \nsize of inventory are stocks, even though they are mental and not physical stocks. \nA snapshot of people\u2019s mental states, however, does not indicate how fast they are \nrevising their beliefs. \nFigure 6-3 lists some common concepts and identifies them as stocks or flows, \nshowing their stock and flow structure and units of measure. Population, Employ- \nees, and Debt are straightforward. Why is the price of a product a stock? Prices \ncharacterize the state of the system, in this case how much you must pay per unit. \nA price posted on an item remains in effect until it is changed, just as the number \nof widgets in an inventory remains constant until it is changed by a flow of pro- \nduction or shipments. Even the bids and offers called out in a trading pit at a fi- \nnancial market are stocks, albeit short-lived ones: a bid or offer remains in effect \nuntil the trader withdraws or alters it by crying out another. \nWhy is the expected customer order rate for a product a stock? Clearly, the ac- \ntual customer order rate is a flow. The flow of customer orders accumulates in a \nbacklog or stock of unfilled orders until the product can be delivered. However, a \nmanager\u2019s belief about the rate at which customer orders are booked is a stock-it \nis a state of the system, in this case a mental state. No one knows the true current \nor future order rate. The manager\u2019s belief about orders can, and usually does, dif- \nfer from the true order rate (the belief can be wrong). Managers\u2019 beliefs about the \ncustomer order rate will tend to remain the same until they become aware of new \ninformation and update their beliefs. The Change in Expected Order Rate is the \nrate at which the belief is updated. Note the units of measure for the expected or- \nder rate. Like the actual order rate, the expected order rate is measured in widgets \nper time period (say weeks). The units of measure for the rate at which the belief \nabout customer orders is updated are (widgets1week)lweek.\n\n200 \nv \nY \nGs \nPart I1 Tools for Systems Thinking \nEmployees \nv \na \n(people) \nFIGURE 6-3 \nExamples of \nstocks and flows \nwith their units of \nmeasure \nThe choice of time \nunit for the flows \n(e.g., days, weeks, \nyears) is arbitrary \nbut must be \nconsistent within a \nsingle model. \nDebt \n($1 \nv \nPopulation \nv \nL1 \nfoeoole) \nL1 \nv \nL3 \nI, \n8 \nI \nBirth Rate \n' \nDeath Rate \nv \nL1 \nb \n(people/yea r) \n(people/yea r) \nExpected \nCustomer \nOrders \nRetirement Rate \n(people/year) \n(people/yea r) \nLayoff Rate \n(people/yea r) \n(people/year) - \nPrice \nI \nu \n($/unit) \nRate of Price \nChange \n($/uniWyea r) \nOrder Rate \n(widge WweeWweek) \nNote that the rate of price change and the change in the expected order rate can \nbe positive or negative (prices and d",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 222
  },
  {
    "child_id": "bdfaa532-d7e9-4831-962d-a63c1eebe7df",
    "parent_id": "5a383b74-3043-47e4-8445-f8aab220107c",
    "text": "nsistent within a \nsingle model. \nDebt \n($1 \nv \nPopulation \nv \nL1 \nfoeoole) \nL1 \nv \nL3 \nI, \n8 \nI \nBirth Rate \n' \nDeath Rate \nv \nL1 \nb \n(people/yea r) \n(people/yea r) \nExpected \nCustomer \nOrders \nRetirement Rate \n(people/year) \n(people/yea r) \nLayoff Rate \n(people/yea r) \n(people/year) - \nPrice \nI \nu \n($/unit) \nRate of Price \nChange \n($/uniWyea r) \nOrder Rate \n(widge WweeWweek) \nNote that the rate of price change and the change in the expected order rate can \nbe positive or negative (prices and demand forecasts can rise or fall). Any flow into \nor out of a stock can be either positive or negative. The direction of the arrow \n(pointing into or out of a stock) defines the sign convention for the flow. An inflow \nadds to the stock when the flow is positive; if the flow is negative it subtracts from \nthe stock. When the outflow is positive, the flow subtracts from the stock.",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 222
  },
  {
    "child_id": "7eaae6b0-539e-4640-8265-1889777c5217",
    "parent_id": "cf3a3faa-8020-41db-9c01-ae71bb104573",
    "text": "Chapter 6 Stocks and Flows \n201 \n6.2.3 \nConservation of Material in \nStock and Flow Networks \nA major strength of the stock and flow representation is the clear distinction be- \ntween the physical flows through the stock and flow network and the information \nfeedbacks that couple the stocks to the flows and close the loops in the system. The \ncontents of the stock and flow networks are consewed in the sense that items en- \ntering a stock remain there until they flow out. When an item flows from one stock \nto another the first stock loses precisely as much as the second gains. Consider the \nstock and flow structure representing the accounts receivable of a firm (Figure \n6-4). The stock of receivables is increased by billings and decreased by payments \nreceived and by defaults. The flow of billings is conserved in the sense that once a \ncustomer is billed, the invoice remains in the stock of receivables until it explicitly \nflows out when the receivables department records the customer\u2019s payment or ac- \nknowledges that the customer has defaulted and writes off the account. In contrast, \ninformation about the stock of receivables is not conserved. The corporate ac- \ncounting system makes the value of the receivables stock available to many \nthroughout the organization. Accessing and using this information does not use it \nup or make it unavailable to others. \nNote also that while the units of accounts payable are dollars and the billing, \npayment, and default flows are measured in dollars per time period, the contents of \nthe stock are not actually dollars. Rather, the content of the receivables stock is in- \nformation, specifically, a ledger or database consisting of records of invoices out- \nstanding. To see why, imagine trying to exchange your firm\u2019s stock of receivables \nfor cash-you can sell them to a collection agency, but only for much less than 100 \ncents on the dollar. Though the contents of the stock of receivables is information \nand not a material quantity, it is nevertheless conserved-you cannot sell a given \nstock of receivables more than once (not legally, anyway). Stocks can represent in- \nformation as well as more tangible quantities such as people, money, and materi- \nals. Stocks can also represent intangible variables including psychological states, \nperceptions, and expectations such as employee morale, the expected rate of infla- \ntion, or perceived inventory.\n\n202 \nPart I1 Tools for Systems Thinking \nFIGURE 6-4 \nStock and flow \nstructure of \naccounts \nreceivable \nThe material flow- \ning through the \nnetwork is actually \ninformation about \ncustomers and the \namounts they owe. \nThis information is \nconserved-the \nonly way a receiv- \nable, once billed, \nis removed from \nthe stock is if the \ncustomer pays or \ndefaults. Informa- \ntion about the size \nand composition of \naccounts payable, \nhowever, can be \nmade available \nthroughout the \nsystem and is \nnot depleted by \nusage. \nInformation about \nAccounts Receivable \nAvailable to Deci",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 226
  },
  {
    "child_id": "d651a026-2ec5-4d08-a4ce-68d8140970f7",
    "parent_id": "cf3a3faa-8020-41db-9c01-ae71bb104573",
    "text": " of \naccounts \nreceivable \nThe material flow- \ning through the \nnetwork is actually \ninformation about \ncustomers and the \namounts they owe. \nThis information is \nconserved-the \nonly way a receiv- \nable, once billed, \nis removed from \nthe stock is if the \ncustomer pays or \ndefaults. Informa- \ntion about the size \nand composition of \naccounts payable, \nhowever, can be \nmade available \nthroughout the \nsystem and is \nnot depleted by \nusage. \nInformation about \nAccounts Receivable \nAvailable to Decision \nMakers \nAccounts \nReceivable \nBillings \nPayments \nDefaults \nc3 \n6.2.4 \nState-Determined Systems \nThe theory of dynamic systems takes a state-determined system or state variable \napproach. The only way a stock can change is via its inflows and outflows. In turn, \nthe stocks determine the flows (Figure 6-5). \nSystems therefore consist of networks of stocks and flows linked by informa- \ntion feedbacks from the stocks to the rates (Figure 6-6). As shown in the figure, the \ndeterminants of rates include any constants and exogenous variables. These too are \nstocks. Constants are state variables that change so slowly they are considered to \nbe constant over the time horizon of interest in the model. Exogenous variables are \nstocks you have chosen not to model explicitly and are therefore outside the model \nboundary. For example, in a model of the demand for a new video game, the size \nof the potential market might depend on the population between, say, ages 4 and \n20. The product life cycle will last a few years at most. Over this time horizon the \npopulation between 4 and 20 years of age is not likely to change significantly and \ncan reasonably be assumed constant. Alternatively, you could model the stock of \nchildren in the target age group as an exogenous variable, using census data and \nprojections to estimate its values. Making population constant or exogenous is ac- \nceptable in ths case since there are no significant feedbacks between sales of video \ngames and birth, death, or migration rates. \n6.2.5 \nAuxiliary Variables \nAs illustrated in Figure 6-6, mathematical description of a system requires only the \nstocks and their rates of change. For ease of communication and clarity, however, \nit is often helpful to define intermediate or auxiliary variables. Auxiliaries consist \nof functions of stocks (and constants or exogenous inputs). For example, a popula- \ntion model might represent the net birth rate as depending on population and the \nfractional birth rate; fractional birth rate in turn can be modeled as a function of \nfood per capita. The left side of Figure 6-7 shows the structure and equations for\n\nChapter 6 Stocks and Flows \n203 \nFIGURE 6-5 \nState-determined \nsystems \nSystems evolve \nby feedback of \ninformation frorn \nthe state of the \nsystem to the \nflows that alter \nthe states. \nLeft Causal loop \nrepresentation in \nwhich the stock. \nand flow \nstructure is not \nexplicit. \nRight: Explicit \nstock and flow \nstructure for the \nsame feedback \nThe e",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 226
  },
  {
    "child_id": "6e8fd5b7-5855-44c2-966c-1f5fc0db8243",
    "parent_id": "cf3a3faa-8020-41db-9c01-ae71bb104573",
    "text": "fractional birth rate in turn can be modeled as a function of \nfood per capita. The left side of Figure 6-7 shows the structure and equations for\n\nChapter 6 Stocks and Flows \n203 \nFIGURE 6-5 \nState-determined \nsystems \nSystems evolve \nby feedback of \ninformation frorn \nthe state of the \nsystem to the \nflows that alter \nthe states. \nLeft Causal loop \nrepresentation in \nwhich the stock. \nand flow \nstructure is not \nexplicit. \nRight: Explicit \nstock and flow \nstructure for the \nsame feedback \nThe equations \ncorrespond to the \nstock and flow \nmap. The net \nrate of change \nof ithe stock is a \nfunction of the \nstock itself, \nclosing the \nfeedback loop. \nloop. \nNet Rate of \nState of thc \nChange \nSystem \nState of the \nSystem \n(Stock) \nNet Rate of \nChange \nState of the System = INTEGRAL(Net Rate of Change, State of the Systemt,) \nNet Rate of Change = f (State of the System) \nthe model. The Net Birth Rate accumulates in the Population stock. The auxiliary \nvariables Fractional Birth Rate and Food per Capita are neither stocks nor flows. \nThey are functions of the stocks (and exogenous inputs, in this case Food). Popu- \nlation participates in two feedback loops: a positive loop (more people, more \nbirths, more people) and a negative loop (more people, less food per person, lower \nfractional net birth rate, fewer births). The inclusion of the auxiliary variables dis- \ntinguishes the two loops and allows unambiguous assignment of link and loop po- \nlarities. \nThe auxiliaries can always be eliminated and the model reduced to a set of \nequations consisting only of stocks and their flows. By substituting the equation \nfor Food per Capita into the equation for Fractional Birth Rate and then substitut- \ning the result into the equation for Net Birth Rate, you can eliminate the auxiliaries, \nreducing the model to one with only Net Birth Rate and Population. The right side \nof Figure 6-7 shows this model and its equations. Though the model is mathemat- \nically equivalent to the model with auxiliaries, it is harder to explain, understand, \nand modify. Note that in the reduced form model population enters the equation for \nthe rate of change of population in both the numerator and denominator. The \npolarity of the causal link between Population and Net Births is now ambiguous, \nand it is not possible to distinguish the two feedback loops involving population \nand births. \nThe process of creating the reduced form model by substitution of intermedi- \nate variables into their rates is a general one and can be carried out on any model. \nHowever, the use of auxiliary variables is critical to effective modeling. Ideally, \neach equation in your models should represent one main idea. Don\u2019t try to econo- \nmize on the number of equations by writing long ones that embed multiple con- \ncepts. These long equations will be hard for others to read and understand. They \nwill be hard for you to understand. Finally, equations with multiple components \nand ideas are hard to change if yo",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 226
  },
  {
    "child_id": "ed3dc659-543a-4ddd-a4e3-97d68fee963c",
    "parent_id": "cf3a3faa-8020-41db-9c01-ae71bb104573",
    "text": "s is a general one and can be carried out on any model. \nHowever, the use of auxiliary variables is critical to effective modeling. Ideally, \neach equation in your models should represent one main idea. Don\u2019t try to econo- \nmize on the number of equations by writing long ones that embed multiple con- \ncepts. These long equations will be hard for others to read and understand. They \nwill be hard for you to understand. Finally, equations with multiple components \nand ideas are hard to change if your client disagrees with one of the ideas.\n\n204 \nPart I1 Tools for Systems Thinking \nFIGURE 6-6 Networks of stocks and flows are coupled by information feedback. \nStocks accumulate their rates of flow; information about the stocks feeds back to alter the rates, \nclosing the loops in the system. Constants are stocks changing too slowly to be modeled explicitly; \nexogenous variables are stocks outside the model boundary (shown by the rectangle with rounded \ncorners). \nEquation representation: The derivatives of the stocks in dynamic systems are, in general, nonlinear \nfunctions of the stocks, the exogenous variables, and any constants. In matrix notation, the rates of \nchange dS/dt are a function f ( )  of the state vector S, the exogenous variables U and the constants C: \ndS/dt = f(S, U, C) \nFor the diagram below, the equation for the rate of change of S4 is \ndS&t = fq(S3, Sq, U3, C3) \nExogenous \nInput, \nExogenous \nInputs \nExogenous \nInput3 \n6.2.6 \nStocks Change Only Through Their Rates \nStocks change only through their rates of flow. There can be no causal link directly \ninto a stock. Consider a model for customer service. Customers arrive at some rate \nand accumulate in a queue of Customers Awaiting Service. The queue could be a \nline at a fast food restaurant, cars awaiting repair at a body shop, or people on hold \ncalling for airline reservations. When the service is completed customers depart \nfrom the queue, decreasing the stock of customers waiting for service. The rate at \nwhich customers can be processed depends on the number of service personnel, \ntheir productivity (in customers processed per hour per person), and the number of \nhours they work (the workweek). If the number of people waiting for service \nincreases, employees increase their workweek as they stay an extra shift, skip \nlunch, or cut down on breaks.",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 226
  },
  {
    "child_id": "5f4e9a5a-ee56-4e70-b234-d5c2346a34a0",
    "parent_id": "c1125a40-2720-4e89-99d1-c317081bb155",
    "text": "Chapter 6 Stocks and Flows \n*z \nb \n205 \nPopulation \nFIGURE 6-7 \nAuxiliary variables \nLeft:A simple population model with auxiliary variables. Fractional Birth Rate and Food per Capita are \nneither stocks nor flows, but intermediate concepts added to the model to aid clarity. \nRight: The same model with the auxiliary variables eliminated by substitution into the rate equation. \nThe link from Population to Net Birth Rate now has an ambiguous sign, a poor practice. \nCorrect \nIncorrect \nFood \nPopulation = INTEGRAL(Net Birth Rate, Populationto) \nNet Birth Rate = f\u2019opulation * Fractional Birth Rate \nFractional Birth Rate = f(Food per Capita) \nFood per Capita = Food/Population \nPopulation = INTEGRAL(Net Birth Rate, PopulationJ \nNet Birth Rate = Population * f(Food/Population) \nI have often seen people in workshops draw the diagram shown in the top of \nFigure 6-8. They correctly recognize that the rate at which customers are processed \nis the product of Service Staff, Productivity, and Workweek and that higher queues \nof waiting customers lead to longer hours and hiring of additional staff, forming \ntwo balancing feedbacks. But often people draw information feedbacks directly \nfrom the workweek and service staff to the stock of Customers Awaiting Service, \nassigning them a negative polarity. They reason that an increase in the workweek \nor staff level decreases the number of customers remaining in the queue, thus clos- \ning the negative feedback loops. \nThe correct diagram is shown in the lower panel of Figure 6-8. The only way \ncustomers can exit the stock is via the departure rate. The departure rate is the \nproduct of the number of staff, their workweek, and their productivity. An increase \nin any of these inputs boosts the rate at which customers are processed and leave \nthe queue. The balancing feedbacks are still present: A longer queue of waiting \ncustomers leads to longer hours and more staff and an increase in the processing \nrate. The valve controlling the outflow from the stock of waiting customers opens \nwider, and customers depart the queue at a higher rate. The polarities of the infor- \nmation links in the feedback loop are all positive, but an increase in the customer \ndeparture rate causes a reduction in the stock of waiting customers because the de- \nparture rate is an outflow from the stock.\n\n206 \nv \nY \nPart I1 Tools for Systems Thinking \nCustomers \nw \n- \nWaiting for \nY \nFIGURE 6-8 \nStocks change \nonly through \ntheir rates. \nTop: Incorrect \nstock and flow \nmap of a service \noperation. Work- \nweek, Service \nStaff ,and other \nvariables cannot \ndirectly alter the \ntomers Awaiting \nService. \nBofforn: Corrected \ndiagram. The \nWorkweek, \nnumber of Service \nStaff, and Produc- \ntivity drive the \nCustomer Depar- \nture Rate, which \ndecreases the \ntomers Awaiting \nService. \nstock of CUS- \nstock of CUS- \nIncorrect - \nCustomers \nY \nCustomer \n- \nCustomer \nStaff \n+ \nCorrect \nArrival \n/ /  \nDeparture \nRate \nWorkweek \n6.2.7 \nContinuous Time and Instanta",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 230
  },
  {
    "child_id": "f78ee8d1-c72b-4a35-a588-eac314f7dcc5",
    "parent_id": "c1125a40-2720-4e89-99d1-c317081bb155",
    "text": " and flow \nmap of a service \noperation. Work- \nweek, Service \nStaff ,and other \nvariables cannot \ndirectly alter the \ntomers Awaiting \nService. \nBofforn: Corrected \ndiagram. The \nWorkweek, \nnumber of Service \nStaff, and Produc- \ntivity drive the \nCustomer Depar- \nture Rate, which \ndecreases the \ntomers Awaiting \nService. \nstock of CUS- \nstock of CUS- \nIncorrect - \nCustomers \nY \nCustomer \n- \nCustomer \nStaff \n+ \nCorrect \nArrival \n/ /  \nDeparture \nRate \nWorkweek \n6.2.7 \nContinuous Time and Instantaneous Flows \nThe stock and flow perspective (and its equivalent integral or differential equation \nstructure) represents time as unfolding continuously. That is, as our experience \nsuggests, time progresses smoothly and continuously. In system dynamics we \nalmost always represent time as continuous. Events can happen at any time; \nchange can occur continuously; and time can be divided into intervals as fine as \none desires.] \n'In numerical simulation time is divided into discrete intervals. However, these intervals must \nbe small enough that the numerical solution is a good approximation of the underlying continuous \ndynamics, and model dynamics cannot depend on the length of the solution interval (cutting it in \nhalf, e.g., should not affect any of your conclusions). In discrete time or difference equation sys- \ntems the time interval is an irreducible minimum time delay in every feedback loop and often has \na large impact on the dynamics. Appendix A discusses numerical integration and the selection of an \nappropriate time step for your simulations.\n\nChapter 6 Stocks and Flows \n207 \nA flow at any time is defined to be its instantaneous value-the rate at which \nwater is flowing into your bathtub right now. Mathematically, the net flow to a \nstock (inflows less outflows) is the instantaneous rate of change of the stock-its \nderivative (this is the meaning of equation 6-2). No one can measure the instanta- \nneous value of any flow. The government does not and cannot report the GDP at a \nparticular moment but instead reports the average rate of production over some \nprior, finite interval of time (typically a quarter of a year). Likewise, quarterly re- \nports of a firm\u2019s sales are the cumulative sales during the quarter, not the instanta- \nneous sales rate at the end of the quarter. During the quarter sales likely varied \nsubstantially. Sales reports at more frequent intervals such as monthly or even \ndaily are better approximations of the instantaneous sales rate but still represent av- \nerages taken over some prior, finite interval. Similarly, the speedometer of a car \ndoes not measure its instantaneous velocity. Because the components of the veloc- \nity sensor and instrumentation have inertia, the speedometer indicates an average \nof the velocity over a (short) prior interval. \nAs the length of the measurement interval shrinks, the reported average rate \nbecomes a better approximation of the instantaneous rate. Most speedometers re- \nspond quickly relative",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 230
  },
  {
    "child_id": "5cf28574-3eb3-42d6-969e-7228528f0f1c",
    "parent_id": "c1125a40-2720-4e89-99d1-c317081bb155",
    "text": "still represent av- \nerages taken over some prior, finite interval. Similarly, the speedometer of a car \ndoes not measure its instantaneous velocity. Because the components of the veloc- \nity sensor and instrumentation have inertia, the speedometer indicates an average \nof the velocity over a (short) prior interval. \nAs the length of the measurement interval shrinks, the reported average rate \nbecomes a better approximation of the instantaneous rate. Most speedometers re- \nspond quickly relative to the rate of change of the car\u2019s true velocity, so for practi- \ncal purposes the average velocity reported on the instrument panel is the same as \nthe actual, current velocity. On the other hand, the delays in reporting the state of \nthe economy or the profits of a company are often long relative to their rates of \nchange and dramatically influence the stability of the system. Though we might \ndevelop instruments for our physical and social systems that shrink the delays in \nmeasuring and reporting rates of flow, we can never measure the instantaneous \nvalue of the flows affecting any stock. \n6.2.8 \nContinuously Divisible versus \nQuantized Flows \nJust as time can be represented as unfolding continuously or in discrete intervals, \nso too the units flowing into and out of stocks can be thought of either as continu- \nously divisible or as a discrete numbers of items. Most flows are actually quan- \ntized, meaning they consist of collections of individual items which cannot be \ndivided into arbitrarily small units. Oil tankers are commissioned one at a time- \nit is not meaningful to speak of launching half a tanker. Company hiring consists \nof a whole number of people. Even the flow in a river consists of an (astronomi- \ncally large) integer number of water molecules. The stock and flow concept and \nthe four equivalent notations shown in Figure 6-2 apply whether the flow is con- \nceived to be infinitely divisible or quantized. The metaphor of the flow of water \ninto a bathtub emphasizes our everyday experience of water as a continuously di- \nvisible substance-we aren\u2019t concerned with the identity of the individual water \nmolecules. However, if it were important to our purpose, we could just as easily \nimagine that the tub is filled by a lumpy flow of individual ice cubes. Whether con- \ntinuous or quantized, the quantity in the stock is always the accumulation of the in- \nflows to the stock less its outflows. \nIn many models it is appropriate and useful to approximate the flow of individ- \nual items as a continuous stream. In modeling the cash flow of a large organization\n\n208 \nPart I1 Tools for Systems Thinking \nyou usually do not need to track individual payments; it is a perfectly acceptable \napproximation to consider the flow of revenue and expenditures as continuous in \ntime and continuously divisible (though of course the accounting department must \ntrack individual payments). Similarly, though organizations hire discrete, whole in- \ndividuals, it is us",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 230
  },
  {
    "child_id": "40a509fd-9a59-4b47-9df3-76aae8c889ed",
    "parent_id": "c1125a40-2720-4e89-99d1-c317081bb155",
    "text": "the flow of individ- \nual items as a continuous stream. In modeling the cash flow of a large organization\n\n208 \nPart I1 Tools for Systems Thinking \nyou usually do not need to track individual payments; it is a perfectly acceptable \napproximation to consider the flow of revenue and expenditures as continuous in \ntime and continuously divisible (though of course the accounting department must \ntrack individual payments). Similarly, though organizations hire discrete, whole in- \ndividuals, it is usually acceptable to assume the flows of people are continuously \ndivisible. Some clients are troubled by the fractional people your model will gen- \nerate, but almost always the error is insignificant compared to the measurement er- \nror in parameters including the number of employees the firm actually has. Since \npeople can be hired part time, work in job-sharing situations, or be assigned to \nmultiple projects, it is quite meaningful to speak of fractional employees, measured \nin FTE (Full-Time Equivalent) people. \nWhen the purpose of the model requires tracking the individual people, for ex- \nample modeling the behavior of people entering the line at the supermarket to de- \ntermine the optimal number of checkout counters, then people can be modeled as \ndiscrete individuals arriving at discrete points; this is a classic modeling paradigm \nin queuing theory (Prabhu 1997; Gross and Harris 1998; Papadopoulos 1993). Yet \neven in many queuing applications, the continuous time, continuous flow approx- \nimation works extremely well and the errors it introduces are often small compared \nto measurement error and parameter uncertainty in the real system. The decision to \nrepresent stocks and flows as continuous or discrete always depends on the pur- \npose of the model. For example, if your purpose is to understand the dynamics of \nprice and the origin of cycles in the oil tanker market (see chapter 20), it is fine to \nassume that the rates of tanker ordering, construction, and scrappage are continu- \nous in time and continuously divisible. In contrast, if your purpose were to model \nthe arrival and offloading of tankers to optimize port facilities you would have to \nmodel the ships as discrete entities. \n6.2.9 \nWhich Modeling Approach Should You Use? \nThe choice of modeling technique and software will depend on which assumptions \nabout the stocks and flows in your system are appropriate to your purpose. In all \ncases make sure your modeling software and method can include the feedback \nprocesses you consider important. In modeling the behavior of people in line at the \nsupermarket, for example, you might choose to use a discrete time, quantized flow \nrepresentation and select a stochastic modeling package, or even use a spreadsheet. \nBe sure, however, that your tools allow you to capture behavioral feedbacks such \nas the feedback from the length of the line to the rate at which people join the line. \nSome models and a great many of the theorems in queuing theory a",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 230
  },
  {
    "child_id": "02ec53ee-1e34-4783-b0d7-d62ea6695a7d",
    "parent_id": "c1125a40-2720-4e89-99d1-c317081bb155",
    "text": "he feedback \nprocesses you consider important. In modeling the behavior of people in line at the \nsupermarket, for example, you might choose to use a discrete time, quantized flow \nrepresentation and select a stochastic modeling package, or even use a spreadsheet. \nBe sure, however, that your tools allow you to capture behavioral feedbacks such \nas the feedback from the length of the line to the rate at which people join the line. \nSome models and a great many of the theorems in queuing theory assume that the \nrate of arrivals to a queue such as the checkout line is exogenous. People actually \nchoose to enter a line based on its length (more precisely, their estimate of ex- \npected waiting time). A long line will cause people to switch to another, defer their \nshopping to a less crowded time of day, or even go to a different store. Such balk- \ning creates a powerful negative feedback loop: The longer the line, the smaller the \narrival rate. Omitting such feedback processes from your model in the interests of \nanalytical tractability or programming convenience will often lead to a fatal flaw \nin your analysis and policy conclusions.",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 230
  },
  {
    "child_id": "8aef6b0d-eaea-4f1e-a2d0-9d43e3eb533f",
    "parent_id": "659eb794-d106-40d0-b4e9-865250dc3b2b",
    "text": "Chapter 6 Stocks and Flows \n209 \n6.2.1 0 \nProcess Point: \nPortraying Stocks and Flows in Practice \nEach of the stock and flow representations in Figure 6-2 (the bathtub, stock and \nflow diagram, integral equation, and differential equation) contains precisely the \nsame information. They are exactly equivalent. Which should you use to develop \nand present your models, especially when you are working in a team? \nThe answer depends on the context of the modeling project you are doing and \nthe background of your client team. While many mathematically sophisticated \nmodelers scoff at the idea of explaining a complex model using bathtubs and pipes, \nI have many times seen otherwise brilliant modeling efforts founder because the \nanalyst tried to explain a model using differential equations and mathematical no- \ntation-or the simulation code-to a client team with little technical background. \nOne of the worst things a consultant can do is humiliate the client. Showing off \nyour mathematical knowledge by using differential equations, lots of Greek letters, \nand other notation the client never studied or forgot a long time ago is a sure-fire \nway to convince your clients you care more for the elegance of your equations than \nfor helping them solve their problem. \nStock and flow diagrams contain the same information as the more mathemat- \nically formal notation but are easier to understand and to modify on the fly. Still, \nsome team members consider even the stock and flow diagram format to be too ab- \nstract. I have often seen clever graphics of tanks, pipes, and valves used to excel- \nlent effect with client teams. For example, a consulting project with a multinational \nchemicals firm represented the flows of production, inventories, shipments, and \ncustomer stocks-along with capacity, cash, and even equipment defects-as a se- \nries of pipes, valves, and tanks. The team members were able to grasp the stock \nand flow structure readily since they were all familiar with the tanks and pipes car- \nrying materials in their plants. In fact, most of the client team were engineers by \ntraining and had plenty of background in mathematics. Yet several commented that \nthey never really understood how the business worked until they saw the chart \nshowing its stock and flow structure as tanks and pipes. \nWhat if your clients have even less technical training than these chemical com- \npany executives? The bathtub metaphor is often used to good effect, as illustrated \nby the case of automobile leasing (see Figure 2.4). What if the stocks and flows in \nyour model aren\u2019t as tangible as barrels of oil or automobiles? Get creative. In a \nmanagement flight simulator of insurance claims processing (Kim 1989; Diehl \n1994), a flow of letters arriving to an inbox represented the addition of new claims \nto the stock of unresolved claims. Letters containing checks flowed out to the cus- \ntomers as claims were settled. Icons of people represented the stock and flow struc- \nture of ",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 234
  },
  {
    "child_id": "bdf575da-3797-43d6-84a3-706ebfdc1a4d",
    "parent_id": "659eb794-d106-40d0-b4e9-865250dc3b2b",
    "text": " of automobile leasing (see Figure 2.4). What if the stocks and flows in \nyour model aren\u2019t as tangible as barrels of oil or automobiles? Get creative. In a \nmanagement flight simulator of insurance claims processing (Kim 1989; Diehl \n1994), a flow of letters arriving to an inbox represented the addition of new claims \nto the stock of unresolved claims. Letters containing checks flowed out to the cus- \ntomers as claims were settled. Icons of people represented the stock and flow struc- \nture of claims adjusters (Figure 6-9). Participants in workshops using the model \nwere able to understand the system structure much better than if the more abstract \nsymbols had been used. \nI am not recommending that you keep the equations or stock and flow dia- \ngrams hidden from your client. Never hide your model from a curious client. You \nshould always look for and create opportunities for client team members to learn \nmore about the modeling process; you should always be prepared to explain the \nworkings of your model.\n\n21 0 \nPart I1 Tools for Systems Thinking \nFIGURE 6-9 \nStocks and flows \nof claims and \nclaims adjusters \nin an insurance \ncompany \nHiring \nm#& \nAdjusters \nTurnover \nClaims \nReceived \nClaims \nOutstanding \nClaims \nSettled \nSource: Kim 1989. \nAnd while I caution the mathematically sophisticated modeler against overly \ntechnical presentation, the opposite problem can also arise: some clients are of- \nfended by what they consider to be simplistic cartoon diagrams and prefer what \nthey view as the more professional presentation of stock and flow diagrams or \neven equations. As always, you must get to know your client deeply and early in \nthe modeling process. \nFinally, a caution for those with less technical training and mathematical back- \nground: Clients may not need to understand the deep relationship between their \nbathtub and the mathematics underlying stocks and flows, but you do. While you \ndon\u2019t need to be able to solve differential equations to be a successful modeler, you \ndo need to understand the structure and dynamics of stocks and flows thoroughly \nand rigorously. \n6.3 \nMAPPING STOCKS AND FLOWS \n6.3.1 \nWhen Should Causal Loop Diagrams Show \nStock and Flow Structure? \nCausal diagrams can be drawn without showing the stock and flow structure of a \nsystem. Or, as shown in Figure 6-8, they can include the stock and flow structure \nexplicitly. When should you include the stock and flow structure, and when can \nyou omit it? Generally, you should include stock and flow structures representing \nphysical processes, delays, or stocks whose behavior is important in the dynamics \nyou seek to explain. For example, consider the flow of a product through a supply \nchain from producer to consumer. The product travels through a network of stocks \n(inventories) and flows (shipment and delivery rates). The stock and flow repre- \nsentation for this process is shown in the top panel of Figure 6-10. \nProduction starts add to the stock of work in process (WI",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 234
  },
  {
    "child_id": "7833bae9-b4a0-494e-9da0-49fd8a8c1cfa",
    "parent_id": "659eb794-d106-40d0-b4e9-865250dc3b2b",
    "text": "de stock and flow structures representing \nphysical processes, delays, or stocks whose behavior is important in the dynamics \nyou seek to explain. For example, consider the flow of a product through a supply \nchain from producer to consumer. The product travels through a network of stocks \n(inventories) and flows (shipment and delivery rates). The stock and flow repre- \nsentation for this process is shown in the top panel of Figure 6-10. \nProduction starts add to the stock of work in process (WIP) Inventory. The \nProduction Completion Rate reduces the stock of WIP and increases the stock of\n\nChapter 6 Stocks and Flows \nWork in \nProcess \n*z-b \nInventory \n21 1 \nv \nFinished \nL-l \nInventory \nL1 \nn \nA \nFIGURE 6-1 0 Stock and flow vs. causal diagram representations \nStock and Flow Representation of a Manufacturing Process \nStart Rate \nCompletion \nRate \nRate \nCausal Loop Diagram Representation of the Manufacturing Process \nA- \nk-----l \nProduction \nWork in \nProduction \nFinished \nShipment \nStart Rate \nProcess \nCompletion \nInventory \nRate \nInventory \nRate \nFinished Inventory. Shipments to customers deplete Finished Inventory. Equiva- \nlently, the stock of WIP accumulates production starts less completions, and the \nstock of finished inventory accumulates production completions less shipments. \nThe causal diagram representation is shown in the bottom panel of Figure \n6- 10. While technically correct, the causal diagram makes it hard to see the physi- \ncal flow of product through the system and the conservation of material in the \nstock and flow chain. It is often confusing to interpret the polarities of the causal \nlinks when they involve stocks and flows. An increase in the Production Comple- \ntion Rate causes Finished Inventory to rise above what it would have been other- \nwise (it rises at a faster rate), hence the polarity of the link is positive. A decrease \nin production completions, however, does not cause finished inventory to fall. \nRather, a decrease in the production completion rate causes finished inventory to \nbe less than it would have been. You cannot say whether finished inventory will be \nrising or falling based on the behavior of the production rate alone. Inventory will \nrise only when production completions exceed the shipment rate; that is, inventory \nrises only when we add to it faster than we remove units from it. You need to know \nthe values of all the flows affecting a stock to determine its behavior. Richardson \n(1986a, 1997) carefully documents the pitfalls of causal diagrams, most of which \ninvolve the failure of causal diagrams to show the stocWflow distinction. \nCIiALLEMGE \nAdding Stock and Flow Structure to Causal Diagrams \nConsider the causal loop diagrams in chapter 5. For each, redraw the diagram \nshowing the important stock and flow structure along with the feedback structure \nshown in the diagram. In particular, identify the main stocks and flows in the fol- \nlowing conceptualization case studies presented in chapter 5:\n\n",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 234
  },
  {
    "child_id": "5fd6c2e3-13a8-4f46-a44a-6fcca8c0c3c5",
    "parent_id": "659eb794-d106-40d0-b4e9-865250dc3b2b",
    "text": "ents the pitfalls of causal diagrams, most of which \ninvolve the failure of causal diagrams to show the stocWflow distinction. \nCIiALLEMGE \nAdding Stock and Flow Structure to Causal Diagrams \nConsider the causal loop diagrams in chapter 5. For each, redraw the diagram \nshowing the important stock and flow structure along with the feedback structure \nshown in the diagram. In particular, identify the main stocks and flows in the fol- \nlowing conceptualization case studies presented in chapter 5:\n\n21 2 \nPart I1 Tools for Systems Thinking \n1. The workload management example. \n2. The oil industry and horse racing examples. \n3. The traffic congestion example. \nIn each case, consider whether the explicit representation of the main stocks and \nflows enhances your ability to understand the dynamics of the system or merely \nclutters the diagram. \nLinking Stock and Flow Structure with Feedback \nOften understanding the dynamics of a system requires linking the feedback loop \nstructure with the stock and flow structure. As an example, consider the gasoline \nshortages of the 1970s. In 1979 the United States (and some other industrialized \nnations) experienced a severe gasoline shortage. Iran\u2019s exports of oil dropped in \nthe wake of the revolution there, and petroleum prices on the world market in- \ncreased sharply. Within weeks, a shortage of gasoline began. Some service stations \nfound their tanks emptied before the next delivery. Drivers, remembering the first \noil embargo in 1973 and worried that they wouldn\u2019t be able to get gas, began to top \noff their tanks, instead of filling up only when the gas gauge fell toward empty. \nSoon, long lines of cars were seen idling in front of gas stations, and \u201cSorry-No \nGas\u201d signs sprouted along the highways of America as station after station found \nits underground tanks pumped dry. The shortage was the top story on the evening \nnews-aerial footage of cars lined up around the block, close-ups of \u201cNo Gas\u201d \nsigns, and interviews with anxious drivers dominated the news. In some states, \nmandatory rationing was imposed, including limiting purchases to, for example, no \nmore than $10 worth of gas. California imposed oddeven purchase rules: Drivers \nwere allowed to buy gas only every other day, based on whether their license plate \nnumber was odd or even. It seemed that the supply of gasoline had been slashed. \nCuriously, the impact of the Iranian revolution on the flow of oil to the US was \nsmall. True, US oil imports from the Persian Gulf (including Iran) fell by 500,000 \nbarrels per day between 1978 and 1979, about 3% of US consumption, but imports \nfrom other nations increased by 640,000 barrels per day, so imports in 1979 actu- \nally increased by 140,000 barrels per day. Domestic production fell by 150,000 \nbarrels per day, so total supply was essentially constant, while consumption fell by \nabout 330,000 barrels per day, a drop of 2% from 1978. Plainly, for the year as a \nwhole, there was no shortage. But if the flow of",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 234
  },
  {
    "child_id": "cbab6b79-dcc3-4d59-bd97-cf7f2b04a947",
    "parent_id": "659eb794-d106-40d0-b4e9-865250dc3b2b",
    "text": " Gulf (including Iran) fell by 500,000 \nbarrels per day between 1978 and 1979, about 3% of US consumption, but imports \nfrom other nations increased by 640,000 barrels per day, so imports in 1979 actu- \nally increased by 140,000 barrels per day. Domestic production fell by 150,000 \nbarrels per day, so total supply was essentially constant, while consumption fell by \nabout 330,000 barrels per day, a drop of 2% from 1978. Plainly, for the year as a \nwhole, there was no shortage. But if the flow of oil into the US was essentially \nconstant, what caused the shortage? Where did the gas go? \nFirst, develop a stock and flow map for the gasoline distribution system. You \nneed not consider the entire supply chain for gasoline but can focus on retail dis- \ntribution. Your diagram should begin with the flow of gasoline to service stations, \nthen represent the stock and flow structure for its subsequent storage, sale, and \neventual combustion. \nOnce you\u2019ve mapped the stock and flow structure, identify the information in- \nputs to the rates of flow in your diagram. Assume that the rate at which gasoline is \ndelivered to service stations is exogenous. By identifying the information inputs to",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 234
  },
  {
    "child_id": "c654041e-d587-4611-9024-ae9ef0144b1c",
    "parent_id": "afba19f3-b9e1-49f7-8669-6081c441a10a",
    "text": "Chapter 6 Stocks and Flows \n21 3 \nthe flows in your stock and flow map, you will be closing some feedback loops, \nloops which should help explain why the shortage occurred and answer the ques- \ntion, Where did the gas go? Be sure to ask how individual drivers would learn \nabout the shortage and what their behavior would then be. \nFinally, using your diagram, assess the likely effectiveness of the maximum \npurchase and odd/even policies. Do policies of this type help ease the shortage or \nmake it worse? Why? What policy would you recommend to ease the shortage? \n6.3.2 \nAggregation in Stock and Flow Mapping \nThe ability to map the stocks and flows in a system is critical to effective model- \ning. Usually it is wise to identify the main stocks in a system and then the flows \nthat alter those stocks. You must select an appropriate level of aggregation and \nboundary for these stock and flow maps. The level of aggregation refers to the \nnumber of internal categories or stocks represented. The boundary refers to how \nfar upstream and downstream one chooses to represent the flows of materials and \nother quantities in the model. \nTo illustrate, consider the manufacturing process discussed above in which \nmaterial flows from production starts through WIP inventory to finished inventory \nand finally shipment to the customer. All the various parts, components, and sub- \nassemblies are aggregated together into a single stock of WIP. And though the firm \nmay carry tens of thousands of SKUs (stock keeping units), these individual items \nare all aggregated into a single stock of finished inventory. For many purposes the \naggregate picture is sufficient. However, the model purpose might require more de- \ntail. If the purpose involved a closer look at the manufacturing process, you could \ndisaggregate the stock of work in process serially to represent the different stages, \nsuch as part fabrication, assembly, and testing (Figure 6- 11). \nThe sum of the three intermediate stocks is the total work in process inventory, \nbut now the model tracks throughput at a finer level of resolution and can represent \nmore potential bottlenecks in the production process. Note that in both the original, \naggregate diagram and in this more detailed diagram there is no provision for re- \nwork or scrap. All units started are eventually completed-the flow of widgets \nthrough the system is conserved. Note also that as material flows through the sys- \ntem it is transformed from parts to finished product. To maintain consistent units \nof measure we might measure parts in widget equivalents-that is, a widget\u2019s \nworth of parts. If necessary for the purpose, you can further disaggregate the stock \nand flow structure.\n\n21 4 \nPart I1 Tools for Systems Thinking \nFIGURE 6-11 \nDisaggregated \nstock and flow \nmap for a \nmanufacturing \nprocess \nProduction \nP Start Rate \nWork in \nProcess \nInventory \nParts in \nProcess \nAssembly \nStart Rate \nAssemblies in \nProcess \nTest \nStart Rate \nf \nProduct in \nTes",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 238
  },
  {
    "child_id": "1adbbea6-4bf3-40fb-a069-f701521a24b2",
    "parent_id": "afba19f3-b9e1-49f7-8669-6081c441a10a",
    "text": "product. To maintain consistent units \nof measure we might measure parts in widget equivalents-that is, a widget\u2019s \nworth of parts. If necessary for the purpose, you can further disaggregate the stock \nand flow structure.\n\n21 4 \nPart I1 Tools for Systems Thinking \nFIGURE 6-11 \nDisaggregated \nstock and flow \nmap for a \nmanufacturing \nprocess \nProduction \nP Start Rate \nWork in \nProcess \nInventory \nParts in \nProcess \nAssembly \nStart Rate \nAssemblies in \nProcess \nTest \nStart Rate \nf \nProduct in \nTesting \nLn4 \nProduction \nCompletion \nRate \nFinished \nInventory \nShipment \nRate \nEach of the three stages of WIP identified in Figure 6-11 consists of other steps, \neach with its own stock and flow structure. Suppose you learn that part fabrication\n\nChapter 6 Stocks and Flows \n21 5 \nat the plant you are modeling actually requires several operations: welding, grind- \ning, and painting. Observation of the grinding operation reveals that workers draw \nparts ready for grinding from a buffer generated by the welding operation. When \ngrinding is completed, the parts are placed in a bin which then goes on to the next \noperation (painting). The welding and paint shops are similar. Draw the disaggre- \ngated stock and flow map for the part fabrication step to show the welding, grind- \nUp to now the discussion has focused on serial disaggregation: how finely to \nbreak down the stages of processing. Throughout, the many different parts and \nproducts produced by a typical firm are aggregated into a single chain of stocks \nand flows. In many situations the process occurs not only in series but also in- \nvolves parallel activities. You could of course replicate the main stock and flow \nchain for each product (many simulation software packages support array struc- \ntures for this purpose). When there are multiple, parallel activities you must make \na decision not only about the number of stages of the process to represent but also \nhow much to aggregate the different parallel processes together. For example, the \nassembly process for automobiles involves integrating the chassis and engine. \nEach subassembly is built on a separate line, often in plants far from the final as- \nsembly point. Suppose the client argues that you can\u2019t aggregate all subcompo- \nnents into a single flow of parts, but must separate chassis and engine fabrication \n(omit the body for simplicity). The stock and flow map for the assembly process \nmight be shown as in Figure 6-12. \nThere are now three distinct stock and flow chains, one each for engines, chas- \nsis, and assembled cars. Because the three chains are separate, each can be mea- \nsured in different units: engines, chassis, and cars. The three chains are linked \nbecause each car beginning the final assembly process requires one engine from \nthe stock of completed engines and one chassis from the stock of completed chas- \nsis. The information arrows from the assembly rate to the engine and chassis use \nrates show these links. The number of engine",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 238
  },
  {
    "child_id": "866de8ea-1be6-43d9-844b-ab7e586f9051",
    "parent_id": "afba19f3-b9e1-49f7-8669-6081c441a10a",
    "text": " and flow chains, one each for engines, chas- \nsis, and assembled cars. Because the three chains are separate, each can be mea- \nsured in different units: engines, chassis, and cars. The three chains are linked \nbecause each car beginning the final assembly process requires one engine from \nthe stock of completed engines and one chassis from the stock of completed chas- \nsis. The information arrows from the assembly rate to the engine and chassis use \nrates show these links. The number of engines and chassis available also determine \nthe maximum assembly start rate, which in turn constrains actual assembly starts: \nIf either component buffer falls to zero, assembly must cease.2 These links (not \nshown) define two balancing feedbacks that regulate the outflows from the stocks \nof components and couple the stock and flow networks. The diagram does not rep- \nresent many other information flows that must exist in the system (such as the de- \nterminants of the chassis start and completion rates); try adding these to the map. \nYou could of course continue to disaggregate. The process can be broken down \ninto more steps: The paint process, for example, actually consists of multiple \nactivities separated by buffers such as part preparation (solvent bath), drying, \nspraying the first coat, drying in the oven, spraying the second coat, drying, and \nso on, with various inspections along the way. You could also continue the parallel \ndisaggregation by splitting the engine or chassis assembly processes into their \n2Firms can sometimes build incomplete units and add the missing components later. When a \n1997 strike shut down a critical supplier, Ford continued to assemble its popular Explorer, storing \nthe nearly completed cars until the missing parts became available and could be retrofitted (try \nmodifying the diagram in Figure 6-12 to accommodate such retrofitting).\n\n21 6 \nPart I1 Tools for Systems Thinking \nFIGURE 6-1 2 \nDisaggregating parallel activities \nEngines in 1 \n4Completed I \nEngines \nI \nEngine \nI \nEngine ' \nI Engine \nStart \nRate \nCompletion \nRate \nUse \nRate \n'4AssembliesI \nin Process \nAssembly \nAssembly \nStart \nCompletion \nRate \nRate \nChassis in 1 \n4Completed I \nChassis - \nChassis \nChassis \nChassis \nStart \nRate \nCompletion \nRate \nUse \nRate \nsubassemblies. In the limit each and every part and operation would be represented \nseparately. Obviously such a model would be just as complex as the real system, at \nleast as hard to understand, and quite useless. \nWhere should you stop? How much detail is necessary? This is always a mat- \nter of judgment to be made by considering the model purpose and the needs of the \nclient. If the purpose is representing the lag in the response of the manufacturing \nsystem to changes in demand as part of a larger model of firm strategy, the simpler \nrepresentation is probably fine. If you seek to reengineer the flow of material \nthrough the production line, a more detailed representation is required. It is better \nto star",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 238
  },
  {
    "child_id": "81ee81d0-1572-4ad5-9090-7c7e241c02a4",
    "parent_id": "afba19f3-b9e1-49f7-8669-6081c441a10a",
    "text": "re should you stop? How much detail is necessary? This is always a mat- \nter of judgment to be made by considering the model purpose and the needs of the \nclient. If the purpose is representing the lag in the response of the manufacturing \nsystem to changes in demand as part of a larger model of firm strategy, the simpler \nrepresentation is probably fine. If you seek to reengineer the flow of material \nthrough the production line, a more detailed representation is required. It is better \nto start with a high-level, aggregate representation and add detail if needed to ad- \ndress the purpose. Beginning with detailed process maps often leads to paralysis \ndue to their complexity, data requirements, and rapid obsolescence rates. The ag- \ngregate map showing only production starts, WIP, production, and finished inven- \ntory is quite stable and remains appropriate even as the details of the production \nprocess change, while a detailed map may become obsolete as new products, tool- \ning, or process technologies are introduced. \n6.3.3 \nGuidelines for Aggregation \nWhen is it appropriate to aggregate different activities together? To determine \nwhether activities taking place serially can be aggregated, consider the average \nresidence time of items in each stock (the average time between entering and exit- \ning the stock). Stocks with short residence times relative to the time scale for the",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 238
  },
  {
    "child_id": "378d3c92-6c7f-4614-b70b-d5bf5d85333b",
    "parent_id": "6735c18b-35e4-491e-b64d-03c58ab0d076",
    "text": "Chapter 6 Stocks and Flows \n21 7 \ndynamics of interest generally do not need to be represented explicitly and can ei- \nther be omitted or lumped into adjacent stocks. For example, in the long-term plan- \nning models of the US energy system developed by the US Department of Energy \n(Nail1 1992), various stocks of undiscovered petroleum and known reserves are \nexplicitly represented because their lifetimes range from years to decades (at cur- \nrent production rates). However, stocks of crude oil and refined products in the pe- \ntroleum supply chain represent only a few months of consumption. In a long-term \nmodel these stocks are too short-lived to require explicit treatment. They fluctuate \naround their equilibrium values as producers, refiners, and distributors react to \nchanges in inventory. In a model of short-term movements in spot petroleum \nprices, however, these stocks are critically important. A good model would repre- \nsent the key stocks in the petroleum supply chain explicitly, perhaps even includ- \ning a separate stock for the inventory of gasoline at retail service stations and the \ninventory of gasoline in the tanks of cars on the road. On the other hand, a short- \nterm spot price model need not include petroleum reserves or undiscovered re- \nsources, as these stocks change too slowly to influence the spot market over a time \nhorizon of a year. \nParallel activities can legitimately be aggregated together if the individual \nflows are governed by similar decision rules and if the time the different items \nspend in the individual stocks is similar. For example, it is often appropriate to ag- \ngregate the many parts required to manufacture a product into a small number of \ncategories since they are usually ordered using the same procedures and their de- \nlivery lead times and residence times in parts inventories generally don\u2019t differ too \nmuch. In contrast, plant and equipment sometimes must be disaggregated. Their \nlifetimes are very different, and the decision rules for new green-field facilities dif- \nfer substantially from those used to order equipment for existing facilities due to \ndifferences in lead times, costs, financing, permitting, and regulatory issues. \nAs a rule of thumb, clients generally want to see more detail in a model than \nthe modeler thinks is needed, and modelers, in turn, generally overestimate the de- \ntail necessary to capture the dynamics of interest. Of course, the amount of detail \nneeded to capture the dynamics relevant to the client\u2019s purpose and the amount of \ndetail needed to give the client confidence in the results are two different things. \nRoberts (1977/1978) estimated that clients often require twice as much detail as the \nmodeler feels is needed to feel comfortable with and accept a model as a basis for \naction, and in my experience this is often an underestimate. Success requires you \nto include the detail necessary to satisfy the client. But this does not mean you \nshould acquiesce to all client",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 242
  },
  {
    "child_id": "bda1cd04-2b18-438d-86f0-17bce8e08fee",
    "parent_id": "6735c18b-35e4-491e-b64d-03c58ab0d076",
    "text": "vant to the client\u2019s purpose and the amount of \ndetail needed to give the client confidence in the results are two different things. \nRoberts (1977/1978) estimated that clients often require twice as much detail as the \nmodeler feels is needed to feel comfortable with and accept a model as a basis for \naction, and in my experience this is often an underestimate. Success requires you \nto include the detail necessary to satisfy the client. But this does not mean you \nshould acquiesce to all client demands for more detail-you will end up with an \nexpensive and useless black box. You must work with the client to understand why \nexcessive detail is often unnecessary. Often, models end up with too much detail, \nbut as the client gains confidence and understanding of the important feedbacks \ndriving the dynamics, the excess structure can be eliminated, resulting in a simpler, \nmore easily maintained, and more useful model (Randers 1980). Still, Roberts is \ncorrect: \u201cYou must provide the level of detail that causes [the client] to be per- \nsuaded that you have properly taken into account his issues, his questions, his level \nof concerns. Otherwise he will not believe the model you have built, he will not ac- \ncept it, and he will not use it\u201d (p. SO).\n\n21 8 \nPart I1 Tools for Systems Thinking \n6.3.4 \nSystem Dynamics in Action: \nModeling Large-Scale Construction Projects \nAggregation of multiple serial and parallel activities is well illustrated in a model \nof large construction projects developed by Jack Homer (Homer et al. 1993). The \nclient was a multinational forest products company, specifically the division of the \ncompany that designs and builds pulp and paper mills. Competition for the small \nnumber of mills built each year was intensifying as the industry globalized, and the \nfirm, already a leader, saw that to remain strong they had to dramatically reduce \nthe time required to design and build mills. Their goal was to reduce significantly \nthe total cycle time, from the handshake with a customer to the handoff of a work- \ning mill, without increasing costs. They knew traditional project management tech- \nniques were not adequate: the design and construction process is exceedingly \ncomplex, with tight couplings among the phases, and they had already done all the \neasy things. They decided to develop a system dynamics model of the entire engi- \nneering, procurement, and construction (EPC) process. \nEarly meetings of the project team focused on the model boundary and aggre- \ngation, in particular, descriptions of the stock and flow structure of a typical pro- \nject. Many issues were raised: Is there a typical project? How much detail is \nneeded? What activities could be aggregated together? One member of the client \nteam argued that the model couldn\u2019t be useful if it didn\u2019t represent every engineer- \ning drawing, every purchase order, and every component installed at the site. Ob- \nviously, such a model could never be built or made useful. Other mem",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 242
  },
  {
    "child_id": "5c405de5-a8f4-4872-9c4c-dd5b080b037e",
    "parent_id": "6735c18b-35e4-491e-b64d-03c58ab0d076",
    "text": "dary and aggre- \ngation, in particular, descriptions of the stock and flow structure of a typical pro- \nject. Many issues were raised: Is there a typical project? How much detail is \nneeded? What activities could be aggregated together? One member of the client \nteam argued that the model couldn\u2019t be useful if it didn\u2019t represent every engineer- \ning drawing, every purchase order, and every component installed at the site. Ob- \nviously, such a model could never be built or made useful. Other members of the \nclient team argued for a simpler approach. They already had highly disaggregate \nscheduling and planning models based on traditional project management tools to \nmanage the detail complexity of the projects. They lacked a tool to manage the dy- \nnamic complexity and interdependencies among the phases and activities of the \nprojects. \nAfter extensive discussion, an initial model boundary and level of aggregation \nwere set (Figure 6-13). The figure is a high-level subsystem diagram showing how \nprojects were aggregated into a reasonable number of phases. The overall project \nwas divided into two main stock and flow chains representing P&E (process and \nequipment) and construction. Each activity goes through design preparation, re- \nview, and design revisions. Next suppliers are selected and purchase orders are is- \nsued. The suppliers then fabricate the materials needed for each activity. On the \nconstruction side, the client felt it was acceptable to aggregate all construction ma- \nterials (e.g., structural steel, concrete forms, rebar) into a single category. The \nprocess and equipment side, however, was divided into three categories: reactor \nvessels, major equipment (e.g., large tanks, pipelines, and conveyors), and minor \nequipment (e.g., pumps, motors, valves, and instrumentation). The design, pro- \ncurement, and construction of these types of equipment are sufficiently different in \nscope, duration, and cost that they could not reasonably be lumped together. The \nreactor vessels, in particular, had to be modeled in more detail as they are the \nlargest subassembly, almost always fall on the critical path, and are frequently a \nbottleneck constraining construction progress. During construction, reactor ves- \nsels, other equipment, and site preparation such as foundations and grading all\n\nChapter 6 Stocks and Flows \n21 9 \nFIGURE 6-13 \nSubsystem diagram showing flows of engineering, procurement, and construction work in a model of \na pulp mill construction project. The diagram illustrates the sector boundaries and level of aggregation \nwithout showing all details. Each block represents a project phase, modeled with a generic module with \nroughly the same structure. An internal gate captures the constraints on work available within a phase \nas a function of ,the work completed. For example, foundations cannot be completed until surveying \nand site prepara.tion are done; see section 14.5. \nBuilding a pulp and paper mill \nDesign \nInternal \nPrepa",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 242
  },
  {
    "child_id": "df32a191-370e-4cda-b1aa-15909230339f",
    "parent_id": "6735c18b-35e4-491e-b64d-03c58ab0d076",
    "text": "tion project. The diagram illustrates the sector boundaries and level of aggregation \nwithout showing all details. Each block represents a project phase, modeled with a generic module with \nroughly the same structure. An internal gate captures the constraints on work available within a phase \nas a function of ,the work completed. For example, foundations cannot be completed until surveying \nand site prepara.tion are done; see section 14.5. \nBuilding a pulp and paper mill \nDesign \nInternal \nPreparation, \nGate \nReview, & \nInternal \nPreparation, \nGate \nReview, & \n\\ Revision \nf \nP&E \\ \nPurchasing \nPO'S & \n\\ \nRevisions J \nPurchasing \nPO'S & \nRevisions \nVessel \nErection \nI \nBasework& 4 \nb \n'Check \nOut' \nBasework & \nb \nInternal \nGate \nStart-up 0 \nSource: Homer et al. (1993). \nmust come together, followed by a functionality check out, start-up and, finally, \nhandoff to the customer. \nEach block in Figure 6-13 represents a project phase. The model consisted of \na generic project phase module, replicated for each block and linked as shown. \nEach module contained a stock and flow structure including the flows of tasks \nwithin the phase along with scheduled deadlines, the labor force dedicated to the\n\n220 \nFIGURE 6-1 4 \nStock and flow \nstructure of tasks \nin a project phase \nSimplified repre- \nsentation of the \nstock and flow \nstructure of a \nphase in the pulp \nmill project model. \nDeterminants of \nthe flows and cou- \nplings among the \ndifferent phases \nare not shown. \nPart I1 Tools for Systems Thinking \nphase, worker productivity, fatigue levels, error rates, and costs. The stock and \nflow structure for tasks within a phase models the progression of tasks from base- \nwork through completion (Figure 6-14). In general the tasks to be completed in a \nphase can only be done as upstream tasks upon which they depend are completed \n(the rate at which basework tasks become available). For example, the reactor ves- \nsels cannot be erected on site until their foundations are completed. Likewise, not \nall tasks within a given phase can be done concurrently. For example, the detailed \ndesign of conveyors and pipelines between the chippers, reactor vessels, and paper \nmachines cannot be done until the high-level physical design of the plant is com- \npleted. These within- and between-phase dependencies were modeled explicitly. \nThe flow of work from the stock of tasks awaiting completion to the stock of tasks \nrequiring rework represents those tasks completed incorrectly or rendered obsolete \nby changes in other subsystems. Generally, errors are not detected immediately and \nthe delay in the discovery of rework can be substantial, as when a design error is \nnot detected until construction in the field is underway. The discovery of rework \nmoves tasks thought to be complete back into the stock of tasks awaiting comple- \ntion (see Ford and Sterman 1998b for a detailed and fully documented model of a \nmultiphase project similar to the one used here; see also the shipbuildin",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 242
  },
  {
    "child_id": "fac433ea-91cd-4fe9-b1b6-4d4b1729ca48",
    "parent_id": "6735c18b-35e4-491e-b64d-03c58ab0d076",
    "text": "ed obsolete \nby changes in other subsystems. Generally, errors are not detected immediately and \nthe delay in the discovery of rework can be substantial, as when a design error is \nnot detected until construction in the field is underway. The discovery of rework \nmoves tasks thought to be complete back into the stock of tasks awaiting comple- \ntion (see Ford and Sterman 1998b for a detailed and fully documented model of a \nmultiphase project similar to the one used here; see also the shipbuilding project \nmodel described in section 2.3). \nThe model was substantially simpler than the client firm\u2019s detailed project \nplanning model, which included literally thousands of individual activities (high \ndetail complexity) but no feedback loops (no dynamic complexity). It was disag- \ngregated enough to capture important interdependencies among design, procure- \nment, and construction activities and between construction and the various types of \nBasework \nTasks Awaiting \nGo-Ahead \nBasework \nTasks Given \nGo-Ahead \nDetection of \nRequired Rework \nUndiscovered \nRework \nTasks \nAwaiting \nComoletion \nI\\ \nTasks Apparently \nCompletion \nRequiring Rework \n& \nTask \nCompleted \n7\n,\n \nI \nTasks \nCompleted",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 242
  },
  {
    "child_id": "7c721126-e56d-4eff-9552-a94b86c5b595",
    "parent_id": "372336f2-4b07-4f23-8a5f-19e1c3483f6b",
    "text": "Chapter 6 Stocks and Flows \n221 \nequipment. The model could capture shifts in the critical path that might result \nfrom policies accelerating the fabrication of the reactor vessels, a policy favored by \nsome client team members. \nIt is important to note that the process of developing the final level of aggre- \ngation involved a number of iterations and revisions. And though the model repre- \nsents the project at a high level of aggregation, the modeling team developed many \nmore detailed diagrams. These more detailed maps helped the modeler and client \nteam discover flaws in their thinlung, estimate parameters better, and deepen their \nunderstanding of the process. And they developed confidence that the more aggre- \ngate representation in the simulation model was acceptable for their purpose so \nthese more detailed stock and flow structures did not have to be incorporated into \nthe model. \nThe level of detail selected also permitted the model to be calibrated against a \nwide range of data collected on one of the company\u2019s current EPC projects. The \nmodel successfully (that is, to the satisfaction of the client) reproduced all relevant \nproject activities, including the various workforces and labor hours, overtime and \nrework rates, purchase order volumes and revision rates, vendor shipments, and the \nprogress of vessel erection and construction (Figure 6-15 shows an example). \nWhile the clients prefer not to disclose the details of policy recommendations, \nthey viewed the model as credible and useful and developed confidence, shared \namong the team, that the model did a good job of representing their EPC projects. \nThey used the model to analyze many policies and identified several which, while \npreviously appearing to be desirable, in fact generated harmful side effects. The \nmodel also helped identify policies that reduced project delivery times by at least \n30% within a few years. Several of the policies were not apparent to the client team \nor were hotly debated prior to the modeling effort. The modeling process helped \nbuild understanding of and consensus around these controversial initiatives, help- \ning the firm successfully implement many of the recommendations. \nFIGURE 6-1 5 !Sample comparison of historical and simulated behavior of the pulp mill model \nP&E = process and equipment. \n1 Cum. P&E Design Labor Hours \n1 Cum. Construction Labor Hours \n---- Actual \n- \nSimulated \n---- Actual \n- \nSimulated \n- \nSimulated \n- \nSimulated \n0 \n20 \n40 \n60 \n80 \n100 \n0 \n20 \n40 \n60 \n80 \n100 \nTime units \nTime units \nNote: Time is expressed as time units to protect client confidential information. \nSource: Homer et al. (1 993).\n\n222 \nPart I1 Tools for Systems Thinking \n6.3.5 \nSetting the Model Boundary: \n\u201cChallenging the Clouds\u201d \nMapping the stock and flow structure of a system involves important decisions \nabout the boundary of the model. In reality, flows of material, people, and money \ninto a stock have to come from somewhere; the flows out have to go som",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 246
  },
  {
    "child_id": "b3cd46be-d0bc-4598-bc19-c75f24868a6d",
    "parent_id": "372336f2-4b07-4f23-8a5f-19e1c3483f6b",
    "text": "0 \n0 \n20 \n40 \n60 \n80 \n100 \nTime units \nTime units \nNote: Time is expressed as time units to protect client confidential information. \nSource: Homer et al. (1 993).\n\n222 \nPart I1 Tools for Systems Thinking \n6.3.5 \nSetting the Model Boundary: \n\u201cChallenging the Clouds\u201d \nMapping the stock and flow structure of a system involves important decisions \nabout the boundary of the model. In reality, flows of material, people, and money \ninto a stock have to come from somewhere; the flows out have to go somewhere. \nTo keep your models manageable, you must truncate these chains using sources \nand sinks, represented in the stock and flow maps by \u2018\u2018clouds\u2019\u2019; see Figure 6-1. \nSources and sinks represent the stocks supplying material to or absorbing material \nfrom the modeled system. Sources and sinks are assumed to have infinite capacity \nand can never constrain the flows they support. In the real world, the stocks sup- \nplying or absorbing flows have finite capacity and do influence the flows. When \nyou truncate a stock and flow chain with a cloud you are setting the boundary of \nthe model-stocks and flows beyond this point are ignored; you exclude all possi- \nble feedbacks from or interactions with the stocks outside the boundary. \nAs a modeler you must critically examine these boundary assumptions; you \nmust, in the words of Barry Richmond (1993, p. 132), \u201cchallenge the clouds.\u201d Is it \nappropriate for your purpose to exclude the stocks outside the boundary of the \nmodel? What feedbacks ignored by your model might exist in the real world, and \nmight they affect your policy recommendations? Can the sources for the flows be \ndepleted and constrain the inflow? Can the sinks be filled and block the outflows, \nbacking up the system like a clogged drain? \nConsider the automobile industry. A stock and flow map for automobile pro- \nduction might begin with production starts, WIP inventory, production, finished in- \nventory, and shipments (Figure 6-16). Drawing the map with a source for the \nproduction start flow presumes that the supply of parts is unlimited and can never \nconstrain the production start rate. Likewise, because shipments flow to a sink, the \nmodeler has assumed stocks of product in the hands of dealers and customers have \nno effect on shipments. In challenging the clouds you ask whether these assump- \ntions are reasonable. For the auto industry they are not. Production starts require \nthe automaker to have an adequate stock of parts. Yet parts stocks may easily be \ndepleted. Suppliers cannot respond instantly to changes in parts orders. Large or- \nders may outstrip supplier capacity, leading to shortages. A strike at a supplier may \ninterrupt the flow of parts to the firm. At the other end, shipments of new cars to \ndealers depend on the size of dealer stocks. Dealers generally try to maintain about \n40 to 60 days of inventory on their lots; this is enough to provide good selection for \nconsumers without carrying excessive and costly inventory. If stoc",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 246
  },
  {
    "child_id": "e71db11a-7592-4aa7-a801-318d3ace4f0c",
    "parent_id": "372336f2-4b07-4f23-8a5f-19e1c3483f6b",
    "text": "be \ndepleted. Suppliers cannot respond instantly to changes in parts orders. Large or- \nders may outstrip supplier capacity, leading to shortages. A strike at a supplier may \ninterrupt the flow of parts to the firm. At the other end, shipments of new cars to \ndealers depend on the size of dealer stocks. Dealers generally try to maintain about \n40 to 60 days of inventory on their lots; this is enough to provide good selection for \nconsumers without carrying excessive and costly inventory. If stocks are low rela- \ntive to their targets, dealers order more from the manufacturers; if stocks are high, \nthey cut back. Figure 6-17 expands the model boundary to capture these effects. \nThe model now represents three distinct organizational entities-suppliers, manu- \nfacturers, and dealers. The inventory of parts held by the manufacturer is now ex- \nplicit. The supplier has the same basic structure as the automaker: a stock of \nfinished inventory and a stock of work in process. At the shipment end, manufac- \nturer shipments no longer disappear into a sink but flow into dealer stocks, allow- \ning you to model the purchase rate as a function of the dealer inventory and sales \nto customers.\n\nChapter 6 Stocks and Flows \n223 \nFIGURE 6-1 6 \ninitial stock and \nflow map for \nthe automobile \nindustry, showing \nthe model \nboundary \nThe sources arid \nsinks for the \nflows through \nthe system are \nassumed to be \ninfinite and can \nhave no impact on \nthe dynamics. \nSource: \nUnlimited \nMaterial 0 \nSupply of 1 \nModel \nBoundary \nSink: 1 \nUnlimited \nAbsorption \nCapacity \nYou could and should continue to challenge the boundary of the model. The \nmodel now allows you to represent supplier order processing, inventory manage- \nment, and delivery, including the possibility that suppliers can become a bottleneck \nand starve automobile production. But now the suppliers are assumed to have un- \nlimited parts and raw materials availability. Is this appropriate? It depends on the \nmodel purpose. You could continue to expand the model boundary by adding the \nsuppliers to the suppliers, and their suppliers, and so on, until you reached the point \nwhere it is acceptable to assume that the supply of materials to the farthest up- \nstream supplier is unlimited. Alternatively, you could represent the entire upstream \nsupply chain by a single aggregate supplier stage. \nThe map shown in Figure 6-17 also assumes that dealer sales flow into a sink \nso there is no feedback from the stock of cars on the road to purchases of new cars. \nThis is obviously a bad assumption: Sales of new cars depend on the number and \nage of the cars people already have relative to their needs. People who have just ac- \nquired a new car are unlikely to buy another for several years, until their loan is \npaid off, their lease expires, or their car is involved in an accident and must be re- \nplaced (see section 2.2). Figure 6-18 expands the downstream end of the stock and \nflow map to include the stock of cars on the roa",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 246
  },
  {
    "child_id": "2541d360-d052-48d6-8ac2-d1677f7a2426",
    "parent_id": "372336f2-4b07-4f23-8a5f-19e1c3483f6b",
    "text": "d to purchases of new cars. \nThis is obviously a bad assumption: Sales of new cars depend on the number and \nage of the cars people already have relative to their needs. People who have just ac- \nquired a new car are unlikely to buy another for several years, until their loan is \npaid off, their lease expires, or their car is involved in an accident and must be re- \nplaced (see section 2.2). Figure 6-18 expands the downstream end of the stock and \nflow map to include the stock of cars on the road. \nYou can continue to challenge the model boundary. What happens to the \ncars when they are scrapped? In the current map, they simply disappear. In reality, \nthey don\u2019t. In North America some 10 to 12 million vehicles are scrapped per \nyear. Roughly 94% are shredded and the steel and some nonferrous metals are\n\n224 \nFIGURE 6-17 \nChallenging the \nclouds \nAdding a supplier \nand dealer sector \nto the stock and \nflow chain for \nautomobile pro- \nduction. Rectan- \ngles with rounded \ncorners denote \nthe boundaries \nbetween different \norganizational en- \ntities and decision- \nmaking units. \nPart I1 Tools for Systems Thinking \nSupplier \nStarts \nC.3 \nProduction \nSupplier \nWIP \nSupplier \nProduction \nSupplier \nInventory \nSupplier \nSupplier \n~ \nSector \nm \nInventory \nProduction \nStarts \n$ Production \nStocks \nNew Car \nSales \nManufacturer \nSector \nDealer \nSector \nrecovered, one of the highest recycling fractions of any industry. However, some \ncars end up abandoned as dangerous eyesores on the side of the road. And much of \nthe plastic, glass, and other nonmetal materials end up in landfills, constituting a \nsignificant source of pollution (more than two billion discarded tires, most sitting \nin huge piles across the country, have already accumulated in the US).\n\nFIGURE 6-18 \nExpanded \nautomobile model \nThe boundary now \ninclludes the stock \nof cars on the \nroad, which feeds \nback to influence \nsales of new cairs. \nChapter 6 Stocks and Flows \nShipments \n225 \nCars on \nthe Road \nScrap \nDealer \nSector \nHousehold \nSector \n6.3.6 \nSystem Dynamics in Action: \nAutomobile Recycling \nBy the mid 1990s, as landfills filled and environmental awareness grew, pressure \nbuilt to recycle more of the material in cars. Germany debated a law that would re- \nquire auto manufacturers to take back their old cars when people deregistered \nthem. Pushed by these forces, the auto industry, first in Europe and then in the US, \nbegan to study ways to increase the recovery of parts and the recycling of materi- \nals from cars. \nPave1 Zamudio-Ramirez (1996) modeled part recovery and the materials recy- \ncling in the US auto industry to help the industry think about a future of enhanced \nauto recycling. Figure 6-19 shows a simplified stock and flow structure adapted \nfrom the model. Old or wrecked cars can either be scrapped legally (sold to a junk- \nyard or dismantler) or illegally abandoned. The stock of abandoned, often burned- \nout, cars is a blight on the landscape and significant source of pollut",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 246
  },
  {
    "child_id": "0c1fc276-44d0-4704-94e1-76875fa8da24",
    "parent_id": "372336f2-4b07-4f23-8a5f-19e1c3483f6b",
    "text": "- \nals from cars. \nPave1 Zamudio-Ramirez (1996) modeled part recovery and the materials recy- \ncling in the US auto industry to help the industry think about a future of enhanced \nauto recycling. Figure 6-19 shows a simplified stock and flow structure adapted \nfrom the model. Old or wrecked cars can either be scrapped legally (sold to a junk- \nyard or dismantler) or illegally abandoned. The stock of abandoned, often burned- \nout, cars is a blight on the landscape and significant source of pollution. There are \ntwo outflows from the stock of illegally abandoned cars: Dismantlers will process \nthem if the value of the recoverable parts and materials is high enough. Alterna- \ntively, illegally dumped cars can be collected (say by local governments) and taken \nto shredders for proper disposal. Both these flows are relatively small, so the stock \nof abandoned cars can build up to high levels even if the abandonment rate is low. \nCars held in the dismantlers\u2019 inventories are stripped of those parts whose \nvalue exceeds the cost of recovery. These parts enter a used parts stock and are \nthen sold to repair shops and used to replace worn or damaged parts on operating \ncars. In this map, the part usage rate flows into a sink. In actuality, these parts are \ninstalled in cars still on the road and eventually flow again through the scrap or \nabandonment rate. Since the number of recovered parts is very small relative to the \ntotal flow of materials through the system, this omission is probably reasonable.",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 246
  },
  {
    "child_id": "bb5d089f-0991-4ba7-89e4-053d0fcfc6d8",
    "parent_id": "e27aa5b4-b9ce-4b81-8b0b-52bfb9d56eeb",
    "text": "226 \nAuto \nMaterials in 4 \nPart I1 Tools for Systems Thinking \nShredder \nInventory 4 \nT 7  \nL1 \nFIGURE 6-1 9 Stock and flow map for a model of automobile recycling \nThe stock and flow structure for the development of new vehicle platforms, defining the mass and \nmaterials composition of cars and level of design for disassembly, is not shown. The model includes a \nparallel stock and flow structure (co-flow) tracking each of these properties as vehicles age and are \neventually retired, dismantled, and shredded. See chapter 12. \nNew Car \nSales Rate \nRate \nSales to \nMaterials \nProcessors \nMaterials \nInventor \nMaterials \nUsage \nRate\n\nChapter 6 Stocks and Flows \n227 \nAfter all parts worth recovering are removed, the gutted car, now called a hulk, \nis sold to a shredder. In the mid 1990s there were about 200 shredders in the US \nwho processed roughly 94% of all deregistered cars. After shredding, the valuable \nmaterials (principally steel and some nonferrous metals) are separated out for re- \ncycling. If the prices of the recovered materials don\u2019t justify the cost, shredders can \ntake hulks directly to a landfill and cut their purchases from dismantlers. What re- \nmains after shredding and separation is a mixture of plastics, glass, elastomers, and \nsome unrecovered metal called automotive shredder residue (ASR) or \u201cfluff,\u201d \nwhich is then landfilled. ASR is one of the major environmental concerns gener- \nated by the disposal of old cars. \nThe recyclable materials accumulate in an inventory and are eventually sold to \nmaterials processors such as steel mills. The inventory of raw materials is then \nused to manufacture new products, including automobiles, thus helping to create a \nclosed material flow and cutting the use of nonrenewable resources. As in the case \nof parts, the materials usage rate flows into a sink since the flow of recovered ma- \nterials relative to the total flow of virgin materials is small. \nZamudio-Ramirez\u2019s model included a rich feedback structure representing the \nbehavior of the various actors in the system, including the automakers, car owners, \ndismantlers, and shredders. Markets for recovered materials were explicit. The \nstock and flow structure for autos began at the design stage for new models and \nplatforms and tracked key properties of the cars including their mass, materials \ncomposition (ferrous, nonferrous, plastics), and the level of design for disassembly \nbuilt into the design. These attributes were tracked as the cars embodying them \nmoved from the design stage to market, age, and are then retired, dismantled, and \nshredded. \nTo gather the required data, Zamudio-Ramirez conducted interviews with var- \nious actors, including carmakers, dismantlers, shredders, and industry analysts and \nmade extensive use of various auto and recycling industry databases. Some of the \ndata required, such as age-dependent scrap rates for cars, were relatively easy to \ngather. Other key parameters were not. Two critical relationships in ",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 251
  },
  {
    "child_id": "c2c913e4-6201-497f-b213-74765b9de877",
    "parent_id": "e27aa5b4-b9ce-4b81-8b0b-52bfb9d56eeb",
    "text": "ng them \nmoved from the design stage to market, age, and are then retired, dismantled, and \nshredded. \nTo gather the required data, Zamudio-Ramirez conducted interviews with var- \nious actors, including carmakers, dismantlers, shredders, and industry analysts and \nmade extensive use of various auto and recycling industry databases. Some of the \ndata required, such as age-dependent scrap rates for cars, were relatively easy to \ngather. Other key parameters were not. Two critical relationships in the model are \nthe supply curves for recovered parts and recovered materials. That is, how will the \nnumber of parts recovered by dismantlers vary as the price they can get and the \ncosts of recovery vary? \nEstimating the parts supply curve is a daunting problem. The principal cost of \nrecovery is the labor time required to remove a part. But the time required to re- \nmove a given part depends on how many other parts must be removed first. These \nprecedence relationships depend on the design of the car and the value of the in- \ntervening parts (can the seat be ripped out quickly to get at a valuable part under it \nor must it be removed carefully? Should workers get at a part from in front or be- \nhind?). To estimate these relationships Zamudio-Ramirez worked at the Vehicle \nRecycling Partnership, a consortium of the Big Three US automakers, dismantlers, \nand the recycling industry. The Vehicle Recycling Partnership assembled a com- \nprehensive database of part removal times by completely disassembling a variety \nof late model cars. Zamudio-Ramirez and his colleague Andrew Spicer then de- \nveloped an optimization model to estimate the supply curve for parts recovery as \nfunctions of part and materials prices, labor costs, and the design of the vehicles. \nThe optimization model determined the number of parts worth recovering and the\n\n228 \nPart I1 Tools for Systems Thinking \noptimal dismantling order for any set of prices, labor costs, and design parame- \nters-the supply curve for recovered parts. The results of the optimization model \nwere then embedded in the simulation model. As the design parameters for cars \nchange and the removal time for key parts falls, the estimated supply curve re- \nsponds by realistically increasing the number and types of parts recovered. \nThough the stock and flow structure in Figure 6-19 is simplified and does not \nshow any of the feedback structure determining the various flows from the full \nmodel, it illustrates the response of the automobile and materials markets to poli- \ncies designed to increase recycling of cars. \nFirst consider the effect of a design for disassembly (DFD) program designed \nto increase the part recovery rate and reduce the amount of fluff ending up in land- \nfills. DFD can reduce the labor cost of part recovery through better design, differ- \nent choice of part fasteners, improved selection and labeling of materials, and other \ntechniques. The first effect is ... nothing. There is a lag of at least sever",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 251
  },
  {
    "child_id": "ff9f692e-affb-481b-b325-3d6989e5a938",
    "parent_id": "e27aa5b4-b9ce-4b81-8b0b-52bfb9d56eeb",
    "text": "omobile and materials markets to poli- \ncies designed to increase recycling of cars. \nFirst consider the effect of a design for disassembly (DFD) program designed \nto increase the part recovery rate and reduce the amount of fluff ending up in land- \nfills. DFD can reduce the labor cost of part recovery through better design, differ- \nent choice of part fasteners, improved selection and labeling of materials, and other \ntechniques. The first effect is ... nothing. There is a lag of at least several years be- \ntween the time an automaker starts a DFD program and the time the first cars de- \nsigned to those specs roll off the assembly line. The average car in the United \nStates stays on the road for about a decade, and new cars have very low scrap rates \n(most of these are wrecks declared total losses by insurance companies). Only af- \nter a delay of many years will the stock of recycling-ready cars be large enough \nand old enough for them to constitute a significant fraction of the scrapped cars \npurchased by dismantlers. \nWhat then happens? Manufacturers expected DFD would eventually cause \npart and material recovery to rise, permanently reducing the flow of materials to \nlandfills. Instead, the model suggests the next effect will be a glut of used parts, as \nthe part recovery rate rises above the used parts usage rate. As parts inventories \nbuild, the price dismantlers can get for used parts falls. The number of parts that \ncan be economically recovered drops, and the dismantling rate drops back. Prices \ncontinue to fall until the number of parts recovered falls enough to balance the \nused parts usage rate. The part usage rate may rise, stimulated by lower prices, but \nunless the demand for used parts is highly price elastic, the part recovery rate will \ndrop back close to its original rate prior to DFD. The demand for used parts is \nlikely to be rather insensitive to price. Automakers and third-party producers of re- \nplacement parts will be reluctant to lose the lucrative parts market and may be able \nto prohibit the use of recovered parts by authorized service centers or for warranty \nrepairs or compete on price. If the demand for used parts is inelastic, the principal \neffect of DFD might simply be to depress the price of used parts, offsetting most \nof the benefit of improved design. \nNow consider the effect of a trend toward smaller, lighter cars with signifi- \ncantly higher plastic content and less steel and metal. Such changes are promoted \nto improve fuel economy, increase part recoverability, and decrease the quantity of \nfluff ending up in landfills. However, the stock and flow structure may cause the \nimpact of such policies to be counter to their intent. The auto industry is a signifi- \ncant consumer of steel. When new cars begin to use less, the recovery of steel from \nshredding of old hulks continues at the prior rate. The price of scrap metal will fall, \nreducing shredder profitability. The number of hulks shredded and the quantit",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 251
  },
  {
    "child_id": "e0f283ad-773b-4f59-b1b7-09edc4e26b86",
    "parent_id": "e27aa5b4-b9ce-4b81-8b0b-52bfb9d56eeb",
    "text": "ove fuel economy, increase part recoverability, and decrease the quantity of \nfluff ending up in landfills. However, the stock and flow structure may cause the \nimpact of such policies to be counter to their intent. The auto industry is a signifi- \ncant consumer of steel. When new cars begin to use less, the recovery of steel from \nshredding of old hulks continues at the prior rate. The price of scrap metal will fall, \nreducing shredder profitability. The number of hulks shredded and the quantity of\n\nChapter 6 Stocks and Flows \n229 \nmetals recovered may fall, and the volume of fluff disposed in landfills may actu- \nally rise. Further, once the scrap rate of cars with reduced steel content increases, \nshredder profit can fall further. With less steel and nonferrous content, shredder \nrevenue per hulk falls, while the fixed costs of shredding remain the same. Zamu- \ndio-Ramirez found that a sustained increase in the plastic content of cars, as ex- \npected, would increase the fraction of materials recovered by dismantlers. But cars \nwith less recyclable metal could also depress hulk prices enough to cut shredder \nprofit, decrease the shredding rate, and actually increase the number of abandoned \ncars and the amount of fluff buried in landfills. \nThe stock and flow map helps illustrate the long delays between a change in \nthe design of cars and the flows of old cars to landfills. By making the stocks of re- \ncovered parts and materials explicit, it is easier to see that there is imperfect coor- \ndination between inflows and outflows, leading to potential imbalances and \nchanges in prices that invalidate the assumptions behind recycling programs. In- \nstitutional structures such as requirements that service centers use new replacement \nparts can overwhelm the logic of the market. Market mechanisms, even when pre- \nsent, are not likely to work smoothly, possibly leading to instability and ineffi- \nciency. Similar dynamics have already been observed in the market for recycled \npaper (Taylor 1999). Supply side steps to increase recyclability alone are not likely \nto be effective unless matched by policies to increase the usage of recovered parts \nand materials. The collection of recyclable materials and the actual recycling of \nthose materials aren\u2019t the same thing. \n6.4 SUMMARY \nThis chapter introduced the stock and flow concept. Stocks accumulate their in- \nflows less their outflows. Stocks are the states of the system upon which decisions \nand actions are based, are the source of inertia and memory in systems, create de- \nlays, and generate disequilibrium dynamics by decoupling rates of flow. The dia- \ngramming notation for stocks and flows can be used with a wide range of \naudiences and makes it easier to relate a causal diagram to the dynamics of the sys- \ntem. Stocks accumulate (integrate) their inflows less their outflows. Equivalently, \nthe rate of change of a stock is the total inflow less the total outflow. Thus a stock \nand flow map correspond",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 251
  },
  {
    "child_id": "92853d5a-cddd-41b6-9883-a0de1f5cebaf",
    "parent_id": "e27aa5b4-b9ce-4b81-8b0b-52bfb9d56eeb",
    "text": ", are the source of inertia and memory in systems, create de- \nlays, and generate disequilibrium dynamics by decoupling rates of flow. The dia- \ngramming notation for stocks and flows can be used with a wide range of \naudiences and makes it easier to relate a causal diagram to the dynamics of the sys- \ntem. Stocks accumulate (integrate) their inflows less their outflows. Equivalently, \nthe rate of change of a stock is the total inflow less the total outflow. Thus a stock \nand flow map corresponds exactly to a system of integral or differential equations. \nHowever, stock and flow maps are much easier to work with and explain. \nThere are several ways to identify the stocks in systems. In the snapshot test \nyou imagine freezing the system at a moment of time-the measurable quantities \n(physical, informational, and psychological) are the stocks, while flows are not in- \nstantaneously observable or measurable. Units of measure can also help identify \nstocks and flows. If a stock is measured in units, its flows must be measured in \nunits per time period. \nStocks existing in series in a network can be aggregated together if they are \nshort-lived relative to the time horizon and dynamics of interest. Multiple parallel \nactivities can be aggregated into a single stock and flow network if the activities \nare governed by similar decision processes and utilize similar resources and if the\n\n230 \nPart I1 Tools for Systems Thinhng \nresidence times of the items in the stocks is similar enough for the purpose of your \nmodel. \nSources and sinks for the flows in a system have infinite capacity, unlike \nstocks in the real world, and thus represent the boundary of the model. Modelers \nshould always challenge these boundary assumptions, asking if the assumption of \ninfinite supply for sources and infinite absorption capacity for sinks is appropriate \nrelative to the model purpose.",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 251
  },
  {
    "child_id": "a30d5a41-8b79-4096-83a8-9d5468ce017d",
    "parent_id": "2ecedacc-492a-41a4-ac2c-f0911cf0bf53",
    "text": "7 \nDynamics of Stocks and Flows \nNature laughs at the dificulties of integration. \n-Pierre-Simon de Laplace (1749-1827) \nThe successes of the differential equation paradigm were impressive and \nextensive. Many problems, including basic and important ones, led to \nequations that could be solved. A process of self-selection set in, wheveby \nequations that could not be solved were automatically of less interest than \nthose that could. \n-Ian \nStewart (1989, p. 39). \nChapter 6 introduced the stock and flow concept and techniques for mapping the \nstock and flow networks of systems. This chapter explores the behavior of stocks \nand flows. Given the dynamics of the flows, what is the behavior of the stock? \nFrom the dynamics of the stock, can you infer the behavior of the flows? These \ntasks are equivalent to integrating the flows to yield the stock and differentiating \nthe stock to yield its net rate of change. For people who have never studied calcu- \nlus, these concepts can seem daunting. In fact, relating the dynamics of stocks and \nflows is actually quite intuitive; it is the use of unfamiliar notation and a focus on \nanalytic solutions that deters many people from study of calculus. \nWhat if you have a strong background in calculus and differential equations? \nIt is generally not possible to solve even small models analytically due to their high \norder and nonlinearities, so the mathematical tools many people have studied are \nof little direct use. If you have more mathematical background you will find this \nchapter straightforward but should still do the graphical integration examples and \nchallenges to be sure your intuitive understanding is as solid as your technical \n231\n\n232 \nPart I1 Tools for Systems Thinking \nknowledge. Modelers, no matter how great or small their training in mathematics, \nneed to be able to relate the behavior of stocks and flows intuitively, using graphi- \ncal and other nonmathematical techniques. The chapter also illustrates how stock \nand flow dynamics give insight into two important policy issues: global warming \nand the war on drugs. \n7.1 \nRELATIONSHIP BETWEEN STOCKS AND FLOWS \nRecall the basic definitions of stocks and flows: the net rate of change of a stock is \nthe sum of all its inflows less the sum of all its outflows. Stocks accumulate the net \nrate of change. Mathematically, stocks integrate their net flows; the net flow is the \nderivative of the stock. \n7.1 .I \nStatic and Dynamic Equilibrium \nA stock is in equilibrium when it is unchanging (a system is in equilibrium when \nall its stocks are unchanging). For a stock to be in equilibrium the net rate of \nchange must be zero, implying the total inflow is just balanced by the total outflow. \nIf water drains out of your tub at exactly the rate it flows in, the quantity of water \nin the tub will remain constant and the tub is in equilibrium. Such a state is termed \na dynamic equilibrium since the water in the tub is always changing. Static equi- \nlibrium arises when",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 256
  },
  {
    "child_id": "b6aefd34-b384-44c5-8ae3-75d4e88fd5fa",
    "parent_id": "2ecedacc-492a-41a4-ac2c-f0911cf0bf53",
    "text": "en it is unchanging (a system is in equilibrium when \nall its stocks are unchanging). For a stock to be in equilibrium the net rate of \nchange must be zero, implying the total inflow is just balanced by the total outflow. \nIf water drains out of your tub at exactly the rate it flows in, the quantity of water \nin the tub will remain constant and the tub is in equilibrium. Such a state is termed \na dynamic equilibrium since the water in the tub is always changing. Static equi- \nlibrium arises when all flows into and out of a stock are zero. Here not only is the \ntotal volume of water in the tub constant, but the tub contains the same water, hour \nafter hour. The number of members of the US senate has been in dynamic equilib- \nrium since 1959 when Hawaii joined the union: the total number of senators re- \nmains constant at 100 even as the membership turns over (albeit slowly). The stock \nof known Bach cantatas is in static equilibrium since we are unlikely to lose the \nones we know of, the odds of discovering previously unknown cantatas are remote, \nand Bach can\u2019t write any new ones. \n7.1.2 Calculus without Mathematics \nTo understand dynamics, you must be able to relate the behavior of the stocks and \nflows in a system. Given the flows into a stock, what must the behavior of the \nstock be? Given the behavior of the stock, what must the net rate of change have \nbeen? These questions are the domain of the calculus. Calculus provides rules to \nanswer these questions mathematically provided you can characterize the behavior \nof the stocks or flows as mathematical functions. Calculus is one of the most beau- \ntiful and useful branches of mathematics but one far too few have studied. Happily, \nthe intuition behind the relationship between stocks and flows is straightforward \nand does not require any mathematics. If you are shown a graph of the behavior of \nthe flows over time, you can always infer the behavior of the stock. This process is \nknown as graphical integration. Likewise, from the trajectory of the stock you can \nalways infer its net rate of change, a process known as graphical diflerentiation. \nIntegration and differentiation are the two fundamental operations in the calculus. \nTable 7-1 provides the definitions graphically and in plain language. \nThe amount added to a stock during any time interval is the area bounded by \nthe curve defining its net rate of change. Why? Consider the bathtub metaphor\n\nChapter 7 Dynamics of Stocks and Flows \n233 \nTABLE 7-1 \nIntegration and differentiation: definitions and examples \nIntegration \nDifferentiation \nStocks accurriulate or integrate their net flow. \nThe quantity added to a stock over any interval \nis the area bounded by the graph of the net rate \nbetween the start and end of the interval. The \nfinal value of Ihe stock is the initial value plus the \narea under the net rate curve between the initial \nand final times. \nIn the example below, the value of the stock at \ntime tl = Si. E\\dding the area under t",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 256
  },
  {
    "child_id": "cfe48e4e-ea76-4296-ae9f-474a6bdfa17f",
    "parent_id": "2ecedacc-492a-41a4-ac2c-f0911cf0bf53",
    "text": " \nIntegration and differentiation: definitions and examples \nIntegration \nDifferentiation \nStocks accurriulate or integrate their net flow. \nThe quantity added to a stock over any interval \nis the area bounded by the graph of the net rate \nbetween the start and end of the interval. The \nfinal value of Ihe stock is the initial value plus the \narea under the net rate curve between the initial \nand final times. \nIn the example below, the value of the stock at \ntime tl = Si. E\\dding the area under the net rate \ncurve between times tl and t2 increases the \nStock to S2. \nThe slope of a line tangent to any point of the \ntrajectory of the stock equals the net rate of \nchange for the stock at that point. The slope of \nthe stock trajectory is the derivative of the stock. \nIn the example below, the slope of the stock \ntrajectory at time t, is R1, so the net rate at ti = \nR1. At time t2, the slope of the stock is larger, so \nthe net rate at t, = R2 is greater than R1. The \nstock rises at an increasing rate, so the net rate \nis positive and increasing. \nn \nu) \nc \nS \nY \n0 \nv) \ne s, \nB s, \nv \nChange in Stock \nh \nQ) \nR, \nC T -  \nQ) \nR, \nt;;g \n= S  \nv \n0 \nn \nu) \nC \nS \nc \n.- \nU \n./. \n/ \n~ in Stock \nI ..... . . -7 \nY 8 \n3i \ntl \nt2 \nagain. How much water is added to the tub in any time interval, such as between \ntime tl and t, in Table 7-l? Divide the entire interval into a number of smaller seg- \nments, each small enough that the net flow of water is not changing significantly \nduring the segment (Figure 7-1). The length of each segment is called \u201cdt\u201d for \n\u201cdelta time.\u201d How much water flows in during each small interval of duration dt? \nThe quantity added is the net flow during the interval, say R, multiplied by \nthe length of the interval, that is, the area of the rectangle dt periods wide and \nR unitslperiod high: \nQuantity added during interval of length dt = \nR \n* \ndt \n(Units) \n= (UnitsRime) (Time) \n(7-1) \nNote the units of measure: The flow in units per time, accumulated for a period of \ntime yields the quantity added to the stock. \nTo use a concrete example, suppose tl = 1 minute and t2 = 2 minutes. The \nquestion is how much water flows into the tub during that minute. Divide the\n\n234 \nPart I1 Tools for Systems Thinking \nFIGURE 7-1 \nI \nGraphical \nintegration \nDivide time into \nsmall intervals of \nlength dt. Each \nrectangle repre- \nsents the amount \nadded during the \ninterval dt, assum- \ning the net rate Ri \nat that time re- \nmains constant \nduring the interval. \nThe area of each \nrectangle is Ridt. \nThe total added to \nthe stock between \nt, and t2 is then the \nsum of the areas \nof the rectangles. \nDividing time into \nsmaller increments \nincreases the \naccuracy of the \napproxi mation. \nminute up into six 10-second intervals and assume the flow is constant throughout \neach of these intervals. If at the start of the first interval the flow was 6 liters per \nminute (that is, 0.1 liters/second), then the amount added would be (0.1 literdsec- \nond)(lO seconds) = 1 ",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 256
  },
  {
    "child_id": "fde6eb1d-2d4a-414f-9a40-4d03c2f152c6",
    "parent_id": "2ecedacc-492a-41a4-ac2c-f0911cf0bf53",
    "text": "ea of each \nrectangle is Ridt. \nThe total added to \nthe stock between \nt, and t2 is then the \nsum of the areas \nof the rectangles. \nDividing time into \nsmaller increments \nincreases the \naccuracy of the \napproxi mation. \nminute up into six 10-second intervals and assume the flow is constant throughout \neach of these intervals. If at the start of the first interval the flow was 6 liters per \nminute (that is, 0.1 liters/second), then the amount added would be (0.1 literdsec- \nond)(lO seconds) = 1 liter. At the start of the second 10-second interval, the flow \nhas increased, perhaps to 7 literdminute, or about 0.117 literdsecond. The area of \nthe second rectangle is then 1.17 liters. Calculating the area of all six rectangles \nand adding them together gives an approximation of the total volume of water \nadded during the minute. The approximation isn't perfect because the net flow is \nactually changing during each 6-second interval. In Figure 7-1, the flow is actually \nrising, so the calculated value of the stock will be too small. To increase the accu- \nracy of the approximation, simply divide time into even finer intervals, increasing \nthe number of rectangles. Computer simulations integrate the stocks in the model \nin precisely this fashion; the modeler must choose the time step dt so that the ap- \nproximation is acceptable for the purp0se.l In the limit, as the time interval be- \ncomes infinitesimal, the sum of the areas of all the rectangles becomes equal to the \ntotal area under the net rate curve. Calculus provides formulas that give the exact \narea under the net rate-provided the net rate can be expressed as a certain type of \nmathematical function. But whether the net rate can be integrated analytically or \nnot, the amount added to a stock is always the area under the net rate. Graphical in- \ntegration is the process of estimating that area from a graph of the net rate. \n7.1.3 \nGraphical Integration \nTo illustrate graphical integration, consider the most basic stock and flow system: \na single stock with one inflow and one outflow. Assume the flows are exogenous- \nthere are no feedbacks from the stock to either flow. Suppose the outflow from the \n'The procedure described above is known as Euler integration and is the most commonly used \nmethod for numerical simulation. Other methods such as Runge-Kutta integration use more sophis- \nticated methods to estimate the area and select the timt step. See Appendix A.",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 256
  },
  {
    "child_id": "bd8de4ce-f629-4f14-8538-9500f2da1b42",
    "parent_id": "15a3f981-6dcc-4374-aa83-1c164182852d",
    "text": "Chapter 7 Dynamics of Stocks and Flows \n235 \nFIGURE 7-2 \nGraphical \nintegration: \nexample \nWhile the rate \nsteps up and steps \ndown, the stock \nrises and remains \nat a higher level. \nNote the different \nunits of rneasure \nfor the rate and \nstock. \n400 7 \n0 '  \nI \nI \nI \n0 \n10 \n20 \n30 \nTime (seconds) \nstock is zero. Suppose also that the inflow to the stock follows the pattern shown \nin Figure 7-2. The inflow begins at zero. At time 10 the inflow suddenly increases \nto 20 unitdsecond, remains at that level for 10 seconds, then steps back down to \nzero. If the initial level of the stock is 100 units, how much is in the stock at time \n30, and what is the behavior of the stock over time? \nTable 7-2 shows the steps involved in graphical integration. Applying these \nsteps to Figure 7-2, first make a set of axes for the stock, lined up under the graph \nfor the flows. Next calculate the net rate. Since there is only one inflow and one \noutflow, and since the outflow is zero at all times, the net rate of change of the \nstock (Total Inflow - Total Outflow) simply equals the inflow. Initially, the stock \nhas a value of 100 units. Between time 0 and time 10, the net flow is zero units/ \nsecond, so the stock remains constant at its initial value. At time 10, the net rate \njumps to 20 unitshecond and remains there for 10 seconds. The amount added is \nthe area under the net rate curve (between the net rate curve and the zero line). \nSince the rate is constant, the area is a rectangle 20 unitshecond high and 10 sec- \nonds long, so the stock rises by 200 units, giving a total level of 300 units by time \n20. Because the net rate is positive and constant during this interval, the stock rises \nlinearly at a rate 20 unitshecond (the slope of the stock is 20 units/second). \nAt time 20, the inflow suddenly ceases. The net rate of change is now zero and \nremains constant, and the stock is again unchanging, though now at the level of \n300 units. \nNote how the process of accumulation creates inertia: though the rate rises and \nfalls back to its original level, the stock does not return to its original level. Instead, \nit remains at its maximum when the net rate falls back to zero. In this fashion, \nstocks provide a memory of all the past events in a system. The only way for the \nstock to fall is for the net rate to become negative (for the outflow to exceed the in- \nflow). Note also how the process of accumulation changed the shape of the input. \nThe input is a rectangular pulse with two discontinuous jumps; the output is a \nsmooth, continuous curve.\n\n236 \nPart I1 Tools for Systems Thinking \nTABLE 7-2 \nSteps in graphical \nintegration \n1. Calculate and graph the total rate of inflow to the stock (the sum of all \ninflows). Calculate and graph the total rate of outflow from the stock (the \nsum of all outflows). \n2. Calculate and graph the net rate of change of the stock (the total inflow less \nthe total outflow). \n3. Make a set of axes to graph the stock. Stocks and their flo",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 260
  },
  {
    "child_id": "9ca48bce-1c93-498f-8aea-441205d99302",
    "parent_id": "15a3f981-6dcc-4374-aa83-1c164182852d",
    "text": "h two discontinuous jumps; the output is a \nsmooth, continuous curve.\n\n236 \nPart I1 Tools for Systems Thinking \nTABLE 7-2 \nSteps in graphical \nintegration \n1. Calculate and graph the total rate of inflow to the stock (the sum of all \ninflows). Calculate and graph the total rate of outflow from the stock (the \nsum of all outflows). \n2. Calculate and graph the net rate of change of the stock (the total inflow less \nthe total outflow). \n3. Make a set of axes to graph the stock. Stocks and their flows have different \nunits of measure (if a stock is measured in units its flows are measured in \nunits per time period). Therefore stocks and their flows must be graphed on \nseparate scales. Make a separate graph for the stock under the graph for \nthe flows, with the time axes lined up. \n4. Plot the initial value of the stock on the stock graph. The initial value must \nbe specified; it cannot be inferred from the net rate. \n5. Break the net flow into intervals with the same behavior and calculate the \namount added to the stock during the interval. Segments might be intervals \nin which the net rate is constant, changing linearly, or following some other \npattern. The amount added to or subtracted from the stock during a \nsegment is the area under the net rate curve during that segment. For \nexample, does the net flow remain constant from time t, to time t,? \nIf so, \nthe rate of change of the stock during that segment is constant, and the \nquantity added to the stock is the area of the rectangle defined by the net \nrate between t, and tp. If the net rate rises linearly in a segment, then the \namount added is the area of the triangle. Estimate the area under the net \nrate curve for the segment and add it to the value of the stock at the start of \nthe segment. The total is the value of the stock at the end of the segment. \nPlot this point on the graph of the stock. \n6. Sketch the trajectory of the stock between the start and end of each \nsegment. Find the value of the net rate at the beginning of the segment. \nIs it positive or negative? If the net flow is positive, the stock will be \nincreasing at that time. If the net flow is negative, the stock will be \ndecreasing. Then ask whether it is rising or falling at an increasing or \ndecreasing rate, and sketch the pattern you infer on the graph. \nIf the net rate is positive and increasing, the stock increases at an \nincreasing rate (the stock accelerates upward). \nIf the net rate is positive and decreasing, the stock increases at a \ndecreasing rate (the stock is decelerating but still moving upward). \nIf the net rate is negative and its magnitude is increasing (the net rate is \nbecoming more negative), the stock decreases at an increasing rate. \nIf the net rate is negative and its magnitude is decreasing (becoming less \nnegative), the stock decreases at a decreasing rate. \n7. Whenever the net rate is zero, the stock is unchanging. Make sure that \nyour graph of the stock shows no change in the stock everywhere the n",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 260
  },
  {
    "child_id": "f7a53c7e-a1f8-4bff-9aa7-2086fc3de076",
    "parent_id": "15a3f981-6dcc-4374-aa83-1c164182852d",
    "text": "es at a \ndecreasing rate (the stock is decelerating but still moving upward). \nIf the net rate is negative and its magnitude is increasing (the net rate is \nbecoming more negative), the stock decreases at an increasing rate. \nIf the net rate is negative and its magnitude is decreasing (becoming less \nnegative), the stock decreases at a decreasing rate. \n7. Whenever the net rate is zero, the stock is unchanging. Make sure that \nyour graph of the stock shows no change in the stock everywhere the net \nrate is zero. If the net rate remains zero for some interval, the stock \nremains constant at whatever value it had when the net rate became zero. \nAt points where the net rate changes from positive to negative, the stock \nreaches a maximum as it ceases to rise and starts to fall. At points where \nthe net rate changes from negative to positive, the stock reaches a \nminimum as it ceases to fall and starts to rise. \n8. Repeat steps 5 through 7 until done.\n\nChapter 7 Dynamics of Stocks and Flows \n237 \nFIGURE 7-3 \nNote the me-quarter cycle lag between the peaks of the net flow and the peaks of the stock. \nThe accumulation process creates delays. \n200 \n150 \nc, \nS . \nE \n100 \n- \nz \nu) \nC \n3 \nu) \n5., .- \n50 \nv \nL\no\n \n-50 \n600 \n400 \n0 3 6 9 1 2  \n24 \n36 \n48 \nTime (months) \nNow consider the flows specified in the top panel of Figure 7-3. The outflow \nis constant at 100 unitdmonth, but the inflow fluctuates around an average of 100 \nwith a period of 12 months and an amplitude of +50 unitdmonth. At the start, the \ninflow is at its maximum. Assume the initial value of the stock is 500 units. \nSince the outflow is constant, the net inflow is a fluctuation with amplitude \nF50 unitdmonth and a mean of zero. The stock begins at its initial value of 500 \nunits, but since the inflow is at its maximum, the stock initially rises with a slope \nof 50 unitdmonth. However, the net flow falls over the first 3 months, so the stock \nincreases at a decreasing rate. At month 3 the net flow reaches zero, then goes neg- \native. The stock must therefore reach a maximum at month 3. The amount added \nto the stock in the first 3 months is the area under the net rate curve. It is not easy\n\n238 \nPart I1 Tools for Systems Thinking \nto estimate the area from the graph because the net rate curve is constantly chang- \ning. You could estimate it by approximating the area as a set of rectangles, as de- \nscribed above, though this would take time. Using simulation to carry out the \naccumulation shows that a little less than 100 units are added to the stock by the \ntime the net rate falls to zero at month 3. \nFrom month 3 to month 6, the net rate is negative. The stock is therefore \nfalling. Just after month 3, the net rate is just barely negative, so the rate of decline \nof the stock is slight. But the magnitude of the net rate increases, so the stock falls \nat an increasing rate. At 6 months, the net rate has reached its minimum (most neg- \native) value of -50 unitslmonth. The stock is declining ",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 260
  },
  {
    "child_id": "cc1ca644-2a6f-4a84-aecf-5f3b1001b805",
    "parent_id": "15a3f981-6dcc-4374-aa83-1c164182852d",
    "text": " little less than 100 units are added to the stock by the \ntime the net rate falls to zero at month 3. \nFrom month 3 to month 6, the net rate is negative. The stock is therefore \nfalling. Just after month 3, the net rate is just barely negative, so the rate of decline \nof the stock is slight. But the magnitude of the net rate increases, so the stock falls \nat an increasing rate. At 6 months, the net rate has reached its minimum (most neg- \native) value of -50 unitslmonth. The stock is declining at its maximum rate; there \nis an inflection point in the trajectory of the stock at month 6. \nHow much did the stock lose between month 3 and month 6? Assuming the \nfluctuation in the net rate is symmetrical, the loss just balanced what was gained in \nthe first 3 months, reducing the stock back to its initial level of 500 units. \nFrom month 6 to month 9, the net flow remains negative, so the stock contin- \nues to fall, but now at a decreasing rate. By month 9 the net flow again reaches \nzero, so the stock ceases to fall and reaches its minimum. Again using the assump- \ntion of symmetry, the quantity lost from months 6 to 9 is equal to the quantity lost \nfrom months 3 to 6, so the stock falls to a level just above 400 units. \nFrom months 9 to 12 the net flow is positive, so the stock is rising. During this \ntime the net rate rises, so the stock increases at an increasing rate, ending with a \nslope of 50 unitdmonth as the net rate reaches its maximum. Again, the stock gains \nthe same amount, recovering its initial level of 500 units exactly at month 12. Be- \nyond month 12 the cycle repeats. \nThe example illustrates the way in which the process of accumulation creates \ndelays. The input to the system is a fluctuation with a 12-month period reaching its \npeak at time = 0, 12, 24, . . . months. The stock, or output of the system, also fluc- \ntuates with a 12-month period but lags behind the net inflow rate, reaching its \npeaks at t = 3, 15, 27, . . . months. The lag is precisely one-quarter cycle. The lag \narises because the stock can only decrease when the net flow is negative. If the net \nflow is positive and falls to zero, the stock increases and reaches its maximum. \nAnalytical Integration of a Fluctuation \nThe example in Figure 7-3 can be made precise using a little basic calculus. The \nstock S is the integral of the net rate R. Assuming the net flow is a cosine with pe- \nriod 12 months and amplitude 50 units/month, R = 50cos(2d12), then \nS = Rdt = 50cos(2~t/12)dt = 50(12/21~)sin(2.rrt/12) + S, \n(7-2) \nJ\nJ\n \nThe stock follows a sine wave with the same period and amplitude (12/2~r) times \nthat of the net flow. The delay caused by the accumulation process is easily seen \nsince sin(0) = cos(@ - d2): \nS = 5 0 ( 1 2 / 2 ~ ) ~ 0 ~ ( 2 d 1 2  \n- ~ 1 2 )  \n+ S, \n(7-3) \nThe stock follows the same trajectory as the net flow but with a phase lag of d 2  \n(one-quarter cycle). Equation (7-2) also shows that the amplitude of the stock is \n(50 unitdmonth) * (12 months/2",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 260
  },
  {
    "child_id": "90cafb99-ed54-42b8-871a-51602487a9af",
    "parent_id": "15a3f981-6dcc-4374-aa83-1c164182852d",
    "text": "= 50(12/21~)sin(2.rrt/12) + S, \n(7-2) \nJ\nJ\n \nThe stock follows a sine wave with the same period and amplitude (12/2~r) times \nthat of the net flow. The delay caused by the accumulation process is easily seen \nsince sin(0) = cos(@ - d2): \nS = 5 0 ( 1 2 / 2 ~ ) ~ 0 ~ ( 2 d 1 2  \n- ~ 1 2 )  \n+ S, \n(7-3) \nThe stock follows the same trajectory as the net flow but with a phase lag of d 2  \n(one-quarter cycle). Equation (7-2) also shows that the amplitude of the stock is \n(50 unitdmonth) * (12 months/2~) = 96 units, so the stock fluctuates between \nabout 404 and 596, as seen in the figure.\n\nChapter 7 Dynamics of Stocks and Flows \n239 \n7.1.4 \nGraphical Differentiation \nThe inverse of integration is differentiation, the calculation of the net rate of \nchange of a stock from its trajectory. Given a graph of a stock, it is always possi- \nble to infer the net rate of change and plot it. As in the case of integration, there are \nanalytic methods to calculate the net rate of a stock if the function describing the \nstock\u2019s path is known. However, in most dynamic models no analytic function for \nthe stocks is known, so you must develop the skill of graphical differentiation. \nGraphical differentiation is straightforward. Simply estimate the slope of the \nstock at each point in time and plot it on a graph of the net rate. Figure 7-5 provides \nan example.",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 260
  },
  {
    "child_id": "830c455c-0a92-47b5-93e2-16a684433fa7",
    "parent_id": "576896e4-3d7c-4918-ba90-3e864fe0583f",
    "text": "240 \nPart I1 Tools for Systems Thinking \nFIGURE 7-5 \nGraphical \ndifferentiation \n2000 \n1750 \n1500 \n1250 \n1000 \n5 weeks \n5 weeks \nTime (weeks) \nThe initial stock is 2000 units. For the first 10 weeks the stock declines lin- \nearly, so the net rate during this interval is negative and constant. The stock falls \nfrom 2000 to 1000 units in 10 weeks, so the net rate (the slope of the stock) is \n- 100 unitdweek. At week 10 the stock suddenly starts increasing. Drawing a line \ntangent to the stock curve at time 10 gives an estimate of the slope of 200 units/ \nweek. The net rate therefore steps up from - 100 unitdweek the instant before the \nstart of week 10 to +200 unitdweek just after it starts. From weeks 10 to 20 the \nstock increases at a decreasing rate, so the net rate is positive but falling. At time \n20 the stock reaches a maximum so the net rate is zero. There are no kinks or \nbumps in the stock trajectory, implying a steady, linear decline in the net rate from \n200 units/week in week 10 to zero in week 20. From week 20 to week 30 the stock \nis falling. By week 30 it is falling rapidly; the slope of a line tangent to the stock \ntrajectory at week 30 has a slope of -200 unitdweek. Again, there are no kinks in \nthe trajectory, so the net rate declines linearly from zero in week 20 to -200 units/ \nweek in week 30. At week 30 the stock suddenly stops changing and remains con- \nstant afterwards. The net rate suddenly steps up from -200 to zero unitdweek and \nremains at zero thereafter. \nGraphical differentiation of a stock reveals only its net rate of change. If the \nstock has multiple inflows and outflows it is not possible to determine their\n\nChapter 7 Dynamics of Stocks and Flows \n241 \nindividual values from the net rate alone: a firm\u2019s stock of cash remains constant \nwhether revenues and expenditures both equal $1 million per year or $1 billion \nper year. \n7.2 \nSYSTEM DYNAMICS IN ACTION: GLOBAL WARMING \nMuch of the power of the system dynamics perspective comes from understand- \ning how the process of accumulation creates dynamics, even before considering \nthe feedbacks coupling the stocks and their flows. To illustrate, consider global \nwarming. \nIs the earth warming? Is the warming caused by emissions of greenhouse gases \n(GHGs) caused by human activity? How much warming is likely over the next \ncentury? What changes in climate patterns, rainfall, growing season, storm inci- \ndence and severity, and sea level might ensue, and how much damage would these \nchanges cause to humanity and to other species? These questions are difficult to \nanswer, and legitimate scientific debates about the impact of anthropogenic GHG \nemissions continue. \nDespite the scientific uncertainty, several facts are not in dispute. The temper- \nature at the earth\u2019s surface-the land, lower atmosphere, and surface layer of the \nocean (the so-called mixed layer, the top 50 to 100 meters, where most sea life ex- \nists)-is primarily determined by the balance of the incoming sol",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 265
  },
  {
    "child_id": "86602832-ea84-4ded-a863-49290380b286",
    "parent_id": "576896e4-3d7c-4918-ba90-3e864fe0583f",
    "text": "\nchanges cause to humanity and to other species? These questions are difficult to \nanswer, and legitimate scientific debates about the impact of anthropogenic GHG \nemissions continue. \nDespite the scientific uncertainty, several facts are not in dispute. The temper- \nature at the earth\u2019s surface-the land, lower atmosphere, and surface layer of the \nocean (the so-called mixed layer, the top 50 to 100 meters, where most sea life ex- \nists)-is primarily determined by the balance of the incoming solar radiation and \nthe outgoing reradiated energy. The earth is a warm mass surrounded by the cold \nof space and like all such masses emits so-called black body radiation whose fre- \nquency distribution and intensity depends on its surface temperature. The warmer \nthe mass, the more energy it radiates. Incoming solar energy warms the earth. As it \nwarms, more energy is radiated back into space. The temperature rises until the \nearth is just warm enough for the energy radiated back to space to balance the in- \ncoming solar energy.\n\n242 \nPart I1 Tools for Systems Thinking \nThe amount of energy radiated back into space depends on the composition of \nthe atmosphere. GHGs such as carbon dioxide and methane trap some of the en- \nergy radiated by the earth, instead of allowing it to escape into space. Thus an in- \ncrease in GHGs causes the earth to warm. The earth heats up until the energy \nescaping through the atmosphere to space rises enough to again balance the in- \ncoming solar energy. Greenhouse gases reduce the emissivity of the atmosphere \nenough to warm the surface of the earth (including the oceans) to a life-sustaining \naverage of about 15\u00b0C (59\u00b0F). Without GHGs in the atmosphere, the mean global \ntemperature would be about - 17\u00b0C (1\u00b0F) and a blanket of ice would perpetually \ncover the earth. \nNatural processes have caused the concentration of carbon dioxide (CO,) in \nthe atmosphere to fluctuate significantly over geological time, and surface temper- \natures have fluctuated with it. Human activity has now reached a scale where it can \naffect these processes. As shown in Figure 7-7, the rate of anthropogenic GHG \nemissions has been growing exponentially since the beginning of the industrial \nage. Atmospheric concentrations of C02 and other GHGs including nitrous oxide \n(N,O), methane (CH,), chlorofluorocarbons (CFCs), hydrofluorocarbons (HFCs), \nperfluorinated carbons (PFCs), and others have been growing exponentially, with \nconcentrations of CO,, N,O, and CH, up by 30, 15, and 145%, respectively, since \n1800. Mean global surface temperature has been rising, though not in a steady pat- \ntern. Compared to the late 1800s, average global temperatures are about 0.5 to 1\u00b0C \nwarmer today. By comparison, the mean global temperature during the last ice age, \nwhen sheets of ice 1000 feet thick covered much of the northern hemisphere, was \nabout 5\u00b0C colder than today. \nDebate continues about the dynamics of the global climate system, its response \nto forcing by hum",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 265
  },
  {
    "child_id": "d0e8d31f-1e9b-4ac3-a95d-a1fd1ce8d97b",
    "parent_id": "576896e4-3d7c-4918-ba90-3e864fe0583f",
    "text": "y 30, 15, and 145%, respectively, since \n1800. Mean global surface temperature has been rising, though not in a steady pat- \ntern. Compared to the late 1800s, average global temperatures are about 0.5 to 1\u00b0C \nwarmer today. By comparison, the mean global temperature during the last ice age, \nwhen sheets of ice 1000 feet thick covered much of the northern hemisphere, was \nabout 5\u00b0C colder than today. \nDebate continues about the dynamics of the global climate system, its response \nto forcing by human activity, and the consequences of a rise in global mean tem- \nperature. The public discussion has been polarized by well-financed campaigns \nto discount the science. Nevertheless, consensus is emerging. In 1995, the UN \nsponsored Intergovernmental Panel on Climate Change (IPCC) concluded that \nglobal warming was indeed occurring, and that human activity was responsible, \nstating \u201cThe balance of evidence suggests a discernible human influence on cli- \nmate\u201d (IPCC 1996). Through the UN Framework Convention on Climate Change \n(UNFCCC) various nations are negotiating limits to GHG emissions, though com- \npliance remains elusive. \nSimulation models of various types are the primary research tool to explore \nthese issues. The enormously detailed general circulation models (GCMs) calcu- \nlate climate at finely spaced intervals covering the entire surface of the earth, but \ntake GHG emissions as exogenous inputs. At the other extreme, so-called inte- \ngrated climate-economy models close some of the feedbacks among the human \neconomy, carbon emissions, and global climate but treat the carbon cycle and cli- \nmate as global aggregates with a small number of stocks. Tom Fiddaman (1997) \nanalyzed many of the most widely used climate-economy models, identifying a \nnumber of problems and inconsistencies in them. For example, the widely cited \nDICE model (Nordhaus 1992a, 1992b) violates the law of conservation of mass by \nassuming that a significant fraction of carbon emissions simply disappear (Nord- \nhaus assumed they flow into a sink outside the model boundary). Fiddaman (1997)\n\nChapter 7 Dynamics of Stocks and Flows \nI\n,\n.\n,\n,\n.\n \n- 750- \nMama Loa \nE \nGas Recorder Data \nO B  \n.- \nu .I! \nZ E  \n5 $ \n700- \na\ns\n \n2 s  650- \ng g  \nSiple Station \nIce Core Data \n600-, \n- \nI\n,\n,\n,\n,\n , \n,\n'\n'\n'\n/\n'\n'\nI\n'\n \n243 \nFlGiURE 7-7 \nGHG emissions, \nconcentration, \nand global mean \ntemperatwre \n1 . 0 '  \" \" \nI\n'\n \" \" \n' \n~ \n' \n1\n'\n \" \n' \nAngell \n1800 \n1850 \n1900 \n1950 \n2( 00 \nSources: Data from the Carbon Dioxide Information Analysis Center (CDIAC), Oak Ridge National \nLaboratory (http://cdiac.esd.ornl.gov/trends/trends.htm). Emissions: Keeling (1 997). Emissions in- \nclude carbon from burning fossil fuels only and excludes other GHGs and changes in carbon flux \nfrom, e.g., deforestation. COP in atmosphere: Siple Station ice core data (Neftel et al. 1994). Mauna \nLoa gas recorder data (Keeling et al. 1997); concentration in ppmv converted to billion tons in total \natmosphere. Global ",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 265
  },
  {
    "child_id": "757f748f-c00b-4010-aeb1-275b9df261ff",
    "parent_id": "576896e4-3d7c-4918-ba90-3e864fe0583f",
    "text": "m the Carbon Dioxide Information Analysis Center (CDIAC), Oak Ridge National \nLaboratory (http://cdiac.esd.ornl.gov/trends/trends.htm). Emissions: Keeling (1 997). Emissions in- \nclude carbon from burning fossil fuels only and excludes other GHGs and changes in carbon flux \nfrom, e.g., deforestation. COP in atmosphere: Siple Station ice core data (Neftel et al. 1994). Mauna \nLoa gas recorder data (Keeling et al. 1997); concentration in ppmv converted to billion tons in total \natmosphere. Global mean surface temperature anomaly: Jones, Wigley, and Wright (1 997) and Angell \n(1997); rescaled so 1960-70 = 0.2'C. \ndeveloped a model that corrects these and other defects in common climate- \neconomy models and linked it to a model of the economy and energy system. The \nmodel sectors were based on the relevant scientific knowledge of the global carbon \ncycle and climate system and carefully calibrated to the available data.",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 265
  },
  {
    "child_id": "970b2151-6392-4643-acc9-be75068bab54",
    "parent_id": "b1a7b97e-5ab0-4de9-9a42-bddbd8ecc196",
    "text": "244 \nPart I1 Tools for Systems Thinking \nDespite the differences among the models, all show the climate system to pos- \nsess enormous inertia. Changes in GHG emissions only slowly show up in changes \nin global temperature and climate, and the changes persist for many decades. To \nillustrate, Figure 7-8 shows an extreme conditions test using Fiddaman\u2019s model. In \nthe simulation, anthropogenic CO, emissions follow their historical path through \nthe mid 1990s, remain constant until 2000, and then fall to zero after 2000. Sur- \nprisingly, though the rate of CO, emissions falls to zero in the year 2000, mean \nglobal temperature continues to rise for about three more decades. It then falls \nvery slowly. \nThe stock and flow structure responsible for the counterintuitive result that \ntemperature rises even though emissions fall to zero is shown in Figure 7-9. The \nleft side of the figure portrays the global carbon cycle; the right side portrays the \nglobal heat balance. Burning fossil fuels adds CO, to the atmosphere. There are \nseveral outflows from the stock of atmospheric CO,. Higher atmospheric CO, con- \ncentration increases the rate at which CO, is consumed by aquatic life or dissolves \ninto the mixed layer of the ocean. Eventually, CO, taken up by the surface layer \ndiffuses to deeper waters, both through ocean currents and as detritus from aquatic \nlife sinks. The transfer of carbon to the depths is slow, and mixing between the sur- \nface and abyssal waters is weak, so many carbon cycle models disaggregate the \nwater column into a number of distinct states and model the transfer of carbon \nbetween adjacent layers explicitly. Fiddaman\u2019s model utilizes 10 layers, enough to \ncapture the slow adjustment of abyssal C02 concentrations to changes in CO, in \nthe mixed layer. \nIncreased atmospheric CO, concentration also stimulates uptake of carbon by \nterrestrial plants (the flux of CO, to biomass). Carbon in biomass can be released \nback into the atmosphere through respiration and metabolic activity of animal and \nbacterial life and by fire (natural and human-caused). As biomass decays, the stock \nof carbon stored in soil increases (the flux of carbon from biomass to soil humus). \nThe carbon in humus can be taken up directly into biomass as plants grow or can \nbe released into the atmosphere through decay. \nNote that the model represents the inflow of CO, to the atmosphere from the \nburning of fossil fuels as flowing from an unlimited source when in fact the flow \ndraws down the carbon sequestered in global stocks of fossil fuels. Similarly, the \nmodel does not capture the conversion of carbon in humus or the abyssal layer of \nthe ocean into new stocks of fossil fuels. Although the dynamics of global warm- \ning will play out over the next several centuries, this time horizon is so short rela- \ntive to the millions of years required to form oil, gas, and coal that these carbon \nflows can be safely ignored. \nThe right side of Figure 7-9 shows the stock and",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 269
  },
  {
    "child_id": "7013d0a6-4632-4759-a121-74de7ac1ebf6",
    "parent_id": "b1a7b97e-5ab0-4de9-9a42-bddbd8ecc196",
    "text": "\ndraws down the carbon sequestered in global stocks of fossil fuels. Similarly, the \nmodel does not capture the conversion of carbon in humus or the abyssal layer of \nthe ocean into new stocks of fossil fuels. Although the dynamics of global warm- \ning will play out over the next several centuries, this time horizon is so short rela- \ntive to the millions of years required to form oil, gas, and coal that these carbon \nflows can be safely ignored. \nThe right side of Figure 7-9 shows the stock and flow structure for the heat \nbalance of the earth\u2019s surface, atmosphere, and oceans. The surface and atmos- \nphere, including the surface layer of the ocean, absorb incoming solar energy and \nradiate heat back into space. Heat is also transferred between the surface layer and \nthe deep ocean, though at slow rates. The rate of heat transfer between surface and \ndeep ocean depends on the temperature differential between the different layers, \ncreating two negative feedbacks which seek to equilibrate the temperatures of the \ndifferent layers. Similarly, net radiative forcing is the difference between the in- \ncoming solar energy and the energy radiated from the warm earth back into space.\n\nFIGURE \n7-8 \nGlobal tempera \nture rises well after \nGHlG emissions \nfall to zero. \nSi ni u I ated emis- \nsions fall to zero \nin 2000. Mean \nsurface tempera- \nture contiinues tlo \nrise for roughly \n20 years \nChapter 7 Dynamics of Stocks and Flows \n245 \n0.8 1 \nAngel1 \nData t \nDO \n2025 \n205 \nSource: Fiddaman (1997). \nThe warmer the surface, the more energy is radiated back into space, cooling the \nearth and forming another negative loop. The concentration of C02 and other \nGHGs increases net radiative forcing by reducing the rate at which energy is radi- \nated back into space for any given surface temperature. \nThe diagram (though not the full model) deliberately omits many additional \nfeedbacks affecting the rates of carbon flow and heat exchange as well as cou- \nplings to other biogeochemical cycles. Knowledge of the nature and strength of \nthe many feedbacks coupling climate, carbon cycle, and human activity is still \nevolving. Some of these feedbacks are negative and may offset GHG emissions or\n\n246 \nPart I1 Tools for Systems Thinking \nFIGURE 7-9 Stock and flow diagram of global carbon cycle and heat balance \nBurning fossil fuels adds C02 to the atmosphere, increasing net radiative forcing until the temperature \nof the land, ocean surface, and atmosphere rises enough to balance reradiation of energy into space \nwith incoming insolation. The diagram deliberately omits many of the feedbacks, both positive and \nnegative, among the carbon stocks and global mean temperature. Flows with arrowheads at both ends \ncan be positive or negative (e.g., Net Radiative Forcing can be an inflow of heat to the atmosphere or \nan outflow). The solid arrowhead indicates the positive direction of two-way flows. \nFlux Biomass \nFlux Humus to \nInsolation \nFlux Atmosphere \nFlux Ocean \nb.3 ' ' \nto ",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 269
  },
  {
    "child_id": "c4663fdc-0984-4e93-8cf4-cbe97cb29db8",
    "parent_id": "b1a7b97e-5ab0-4de9-9a42-bddbd8ecc196",
    "text": "adiation of energy into space \nwith incoming insolation. The diagram deliberately omits many of the feedbacks, both positive and \nnegative, among the carbon stocks and global mean temperature. Flows with arrowheads at both ends \ncan be positive or negative (e.g., Net Radiative Forcing can be an inflow of heat to the atmosphere or \nan outflow). The solid arrowhead indicates the positive direction of two-way flows. \nFlux Biomass \nFlux Humus to \nInsolation \nFlux Atmosphere \nFlux Ocean \nb.3 ' ' \nto Atmosphere \nto Ocean \nI \nI \nCO, in \nMixed Layer \nn \nNet C o p  Fiux \nto Deep Ocean \nCO, in \nDeep Ocean \nAtmosphere \n& Upper Ocean \nTem perat u re \nAtmosphere \n& Upper Ocean \n\\ f. \n, \nExchange \n, \n;Tempera7 \n+ \nDifference \nbetween \nSurface and \nDeep Ocean \nHeat Stored in \n/ \nDeep Ocean \nTemperature \nDeep Ocean \n+ \nSource: Adapted from Fiddaman (1 997).\n\nChapter 7 Dynamics of Stocks and Flows \n247 \nwarming. These include increased carbon uptake by biomass, stimulated by higher \nC02 concentrations, and increased cloud cover from enhanced evaporation, re- \nflecting more incoming sunlight to space. Particulate aerosols from fossil fuel con- \nsumption (air pollution and smog) also increase reflection of incoming solar \nradiation and may account for the slower than expected rate of temperature rise ob- \nserved in the Northern Hemisphere. \nAmong the positive feedbacks driving climate change are changes in surface \nalbedo: Warming reduces the winter snow cover and shrinks the highly reflective \npolar ice caps, thus increasing heat absorption and leading to further melting, less \nsnow cover, and still greater absorption. Scientists expect this positive loop will \ncause much greater warming at the poles than in the tropics and more warming in \nwinter than summer. Thawing of permafrost may release large quantities of \nmethane from decay of organic matter, increasing the concentration of GHGs and \nleading to further warming in another positive loop. Increased evaporation from \nwarmer land and surface waters may be self-reinforcing since water vapor is a \npowerful GHG. At present it is not known whether the negative or positive feed- \nbacks dominate the dynamics nor how the dominance of the loops might change as \nvarious nonlinearities come into play. However, Goulden et al. (1998) studied the \nnorthern boreal forest of Canada and found that warming has resulted in net carbon \nflux to the atmosphere as C02 released from decay of thawed biomass outweighed \nincreased carbon uptake by plants. For that biome, at least, the positive feedbacks \nappear to dominate the negative loop of increased biotic activity. \nThe impact of warming on sea level may also be driven by positive feedback. \nThe huge West Antarctic Ice Sheet (WAIS) consists of a floating tongue attached \nto a larger ice mass so heavy it rests on bedrock below sea level. The WAIS holds \na lot of water: \u201cIf it melted away in a greenhouse-warmed world, it would raise all \nthe world\u2019s oceans by 5 meters\u201d (Kerr 1998, p",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 269
  },
  {
    "child_id": "8f8b898b-c223-4559-9b03-75e459ec7c33",
    "parent_id": "b1a7b97e-5ab0-4de9-9a42-bddbd8ecc196",
    "text": "by plants. For that biome, at least, the positive feedbacks \nappear to dominate the negative loop of increased biotic activity. \nThe impact of warming on sea level may also be driven by positive feedback. \nThe huge West Antarctic Ice Sheet (WAIS) consists of a floating tongue attached \nto a larger ice mass so heavy it rests on bedrock below sea level. The WAIS holds \na lot of water: \u201cIf it melted away in a greenhouse-warmed world, it would raise all \nthe world\u2019s oceans by 5 meters\u201d (Kerr 1998, p. 17). If warmer seas cause the WAIS \nto thin, it will rise farther off the sea bed, exposing more of the ice to melting and \naccelerating thinning in a positive loop. As the edge thins, the higher ice on the \nAntarctic land mass flows faster into the sea, where it is exposed to the warmer wa- \nters, further speeding melting in another positive feedback. Rignot (1998) notes \nthat a glacier with \u201c[tlhis configuration is theoretically unstable because a retreat \nof its grounding line (where the glacier starts to float) would be self-perpetuating \nand irreversible\u201d and shows that the grounding line of the Pine Island glacier feed- \ning the WAIS is retreating at 1.2 ? 0.3 kilometers per year. Ice cores show that \nwithin the past 1.3 million years, \u201cat a time perhaps not much warmer than today, \nthe WAIS wasted away to a scrap and flooded the world\u2019s coasts\u201d (Kerr 1998, \np. 17). Ice core data from Greenland also suggest the paleoclimate repeatedly \nwarmed and cooled, with corresponding changes in snowfall, over time scales of \nonly decades. These rapid changes suggest positive feedbacks may have domi- \nnated climate dynamics in geologically recent times. \nIt will take years of research to discover all the feedbacks that drive the climate \nand determine the likely effects of greenhouse warming. Nevertheless, the stock \nand flow structure of the global carbon cycle and heat budget explains some basic \nfeatures of the dynamics. The stock and flow structure shows how it is possible for",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 269
  },
  {
    "child_id": "a6890c8e-737f-4f59-acf8-7bd84ec77e17",
    "parent_id": "967f3659-ac4a-4516-a898-6a9cdabc1bec",
    "text": "248 \nPart I1 Tools for Systems Thinking \nthe global temperature to rise even after human GHG emissions fall to zero. When \nemissions fall to zero the inflows to the stock of atmospheric carbon fall below the \noutflows. Therefore the stock of CO, in the atmosphere peaks and begins to fall. \nThe concentration of CO, in the atmosphere falls only slowly, however. First, the \nuptake of carbon by biomass falls as the concentration of CO, in the atmosphere \ndeclines, while CO, continues to flow into the air from burning and decay of bio- \nmass and humus stocks. Second, as atmospheric C02 falls, the flux of carbon from \nthe air to the mixed layer of the ocean falls, while the flux of carbon from the ocean \nto the air increases. These compensatory responses slow the decline of atmospheric \nCO, so that 50 years after human emissions stop completely, the concentration of \nCO, in the model atmosphere has fallen back only to its 1990 level. \nThe heat content of the surface layer rises as long as incoming radiation ex- \nceeds the heat radiated back to space or transferred to the deep ocean. Though \nfalling after the year 2000, global atmospheric C02 concentrations remain high \nenough to reduce the energy radiated back to space below incoming insolation. \nDeclining atmospheric C02 after 2000 means global mean temperature grows at a \ndiminishing rate. By about 2030 the surface has warmed enough and the concen- \ntration of CO, in the atmosphere has fallen enough for insolation to be balanced \nagain by the earth\u2019s black-body radiation and the rate of heat transfer to the deep \nocean. Note that global mean temperature falls only slowly after 2030. First, the \nslow decline of GHG concentrations after 2000 slows the increase in radiative \nemissivity. Second, during the warmest decades when the surface temperature ex- \nceeded the temperature of the deep ocean, heat flowed from the surface layer to the \ndeep. As the surface layer cools, heat stored in the deep ocean now flows back to \nthe surface, slowing atmospheric cooling. \nThe stock and flow structure of the carbon cycle and heat balance explains the \nseemingly paradoxical result that temperatures can rise even when emissions fall. \nThere are several lessons. First, global warming cannot be proven or disproven by \ncorrelating emissions and temperature: the dynamics are too complex for such \nnaive commonsense approaches. Second, the full impact of past emissions has not \nyet been observed. The oceans and terrestrial carbon stocks have been absorbing \ncarbon out of the atmosphere at higher rates, suppressing the rise in atmospheric \nCO, concentrations. And as these stocks increase, their absorption capacity dimin- \nishes. The impact of future emissions on atmospheric CO, may well be larger than \nthat observed in the past. Third, the inertia of the system means further warming \nand climate change are already underway. Action to halt warming must be taken \ndecades before we can know what the consequences of warming wil",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 273
  },
  {
    "child_id": "7fbc827d-983e-495b-b37e-3ff0e140b884",
    "parent_id": "967f3659-ac4a-4516-a898-6a9cdabc1bec",
    "text": "ocks have been absorbing \ncarbon out of the atmosphere at higher rates, suppressing the rise in atmospheric \nCO, concentrations. And as these stocks increase, their absorption capacity dimin- \nishes. The impact of future emissions on atmospheric CO, may well be larger than \nthat observed in the past. Third, the inertia of the system means further warming \nand climate change are already underway. Action to halt warming must be taken \ndecades before we can know what the consequences of warming will be and before \nscientific certainty about the dynamics of the global climate can be gained. \nMost important, the stock and flow structure of the global climate means sta- \nbilizing emissions near current rates will not stabilize the climate. Figure 7- 10 \nshows a simulation in which emissions are stabilized in 1995. The concentration of \natmospheric CO, continues to rise, more than doubling by 2300. Global mean sur- \nface temperature rises by about 3\u00b0C. Many industrialized nations agreed at the Rio \nconference on the environment to stabilize their GHG emissions at 1990 levels, \nand 38 industrialized nations agreed at the 1997 Kyoto conference of the UNFCCC \nto reduce emissions by 2012 to about 95% of 1990 rates. But the US Senate de- \nclared the treaty dead on arrival. Implementation remains elusive; signing a treaty\n\nChapter 7 Dynamics of Stocks and Flows \n249 \nFIGURE 7-1 0 \nStabilizing GHG \nemissions does \nnot stabilize the \nclimate. \nStabilizing GHG \nemiissions at 19!35 \nlevels causes at- \nmospheric COP \nconcentrations to \ndouble by 2300, \nwhile mean global \nsurface tc, lm p era- \nture increases \nabout 3\u00b0C;. Even \nunder the pro- \nposed Kyoto \nagreement, global \nemissions are \nlikely to increase \nsubstantially over \nthe next several \ndecades. \n1 L \n2 \nHistory :v \n0 \n1950 \n2000 \nI\n.\n,\n.\n \n2050 ~ . . ~ ' ~ ' ' ' ' l . ' . ' ~ ' \" ' ~ '\n2100 \n2150 \n2200 \n2250 \n2300 \nSimulati \nHistory Simulation \n8ool \" ' ' I '  \" \" \nI\n'\n ' \" \nI\n'\n \" \" \" \" \nI\n'\n \" \n'\nI\n A \n1950 \n2000 \n2050 \n2100 \n2150 \n220C \nSource: Fiddaman (1 997) \nis one thing, actually reducing emissions another. Most troubling, the emissions of \nrapidly developing nations such as China continue to grow at high exponential \nrates. The US Energy Information Administration forecast in 1997 that GHG emis- \nsions from developing nations would nearly double by 2015, accounting for the \nlarge majority of the world total (Malakoff 1997). \nWhile different climate models differ in their details and in their estimates of \nfuture warming, all agree that stabilizing emissions near current levels will not sta- \nbilize the climate. Mitigating the risk of climate change from global warming re- \nquires a substantial decline in the rate of GHG emissions. The world has yet to face \nup to the inexorable logic of the stocks and flows of the global climate system.\n\n250 \nPart II Tools for Systems Thinking \n7.3 SYSTEM DYNAMICS IN ACTION: THE WAR ON DRUGS \nIn the 1980s the use of cocaine increased dramatically. As cocaine spr",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 273
  },
  {
    "child_id": "5b5282f3-ef91-42c2-b01a-70df2710aded",
    "parent_id": "967f3659-ac4a-4516-a898-6a9cdabc1bec",
    "text": "\nfuture warming, all agree that stabilizing emissions near current levels will not sta- \nbilize the climate. Mitigating the risk of climate change from global warming re- \nquires a substantial decline in the rate of GHG emissions. The world has yet to face \nup to the inexorable logic of the stocks and flows of the global climate system.\n\n250 \nPart II Tools for Systems Thinking \n7.3 SYSTEM DYNAMICS IN ACTION: THE WAR ON DRUGS \nIn the 1980s the use of cocaine increased dramatically. As cocaine spread, crime, \nviolence, and health problems grew exponentially. The United States declared a \nwar on drugs. A new federal agency, the White House Office of National Drug \nControl Policy (ONDCP), headed by the \u201cdrug czar,\u201d was appointed to oversee the \ncampaign. Penalties for possession, sale and use of drugs were stiffened. Billions \nwere spent to increase enforcement, especially to reduce the flow of cocaine into \nthe US, estimated by the ONDCP to be 550 to 660 metric tons in 1989. The focus \nof the war on drugs was primarily the supply side: slashing the production of co- \ncaine, choking off smuggling into the US, and stiffening penalties for possession \nand sale. On the demand side, kids were told to \u201cJust say NO.\u201d \nDid it work? In the late 1980s the data told a conflicting story. Some drug data \nshowed improvement. Through the \u201cNational Household Survey\u201d (NHS) and \n\u201cHigh School Senior Survey\u201d (HSSS), the government regularly asks people about \ntheir use of alcohol and drugs. To assess trends in incidence and prevalence, the \nsurveys ask whether people have ever used cocaine, whether they\u2019ve used it in the \nlast year, and whether they\u2019ve used it in the last month. Figure 7-11 shows NHS \ndata for the fraction of people responding that they have used cocaine in the past \nmonth. According to the surveys, cocaine use was falling sharply, with less than \n1% of the population reporting past month cocaine use in 1990, down from 3% in \n1985. The drop in reported use coincided with a sharp increase in the seizure rate, \nto more than 75 metric tons per year (Figure 7-11). The war on drugs seemed to be \nworking; citing these data, the administration called for even more money to finish \nthe job. \nHowever, other indicators showed the problem was getting worse. Arrests for \npossession and sale of cocaine, the number of emergency room visits associated \nwith cocaine, and the number of cocaine-related deaths all showed exponential in- \ncreases, while the purity of cocaine on the street was growing and the street price \nwas falling (Figure 7-11). By these measures, cocaine use was up sharply and \navailability was growing. Critics, citing the failure of prohibition in the 1920s and \n1930s, argued that interdiction could never work and called for stronger demand- \nside measures (MacCoun and Reuter 1997 review the debate). Others argued that \ndecriminalization would eliminate the crime problem caused by use of illegal \ndrugs and allow the government to regulate purity to p",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 273
  },
  {
    "child_id": "1fbd3030-2c0e-4db5-8333-1bb3724d6521",
    "parent_id": "967f3659-ac4a-4516-a898-6a9cdabc1bec",
    "text": " street was growing and the street price \nwas falling (Figure 7-11). By these measures, cocaine use was up sharply and \navailability was growing. Critics, citing the failure of prohibition in the 1920s and \n1930s, argued that interdiction could never work and called for stronger demand- \nside measures (MacCoun and Reuter 1997 review the debate). Others argued that \ndecriminalization would eliminate the crime problem caused by use of illegal \ndrugs and allow the government to regulate purity to prevent accidental overdoses. \nMuch of the debate focused on which data series were right and which were \nwrong. The stakes were high: Besides the issues of public health and safety, the \ndrug war was prosecuted and data series were collected by an alphabet soup of \nfederal and state agencies, including the FBI, DEA, SAMHSA, NIJ, NIDA, DEPB, \nONDCP, and CIA.2 Each argued for the primacy and correctness of its data and \n2Federal Bureau of Investigation, Drug Enforcement Agency, Substance Abuse and Mental \nHealth Services Administration of the Department of Health and Human Services, National \nInstitute of Justice, National Institute on Drug Abuse, Drug Enforcement Policy Board, Office of \nNational Drug Control Policy, and Central Intelligence Agency.\n\nt '  \n, \" L \" \" \" \" ' '  \nW \nb \n,\n\"\n'\n,\n,\n'\n'\n#\n.\n-\nm\n \n0 \n0 \n0 - 0  \nI \n,\n\"\n'\n1\n\"\n'\n1\n\"\n'\n1\n\"\n'\n \n0 \n0 \n0 \n0 \na \nnn \n0 \nIn \n0 \nilc \nIn \nN \n-I------, \n' \n' \n' \nI \n' \n' \n' \nI \n' \n' \n' \nr. \n0 \nm \nm \nc \nm \nm \nm \nc \nW \nCO \nm \nc \nd \nm \nm \nc \nN \nm \nm \nc \n0 \nm \nm \nr \n0) \nb \nm \nc \nW \nb \nm \nr- \n0 \nm \nm \nc \nm \nm \nm \n7 \nW \nm \nm \nc \nP \nm \nm \nc \nN \ne0 \nm \nr \n0 \nm \nm \nr \nco \nb \nm \nr \nW \nb \nm \nc \n0 \n0 \n0 \n0 \n-=J \nN \n< \nieaK/aldoad puesnoyl \nm \nm \nm\n-\n \n7 \n(D \nm \nm\n-\n \nc \nP \nm \nm\n-\n \nc \nN \nm \nm\n-\n \nc \n0 \nm \nm\n-\n \nc \nm \nm\n-\n \nb \nc \n0 \nm \nm \nc \ne0 \nm \nm \nr \nW \nm \nm \nc \n.;r \nm \nm \nc \nN \nm \nm \n7 \n0 \nm \nm \n7 \nm \nb \nm \n7 \nW \nb \nm \nc \n0 \n0 \n0 \n0 \n0 \n0 \n0 \n0) \nW \nd \n01 \nm \ne\no\n \n251",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 273
  },
  {
    "child_id": "2103bf35-9dce-43e5-90bb-414d53b1962c",
    "parent_id": "28bbece7-3fb2-4946-8bc6-fb74e944c0b8",
    "text": "252 \nPart I1 Tools for Systems Thinking \ndrug-enforcement programs as they struggled to gain a larger share of more than \n$10 billion per year devoted to the war on drugs. \nSupporters of the interdiction strategy argued that the survey data directly \nmeasured what counts-the use of drugs-while other indicators were indirect. \nThey argued that rising arrest rates and seizures reflected greater enforcement, not \ngreater drug use, and were therefore a sign of success; falling prices, rising purity, \nand the surge in medical emergencies and deaths simply reflected the substitution \nof more potent crack for the less pure powder form. Critics of interdiction and the \nsurvey data argued that drug users are less likely than law-abiding citizens to be se- \nlected for or participate in the surveys. Many cocaine users are likely to deny they \nuse drugs when the government asks. Defenders of the surveys pointed to the so- \nphisticated sampling methods they used to account for possible underrepresenta- \ntion of certain subpopulations. They guaranteed anonymity to survey respondents \nand claimed that while \u201c[tlhe value of self-reports obviously depends on the hon- \nesty and memory of sampled respondents[, rlesearch has supported the validity of \nself-report data in similar contexts\u201d (SAMHSA 1994). \nIn the late 1980s the National Institute of Justice commissioned a study to re- \nsolve the apparent paradox of declining measures of cocaine use and rising con- \nsumption, crime, arrests, and deaths. As part of the study, a system dynamics \nmodel was developed to integrate the demand and supply sides of the market \n(Homer 1993, 1997). The full model consisted of several hundred equations and \nincluded a detailed representation of the stock and flow structure of users, along \nwith the feedbacks among different market actors, the market, and the criminal jus- \ntice system. \nFigure 7-12 shows a simplified representation of the stock and flow structure \nfor the different categories of drug users represented in the model. The NHS con- \nsiders all persons age 12 and over to be potential drug users. As people in this age \ngroup first experiment with cocaine they move from the \u201cnever used\u201d population \nto the stock of active casual users (those who have used cocaine in the past month \nbut are not addicted). Some casual users find they cannot control their cocaine con- \nsumption and become compulsive users. Active users, both casual and compulsive, \ncan stop, becoming \u201ctransitional users\u201d (those who have used cocaine in the past \nyear, but not in the past month). Transitional users can relapse, becoming active \nusers again. After a year without any cocaine use, transitional users are reclassified \nas ex-users. Some ex-users relapse, becoming active users again. Others quit per- \nmanently. There are, of course, death rates out of each stock, both from drug- \nrelated causes and all other sources. \nThe full model has a more complex stock and flow structure than shown \nin Figure ",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 277
  },
  {
    "child_id": "efdc5eb7-8712-4586-8cdb-b3e920c1f5b8",
    "parent_id": "28bbece7-3fb2-4946-8bc6-fb74e944c0b8",
    "text": "rs\u201d (those who have used cocaine in the past \nyear, but not in the past month). Transitional users can relapse, becoming active \nusers again. After a year without any cocaine use, transitional users are reclassified \nas ex-users. Some ex-users relapse, becoming active users again. Others quit per- \nmanently. There are, of course, death rates out of each stock, both from drug- \nrelated causes and all other sources. \nThe full model has a more complex stock and flow structure than shown \nin Figure 7- 12, explicitly distinguishing between casual and compulsive transi- \ntional and ex-users and between users of powder and crack cocaine. The model \naccounted for escalation from casual to compulsive use and for switching between \npowder and crack. This disaggregation was necessary because the probabilities \nof moving from one state to another depend on the form and intensity of use. \nCompulsive users are less likely to quit and more likely to relapse, and crack users \nare more likely to escalate from casual to compulsive use and suffer higher re- \nlapse rates.\n\nChapter 7 Dynamics of Stocks and Flows \n253 \nFIG~JRE \n7-1 2 \nCocaine use: \nstocks and flows \nr \nActive \nActive \nCasual \n- \nUsers \nEscalsion to \nUsers \nCompulsive \nUse \nT 7  \nbCompulsive \nTotal Active Users \nTransitional \nUser Relapse \nRelapse \nRate \nRate \nTransitionall z 4 Ex-Users I \nI \nUsers \nQuit - \nRate \nEver-Used Population \nSource:Adapted from Homer (1993). \n+ew3 \nDeath Rate \n(All Causes) \nNote that the categories of use in the model can be directly compared to those \nused in the surveys. The total number of active users, both casual and compulsive, \nfor both powder and crack, is the number of people who have actually used cocaine \nin the past month. The sum of the active users and the transitional users is the total \nnumber who actually used cocaine in the past year. Finally, the sum of active, tran- \nsitional, and ex-users is the total number who have ever used cocaine. \nWhat are the determinants of the initiation rate-what causes people to use co- \ncaine for the first time? Studies show most people begin using drugs through peer \ninfluence-by observing others using drugs and through their membership in so- \ncial networks in which others use drugs (that is, by hanging with the wrong \ncrowd). As more people start using cocaine, the social networks of users expand, \nbringing still more nonusers into contact with the drug, in a positive feedback \nprocess analogous to the spread of an infectious disease (chapter 9). The strength \nof the social exposure feedback depends on the social aura of the drug: how chic \ncocaine is perceived to be (is this the drug the opinion leaders, the beautiful peo- \nple, are using this year?). The positive feedback also depends on whether current\n\n254 \nPart I1 Tools for Systems Thinking \nand potential users view the drug as benign-is it perceived to offer a good high \nwithout negative effects such as addiction, bad trips or the risk of sudden death? \nPrice has a co",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 277
  },
  {
    "child_id": "2b2feb53-6f67-4806-bac2-c040d069fc6c",
    "parent_id": "28bbece7-3fb2-4946-8bc6-fb74e944c0b8",
    "text": " (chapter 9). The strength \nof the social exposure feedback depends on the social aura of the drug: how chic \ncocaine is perceived to be (is this the drug the opinion leaders, the beautiful peo- \nple, are using this year?). The positive feedback also depends on whether current\n\n254 \nPart I1 Tools for Systems Thinking \nand potential users view the drug as benign-is it perceived to offer a good high \nwithout negative effects such as addiction, bad trips or the risk of sudden death? \nPrice has a comparatively modest effect, at least in higher socioeconomic groups, \nbecause high price and scarcity confer social status on those who can provide the \ndrug for friends at parties or in the workplace. In the mid 1970s, as the cocaine \nepidemic began, cocaine was viewed as a benign, nonaddictive drug posing little \nhealth risk. It became the in-group drug of choice among certain professional \nelites. The entertainment industry reinforced the chic image of the drug. All these \nself-reinforcing processes are captured by the Word of Mouth loop R1 in Fig- \nure 7-13. \nThe dynamics of the market reinforced the growth of the epidemic. As con- \nsumption increased, the supply side of the market became much more efficient. \nPrice declined and purity increased. The growing scale of the industry created huge \nincentives for technological and organizational innovation by producers and smug- \nglers. The introduction of crack cocaine in 1981 was the most important, but far \nfrom the only, technical innovation in the market. As in many legitimate industries, \ngrowth led to production and especially distribution scale economies. Horizontal \nand vertical market integration through the cocaine cartels cut costs and led to \nmore consistent product quality. Growing experience led to a substantial learning \ncurve as harvesting, production, smuggling, distribution, and money laundering \noperations were improved. These scale and learning effects created additional pos- \nitive feedbacks leading to wider availability, greater purity, and lower prices, mak- \ning cocaine affordable and accessible to all (loop R2). \nAs long as people perceived the health and legal risks of cocaine to be small, \nthese positive feedbacks dominated the system. Cocaine use mushroomed, spread- \ning gradually from middle and upper income, trend-conscious populations on the \neast and west coasts to every social and income level in every state of the country. \nWhy then did the data show such a large drop in the incidence of current co- \ncaine use after 1985? Supporters of the interdiction strategy credited the adminis- \ntration\u2019s supply-side policy. They argued that enhanced enforcement increased the \nfraction of cocaine seized, cutting the availability of the drug (the balancing Sup- \nply Disruption loop B 1) and that aggressively arresting and incarcerating pushers \nand users helps clean up the Streets (the balancing loop B2). Both these negative \nloops, it was argued, cut drug use, as indicated by the surve",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 277
  },
  {
    "child_id": "b475fbc9-3e8a-494d-bd68-7c0f0cf6e8b5",
    "parent_id": "28bbece7-3fb2-4946-8bc6-fb74e944c0b8",
    "text": "e of current co- \ncaine use after 1985? Supporters of the interdiction strategy credited the adminis- \ntration\u2019s supply-side policy. They argued that enhanced enforcement increased the \nfraction of cocaine seized, cutting the availability of the drug (the balancing Sup- \nply Disruption loop B 1) and that aggressively arresting and incarcerating pushers \nand users helps clean up the Streets (the balancing loop B2). Both these negative \nloops, it was argued, cut drug use, as indicated by the survey data. \nHowever, stock and flow structure for drug users showed that the survey data \ncould not be correct and were substantially understating the prevalence of drug \nuse. In addition to asking about past month use, the NHS asks respondents if they \nhave used cocaine in the past year and if they have ever used cocaine. Homer care- \nfully disaggregated the user population into stocks corresponding to these cate- \ngories so the model could be directly compared to the data. \nFigure 7-14 shows the NHS data for the fraction of the population who re- \nsponded affirmatively when asked if they had ever used cocaine. Note that the \nreported ever-used-cocaine population peaks in 1982 at about 12% and falls to \nabout 10% by 1988. \nThe lifetime cocaine prevalence data in Figure 7-14 is the ratio of the ever- \nused population to the total population (those who never used plus those who ever \nused). The inflow to the total stock of people who have actually used cocaine is the\n\nFIGURE 7-1 3 \nFeedback structure of the cocaine epidemic \n/ - \nRepcrtd \nUnderreporting of \nPrevalence of \nCocaine Use \nCocaine Use \n(Fraction of Users Lying) \nSocial \nExposure to \nWord of Mouth \n/Cocaine User Populatioa \nCocaine Market \nRetail price \nDisaggregated by \nPreferred form \nScale and \nRetail sales \nIntensity of use \nLearning \nImports \n@ \nPurity \n- \nRecency of use \nEffects \nSocial \nAcceptability \nof Drugs \n+ \nCocaine- \nHealth \nRisks \nCrime \nEnforcement Intensity; \nPerceived \nLegal Risks \nIncarceration + \nSource:Adapted from Homer (1993). \nh) \ntn \ncn",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 277
  },
  {
    "child_id": "c6ed23a5-9e28-49bf-a65c-22cfd8ad20f2",
    "parent_id": "feb167de-5cb5-43e9-94c2-86d1b0f413d7",
    "text": "256 \n0 .- \nc - \nQ \nf \nFIGURE 7-14 \nSurvey estimates \nof lifetime cocaine \nprevalence \nNHS Lifetime User Prevalence Fraction \nPart I1 Tools for Systems Thinking \nm \n0 - \n? \np ' o . 0 0  \n, \n, \n, \n, \n, \n, \n, \n, \n, \n, \n, \n, \nI\n,\n,\n , \n, \n, \n, \ninitiation rate. The only outflow is death. The only way the stock of people who \nhave ever used cocaine can decline is for the death rate of current and past users to \nexceed the initiation rate of new users.3 Yet the survey data reported a 3.2% drop \nin the number of people who have ever used cocaine from 1982 to 1988. Even if \nthe rate at which people tried cocaine for the first time fell to zero in 1985-even \nif every man, woman, and child in the US who had never used cocaine just said \nNO !, something not even the administration believed-mortality rates of the ever- \nused population are too small to cause the reported decline in the number of peo- \nple who have ever tried cocaine. Even with the most optimistic estimates for the \ndecline in the initiation rate, it is physically impossible for the stock of people who \nhave ever used cocaine to fall as quickly as the surveys ~uggested.~ \nWhy then did the reported incidence of use fall so dramatically after 1985? \nThere are two main reasons. First, the surveys presume that their samples are prop- \nerly stratified, that is, that the representation and response rates of subpopulations \n(such as different geographic, ethnic, racial, and socioeconomic groups) are ad- \njusted to match the proportion of these groups in the overall population and that \nany underrepresentation is constant through time. Heavy drug users, however, are \nmuch less likely to be interviewed for the survey. Though the NHS methodology \nattempted to adjust for this underrepresentation, they cautioned that \nPrevalence estimates for specific subgroups are sometimes based on modest to \nsmall sample sizes, which may lead to substantial sampling error. . . [Tlhis report \ndoes not present estimates for some segments of the US population that may con- \ntain a substantial proportion of drug users, such as transients not residing in shelters \n31n principle, the lifetime prevalence fraction could fall if those in the ever-used population emi- \ngrated from the US to other countries at a rate much higher than that of those who have never used \ncocaine. These rates, however, are negligible. For the survey to be correct the required outmigration \nof drug users would greatly exceed all outmigration from the US. \nlation that has ever used cocaine. The decline in relative lifetime prevalence would require the \ndeath rate of former cocaine users to greatly exceed the death rate of those who have never used \ncocaine. The difference in death rates, however, is very small, partly due to the low excess mortal- \nity of active users and largely because most members of the ever-used population no longer use \ncocaine and experience mortality rates about the same as the never-used population. \n4The problem in the surve",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 281
  },
  {
    "child_id": "e849ae78-a6c6-4b28-93da-2917793f4be6",
    "parent_id": "feb167de-5cb5-43e9-94c2-86d1b0f413d7",
    "text": "on that has ever used cocaine. The decline in relative lifetime prevalence would require the \ndeath rate of former cocaine users to greatly exceed the death rate of those who have never used \ncocaine. The difference in death rates, however, is very small, partly due to the low excess mortal- \nity of active users and largely because most members of the ever-used population no longer use \ncocaine and experience mortality rates about the same as the never-used population. \n4The problem in the survey data is worse. The NHS reported a drop in thefraction of the popu-\n\nChapter 7 Dynamics of Stocks and Flows \n257 \n(e.g., users of soup kitchens or residents of street encampments) and those incarcer- \nated in county jails or State and Federal prisons (SAMHSA 1994). \nThat is, few federal workers are willing to knock on the doors of a crack house to \nask the occupants whether they use illegal drugs. Consequently, active and espe- \ncially compulsive users are underrepresented in the surveys. Because these popu- \nlations grew rapidly in the 1980s, the surveys systematically underestimated the \ngrowth in cocaine use. \nSecond, and more importantly, increasing legal risks caused a larger fraction \nof current and especially former users to deny they ever used cocaine. In plain lan- \nguage, more people lied about their past cocaine use. The changing distribution of \ncocaine users and declining social acceptance of cocaine led to systematic under- \nestimation of cocaine prevalence in the survey data. \nBy integrating all the available data into a consistent and unified framework, \nthe model provided more accurate estimates of drug use than were available previ- \nously. Model estimates of the ever-used population (along with the other categories \nof drug use) were derived to be consistent with other demographic, crime, health, \nprice, and purity data, constrained by the stock and flow structure of the population \nand epidemiological and medical data on health risks. Understanding the dynam- \nics of the stocks and flows of users helps reconcile the apparently contradictory \ndata. Figure 7-15 compares the model\u2019s behavior for reported lifetime use against \nthe survey data, along with the model\u2019s estimate of the actual ever-used population. \nThe actual population of past users must have continued to grow because the num- \nber of people trying cocaine for the first time exceeded the death rate of those who \nhad ever tried it. The availability, purity, and use of cocaine were in fact increasing \nthroughout the late 1980s despite the billions spent on enforcement and supply \nreduction. \nIn hindsight it seems quite obvious that the stock of people who have ever used \ncocaine cannot decline as rapidly as the data suggested, so the survey data should \nimmediately have been challenged. But hindsight is always crystal clear. The fact \nremains that the data were not challenged. Instead, the government used the survey \ndata to take credit for winning the drug war, to justify inte",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 281
  },
  {
    "child_id": "8ec5a0a1-7351-4385-aa75-884ae207c6d4",
    "parent_id": "feb167de-5cb5-43e9-94c2-86d1b0f413d7",
    "text": "ct increasing \nthroughout the late 1980s despite the billions spent on enforcement and supply \nreduction. \nIn hindsight it seems quite obvious that the stock of people who have ever used \ncocaine cannot decline as rapidly as the data suggested, so the survey data should \nimmediately have been challenged. But hindsight is always crystal clear. The fact \nremains that the data were not challenged. Instead, the government used the survey \ndata to take credit for winning the drug war, to justify intervention in the affairs of \nother nations, and to lobby for tougher penalties, greater powers for law enforce- \nment agencies, more prisons, and more resources to defend the borders of the US \nagainst the threat of foreign drugs. \nPerhaps the administration knew the data overstated the reduction in drug use \nand used it cynically to manipulate public opinion and the congress. Even if true, \nit immediately begs the question of why others in government, along with the me- \ndia, policy analysts, and the public at large did not recognize the flaw in the data. \nThe administration, congress, and the media all focused on the data showing \nrecent use-the NHS past month or past week data, along with the HSSS-rather \nthan lifetime use. Recent use provides a better snapshot of current drug trends, and \nshowed the largest decline, making the case most favorable to the administration. \nHowever, the data showing decline in recent use confounded the actual decline \nin use with the increase in underreporting. The two sources of decline cannot be \ndisentangled from the recent-use data because the recent user stock can drop as \npeople quit; likewise, past users age out of the high school senior population. It is\n\n258 \nPart I1 Tools for Systems Thinking \nFIGURE 7-1 5 \nSimulated vs. \nactual population \nof lifetime cocaine \nusers \nNote that while the \nsurvey data show \na drop in the ever- \nused population \nafter 1982, the \nmodel estimates \nfor the actual \npopulation of \nthose who have \never used cocaine \ncontinue to rise, \nthough at a \ndiminishing rate. \nIncreasing legal \nrisks led to a large \nincrease in the \nfraction of former \nusers who denied \ntheir cocaine use. \nS \n0 .- \nc \nE = \n0.2- \nFraction \n1976 \n1980 \n1984 \n1988 \n1992 \n1996 \no\n,\n,\n,\n.\n,\n,\n,\n,\n,\n,\n,\n,\n,\n,\n,\n,\n \nI\n,\n \nSource: Homer (1993, 1997). \nonly by explicitly accounting for the stock and flow structure of drug use-for the \ninexorable accumulation of users into the ever-used population-that the two com- \npeting sources of decline in current use data can be separated. Unfortunately, the \nability to understand basic stock and flow relationships is far too rare in our soci- \nety today, even among many professional policy analysts. \n7.3.1 \nThe Cocaine Epidemic after 1990 \nThe model showed persuasively that the survey data significantly underestimated \ncocaine use and highlighted the failure of the supply-side strategy. As MacCoun \nand Reuter (1997, p. 47) put it, \u201cThe probability of a cocaine or heroin seller being \ni",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 281
  },
  {
    "child_id": "1fb6e3c2-e04f-48b3-bd73-10e19f43acb4",
    "parent_id": "feb167de-5cb5-43e9-94c2-86d1b0f413d7",
    "text": "ecline in current use data can be separated. Unfortunately, the \nability to understand basic stock and flow relationships is far too rare in our soci- \nety today, even among many professional policy analysts. \n7.3.1 \nThe Cocaine Epidemic after 1990 \nThe model showed persuasively that the survey data significantly underestimated \ncocaine use and highlighted the failure of the supply-side strategy. As MacCoun \nand Reuter (1997, p. 47) put it, \u201cThe probability of a cocaine or heroin seller being \nincarcerated has risen sharply since about 1985 but that has led neither to increased \nprice nor reduced availability.\u201d However, a close look at the simulation in Figure \n7-15 shows that by the late 1980s the number of people who had ever used \ncocaine, though still rising, was growing at a diminishing rate. Therefore the ini- \ntiation rate must have been falling. By the mid 1990s, the epidemic began to abate: \nthe growth of cocaine-related medical emergencies and deaths slowed; arrests fell \nslightly. The ONDCP estimated net imports in 1995 at between 421 and 5 13 metric \ntons, with 98 metric tons seized, leaving net cocaine available on the streets of \nAmerica at about three-quarters the 1989 level. The model, originally developed \nin the late 1980s, forecast these dramatic shifts in cocaine use quite well (Fig- \nure 7-16). \nNote that the point-by-point fit of the model in the 1990s isn\u2019t perfect, and you \nshould not expect it to be. Simulated arrests are too high, and the model does not \ntrack the temporary dip in cocaine related medical emergencies in 1990-9 1. Never- \ntheless, the model\u2019s ability to capture the turning point in the epidemic, from \nexponential growth to gradual decline, is quite remarkable, considering that the \nsimulations shown in Figure 7-16 were based on data available only through 1989. \nThe only exogenous inputs affecting model behavior after 1990 are the target \npopulation (those age 12 and over) and the prevalence of marijuana use (a proxy \nfor social tolerance of drugs). Changes in data-reporting systems and definitions \nwere not included.\n\nChapter I \nDynamics of Stocks and Flows \nHistory \n259 \nForecast \nFIGIJRE \n7-1 6 \nSimulated vs. \nactual cocaine \nepidemic \nDashed lines, \ndata; solicl lines, \nmodel. \nHistory Forecast \n1 \nL \n600- \nP \n% 4001 \na, \nP - \n-0 \nm \nu) \nc \nI- s 200: \n1976 \n1980 \n1984 \n1988 \n1992 \n0 \n1 \n1996 \n- 0 . 0 5  \n~\n\"\n\"\n'\n~\n\"\n\"\n\"\n'\n'\n*\n \n5 \n. \nSimulated \nHistory Forecast \n1976 \n1980 \n1984 \n1988 \n1992 \n1996 \nSource: Homer (1 993, 1997). \nAdding additional exogenous inputs could improve the fit to the data. But \nmodels should not be tuned to fit data by introducing exogenous variables whose \nsole function is to improve the correspondence of model output to data. Exogenous \nvariables must be justified by significant real world evidence independent of their \npotential contribution to historical fit. Further, variables involved in any feedback \nloops judged to be potentially significant relative to the model purpose ",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 281
  },
  {
    "child_id": "1e3b5d98-8671-426e-935c-ddc5fe129ed6",
    "parent_id": "feb167de-5cb5-43e9-94c2-86d1b0f413d7",
    "text": "(1 993, 1997). \nAdding additional exogenous inputs could improve the fit to the data. But \nmodels should not be tuned to fit data by introducing exogenous variables whose \nsole function is to improve the correspondence of model output to data. Exogenous \nvariables must be justified by significant real world evidence independent of their \npotential contribution to historical fit. Further, variables involved in any feedback \nloops judged to be potentially significant relative to the model purpose must be \ncaptured as part of the model's endogenous structure and cannot be used as exoge- \nnous inputs to improve historical fit.",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 281
  },
  {
    "child_id": "c77ed838-7de6-40d2-b554-38f6f6c3b98c",
    "parent_id": "10da9cd3-e2e4-40e9-807b-9c19df80eb6b",
    "text": "260 \nPart I1 Tools for Systems Thinking \nWhile the model shows that the survey data overestimated the decline in co- \ncaine use, model-generated estimates of the actual number of active users, while \nremaining significantly higher than the estimates reported in the surveys, do show \na decline. The field research and model results showed the drop in cocaine use was \nnot caused primarily by the Supply Disruption Loop B 1 in Figure 7-13 or by the \nClean up the Streets loop B2, as supporters of the interdiction policy claimed. \nRather, the exponential growth of cocaine use was eventually halted by two nega- \ntive feedbacks involving public perceptions of cocaine\u2019s health and legal risks. \nFirst, cocaine is not the benign substance it was thought to be in the 1970s. As peo- \nple began to experience or hear about the Negative Health and Social Effects of the \ndrug, they became less likely to start and more likely to stop (balancing loop B3 in \nFigure 7-13). Second, growing legal risks of drug use due to higher arrest rates and \nlonger sentences decreased the willingness of people to start and increased the quit \nrate-the Fear of Arrest reduced usage (balancing loop B4). As the population of \nactive users began to fall, the social exposure of nonusers also fell, weakening the \nreinforcing Word of Mouth loop (R1). \nUnfortunately, both of these negative loops involve long delays. First, there is \na lag between growth in cocaine use and the incidence of harmful health and legal \neffects. As the initiation rate grew exponentially, so did the stock of active casual \nusers. The stock of compulsive users also rose exponentially, though with a sub- \nstantial lag. The lag in the growth of the compulsive user population is important \nbecause compulsive users are more likely to experience severe health effects (es- \npecially as they turn to crack) and more likely to commit drug-related crimes in- \ncluding pushing the drug to finance their own habits. Thus the exponential growth \nin cocaine-related crime, arrests, medical emergencies, and deaths lags behind the \ngrowth of the casual user population, which in turn lags behind the initiation rate. \nThere is a further lag in the perception by the public of the true health effects \nof cocaine. Most people don\u2019t read the New England Journal of Medicine or the \nAnnals of Addiction to learn about the health risks of illegal drugs. Instead, public \nperceptions of risk are strongly conditioned by personal experience, personal \nacquaintance with someone harmed by cocaine, and media reports of high-profile \nindividuals who were arrested for, injured by, or died from cocaine use, such as the \ncomedian Richard Pryor, who was severely burned while freebasing, or the Uni- \nversity of Maryland basketball star Len Bias, who died of acute heart failure while \ndoing cocaine to celebrate his selection as a top draft pick by the Boston Celtics of \nthe National Basketball Association. \nThe strength of all these channels of public awaren",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 285
  },
  {
    "child_id": "15d10e0a-30b7-4c18-902d-b7db2518fb41",
    "parent_id": "10da9cd3-e2e4-40e9-807b-9c19df80eb6b",
    "text": "ntance with someone harmed by cocaine, and media reports of high-profile \nindividuals who were arrested for, injured by, or died from cocaine use, such as the \ncomedian Richard Pryor, who was severely burned while freebasing, or the Uni- \nversity of Maryland basketball star Len Bias, who died of acute heart failure while \ndoing cocaine to celebrate his selection as a top draft pick by the Boston Celtics of \nthe National Basketball Association. \nThe strength of all these channels of public awareness therefore lags behind \nthe population of active users driving the growth of the epidemic. Exponential \ngrowth in cocaine use did eventually reduce the social acceptability of the drug and \nthus the initiation rate. However, the stock of active users lags well behind the ini- \ntiation rate. The stock of active users will rise as long as initiation exceeds the rate \nat which people stop using, and the stock of compulsive users increases as long as \nthe escalation rate exceeds the rate at which compulsive users stop. The dynamics \nof the stock and flow structure inevitably mean that the population of drug users, \nespecially the compulsive users responsible for most of the crime and health ef- \nfects, continues to grow even after the initiation rate peaks and falls. The delay en- \nsures that the reinforcing social exposure and word of mouth feedbacks dominate\n\nChapter 7 Dynamics of Stocks and Flows \n261 \nthe negative risk perception loops in the early years of the epidemic, leading to a \nlater and higher peak for incidence and prevalence. \nStill, by the late 1980s, nearly every community had experienced the arrest, in- \njury, or death of at least one of its promising young people, slowly strengthening \nthe negative feedbacks that slow the initiation rate. Ironically, the cocaine epidemic \ndid not abate because interdiction made the drug less available; on the contrary, the \ndata showed growing accessibility, purity, and affordability throughout the 1980s. \nInstead, the very abundance of cocaine, by leading to a large increase in personal \nknowledge of its harmful effects, led people to turn away from the drug. No longer \nchic, stripped of its social aura and benign image, those who craved escape from \nthe world turned from cocaine to other drugs. Thus, the cocaine epidemic was ul- \ntimately self-limiting. \nThe feedback structure outlined in Figure 7-13 is quite general and applies to \nany harmful drug, legal or illegal. The positive feedbacks generating growth in us- \nage act swiftly, while the negative feedbacks that deter usage, particularly public \nrecognition of a drug\u2019s harmful effects, are only perceived slowly. The result is the \ncharacteristic boom and bust pattern for drug use. Each new or newly popular drug \ngenerates a wave of naive enthusiasm in which users extol its benefits, only to dis- \ncover as the population of users grows and more people escalate to compulsive use \nthat the drug isn\u2019t as benign as people were led to believe. \nIn fact, th",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 285
  },
  {
    "child_id": "40a06876-43cf-4c2d-8ba1-0ec5dbcd1564",
    "parent_id": "10da9cd3-e2e4-40e9-807b-9c19df80eb6b",
    "text": "- \nage act swiftly, while the negative feedbacks that deter usage, particularly public \nrecognition of a drug\u2019s harmful effects, are only perceived slowly. The result is the \ncharacteristic boom and bust pattern for drug use. Each new or newly popular drug \ngenerates a wave of naive enthusiasm in which users extol its benefits, only to dis- \ncover as the population of users grows and more people escalate to compulsive use \nthat the drug isn\u2019t as benign as people were led to believe. \nIn fact, the cocaine epidemic of the 1980s was not the first. A similar boom and \nbust in cocaine use occurred in the late 1800s. It began with medicinal use, as co- \ncaine was praised by the medical community, including Freud in his famous 1884 \npaper \u201cOn Coca,\u201d as a cure for opium addiction, alcoholism, fatigue, depression, \nnervousness, timidity, impotence, and seasickness, among other complaints. Fol- \nlowing the classic pattern, cocaine moved into more general and recreational use, \nbecoming an ingredient in Coca-Cola and some cigarettes. As use spread, avail- \nability and purity increased; instead of injecting or drinking the preparation, pow- \nder for snorting became popular. Soon the harmful effects began to be experienced, \nobserved, and reported in the medical and popular press. By the early 1900s, co- \ncaine use had spread from social elites to lower social classes. Communities across \nthe country struggled to deal with compulsive users (known as \u201ccoke fiends\u201d), and \n\u201cby 1914 the Atlanta police chief was blaming 70 percent of the crimes [in the city] \non cocaine\u201d (Grinspoon and Bakalar 1985, p. 38). In response, legal restrictions \nand prohibitions grew increasingly severe; in 1922 congress defined cocaine as a \nnarcotic and banned importation of coca; by 193 1 every state had restricted its sale \nand most made possession a crime. Cocaine use fell from its peak and remained \nlow as people turned to other drugs, until the current epidemic began. Similar \nwaves of drug use have been repeatedly observed for the opiates, for psychedelics, \nand for various stimulants and barbiturates. \nWhile epidemics of any particular illegal drug are ultimately self-limiting (if \nthe drug is harmful enough) people have always sought out mind-altering sub- \nstances. Even as one drug falls out of favor, new epidemics begin, centered on new \ndrugs for which there is as yet no experience of harmful effects or on old drugs for \nwhich the hard-won knowledge of harm gained by prior generations has faded \nfrom collective memory. The modest decline in cocaine use in the 1990s led to an \nincrease in the use of other drugs, including marijuana, methamphetamine, and\n\n262 \n7.4 \nPart I1 Tools for Systems Thinking \nmost troubling, a resurgence of heroin use, more than 20 years after the last wave \nof heroin crested. This latest heroin epidemic was stimulated by the usual self- \nreinforcing word of mouth and media feedbacks, including the glorification of \n\u201cheroin chic\u201d in popular culture an",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 285
  },
  {
    "child_id": "824e1267-68f9-415c-8b69-ae23b7b22506",
    "parent_id": "10da9cd3-e2e4-40e9-807b-9c19df80eb6b",
    "text": "s has faded \nfrom collective memory. The modest decline in cocaine use in the 1990s led to an \nincrease in the use of other drugs, including marijuana, methamphetamine, and\n\n262 \n7.4 \nPart I1 Tools for Systems Thinking \nmost troubling, a resurgence of heroin use, more than 20 years after the last wave \nof heroin crested. This latest heroin epidemic was stimulated by the usual self- \nreinforcing word of mouth and media feedbacks, including the glorification of \n\u201cheroin chic\u201d in popular culture and Calvin Klein underwear ads.5 \nSUMMARY \nThis chapter showed how stocks and flows generate dynamics. The process of ac- \ncumulation is equivalent to integration in calculus. The amount added to a stock in \nany period is equal to the area swept out by the net rate of change in the stock over \nthat period. Conversely, the slope of the trajectory of a stock at any time is its de- \nrivative, the net rate of change. Graphical methods for integration and differentia- \ntion were introduced. Given the behavior over time for the rates affecting any \nstock, you can deduce the behavior of the stock; given the trajectory of the stock \nyou can deduce its net rate of change, all without use of calculus. The ability to re- \nlate stocks and flows intuitively is essential for all modelers, even those with ex- \ntensive mathematics training, because most realistic models have no analytical \nsolutions. Examples show that understanding the dynamics of stocks and flows, \neven without feedback, can yield insight into important problems. \n5Further reading: Shreckengost developed a model for the US CIA to estimate heroin imports \nby integrating prevalence, crime, price, purity, and other data (Gardiner and Shreckengost 1987). \nShreckengost (1991) applies the framework to cocaine. Levin, Hirsch, and Roberts (1975), in The \nPersistent Poppy, develop a system dynamics model of heroin use and abuse in a community based \non a case study of the south Bronx. They use the model to explore a variety of policy options in- \ncluding demand-side policies, increased enforcement, and methadone maintenance. See also Levin, \nHirsch, and Roberts (1978). Richardson (1983) develops a simple model to explain why aggressive \npolice effort to seize street supplies of heroin actually increases drug-related crime. Goluke, \nLandeen, and Meadows (1981a, 1981b) developed a model of addictive behavior, focusing on \nalcoholism. Holder and Blose (1987) develop a model of community level policy responses to \nalcoholism. Homer et al. (1982) present a system dynamics model of (tobacco) smoking and \nanalyze a variety of policies.\n\n8 \nClosing the Loop: Dynamics of \nSimple Structures \nA mathematical theory is not to be considered complete until you have made it \nso clear that you can explain it to the first man whom you meet on the street. \n-David Hilbert \nI hope to show. ..that mathematical notation can be kept close to the vocabulary \nof business; that each variable and constant in an equation has individual \nmeani",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 285
  },
  {
    "child_id": "93597589-0791-453e-b419-db52663fbd8e",
    "parent_id": "10da9cd3-e2e4-40e9-807b-9c19df80eb6b",
    "text": "omer et al. (1982) present a system dynamics model of (tobacco) smoking and \nanalyze a variety of policies.\n\n8 \nClosing the Loop: Dynamics of \nSimple Structures \nA mathematical theory is not to be considered complete until you have made it \nso clear that you can explain it to the first man whom you meet on the street. \n-David Hilbert \nI hope to show. ..that mathematical notation can be kept close to the vocabulary \nof business; that each variable and constant in an equation has individual \nmeaning to the practicing manager; that the required mathematics is within the \nreach of almost anyone who can successfully manage a modern corporation. \n-Jay W. Forrester (Industrial Dynamics, 1961, p. 9) \nThis chapter formalizes the connection between structure and behavior by linking \nfeedback with stock and flow structures. The focus is the simplest feedback sys- \ntems, those with one stock (known as first-order systems). Linear first-order sys- \ntems (defined in this chapter) can generate exponential growth and goal-seeking \nbehavior. Nonlinearity in first-order systems causes shifts in the dominant loops, \nleading for example to S-shaped growth. The chapter also introduces the concept \nof a phase plot-a graph showing how the net rate of change of a stock is related \nto the stock itself-and shows how dynamics can be derived from the phase plot \nwithout calculus or differential equations. \n8.l \nFIRSFORDER \nSYSTEMS \nChapter 4 discussed the basic modes of behavior generated by complex systems \nand the feedback structures responsible for them. The most fundamental modes are \n263",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 285
  },
  {
    "child_id": "196c3fb3-3e5a-4e0f-b9f8-fd81ff259e41",
    "parent_id": "6ef3b8f7-bb9c-4b3a-90c0-6b1e1fb6707b",
    "text": "264 \nPart I1 Tools for Systems Thinking \nFIGURE 8-1 Growth and goal seeking: structure and behavior \nState of the / \nNet / \ni+ \nIncrease \ns;:.~he \nRate \nGoal \n- \nTime - \n+ State of the \nGoal \nSystem \\ \n(Desired \n\\ S t a T f  System) \n( \nDiscrepancy + \nCorrective \nAction \n+ \nexponential growth and goal seeking. Positive feedback causes exponential \ngrowth, and negative feedback causes goal-seeking behavior (Figure 8- 1). \nThe simplest system that can generate these behaviors is the first-order, linear \nfeedback system. The order of a dynamic system or loop is the number of state \nvariables, or stocks, it contains. A first-order system contains only one stock. Lin- \near systems are systems in which the rate equations are linear combinations of the \nstate variables and any exogenous inputs. \nThe term \u201clinear\u201d has a precise meaning in dynamics: in a linear system the \nrate equations (the net inflows to the stocks) are always a weighted sum of the state \nvariables (and any exogenous variables, denoted Uj ): \ndS/dt = Net Inflow = alSl + a,S2 + . . . + a$\u201d f blUl + b2U2 + . . . + bmUm (8-1) \nwhere the coefficients ai and bj are constants. Any other form for the net inflows is \nnonlinear.\u2019 \n8.2 \nPOSITIVE FEEDBACK AND EXPONENTIAL GROWTH \nThe simplest feedback system is a first-order positive feedback loop. In a first- \norder system, there is only one state variable (stock), denoted here by s. The state \nof the system accumulates its net inflow rate; in turn, the net inflow depends on the \n\u2018For example, formulations for the net inflow such as a, * S1 * Sz, a, * Sl/S2. or MAX(0, al * S,) \nare all nonlinear. The term \u201cnonlinear\u201d is often used in other senses, for example to describe the \nnonchronological narrative structure of novels such as Cortizar \u2019s Hopscotch. The term \u201cnonlinear\u201d \nin these contexts actually means \u201cnonsequential\u201d and has nothing to do with the technical meaning \nof linearity.\n\nChapter 8 Closing the Loop: Dynamics of Simple Structures \n265 \nstate of the system (for now, assume no exogenous inputs). In general, the net in- \nflow is a possibly nonlinear function of the state of the system: \nS = INTEGRAL(Net Inflow, S(0)) \n(8-2) \nNet Inflow = f<S). \n(8-3) \nIf the system is linear, the net inflow must be directly proportional to the state of \nthe system: \nNet Inflow = gS \n(8-4) \nwhere the constant g has units of (Mime) and represents the fractional growth rate \nof the stock.2 \nFigure 8-2 shows the structure of this system as a causal diagram and also as a \nset of equations. As examples, consider the accumulation of interest income into a \nbank account or the growth of a population. The principal and prevailing interest \nrate determine the interest payment; population and the fractional net birth rate \ndetermine the net birth rate.3 \nWhat will the behavior of the system be? Section 8.2.1 uses basic calculus to \nsolve the differential equation; the solution is the exponential function \ns(t> = S(O)exp(gt) \n(8-5) \nwhere S(0) is the value of S at ",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 289
  },
  {
    "child_id": "5a8bbcab-f629-47cc-8edb-ff0bbf620c2a",
    "parent_id": "6ef3b8f7-bb9c-4b3a-90c0-6b1e1fb6707b",
    "text": "s a \nset of equations. As examples, consider the accumulation of interest income into a \nbank account or the growth of a population. The principal and prevailing interest \nrate determine the interest payment; population and the fractional net birth rate \ndetermine the net birth rate.3 \nWhat will the behavior of the system be? Section 8.2.1 uses basic calculus to \nsolve the differential equation; the solution is the exponential function \ns(t> = S(O)exp(gt) \n(8-5) \nwhere S(0) is the value of S at the initial time t = 0. The state of the system grows \nexponentially from its initial value at a constant fractional rate of g per time unit. \n8.2.1 \nAnalytic Solution for the \nLinear First-Order System \nTo solve the differential equation for the first-order linear system, dS/dt = gS, first \nseparate variables, to obtain \ndS - \n= gdt \nS \nNow, integrate both sides \n1 f = lgdt \nto get \nln(S) = gt + c \nwhere c is a constant. Taking exponentials of both sides gives \n21n the general case of a multistate system, the rates of change, dS/dt, are a functionfo of the \nstate vector S and any exogenous variables U: dS/dt = f ( S ,  U). In a linear system, the rates are \nlinear combinations of the states and exogenous variables: dS/dt = AS + BU where A and B are \nmatrices of coefficients. For good treatments of linear system theory, see, e.g., Ogata (1997) and \nKamopp, Margolis, and Rosenberg (1990). \nbirth and the ability to reproduce, a poor assumption for mammals, but reasonable for many \nunicellular and other small organisms. \n3Representing population growth as a first-order process assumes there is no delay between",
    "source_file": "John D Sterman - Business Dynamics Systems Thinking and Modeling for a Complex World-McGraw-Hill Higher Education 2000.pdf",
    "page_number": 289
  },
  {
    "child_id": "3113b710-c040-4537-be46-dcc9316e94ac",
    "parent_id": "2c42c481-bae0-4fb0-8479-dc46a5984ecb",
    "text": "Conceptual Understanding \nStudents need to be equipped with both the methods and conceptual  \nunderstanding of statistics. MyStatLab offers a full question library of over \n1,000 conceptual-based questions to help tighten the comprehension of  \nstatistical concepts.\nReal-World Statistics\nMyStatLab video resources help foster conceptual understanding. StatTalk  \nVideos, hosted by fun-loving statistician, Andrew Vickers, demonstrate  \nimportant statistical concepts through interesting stories and real-life events. \nThis series of 24 videos includes assignable questions built in MyStatLab and  \nan instructor\u2019s guide.\nVisit www.mystatlab.com and click Get Trained to make sure  \nyou\u2019re getting the most out of MyStatLab.\n\nBIOSTATISTICS\nFOR THE BIOLOGICAL  \nAND HEALTH SCIENCES\nMARC M. TRIOLA, MD, FACP\nNew York University School of Medicine\nMARIO F. TRIOLA\nDutchess Community College \nJASON ROY, PHD\nUniversity of Pennsylvania \nPerelman School of Medicine\nSECOND EDITION\n\nTo Ginny\nDushana and Marisa\nTrevor and Mitchell\nDirector, Portfolio Management Deirdre Lynch\nSenior Portfolio Manager Suzy Bainbridge\nPortfolio Management Assistant Justin Billing\nContent Producer Peggy McMahon\nManaging Producer Karen Wernholm\nCourseware QA Manager Mary Durnwald\nSenior Producer Vicki Dreyfus\nProduct Marketing Manager Yvonne Vannatta\nField Marketing Manager Evan St. Cyr\nProduct Marketing Assistant Jennifer Myers\nField Marketing Assistant Erin Rush\nSenior Author Support/Technology Specialist Joe Vetere \nManager, Rights and Permissions Gina M. Cheselka\nText and Cover Design, Illustrations, Production  Coordination, \nComposition Cenveo Publisher Services\nCover Image Robert Essel NYC/Getty Images\nCopyright \u00a9 2018, 2006 by Pearson Education, Inc. All Rights Reserved. Printed in the United States of America. This publica-\ntion is protected by copyright, and permission should be obtained from the publisher prior to any prohibited reproduction, storage \nin a retrieval system, or transmission in any form or by any means, electronic, mechanical, photocopying, recording, or otherwise. \nFor information regarding permissions, request forms and the appropriate contacts within the Pearson Education Global Rights & \nPermissions department, please visit www.pearsoned.com/permissions/.\nAttributions of third party content appear on page 683\u2013684, which constitutes an extension of this copyright page.\nPEARSON, ALWAYS LEARNING, and MYSTATLAB\u00a0are exclusive trademarks owned by Pearson Education, Inc. or its affiliates \nin the U.S. and/or other countries.\nUnless otherwise indicated herein, any third-party trademarks that may appear in this work are the property of their respective own-\ners and any references to third-party trademarks, logos or other trade dress are for demonstrative or descriptive purposes only. Such \nreferences are not intended to imply any sponsorship, endorsement, authorization, or promotion of Pearson\u2019s products by the owners \nof such marks, or any relationship between the owne",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 2
  },
  {
    "child_id": "c0a55682-a7b9-4c23-bd36-358619cf5f31",
    "parent_id": "2c42c481-bae0-4fb0-8479-dc46a5984ecb",
    "text": " affiliates \nin the U.S. and/or other countries.\nUnless otherwise indicated herein, any third-party trademarks that may appear in this work are the property of their respective own-\ners and any references to third-party trademarks, logos or other trade dress are for demonstrative or descriptive purposes only. Such \nreferences are not intended to imply any sponsorship, endorsement, authorization, or promotion of Pearson\u2019s products by the owners \nof such marks, or any relationship between the owner and Pearson Education, Inc. or its affiliates, authors, licensees or distributors.\nMICROSOFT AND>OR ITS RESPECTIVE SUPPLIERS MAKE NO REPRESENTATIONS ABOUT THE SUITABILITY OF THE INFORMATION CONTAINED IN THE \nDOCUMENTS AND RELATED GRAPHICS PUBLISHED AS PART OF THE SERVICES FOR ANY PURPOSE. ALL SUCH DOCUMENTS AND RELATED GRAPHICS \nARE PROVIDED \u201cAS IS\u201d WITHOUT WARRANTY OF ANY KIND. MICROSOFT AND>OR ITS RESPECTIVE SUPPLIERS HEREBY DISCLAIM ALL WARRANTIES \nAND CONDITIONS WITH REGARD TO THIS INFORMATION, INCLUDING ALL WARRANTIES AND CONDITIONS OF MERCHANTABILITY, WHETHER EXPRESS, \nIMPLIED OR STATUTORY, FITNESS FOR A PARTICULAR PURPOSE, TITLE AND NON-INFRINGEMENT. IN NO EVENT SHALL MICROSOFTAND>OR ITS RESPEC-\nTIVE SUPPLIERS BE LIABLE FOR ANY SPECIAL, INDIRECT OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF \nUSE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH \nTHE USE OR PERFORMANCE OF INFORMATION AVAILABLE FROM THE SERVICES.\nTHE DOCUMENTS AND RELATED GRAPHICS CONTAINED HEREIN COULD INCLUDE TECHNICAL INACCURACIES OR TYPOGRAPHICAL ERRORS. CHANGES \nARE PERIODICALLY ADDED TO THE INFORMATION HEREIN. MICROSOFT AND>OR ITS RESPECTIVE SUPPLIERS MAY MAKE IMPROVEMENTS AND>OR \nCHANGES IN THE PRODUCT(S) AND>OR THE PROGRAM(S) DESCRIBED HEREIN AT ANY TIME. PARTIAL SCREEN SHOTS MAY BE VIEWED IN FULL WITHIN \nTHE SOFTWARE VERSION SPECIFIED.\nLibrary of Congress Cataloging-in-Publication Data\nNames: Triola, Marc M. | Triola, Mario F. | Roy, Jason (Jason Allen)\nTitle: Biostatistics for the biological and health sciences.\nDescription: Second edition / Marc M. Triola, New York University, \nMario F. Triola, Dutchess Community College, Jason Roy, University of \nPennsylvania. | Boston : Pearson, [2018] | Includes bibliographical \nreferences and index.\nIdentifiers: LCCN\u00a02016016759| ISBN 9780134039015 (hardcover) | ISBN\n0134039017 (hardcover)\nSubjects: LCSH: Biometry. | Medical statistics.\nClassification: LCC QH323.5 .T75 2018 | DDC 570.1/5195\u2013dc23\nLC record available at\u00a0https://lccn.loc.gov/2016016759\n1 16\nISBN 13: 978-0-13-403901-5\nISBN 10: 0-13-403901-7\n\niii\nMarc Triola, MD, FACP is the \nAssociate Dean for Educational \nInformatics at NYU School of \nMedicine, the founding director \nof the NYU Langone  Medical \nCenter Institute for Innovations \nin Medical Education (IIME), \nand an  Associate Professor of \nMedicine. Dr. Triola\u2019s research \nexperience and expertise focus \non the disruptiv",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 2
  },
  {
    "child_id": "876dbe2c-a62d-43dd-b0a3-8991996e0dae",
    "parent_id": "2c42c481-bae0-4fb0-8479-dc46a5984ecb",
    "text": "fication: LCC QH323.5 .T75 2018 | DDC 570.1/5195\u2013dc23\nLC record available at\u00a0https://lccn.loc.gov/2016016759\n1 16\nISBN 13: 978-0-13-403901-5\nISBN 10: 0-13-403901-7\n\niii\nMarc Triola, MD, FACP is the \nAssociate Dean for Educational \nInformatics at NYU School of \nMedicine, the founding director \nof the NYU Langone  Medical \nCenter Institute for Innovations \nin Medical Education (IIME), \nand an  Associate Professor of \nMedicine. Dr. Triola\u2019s research \nexperience and expertise focus \non the disruptive effects of the \npresent revolution in educa-\ntion, driven by technological \nadvances, big data, and learn-\ning analytics. Dr. Triola has \nworked to create a \u201clearning \necosystem\u201d that includes interconnected computer-based e-learning tools and new \nways to effectively integrate growing amounts of electronic data in educational re-\nsearch. Dr. Triola and IIME have been funded by the National Institutes of Health, \nthe Integrated Advanced Information Management Systems program, the National \nScience Foundation Advanced Learning Technologies program, the Josiah Macy, \nJr. Foundation, the U.S. Department of Education, and the American Medical As-\nsociation Accelerating Change in Medical Education program. He chairs numer-\nous committees at the state and national levels focused on the future of health \nprofessions educational technology development and research.\nMario F. Triola is a Professor \nEmeritus of Mathematics at \nDutchess Community College, \nwhere he has taught statistics \nfor over 30 years. Marty is the \nauthor of Elementary Statistics, \n13th edition, Essentials of Sta-\ntistics, 5th edition, Elementary \nStatistics Using Excel, 6th edi-\ntion, and Elementary Statis-\ntics Using the TI-83>84 Plus \nCalculator, 4th edition, and \nhe is a co-author of Statistical \nReasoning for Everyday Life, \n5th edition. Elementary Statis-\ntics is currently available as an \nInternational Edition, and it has been translated into several foreign languages. \nMarty designed the original Statdisk statistical software, and he has  written \n several  manuals and workbooks for technology supporting statistics education. \nABOUT THE AUTHORS\n\niv \nAbout the Authors\nHe has been a speaker at many conferences and colleges. Marty\u2019s consulting work \nincludes the design of casino slot machines and the design of fishing rods. He has \nworked with attorneys in determining probabilities in paternity lawsuits, analyz-\ning data in medical malpractice lawsuits, identifying salary inequities based on \ngender, and analyzing disputed election results. He has also used statistical meth-\nods in analyzing medical school surveys and in analyzing survey results for the \nNew York City Transit Authority. Marty has testified as an expert witness in the \nNew York State Supreme Court.\nJason Roy, PhD, is Associate \nProfessor of Biostatistics in \nthe Department of Biostatistics \nand Epidemiology, Perelman \nSchool of Medicine, Univer-\nsity of Pennsylvania. He re-\nceived his PhD in Biostatistics \nin 2000 from the ",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 2
  },
  {
    "child_id": "d816edba-ff2e-4ea9-a3b5-8ad1715dd0ec",
    "parent_id": "2c42c481-bae0-4fb0-8479-dc46a5984ecb",
    "text": ", and analyzing disputed election results. He has also used statistical meth-\nods in analyzing medical school surveys and in analyzing survey results for the \nNew York City Transit Authority. Marty has testified as an expert witness in the \nNew York State Supreme Court.\nJason Roy, PhD, is Associate \nProfessor of Biostatistics in \nthe Department of Biostatistics \nand Epidemiology, Perelman \nSchool of Medicine, Univer-\nsity of Pennsylvania. He re-\nceived his PhD in Biostatistics \nin 2000 from the University \nof Michigan. He was recipi-\nent of the 2002 David P. Byar \nYoung Investigator Award from \nthe American Statistical Asso-\nciation Biometrics Section. His \nstatistical research interests are \nin the areas of causal inference, \nmissing data, and prediction \nmodeling. He is especially interested in the statistical challenges with analyzing \ndata from large health care databases. He collaborates in many different disease \nareas, including chronic kidney disease, cardiovascular disease, and liver diseases. \nDr Roy is Associate Editor of Biometrics, Journal of the American Statistical \nAssociation, and Pharmacoepidemiology & Drug Safety, and has over 90 peer- \nreviewed publications.\n\nv\nCONTENTS\n1 \nINTRODUCTION TO STATISTICS \n1\n1-1  \nStatistical and Critical Thinking  4\n1-2  \nTypes of Data  13\n1-3  \nCollecting Sample Data  24\n2 \nEXPLORING DATA WITH TABLES AND GRAPHS \n40\n2-1  \nFrequency Distributions for Organizing and Summarizing Data  42\n2-2  Histograms  51\n2-3  Graphs That Enlighten and Graphs That Deceive  56\n2-4  Scatterplots, Correlation, and Regression  65\n3 \nDESCRIBING, EXPLORING, AND COMPARING DATA \n75\n3-1  \nMeasures of Center  77\n3-2  Measures of Variation  89\n3-3  Measures of Relative Standing and Boxplots  102\n4 \nPROBABILITY \n118\n4-1  \nBasic Concepts of Probability  120\n4-2  Addition Rule and Multiplication Rule  131\n4-3  Complements, Conditional Probability, and Bayes\u2019 Theorem  144\n4-4  Risks and Odds  153\n4-5  Rates of Mortality, Fertility, and Morbidity  162\n4-6  Counting  167\n5 \nDISCRETE PROBABILITY DISTRIBUTIONS \n180\n5-1  \nProbability Distributions  182\n5-2  Binomial Probability Distributions  193\n5-3  Poisson Probability Distributions  206\n6 \nNORMAL PROBABILITY DISTRIBUTIONS \n216\n6-1  \nThe Standard Normal Distribution  218\n6-2  Real Applications of Normal Distributions  231\n6-3  Sampling Distributions and Estimators  241\n6-4  The Central Limit Theorem  252\n6-5  Assessing Normality  261\n6-6  Normal as Approximation to Binomial  269\n7 \nESTIMATING PARAMETERS AND DETERMINING SAMPLE SIZES \n282\n7-1 \nEstimating a Population Proportion  284\n7-2  Estimating a Population Mean  299\n7-3  Estimating a Population Standard Deviation or Variance  315\n7-4  Bootstrapping: Using Technology for Estimates  324\n8 \nHYPOTHESIS TESTING  \n336\n8-1  \nBasics of Hypothesis Testing  338\n8-2  Testing a Claim About a Proportion  354\n8-3  Testing a Claim About a Mean  366\n8-4  Testing a Claim About a Standard Deviation or Variance  377\n9 \nINFERENCES FROM TWO SAMPLES  \n",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 2
  },
  {
    "child_id": "d8f74880-4561-48a9-b29b-40ed125cf68c",
    "parent_id": "2c42c481-bae0-4fb0-8479-dc46a5984ecb",
    "text": "PARAMETERS AND DETERMINING SAMPLE SIZES \n282\n7-1 \nEstimating a Population Proportion  284\n7-2  Estimating a Population Mean  299\n7-3  Estimating a Population Standard Deviation or Variance  315\n7-4  Bootstrapping: Using Technology for Estimates  324\n8 \nHYPOTHESIS TESTING  \n336\n8-1  \nBasics of Hypothesis Testing  338\n8-2  Testing a Claim About a Proportion  354\n8-3  Testing a Claim About a Mean  366\n8-4  Testing a Claim About a Standard Deviation or Variance  377\n9 \nINFERENCES FROM TWO SAMPLES  \n392\n9-1  \nTwo Proportions  394\n9-2  Two Means: Independent Samples  406\n9-3  Two Dependent Samples (Matched Pairs)  418\n9-4  Two Variances or Standard Deviations  428\n\nvi \nContents\n10 \nCORRELATION AND REGRESSION  \n442\n10-1  Correlation  444\n10-2  Regression  462\n10-3  Prediction Intervals and Variation  474\n10-4  Multiple Regression  481\n10-5  Dummy Variables and Logistic Regression  489\n11 \nGOODNESS-OF-FIT AND CONTINGENCY TABLES  \n502\n11-1  Goodness-of-Fit  503\n11-2  Contingency Tables  514\n12 \nANALYSIS OF VARIANCE  \n531\n12-1  One-Way ANOVA  533\n12-2  Two-Way ANOVA  547\n13 \nNONPARAMETRIC TESTS  \n560\n13-1  Basics of Nonparametric Tests  562\n13-2  Sign Test  564\n13-3  Wilcoxon Signed-Ranks Test for Matched Pairs  575\n13-4  Wilcoxon Rank-Sum Test for Two Independent Samples  581\n13-5  Kruskal-Wallis Test for Three or More Samples  586\n13-6  Rank Correlation  592\n14 \nSURVIVAL ANALYSIS  \n603\n14-1  Life Tables  604\n14-2  Kaplan-Meier Survival Analysis  614\nAPPENDIX A TABLES  \n625\nAPPENDIX B DATA SETS  \n638\nAPPENDIX C WEBSITES AND BIBLIOGRAPHY OF BOOKS   \n645\nAPPENDIX D ANSWERS TO ODD-NUMBERED SECTION EXERCISES  \n646\n(and all Quick Quizzes, all Review Exercises, and all Cumulative Review Exercises)\nCredits  683\nIndex  685",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 2
  },
  {
    "child_id": "d6d1d760-8b76-4c67-908f-4cd90f90d912",
    "parent_id": "2fce38a9-638e-420c-9e64-c9078718f1e4",
    "text": "PREFACE\nStatistics permeates nearly every aspect of our lives, and its role has become partic-\nularly important in the biological, life, medical, and health sciences. From opinion \npolls to clinical trials in medicine and analysis of big data from health applications, \nstatistics influences and shapes the world around us. Biostatistics for the Health and \nBiological Sciences forges the relationship between statistics and our world through \nextensive use of a wide variety of real applications that bring life to theory and \nmethods.\nGoals of This Second Edition\n \n\u25a0Incorporate the latest and best methods used by professional statisticians.\n \n\u25a0Include features that address all of the recommendations included in the Guide-\nlines for Assessment and Instruction in Statistics Education (GAISE) as recom-\nmended by the American Statistical Association.\n \n\u25a0Provide an abundance of new and interesting data sets, examples, and exercises.\n \n\u25a0Foster personal growth of students through critical thinking, use of technology, \ncollaborative work, and development of communication skills.\n \n\u25a0Enhance teaching and learning with the most extensive and best set of supple-\nments and digital resources.\nAudience, Prerequisites\nBiostatistics for the Health and Biological Sciences is written for students major-\ning in the biological and health sciences, and it is designed for a wide variety of \nstudents taking their first statistics course. Algebra is used minimally, and calculus \nis not required. It is recommended that students have completed at least an elemen-\ntary algebra course or that students should learn the relevant algebra components \nthrough an integrated or co-requisite course. In many cases, underlying theory is \nincluded, but this book does not require the mathematical rigor more appropriate for \nmathematics majors.\nHallmark Features\nGreat care has been taken to ensure that each chapter of Biostatistics for the Health \nand Biological Sciences will help students understand the concepts presented. The \nfollowing features are designed to help meet that objective.\nReal Data\nHundreds of hours have been devoted to finding data that are real, meaningful, and \ninteresting to students. Fully 87% of the examples are based on real data, and 89% of \nthe exercises are based on real data. Some exercises refer to the 18 data sets listed in \nAppendix B, and 12 of those data sets are new to this edition. Exercises requiring use \nof the Appendix B data sets are located toward the end of each exercise set and are \nmarked with a special data set icon \n.\nReal data sets are included throughout the book to provide relevant and interesting \nreal-world statistical applications, including biometric security, body measurements, \nbrain sizes and IQ scores, and data from births. Appendix B includes descriptions of \nvii\n\nviii \nPreface\nthe 18 data sets that can be downloaded from the companion website www.pearson-\nhighered.com/triola, the author maintained www.TriolaStats.com and MyStatLab.\nTr",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 9
  },
  {
    "child_id": "86c724d8-3d65-4f39-9f45-d99fabd96d99",
    "parent_id": "2fce38a9-638e-420c-9e64-c9078718f1e4",
    "text": "h exercise set and are \nmarked with a special data set icon \n.\nReal data sets are included throughout the book to provide relevant and interesting \nreal-world statistical applications, including biometric security, body measurements, \nbrain sizes and IQ scores, and data from births. Appendix B includes descriptions of \nvii\n\nviii \nPreface\nthe 18 data sets that can be downloaded from the companion website www.pearson-\nhighered.com/triola, the author maintained www.TriolaStats.com and MyStatLab.\nTriolaStats.com includes downloadable data sets in formats for technologies \nincluding Excel, Minitab, JMP, SPSS, and TI@83>84 Plus calculators. The data \nsets are also included in the free Statdisk software, which is also available on the \nwebsite.\nReadability\nGreat care, enthusiasm, and passion have been devoted to creating a book that is readable, \nunderstandable, interesting, and relevant. Students pursuing any major in the biological, \nlife, medical, or health fields are sure to find applications related to their future work.\nWebsite\nThis textbook is supported by www.TriolaStats.com, and www.pearsonhighered.com/\ntriola which are continually updated to provide the latest digital resources, including:\n \n\u25a0Statdisk: A free, robust statistical software package designed for this book.\n \n\u25a0Downloadable Appendix B data sets in a variety of technology formats.\n \n\u25a0Downloadable textbook supplements including Glossary of Statistical Terms and \nFormulas and Tables.\n \n\u25a0Online instructional videos created specifically for this book that provide step-\nby-step technology instructions.\n \n\u25a0Triola Blog, which highlights current applications of statistics, statistics in the \nnews, and online resources.\nChapter Features\nChapter Opening Features\n \n\u25a0Chapters begin with a Chapter Problem that uses real data and motivates the \nchapter material.\n \n\u25a0Chapter Objectives provide a summary of key learning goals for each section in \nthe chapter.\nExercises\nMany exercises require the interpretation of results. Great care has been taken to \nensure their usefulness, relevance, and accuracy. Exercises are arranged in order of \nincreasing difficulty, and they begin with Basic Skills and Concepts. Most sections \ninclude additional Beyond the Basics exercises that address more difficult concepts or \nrequire a stronger mathematical background. In a few cases, these exercises introduce \na new concept.\nEnd-of-Chapter Features\n \n\u25a0Chapter Quick Quiz provides review questions that require brief answers.\n \n\u25a0Review Exercises offer practice on the chapter concepts and procedures.\n \n\u25a0Cumulative Review Exercises reinforce earlier material.\n \n\u25a0Technology Project provides an activity that can be used with a variety of \n technologies.\n \n\u25a0From Data to Decision is a capstone problem that requires critical thinking and \nwriting.\n \n\u25a0Cooperative Group Activities encourage active learning in groups.\n\nPreface \nix\nOther Features\nMargin Essays There are 57 margin essays designed to highlight real-world topics \nand fo",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 9
  },
  {
    "child_id": "ea41a53f-949d-4177-9c34-6a2673419136",
    "parent_id": "2fce38a9-638e-420c-9e64-c9078718f1e4",
    "text": "iew Exercises offer practice on the chapter concepts and procedures.\n \n\u25a0Cumulative Review Exercises reinforce earlier material.\n \n\u25a0Technology Project provides an activity that can be used with a variety of \n technologies.\n \n\u25a0From Data to Decision is a capstone problem that requires critical thinking and \nwriting.\n \n\u25a0Cooperative Group Activities encourage active learning in groups.\n\nPreface \nix\nOther Features\nMargin Essays There are 57 margin essays designed to highlight real-world topics \nand foster student interest.\nFlowcharts The text includes flowcharts that simplify and clarify more complex con-\ncepts and procedures. Animated versions of the text\u2019s flowcharts are available within \nMyStatLab and MathXL.\nQuick-Reference Endpapers Tables A-2 and A-3 (the normal and t distributions) are \nreproduced on the rear inside cover pages.\nDetachable Formula and Table Card This insert, organized by chapter, gives students \na quick reference for studying, or for use when taking tests (if allowed by the instruc-\ntor). It also includes the most commonly used tables. This is also available for download \nat www.TriolaStats.com, www.pearsonhighered.com/triola and in MyStatLab.\nTechnology Integration\nAs in the preceding edition, there are many displays of screens from technology through-\nout the book, and some exercises are based on displayed results from technology. Where \nappropriate, sections include a reference to an online Tech Center subsection that in-\ncludes detailed instructions for Statdisk, Minitab\u00ae, Excel\u00ae, StatCrunch, or a TI@83>84\nPlus\u00ae calculator. (Throughout this text, \u201cTI-83>84 Plus\u201d is used to identify a TI-83 Plus \nor TI-84 Plus calculator). The end-of-chapter features include a Technology Project.\nThe Statdisk statistical software package is designed specifically for this textbook \nand contains all Appendix B data sets. Statdisk is free to users of this book, and it can \nbe downloaded at www.statdisk.org.\nChanges in This Edition\nNew Features\nChapter Objectives provide a summary of key learning goals for each section in the \nchapter.\nLarger Data Sets: Some of the data sets in Appendix B are much larger than in the \nprevious edition. It is no longer practical to print all of the Appendix B data sets in this \nbook, so the data sets are described in Appendix B, and they can be downloaded at \nwww.TriolaStats.com, www.pearsonhighered.com/triola, and MyStatLab.\nNew Content: New examples, new exercises, and Chapter Problems provide relevant \nand interesting real-world statistical applications, including biometric security, drug \ntesting, gender selection, and analyzing ultrasound images.\nNumber\nNew to This Edition\nUse Real Data\nExercises\n1600\n85%\n89%\nExamples\n 200\n84%\n87%\nMajor Organization Changes\nAll Chapters\n \n\u25a0New Chapter Objectives: All chapters now begin with a list of key learning goals \nfor that chapter. Chapter Objectives replaces the former Overview numbered sec-\ntions. The first numbered section of each chapter now covers a major topic.\nCha",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 9
  },
  {
    "child_id": "e86b6e43-912f-407f-8f1e-2471d7ccd2d8",
    "parent_id": "2fce38a9-638e-420c-9e64-c9078718f1e4",
    "text": "l-world statistical applications, including biometric security, drug \ntesting, gender selection, and analyzing ultrasound images.\nNumber\nNew to This Edition\nUse Real Data\nExercises\n1600\n85%\n89%\nExamples\n 200\n84%\n87%\nMajor Organization Changes\nAll Chapters\n \n\u25a0New Chapter Objectives: All chapters now begin with a list of key learning goals \nfor that chapter. Chapter Objectives replaces the former Overview numbered sec-\ntions. The first numbered section of each chapter now covers a major topic.\nChapter 1\n \n\u25a0New Section 1-1: Statistical and Critical Thinking\n \n\u25a0New Subsection 1-3, Part 2: Big Data and Missing Data: Too Much and Not Enough\n\nx \nPreface\nChapters 2 and 3\n \n\u25a0Chapter Partitioned: Chapter 2 (Describing, Exploring, and Comparing Data) \nfrom the first edition has been partitioned into Chapter 2 (Summarizing and Graph-\ning) and Chapter 3 (Statistics for Describing, Exploring, and Comparing Data).\n \n\u25a0New Section 2-4: Scatterplots, Correlation, and Regression This new section \nincludes scatterplots in Part 1, the linear correlation coefficient r in Part 2, and \nlinear regression in Part 3. These additions are intended to greatly facilitate cover-\nage for those professors who prefer some early coverage of correlation and regres-\nsion concepts. Chapter 10 includes these topics discussed with much greater detail.\nChapter 4\n \n\u25a0Combined Sections: Section 3-3 (Addition Rule) and Section 3-4 (Multiplication \nRule) from the first edition are now combined into one section: 4-2 (Addition \nRule and Multiplication Rule).\n \n\u25a0New Subsection 4-3, Part 3: Bayes\u2019 Theorem\nChapter 5\n \n\u25a0Combined Sections: Section 4-3 (Binomial Probability Distributions) and \nSection 4-4 (Mean, Variance, and Standard Deviation for the Binomial Distribu-\ntion) from the first edition are now combined into one section: 5-2 (Binomial \nProbability Distributions).\nChapter 6\n \n\u25a0Switched Sections: Section 6-5 (Assessing Normality) now precedes Section 6-6 \n(Normal as Approximation to Binomial).\nChapter 7\n \n\u25a0Combined Sections: Sections 6-4 (Estimating a Population Mean: s Known) \nand 6-5 (Estimating a Population Mean: s Not Known) from the first edition \nhave been combined into one section: 7-2 (Estimating a Population Mean). The \ncoverage of the s known case has been substantially reduced and it is now lim-\nited to Part 2 of Section 7-2.\n \n\u25a0New Section 7-4: Bootstrapping: Using Technology for Estimates\nChapter 8\n \n\u25a0Combined Sections: Sections 7-4 (Testing a Claim About a Population Mean: s \nKnown) and 7-5 (Testing a Claim About a Population Mean: s Not Known) from \nthe first edition have been combined into one section: 8-3 (Testing a Claim About \na Mean). Coverage of the s known case has been substantially reduced and it is \nnow limited to Part 2 of Section 8-3.\nChapter 10\n \n\u25a0New Section: 10-5 Dummy Variables and Logistic Regression\nChapter 11\n \n\u25a0New Subsection: Section 11-2, Part 2 Test of Homogeneity, Fisher\u2019s Exact Test, \nand McNemar\u2019s Test for Matched Pairs\nChapter 14\n \n\u25a0Combined Sectio",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 9
  },
  {
    "child_id": "a8877971-243e-4b87-989c-f917ac2034d9",
    "parent_id": "2fce38a9-638e-420c-9e64-c9078718f1e4",
    "text": "d 7-5 (Testing a Claim About a Population Mean: s Not Known) from \nthe first edition have been combined into one section: 8-3 (Testing a Claim About \na Mean). Coverage of the s known case has been substantially reduced and it is \nnow limited to Part 2 of Section 8-3.\nChapter 10\n \n\u25a0New Section: 10-5 Dummy Variables and Logistic Regression\nChapter 11\n \n\u25a0New Subsection: Section 11-2, Part 2 Test of Homogeneity, Fisher\u2019s Exact Test, \nand McNemar\u2019s Test for Matched Pairs\nChapter 14\n \n\u25a0Combined Sections: Section 13-2 (Elements of a Life Table) and Section 13-3 \n(Applications of Life Tables) from the first edition have been combined into \nSection 14-1 (Life Tables).\n \n\u25a0New Section: 14-2 Kaplan-Meier Survival Analysis",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 9
  },
  {
    "child_id": "5bdaad20-e15d-4828-aece-c09c08c3b90a",
    "parent_id": "0309d59a-def5-4f73-94c6-215442d73b5e",
    "text": "Preface \nxi\nFlexible Syllabus\nThis book\u2019s organization reflects the preferences of most statistics instructors, but \nthere are two common variations:\n \n\u25a0Early Coverage of Correlation and Regression: Some instructors prefer to \ncover the basics of correlation and regression early in the course. Section 2-4 \nnow includes basic concepts of scatterplots, correlation, and regression without \nthe use of formulas and greater depth found in Sections 10-1 (Correlation) and \n10-2 (Regression).\n \n\u25a0Minimum Probability: Some instructors prefer extensive coverage of probability, \nwhile others prefer to include only basic concepts. Instructors preferring mini-\nmum coverage can include Section 4-1 while skipping the remaining sections of \nChapter 4, as they are not essential for the chapters that follow. Many instructors \nprefer to cover the fundamentals of probability along with the basics of the addi-\ntion rule and multiplication rule (Section 4-2).\nGAISE\nThis book reflects recommendations from the American Statistical Association and \nits Guidelines for Assessment and Instruction in Statistics Education (GAISE). Those \nguidelines suggest the following objectives and strategies.\n1. Emphasize statistical literacy and develop statistical thinking: Each section \nexercise set begins with Statistical Literacy and Critical Thinking exercises. \nMany of the book\u2019s exercises are designed to encourage statistical thinking \nrather than the blind use of mechanical procedures.\n2. Use real data: 87% of the examples and 89% of the exercises use real data.\n3. Stress conceptual understanding rather than mere knowledge of procedures: \nInstead of seeking simple numerical answers, most exercises and examples \ninvolve conceptual understanding through questions that encourage practical \ninterpretations of results. Also, each chapter includes a From Data to Decision \nproject.\n4. Foster active learning in the classroom: Each chapter ends with several \nCooperative Group Activities.\n5. Use technology for developing conceptual understanding and analyzing data: \nComputer software displays are included throughout the book. Special Tech \nCenter subsections are available online, and they include instruction for using \nthe software. Each chapter includes a Technology Project. When there are dis-\ncrepancies between answers based on tables and answers based on technology, \nAppendix D provides both answers. The websites www.TriolaStats.com and \nwww.pearsonhighered.com/triola as well as MyStatLab include free text-specific \nsoftware (Statdisk), data sets formatted for several different technologies, and \ninstructional videos for technologies.\n6. Use assessments to improve and evaluate student learning: Assessment tools \ninclude an abundance of section exercises, Chapter Quick Quizzes, Review \nExercises, Cumulative Review Exercises, Technology Projects, From Data to \nDecision projects, and Cooperative Group Activities.\n\nxii \nPreface\nAcknowledgments\nWe would like to thank the many statistics profe",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 13
  },
  {
    "child_id": "d769fb26-3996-489a-b6e6-66cbc129d6ff",
    "parent_id": "0309d59a-def5-4f73-94c6-215442d73b5e",
    "text": "free text-specific \nsoftware (Statdisk), data sets formatted for several different technologies, and \ninstructional videos for technologies.\n6. Use assessments to improve and evaluate student learning: Assessment tools \ninclude an abundance of section exercises, Chapter Quick Quizzes, Review \nExercises, Cumulative Review Exercises, Technology Projects, From Data to \nDecision projects, and Cooperative Group Activities.\n\nxii \nPreface\nAcknowledgments\nWe would like to thank the many statistics professors and students who have contrib-\nuted to the success of this book. We thank the reviewers for their suggestions for this \nsecond edition:\nJames Baldone, Virginia College\nNaomi Brownstein, Florida State University\nChristina Caruso, University of Guelph\nErica A. Corbett, Southeastern Oklahoma State University\nXiangming Fang, East Carolina University\nPhil Gona, UMASS Boston\nSharon Homan, University of North Texas\nJackie Milton, Boston University\nJoe Pick, Palm Beach State College\nSteve Rigdon, St. Louis University\nBrian Smith, Black Hills State University\nMahbobeh Vezvaei, Kent State University\nDavid Zeitler, Grand Valley State University\nWe also thank Paul Lorczak, Joseph Pick and Erica Corbett for their help in \nchecking the accuracy of the text and answers.\nMarc Triola\nMario Triola\nJason Roy\nSeptember 2016\n\nMyStatLab\n\u00ae Online Course for Biostatistics: For  \nthe Biological and Health Sciences, 2e by Marc M. Triola, \nMario F. Triola and Jason Roy (access code required)\nMyStatLab is available to accompany Pearson\u2019s market leading text offerings. To give \nstudents a consistent tone, voice, and teaching method each text\u2019s flavor and ap-\nproach is tightly integrated throughout the accompanying MyStatLab course, making \nlearning the material as seamless as possible.\nReal-World Data Examples - Help \nunderstand how statistics applies to \neveryday life through the extensive \ncurrent, real-world data examples and \nexercises provided throughout the text.\nMathXL coverage - MathXL is a market-leading \ntext-speci\ufb01c autograded homework system built \nto improve student learning outcomes.\nEnhanced video program to meet Introductory \nStatistics needs:\n\u2022  New! Tech-Specific Video Tutorials - These \nshort, topical videos address how to use varying \ntechnologies to complete exercises.\n\u2022  Updated! Section Lecture Videos - Watch author, \nMarty Triola, work through examples and elaborate \non key objectives of the chapter.\nResources for Success\nwww.mystatlab.com\nxiii\n\nxiv \nPreface\nSupplements\nFor the Student\nStudent\u2019s Solutions Manual, by James Lapp (Colorado \nMesa University) provides detailed, worked-out solutions \nto all odd-numbered text exercises.\n(ISBN-13: 978-0-13-403909-1; ISBN-10: 0-13-403909-2)\nStudent Workbook for the Triola Statistics Series, by \nLaura lossi (Broward College) offers additional exam-\nples, concept exercises, and vocabulary exercises for each \nchapter.\n(ISBN-13: 978-0-13-446423-7; ISBN 10: 0-13-446423-0)\nThe following technology manuals, available in ",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 13
  },
  {
    "child_id": "c6ac5ff2-710f-4e90-a09c-c763640578cd",
    "parent_id": "0309d59a-def5-4f73-94c6-215442d73b5e",
    "text": "ments\nFor the Student\nStudent\u2019s Solutions Manual, by James Lapp (Colorado \nMesa University) provides detailed, worked-out solutions \nto all odd-numbered text exercises.\n(ISBN-13: 978-0-13-403909-1; ISBN-10: 0-13-403909-2)\nStudent Workbook for the Triola Statistics Series, by \nLaura lossi (Broward College) offers additional exam-\nples, concept exercises, and vocabulary exercises for each \nchapter.\n(ISBN-13: 978-0-13-446423-7; ISBN 10: 0-13-446423-0)\nThe following technology manuals, available in  MyStatLab, \ninclude instructions, examples from the main text, and \ninterpretations to complement those given in the text.\nExcel Student Laboratory Manual and Workbook \n(Download Only), by Laurel Chiappetta (University of \nPittsburgh).\n(ISBN-13: 978-0-13-446427-5; ISBN-10: 0-13-446427-3)\nMINITAB Student Laboratory Manual and Work-\nbook (Download Only), by Mario F. Triola.\n(ISBN-13: 978-0-13-446418-3; ISBN-10: 0-13-446418-4)\nGraphing Calculator Manual for the TI-83 Plus, \nTI-84 Plus, TI-84 Plus C and TI-84 Plus CE (Down-\nload Only), by Kathleen McLaughlin (University of \nConnecticut) & Dorothy Wakefield (University of Con-\nnecticut Health Center).\n(ISBN-13: 978-0-13-446414-5; ISBN 10: 0-13-446414-1)\nStatdisk Student Laboratory Manual and Workbook \n(Download Only), by Mario F. Triola. These files are \navailable to instructors and students through the Triola Sta-\ntistics Series website, www.pearsonhighered.com/triola, \nand MyStatLab.\nSPSS Student Laboratory Manual and Workbook \n(Download Only), by James J. Ball (Indiana State Uni-\nversity). These files are available to instructors and stu-\ndents through the Triola Statistics Series website, www.\npearsonhighered.com/triola, and MyStatLab.\nFor the Instructor\nInstructor\u2019s Solutions Manual (Download Only), by \nJames Lapp (Colorado Mesa University) contains so-\nlutions to all the exercises. These files are available to \nqualified instructors through Pearson Education\u2019s on-\nline catalog at www.pearsonhighered.com/irc or within \nMyStatLab.\nInsider\u2019s Guide to Teaching with the Triola Statistics \nSeries, by Mario F. Triola, contains sample syllabi and \ntips for incorporating projects, as well as lesson overviews, \nextra examples, minimum outcome objectives, and recom-\nmended assignments for each chapter.\n(ISBN-13: 978-0-13-446425-1; ISBN-10: 0-13-446425-7)\nTestGen\u00ae Computerized Test Bank (www.pearsoned.\ncom/testgen) enables instructors to build, edit, print, and \nadminister tests using a computerized bank of questions \ndeveloped to cover all the objectives of the text. TestGen is \nalgorithmically based, allowing instructors to create mul-\ntiple but equivalent versions of the same question or test \nwith the click of a button. Instructors can also modify test \nbank questions or add new questions. The software and tes-\ntbank are available for download from Pearson Education\u2019s \nonline catalog at www.pearsonhighered.com. A test bank \n(Download Only) is also available from the  online catalog.\nLearning Catalytics: Learning",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 13
  },
  {
    "child_id": "aa95d682-de4b-4a55-816f-93fa43df61d7",
    "parent_id": "0309d59a-def5-4f73-94c6-215442d73b5e",
    "text": "ed to cover all the objectives of the text. TestGen is \nalgorithmically based, allowing instructors to create mul-\ntiple but equivalent versions of the same question or test \nwith the click of a button. Instructors can also modify test \nbank questions or add new questions. The software and tes-\ntbank are available for download from Pearson Education\u2019s \nonline catalog at www.pearsonhighered.com. A test bank \n(Download Only) is also available from the  online catalog.\nLearning Catalytics: Learning Catalytics is a web-based \nengagement and assessment tool. As a \u201cbring-your-own-\ndevice\u201d direct response system, Learning Catalytics offers \na diverse library of dynamic question types that allow stu-\ndents to interact with and think critically about statistical \nconcepts. As a real-time resource, instructors can take ad-\nvantage of critical teaching moments both in the classroom \nor through assignable and gradeable homework.\nTechnology Resources\nThe following resources can be found on the Triola Statistics \nSeries website (http://www.pearsonhighered.com/triola), the \nauthor maintained www.triolastats.com, and MyStatLab\n \n\u25a0Appendix B data sets formatted for Minitab, SPSS, \nSAS, Excel, JMP, and as text files. Additionally, these \ndata sets are available as an APP for the TI-83>84 \nPlus calculators, and supplemental programs for the \nTI-83>84 Plus calculator are also available.\n \n\u25a0Statdisk statistical software instructions for down-\nload. New features include the ability to directly use \nlists of data instead of requiring the use of their sum-\nmary statistics.\n \n\u25a0Extra data sets, an index of applications, and a sym-\nbols table.\nVideo resources have been expanded, updated and now \nsupplement most sections of the book, with many topics \npresented by the author.  The videos aim to support both \ninstructors and students through lecture, reinforcing sta-\ntistical basics through technology, and applying concepts:\n \n\u25a0Section Lecture Videos",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 13
  },
  {
    "child_id": "efbae39a-54f9-47c7-a22b-c59f4b94a7ca",
    "parent_id": "434f9b2c-4198-46e4-b7c6-850971583095",
    "text": "Preface \nxv\n \n\u25a0New! Technology Video Tutorials - These short, \ntopical videos address how to use Excel, Statdisk, \nand the TI graphing calculator to complete exercises.\n \n\u25a0StatTalk Videos: 24 Conceptual Videos to Help \nYou Actually Understand Statistics. Fun-loving \nstatistician Andrew Vickers takes to the streets of \nBrooklyn, NY, to demonstrate important statistical \nconcepts through interesting stories and real-life \nevents. These fun and engaging videos will help \nstudents actually understand statistical concepts. \nAvailable with an instructors user guide and assess-\nment questions.\nMyStatLab\u2122 Online Course (access code required)\nMyStatLab is a course management system that delivers \nproven results in helping individual students succeed.\n \n\u25a0MyStatLab can be successfully implemented in \nany environment\u2014lab-based, hybrid, fully online, \ntraditional\u2014and demonstrates the quantifiable differ-\nence that integrated usage has on student retention, \nsubsequent success, and overall achievement.\n \n\u25a0MyStatLab\u2019s comprehensive online gradebook au-\ntomatically tracks students\u2019 results on tests, quizzes, \nhomework, and in the study plan. Instructors can use \nthe gradebook to provide positive feedback or inter-\nvene if students have trouble. Gradebook data can be \neasily exported to a variety of spreadsheet programs, \nsuch as Microsoft Excel. You can determine which \npoints of data you want to export, and then analyze \nthe results to determine success.\nMyStatLab provides engaging experiences that personal-\nize, stimulate, and measure learning for each student. In \naddition to the resources below, each course includes a full \ninteractive online version of the accompanying textbook.\n \n\u25a0Tutorial Exercises with Multimedia Learning Aids: \nThe homework and practice exercises in MyStatLab \nalign with the exercises in the textbook, and they \nregenerate algorithmically to give students unlim-\nited opportunity for practice and mastery. Exercises \noffer immediate helpful feedback, guided solutions, \nsample problems, animations, videos, and eText clips \nfor extra help at point-of-use.\n \n\u25a0Getting Ready for Statistics: A library of questions \nnow appears within each MyStatLab course to offer \nthe developmental math topics students need for the \ncourse. These can be assigned as a prerequisite to \nother assignments, if desired.\n \n\u25a0Conceptual Question Library: In addition to algo-\nrithmically regenerated questions that are aligned with \nyour textbook, there is a library of 1000 Conceptual \nQuestions available in the assessment manager that re-\nquire students to apply their statistical understanding.\n \n\u25a0StatCrunch\u2122: MyStatLab integrates the web-based \nstatistical software, StatCrunch, within the online as-\nsessment platform so that students can easily analyze \ndata sets from exercises and the text. In addition, \nMyStatLab includes access to www.StatCrunch.com, \na website where users can access more than 15,000 \nshared data sets, conduct online surveys, perform \ncomplex analyse",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 17
  },
  {
    "child_id": "74efcc40-f2c6-46ad-a472-8261ae168686",
    "parent_id": "434f9b2c-4198-46e4-b7c6-850971583095",
    "text": "ual \nQuestions available in the assessment manager that re-\nquire students to apply their statistical understanding.\n \n\u25a0StatCrunch\u2122: MyStatLab integrates the web-based \nstatistical software, StatCrunch, within the online as-\nsessment platform so that students can easily analyze \ndata sets from exercises and the text. In addition, \nMyStatLab includes access to www.StatCrunch.com, \na website where users can access more than 15,000 \nshared data sets, conduct online surveys, perform \ncomplex analyses using the powerful statistical \nsoftware, and generate compelling reports.\n \n\u25a0Statistical Software Support: Knowing that  students \noften use external statistical software, we make it \neasy to copy our data sets, both from the ebook and \nthe MyStatLab questions, into software such as \nStatCrunch, Minitab, Excel, and more. Students have \naccess to a variety of support tools\u2014Technology  \nTutorial Videos, Technology Study Cards, and Tech-\nnology Manuals for select titles\u2014to learn how to \neffectively use statistical software.\nMathXL\u00ae for Statistics Online Course (access code \nrequired)\nMathXL\u00ae is the homework and assessment engine that \nruns MyStatLab. (MyStatLab is MathXL plus a learning \nmanagement system.)\nWith MathXL for Statistics, instructors can:\n \n\u25a0Create, edit, and assign online homework and tests \nusing algorithmically generated exercises correlated \nat the objective level to the textbook.\n \n\u25a0Create and assign their own online exercises and \nimport TestGen tests for added flexibility.\n \n\u25a0Maintain records of all student work, tracked in \nMathXL\u2019s online gradebook.\nWith MathXL for Statistics, students can:\n \n\u25a0Take chapter tests in MathXL and receive personal-\nized study plans and>or personalized homework \nassignments based on their test results.\n \n\u25a0Use the study plan and>or the homework to link \ndirectly to tutorial exercises for the objectives they \nneed to study.\n \n\u25a0Students can also access supplemental animations \nand video clips directly from selected exercises.\n \n\u25a0Knowing that students often use external statistical \nsoftware, we make it easy to copy our data sets, both \nfrom the ebook and the MyStatLab questions, into \nsoftware like StatCrunch\u2122, Minitab, Excel, and more.\n\nxvi\t\nPreface\nMathXL for Statistics is available to qualified adopters. \nFor more information, visit our website at www.mathxl \n.com, or contact your Pearson representative.\nStatCrunch\u2122\nStatCrunch is powerful, web-based statistical software \nthat allows users to perform complex analyses, share data \nsets, and generate compelling reports. A vibrant online \ncommunity offers more than 15,000 data sets for students \nto analyze.\n\u25a0\n\u25a0Collect. Users can upload their own data to \u00adStatCrunch \nor search a large library of publicly shared data sets, \nspanning almost any topic of interest. Also, an online \nsurvey tool allows users to quickly collect data via \nweb-based surveys.\n\u25a0\n\u25a0Crunch. A full range of numerical and graphical \nmethods allow users to analyze and gain insights \nfrom any dat",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 17
  },
  {
    "child_id": "2b4b93cb-0a39-4b88-9c1d-054670b7c480",
    "parent_id": "434f9b2c-4198-46e4-b7c6-850971583095",
    "text": " share data \nsets, and generate compelling reports. A vibrant online \ncommunity offers more than 15,000 data sets for students \nto analyze.\n\u25a0\n\u25a0Collect. Users can upload their own data to \u00adStatCrunch \nor search a large library of publicly shared data sets, \nspanning almost any topic of interest. Also, an online \nsurvey tool allows users to quickly collect data via \nweb-based surveys.\n\u25a0\n\u25a0Crunch. A full range of numerical and graphical \nmethods allow users to analyze and gain insights \nfrom any data set. Interactive graphics help users \nunderstand statistical concepts and are available for \nexport to enrich reports with visual representations \nof data.\n\u25a0\n\u25a0Communicate. Reporting options help users create a \nwide variety of visually appealing representations of \ntheir data.\nFull access to StatCrunch is available with \u00adMyStatLab \nand StatCrunch is available by itself to qualified adopt-\ners. StatCrunch Mobile is now available to access from \nyour mobile device. For more information, visit our web-\nsite at www.StatCrunch.com, or contact your Pearson \n\u00adrepresentative.\nMinitab\u00ae 17 and Minitab Express\u2122 make learning sta-\ntistics easy and provide students with a skill-set that\u2019s \nin demand in today\u2019s data driven workforce. Bundling \nMinitab\u00ae software with educational materials ensures stu-\ndents have access to the software they need in the class-\nroom, around campus, and at home. And having 12 month \nversions of Minitab 17 and Minitab Express available \nensures students can use the software for the duration of \ntheir course.\nISBN 13: 978-0-13-445640-9\nISBN 10: 0-13-445640-8 (Access Card only; not sold as \nstand alone.)\nJMP Student Edition, Version 12 is an easy-to-use, stream-\nlined version of JMP desktop statistical discovery software \nfrom SAS Institute, Inc., and is available for bundling with \nthe text.\n(ISBN-13: 978-0-13-467979-2 ISBN-10: 0-13-467979-2)\n\nStatistical and Critical \nThinking\nTypes of Data\nCollecting Sample Data\n1-1\n1-2\n1-3\nSurvey Question: Do You Need Caffeine to Start Up Your Brain for the Day?\nCHAPTER \nPROBLEM\nIntroduction  \nto Statistics\n1\nSurveys provide data that enable us to improve products or \nservices. Surveys guide political candidates, shape business \npractices, identify effective medical treatments, and affect \nmany aspects of our lives. Surveys give us insight into the \nopinions and behaviors of others. As an example, the National \nHealth and Nutrition Examination Survey (NHANES) is part \n1\nof a research program that studies the health and nutrition of \nthousands of adults and children in the United States.\nLet\u2019s consider one USA Today survey in which respondents \nwere asked if they need caffeine to start up their brain for the \nday. Among 2,006 respondents, 74% said that they did need the \ncaffeine. Figure 1-1 includes graphs that depict these results.\n\nThe survey results suggest that people overwhelmingly need caffeine to start up their brains \nfor the day. The graphs in Figure 1-1 visually depict the survey results. One of",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 17
  },
  {
    "child_id": "90502809-ae39-460c-bb09-4ab426f76027",
    "parent_id": "434f9b2c-4198-46e4-b7c6-850971583095",
    "text": " and nutrition of \nthousands of adults and children in the United States.\nLet\u2019s consider one USA Today survey in which respondents \nwere asked if they need caffeine to start up their brain for the \nday. Among 2,006 respondents, 74% said that they did need the \ncaffeine. Figure 1-1 includes graphs that depict these results.\n\nThe survey results suggest that people overwhelmingly need caffeine to start up their brains \nfor the day. The graphs in Figure 1-1 visually depict the survey results. One of the most impor-\ntant objectives of this book is to encourage the use of critical thinking so that such results are \nnot blindly accepted. We might question whether the survey results are valid. Who conducted \nthe survey? How were respondents selected? Do the graphs in Figure 1-1 depict the results \nwell, or are those graphs somehow misleading?\nThe survey results presented here have major flaws that are among the most common, so \nthey are especially important to recognize. Here are brief descriptions of each of the major flaws:\nFlaw 1: Misleading Graphs The bar chart in Figure 1-1(a) is very deceptive. By using a \nvertical scale that does not start at zero, the difference between the two percentages is grossly \nexaggerated. Figure 1-1(a) makes it appear that approximately eight times as many people \nneed the caffeine. However, with 74% needing caffeine and 26% not needing caffeine, the \nratio is actually about 3:1, rather than the 8:1 ratio that is suggested by the graph.\nThe illustration in Figure 1-1(b) is also deceptive. Again, the difference between the actual \nresponse rates of 74% (needing caffeine) and 26% (not needing caffeine) is a difference that \nis grossly distorted. The picture graph (or \u201cpictograph\u201d) in Figure 1-1(b) makes it appear that \n2 \nCHAPTER 1 Introduction to Statistics\nFIGURE 1-1(a) Survey Results\nFIGURE 1-1(b) Survey Results\nPeople Needing Ca\ufb00eine to Start\nUp Brain for the Day\nPeople Not Needing Ca\ufb00eine to Start\nUp Brain for the Day",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 17
  },
  {
    "child_id": "9593c1dc-62ab-4d63-b633-94c8bc6f4060",
    "parent_id": "d1c8ed3c-dfa4-411f-8070-d146a81bcec3",
    "text": "the ratio of people needing caffeine to people not needing caffeine is roughly 9:1 instead of \nthe correct ratio of about 3:1. (Objects with area or volume can distort perceptions because \nthey can be drawn to be disproportionately larger or smaller than the data indicate.) Decep-\ntive graphs are discussed in more detail in Section 2-3, but we see here that the illustrations in \nFigure 1-1 grossly exaggerate the number of people needing caffeine.\nFlaw 2: Bad Sampling Method The aforementioned survey responses are from a USA \nToday survey of Internet users. The survey question was posted on a website and Internet \nusers decided whether to respond. This is an example of a voluntary response sample\u2014a \nsample in which respondents themselves decide whether to participate. With a voluntary \nresponse sample, it often happens that those with a strong interest in the topic are more likely \nto participate, so the results are very questionable. For example, people who strongly feel that \nthey cannot function without their morning cup(s) of coffee might be more likely to respond to \nthe caffeine survey than people who are more ambivalent about caffeine or coffee. When using \nsample data to learn something about a population, it is extremely important to obtain sample \ndata that are representative of the population from which the data are drawn. As we proceed \nthrough this chapter and discuss types of data and sampling methods, we should focus on \nthese key concepts:\n\u2022 Sample data must be collected in an appropriate way, such as through a process of \nrandom selection.\n\u2022 If sample data are not collected in an appropriate way, the data may be so completely \nuseless that no amount of statistical torturing can salvage them.\nIt would be easy to accept the preceding survey results and blindly proceed with calcula-\ntions and statistical analyses, but we would miss the critical two flaws described above. We \ncould then develop conclusions that are fundamentally wrong and misleading. Instead, we \nshould develop skills in statistical thinking and critical thinking so that we are better prepared \nto analyze such data.\nChapter Objectives \n3\nThe single most important concept presented in this chapter is this: When using meth-\nods of statistics with sample data to form conclusions about a population, it is absolutely \nessential to collect sample data in a way that is appropriate. Here are the main chapter \nobjectives:\nStatistical and Critical Thinking\n\u2022 Analyze sample data relative to context, source, and sampling method.\n\u2022 Understand the difference between statistical significance and practical significance.\n\u2022 Define and identify a voluntary response sample and know that statistical conclu-\nsions based on data from such a sample are generally not valid.\n1-1\nCHAPTER OBJECTIVES\n>>>\n\n4 \nCHAPTER 1 Introduction to Statistics\nBecause populations are often very large, a common objective of the use of statis-\ntics is to obtain data from a sample and then use those data to form a ",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 21
  },
  {
    "child_id": "d9ef9db6-cd9a-46f4-b139-9c6d513c2c43",
    "parent_id": "d1c8ed3c-dfa4-411f-8070-d146a81bcec3",
    "text": "to context, source, and sampling method.\n\u2022 Understand the difference between statistical significance and practical significance.\n\u2022 Define and identify a voluntary response sample and know that statistical conclu-\nsions based on data from such a sample are generally not valid.\n1-1\nCHAPTER OBJECTIVES\n>>>\n\n4 \nCHAPTER 1 Introduction to Statistics\nBecause populations are often very large, a common objective of the use of statis-\ntics is to obtain data from a sample and then use those data to form a conclusion about \nthe population.\nTypes of Data\n\u2022 Distinguish between a parameter and a statistic.\n\u2022 Distinguish between quantitative data and categorical (or qualitative or attribute) data.\n\u2022 Distinguish between discrete data and continuous data.\n\u2022 Determine whether basic statistical calculations are appropriate for a particular data set.\nCollecting Sample Data\n\u2022 Define and identify a simple random sample.\n\u2022 Understand the importance of sound sampling methods and the importance of \ngood design of experiments.\n1-2\n1-3\nTypes of Data\n\u2022 Distinguish between a parameter and a\nr r\nstatistic.\n\u2022 Distinguish between quantitative data and categorical (or \nl l\nqualitative or attribute) data.\n\u2022 Distinguish between discrete data and continuous data.\n\u2022 Determine whether basic statistical calculations are appropriate for a particular data set.\nCollecting Sample Data\n\u2022 Define and identify a simple random sample.\n\u2022 Understand the importance of sound sampling methods and the importance of \ngood design of experiments.\nKey Concept In this section we begin with a few very basic definitions, and then we \nconsider an overview of the process involved in conducting a statistical study. This \nprocess consists of \u201cprepare, analyze, and conclude.\u201d \u201cPreparation\u201d involves consid-\neration of the context, the source of data, and sampling method. In future chapters we \nconstruct suitable graphs, explore the data, and execute computations required for the \nstatistical method being used. In future chapters we also form conclusions by deter-\nmining whether results have statistical significance and practical significance.\nStatistical thinking involves critical thinking and the ability to make sense of results. \nStatistical thinking demands so much more than the ability to execute complicated cal-\nculations. Through numerous examples, exercises, and discussions, this text will help \nyou develop the statistical thinking skills that are so important in today\u2019s world.\nWe begin with some very basic definitions.\n1-1 \nStatistical and Critical Thinking\nDEFINITIONS\nData are collections of observations, such as measurements, or survey responses. \n(A single data value is called a datum, a term rarely used. The term \u201cdata\u201d is plural, \nso it is correct to say \u201cdata are\u2026\u201d not \u201cdata is\u2026\u201d)\nStatistics is the science of planning studies and experiments; obtaining data; and \norganizing, summarizing, presenting, analyzing, and interpreting those data and \nthen drawing conclusions based on them.\nA population is t",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 21
  },
  {
    "child_id": "4a4abaab-d0e0-4c14-8664-26b9c17e8089",
    "parent_id": "d1c8ed3c-dfa4-411f-8070-d146a81bcec3",
    "text": "ons.\n1-1 \nStatistical and Critical Thinking\nDEFINITIONS\nData are collections of observations, such as measurements, or survey responses. \n(A single data value is called a datum, a term rarely used. The term \u201cdata\u201d is plural, \nso it is correct to say \u201cdata are\u2026\u201d not \u201cdata is\u2026\u201d)\nStatistics is the science of planning studies and experiments; obtaining data; and \norganizing, summarizing, presenting, analyzing, and interpreting those data and \nthen drawing conclusions based on them.\nA population is the complete collection of all measurements or data that are be-\ning considered. Typically, the population is the complete collection of data that we \nwould like to make inferences about.\nA census is the collection of data from every member of the population.\nA sample is a subcollection of members selected from a population.\n\n1-1 Statistical and Critical Thinking \n5\nWe now proceed to consider the process involved in a statistical study. See Figure 1-2 \nfor a summary of this process and note that the focus is on critical thinking, not mathe-\nmatical calculations. Thanks to wonderful developments in technology, we have power-\nful tools that effectively do the number crunching so that we can focus on understanding \nand interpreting results.\nEXAMPLE 1  Residential Carbon Monoxide Detectors\nIn the journal article \u201cResidential Carbon Monoxide Detector Failure Rates in the \nUnited States\u201d (by Ryan and Arnold, American Journal of Public Health, Vol. 101, \nNo. 10), it was stated that there are 38 million carbon monoxide detectors installed \nin the United States. When 30 of them were randomly selected and tested, it was \nfound that 12 of them failed to provide an alarm in hazardous carbon monoxide \nconditions. In this case, the population and sample are as follows:\nPopulation: All 38 million carbon monoxide detectors in the United States \nSample: The 30 carbon monoxide detectors that were selected and tested \nThe objective is to use the sample data as a basis for drawing a conclusion about the \npopulation of all carbon monoxide detectors, and methods of statistics are helpful in \ndrawing such conclusions.\nConclude\n1. Signi\ufb01cance\n\u2022 Do the results have statistical signi\ufb01cance?\n\u2022 Do the results have practical signi\ufb01cance?\nAnalyze\n1. Graph the Data\n2. Explore the Data\n\u2022 Are there any outliers (numbers very far away from almost all of the other data)?\n\u2022 What important statistics summarize the data (such as the mean and standard deviation\n described in Chapter 3)?\n\u2022 How are the data distributed?\n\u2022 Are there missing data?\n\u2022 Did many selected subjects refuse to respond?\n3. Apply Statistical Methods\n\u2022 Use technology to obtain results.\nPrepare\n1. Context\n\u2022 What do the data represent?\n\u2022 What is the goal of study? \n2. Source of the Data\n\u2022 Are the data from a source with a special interest so that there is pressure to obtain \n results that are favorable to the source?\n3. Sampling Method\n \n\u2022 Were the data collected in a way that is unbiased, or were the data collected in a \n way t",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 21
  },
  {
    "child_id": "dbc8ee73-1ca8-4572-902f-2ac6bd5208cf",
    "parent_id": "d1c8ed3c-dfa4-411f-8070-d146a81bcec3",
    "text": " distributed?\n\u2022 Are there missing data?\n\u2022 Did many selected subjects refuse to respond?\n3. Apply Statistical Methods\n\u2022 Use technology to obtain results.\nPrepare\n1. Context\n\u2022 What do the data represent?\n\u2022 What is the goal of study? \n2. Source of the Data\n\u2022 Are the data from a source with a special interest so that there is pressure to obtain \n results that are favorable to the source?\n3. Sampling Method\n \n\u2022 Were the data collected in a way that is unbiased, or were the data collected in a \n way that is biased (such as a procedure in which respondents volunteer to participate)?\nFIGURE 1-2 Statistical Thinking\nSurvivorship Bias\nIn World War \nII, statisti-\ncian Abraham \nWald saved \nmany lives \nwith his work \non the Applied \nMathematics Panel. Military \nleaders asked the panel how they \ncould improve the chances of \naircraft bombers returning after \nmissions. They wanted to add \nsome armor for protection, and \nthey recorded locations on the \nbombers where damaging holes \nwere found. They reasoned that \narmor should be placed in loca-\ntions with the most holes, but \nWald said that strategy would be \na big mistake. He said that armor \nshould be placed where returning \nbombers were not damaged. His \nreasoning was this: The bombers \nthat made it back with damage \nwere survivors, so the damage \nthey suffered could be survived. \nLocations on the aircraft that \nwere not damaged were the most \nvulnerable, and aircraft suffer-\ning damage in those vulnerable \nareas were the ones that did \nnot make it back. The military \nleaders would have made a big \nmistake with survivorship bias by \nstudying the planes that survived \ninstead of thinking about the \nplanes that did not survive.",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 21
  },
  {
    "child_id": "62cc721f-7f77-473c-a2af-a06e70d6bebe",
    "parent_id": "b7b605b1-098b-4042-b931-a2f82bb6eadf",
    "text": "6 \nCHAPTER 1 Introduction to Statistics\nPrepare\nContext Figure 1-2 suggests that we begin our preparation by considering the context \nof the data, so let\u2019s start with context by considering the data in Table 1-1. (The data \nare from Data Set 9 \u201cIQ and Brain Size\u201d in Appendix B.) The data in Table 1-1 consist \nof measured IQ scores and measured brain volumes from 10 different subjects. The \ndata are matched in the sense that each individual \u201cIQ>brain volume\u201d pair of values \nis from the same person. The first subject had a measured IQ score of 96 and a brain \nvolume of 1005 cm3. The format of Table 1-1 suggests the following goal: Determine \nwhether there is a relationship between IQ score and brain volume. This goal suggests \na possible hypothesis: People with larger brains tend to have higher IQ scores.\nSource of the Data The data in Table 1-1 were provided by M. J. Tramo, W. C. \nLoftus, T. A. Stukel, J. B. Weaver, and M. S. Gazziniga, who discuss the data in the \narticle \u201cBrain Size, Head Size, and IQ in Monozygotic Twins,\u201d Neurology, Vol. 50. \nThe researchers are from reputable medical schools and hospitals, and they would not \ngain by presenting the results in way that is misleading. In contrast, Kiwi Brands, a \nmaker of shoe polish, commissioned a study that resulted in this statement, which was \nprinted in some newspapers: \u201cAccording to a nationwide survey of 250 hiring profes-\nsionals, scuffed shoes was the most common reason for a male job seeker\u2019s failure to \nmake a good first impression.\u201d\nWhen physicians who conduct clinical experiments on the efficacy of drugs re-\nceive funding from drug companies, they have an incentive to obtain favorable results. \nSome professional journals, such as the Journal of the American Medical Association, \nnow require that physicians report sources of funding in journal articles. We should be \nskeptical of studies from sources that may be biased.\nSampling Method Figure 1-2 suggests that we conclude our preparation by consid-\nering the sampling method. The data in Table 1-1 were obtained from subjects whose \nmedical histories were reviewed in an effort to ensure that no subjects had neurologic \nor psychiatric disease. In this case, the sampling method appears to be sound, but we \ncannot be sure of that without knowing how the subjects were recruited and whether \nany payments may have affected participation in the study.\nSampling methods and the use of randomization will be discussed in Section 1-3, \nbut for now, we stress that a sound sampling method is absolutely essential for good \nresults in a statistical study. It is generally a bad practice to use voluntary response (or \nself-selected) samples, even though their use is common.\nTABLE 1-1 IQ Scores and Brain Volumes (cm3)\nIQ\n96\n87\n101\n103\n127\n96\n88\n85\n97\n124\nBrain Volume (cm3)\n1005\n1035\n1281\n1051\n1034\n1079\n1104\n1439\n1029\n1160\nDEFINITION\nA voluntary response sample (or self-selected sample) is one in which the \nrespondents themselves decide whether to be in",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 24
  },
  {
    "child_id": "853a7e53-9457-4a27-bb7d-849614a2d246",
    "parent_id": "b7b605b1-098b-4042-b931-a2f82bb6eadf",
    "text": "ess that a sound sampling method is absolutely essential for good \nresults in a statistical study. It is generally a bad practice to use voluntary response (or \nself-selected) samples, even though their use is common.\nTABLE 1-1 IQ Scores and Brain Volumes (cm3)\nIQ\n96\n87\n101\n103\n127\n96\n88\n85\n97\n124\nBrain Volume (cm3)\n1005\n1035\n1281\n1051\n1034\n1079\n1104\n1439\n1029\n1160\nDEFINITION\nA voluntary response sample (or self-selected sample) is one in which the \nrespondents themselves decide whether to be included.\nThe following types of polls are common examples of voluntary response samples. \nBy their very nature, all are seriously flawed because we should not make conclusions \nabout a population on the basis of samples with a strong possibility of bias:\n \n\u25a0Internet polls, in which people online can decide whether to respond\n \n\u25a0Mail-in polls, in which people decide whether to reply\nOrigin of \u201cStatistics\u201d\nThe word \nstatistics is \nderived from \nthe Latin word \nstatus (mean-\ning \u201cstate\u201d). \nEarly uses of \nstatistics involved compilations \nof data and graphs describing \nvarious aspects of a state or \ncountry. In 1662, John Graunt \npublished statistical information \nabout births and deaths. Graunt\u2019s \nwork was followed by studies \nof mortality and disease rates, \npopulation sizes, incomes, and \nunemployment rates. House-\nholds, governments, and busi-\nnesses rely heavily on statistical \ndata for guidance. For example, \nunemployment rates, inflation \nrates, consumer indexes, and \nbirth and death rates are carefully \ncompiled on a regular basis, \nand the resulting data are used \nby business leaders to make \ndecisions affecting future hiring, \nproduction levels, and expansion \ninto new markets.\n\n1-1 Statistical and Critical Thinking \n7\n \n\u25a0Telephone call-in polls, in which newspaper, radio, or television announcements \nask that you voluntarily call a special number to register your opinion\nThe Chapter Problem involves a USA Today survey with a voluntary response sample. \nSee also the following Example 2.\nEXAMPLE 2  Voluntary Response Sample\nUSA Today posted this question on the electronic edition of their newspaper: \u201cHave \nyou ever been bitten by an animal?\u201d Internet users who saw that question then de-\ncided themselves whether to respond. Among the 2361 responses, 65% said \u201cyes\u201d \nand 35% said \u201cno.\u201d Because the 2361 subjects themselves chose to respond, they \nare a voluntary response sample and the results of the survey are highly question-\nable. It would be much better to get results through a poll in which the pollster ran-\ndomly selects the subjects, instead of allowing the subjects to volunteer themselves.\nAnalyze\nFigure 1-2 indicates that after completing our preparation by considering the context, \nsource, and sampling method, we begin to analyze the data.\nGraph and Explore An analysis should begin with appropriate graphs and explora-\ntions of the data. Graphs are discussed in Chapter 2, and important statistics are dis-\ncussed in Chapter 3.\nApply Statistical Met",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 24
  },
  {
    "child_id": "d9f7ca8d-6c6f-4f95-96ea-0cecc57e0cb5",
    "parent_id": "b7b605b1-098b-4042-b931-a2f82bb6eadf",
    "text": "esults through a poll in which the pollster ran-\ndomly selects the subjects, instead of allowing the subjects to volunteer themselves.\nAnalyze\nFigure 1-2 indicates that after completing our preparation by considering the context, \nsource, and sampling method, we begin to analyze the data.\nGraph and Explore An analysis should begin with appropriate graphs and explora-\ntions of the data. Graphs are discussed in Chapter 2, and important statistics are dis-\ncussed in Chapter 3.\nApply Statistical Methods Later chapters describe important statistical methods, \nbut application of these methods is often made easy with technology (calculators \nand>or statistical software packages). A good statistical analysis does not require \nstrong computational skills. A good statistical analysis does require using common \nsense and paying careful attention to sound statistical methods.\nConclude\nFigure 1-2 shows that the final step in our statistical process involves conclusions, and \nwe should develop an ability to distinguish between statistical significance and practi-\ncal significance.\nStatistical Significance Statistical significance is achieved in a study when we get \na result that is very unlikely to occur by chance. A common criterion is that we have \nstatistical significance if the likelihood of an event occurring by chance is 5% or less.\n \n\u25a0Getting 98 girls in 100 random births is statistically significant because such an \nextreme outcome is not likely to result from random chance.\n \n\u25a0Getting 52 girls in 100 births is not statistically significant because that event \ncould easily occur with random chance.\nPractical Significance It is possible that some treatment or finding is effective, but \ncommon sense might suggest that the treatment or finding does not make enough of a \ndifference to justify its use or to be practical, as illustrated in Example 3 which follows.\n\n8 \nCHAPTER 1 Introduction to Statistics\nAnalyzing Data: Potential Pitfalls\nHere are a few more items that could cause problems when analyzing data.\nMisleading Conclusions When forming a conclusion based on a statistical analy-\nsis, we should make statements that are clear even to those who have no understand-\ning of statistics and its terminology. We should carefully avoid making statements \nnot justified by the statistical analysis. For example, later in this book we introduce \nthe concept of a correlation, or association between two variables, such as smoking \nand pulse rate. A statistical analysis might justify the statement that there is a cor-\nrelation between the number of cigarettes smoked and pulse rate, but it would not \njustify a statement that the number of cigarettes smoked causes a person\u2019s pulse rate \nto change. Such a statement about causality can be justified by physical evidence, not \nby statistical analysis.\nCorrelation does not imply causation.\nSample Data Reported Instead of Measured When collecting data from people, \nit is better to take measurements yourself instead of asking",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 24
  },
  {
    "child_id": "bf2ccfda-38a8-4d70-bbac-0bc22c6e4f7b",
    "parent_id": "b7b605b1-098b-4042-b931-a2f82bb6eadf",
    "text": "justify the statement that there is a cor-\nrelation between the number of cigarettes smoked and pulse rate, but it would not \njustify a statement that the number of cigarettes smoked causes a person\u2019s pulse rate \nto change. Such a statement about causality can be justified by physical evidence, not \nby statistical analysis.\nCorrelation does not imply causation.\nSample Data Reported Instead of Measured When collecting data from people, \nit is better to take measurements yourself instead of asking subjects to report results. \nAsk people what they weigh and you are likely to get their desired weights, not their \nactual weights. People tend to round, usually down, sometimes way down. When \nasked, someone with a weight of 187 lb might respond that he or she weighs 160 lb. \nAccurate weights are collected by using a scale to measure weights, not by asking \npeople what they weigh.\nLoaded Questions If survey questions are not worded carefully, the results of a \nstudy can be misleading. Survey questions can be \u201cloaded\u201d or intentionally worded to \nelicit a desired response. Here are the actual rates of \u201cyes\u201d responses for the two dif-\nferent wordings of a question:\n97% yes: \u201cShould the President have the line item veto to eliminate waste?\u201d\n57% yes: \u201cShould the President have the line item veto, or not?\u201d\nOrder of Questions Sometimes survey questions are unintentionally loaded \nby such factors as the order of the items being considered. See the following two \nEXAMPLE 3   Statistical Significance Versus  \nPractical Significance\nProCare Industries once supplied a product named Gender Choice that supposedly \nincreased the chance of a couple having a baby with the gender that they desired. \nIn the absence of any evidence of its effectiveness, the product was banned by the \nFood and Drug Administration (FDA) as a \u201cgross deception of the consumer.\u201d But \nsuppose that the product was tested with 10,000 couples who wanted to have baby \ngirls, and the results consist of 5200 baby girls born in the 10,000 births. This re-\nsult is statistically significant because the likelihood of it happening due to chance \nis only 0.003%, so chance doesn\u2019t seem like a feasible explanation. That 52% rate \nof girls is statistically significant, but it lacks practical significance because 52% is \nonly slightly above 50%. Couples would not want to spend the time and money to \nincrease the likelihood of a girl from 50% to 52%. (Note: In reality, the likelihood \nof\u00a0a baby being a girl is about 48.8%, not 50%.)",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 24
  },
  {
    "child_id": "d387bae9-5715-4b9d-b478-54997358891f",
    "parent_id": "b07de4ed-7142-4ae3-9942-db3d40a25a93",
    "text": "1-1 Statistical and Critical Thinking \n9\nquestions from a poll conducted in Germany, along with the very different response \nrates:\n\u201cWould you say that tra\ufb03c contributes more or less to air pollution than indus-\ntry?\u201d (45% blamed tra\ufb03c; 27% blamed industry.)\n\u201cWould you say that industry contributes more or less to air pollution than traf-\n\ufb01c?\u201d (24% blamed tra\ufb03c; 57% blamed industry.)\nIn addition to the order of items within a question, as illustrated above, the order of \nseparate questions could also affect responses.\nNonresponse A nonresponse occurs when someone either refuses to respond to \na survey question or is unavailable. When people are asked survey questions, some \nfirmly refuse to answer. The refusal rate has been growing in recent years, partly be-\ncause many persistent telemarketers try to sell goods or services by beginning with a \nsales pitch that initially sounds as though it is part of an opinion poll. (This \u201cselling \nunder the guise\u201d of a poll is called sugging.) In Lies, Damn Lies, and Statistics, author \nMichael Wheeler makes this very important observation:\nPeople who refuse to talk to pollsters are likely to be different from those \nwho do not. Some may be fearful of strangers and others jealous of their \nprivacy, but their refusal to talk demonstrates that their view of the \nworld around them is markedly different from that of those people who \nwill let poll-takers into their homes.\nPercentages Some studies cite misleading or unclear percentages. Note that 100% \nof some quantity is all of it, but if there are references made to percentages that exceed \n100%, such references are often not justified. If a medical researcher claims that she \nhas developed a treatment for migraine headaches and the treatment results in a 150% \nreduction in those headaches, that researcher cannot be correct, because totally elimi-\nnating all migraine headaches would be a 100% reduction. It is impossible to reduce \nthe number of migraine headaches by more than 100%.\nWhen working with percentages, we should know that % or \u201cpercent\u201d really \nmeans \u201cdivided by 100.\u201d Here is a principle used often in this book.\nPercentage of: To \ufb01nd a percentage of an amount, replace the % symbol with \ndivision by 100, and then interpret \u201cof\u201d to be multiplication. The following \n calculation shows that 6% of 1200 is 72:\n6% of 1200 responses =\n6\n100 * 1200 = 72\nStatistical Literacy and Critical Thinking\n1. Online Medical Info USA Today posted this question on its website: \u201cHow often do you seek \nmedical information online?\u201d Of 1072 Internet users who chose to respond, 38% of them responded \nwith \u201cfrequently.\u201d What term is used to describe this type of survey in which the people surveyed \nconsist of those who decided to respond? What is wrong with this type of sampling method?\n2. Reported Versus Measured In a survey of 1046 adults conducted by Bradley Corpora-\ntion, subjects were asked how often they wash their hands when using a public restroom, and \n70% of the responde",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 27
  },
  {
    "child_id": "68bd5ba9-13ca-4f2a-b094-71c141d86c20",
    "parent_id": "b07de4ed-7142-4ae3-9942-db3d40a25a93",
    "text": "ten do you seek \nmedical information online?\u201d Of 1072 Internet users who chose to respond, 38% of them responded \nwith \u201cfrequently.\u201d What term is used to describe this type of survey in which the people surveyed \nconsist of those who decided to respond? What is wrong with this type of sampling method?\n2. Reported Versus Measured In a survey of 1046 adults conducted by Bradley Corpora-\ntion, subjects were asked how often they wash their hands when using a public restroom, and \n70% of the respondents said \u201calways.\u201d\na. Identify the sample and the population.\nb. Why would better results be obtained by observing the hand washing instead of asking about it?\n1-1 Basic Skills and Concepts\ne \nPublication Bias\nThere is a \u201cpub-\nlication bias\u201d \nin professional \njournals. It is \nthe tendency to \npublish positive \nresults (such \nas showing that some treatment \nis effective) much more often \nthan negative results (such as \nshowing that some treatment has \nno effect). In the article \u201cRegis-\ntering Clinical Trials\u201d (Journal of \nthe American Medical Asso-\nciation, Vol. 290, No. 4), authors \nKay Dickersin and Drummond \n Rennie state that \u201cthe result of \nnot knowing who has performed \nwhat (clinical trial) is loss and \ndistortion of the evidence, waste \nand duplication of trials, inability \nof funding agencies to plan, and \na chaotic system from which \nonly certain sponsors might \nbenefit, and is invariably against \nthe interest of those who offered \nto participate in trials and of \npatients in general.\u201d They sup-\nport a process in which all clinical \ntrials are registered in one central \nsystem, so that future research-\ners have access to all previous \nstudies, not just the studies that \nwere published.\n\n10 \nCHAPTER 1 Introduction to Statistics\n3. Statistical Significance Versus Practical Significance When testing a new treatment, \nwhat is the difference between statistical significance and practical significance? Can a treat-\nment have statistical significance, but not practical significance?\n4. Correlation One study showed that for a recent period of 11 years, there was a strong cor-\nrelation (or association) between the numbers of people who drowned in swimming pools and \nthe amounts of power generated by nuclear power plants (based on data from the Centers for \nDisease Control and Prevention and the Department of Energy). Does this imply that increas-\ning power from nuclear power plants is the cause of more deaths in swimming pools? Why or \nwhy not?\nConsider the Source. In Exercises 5\u20138, determine whether the given source has the \n potential to create a bias in a statistical study.\n5. Physicians Committee for Responsible Medicine The Physicians Committee for Re-\nsponsible Medicine tends to oppose the use of meat and dairy products in our diets, and that \norganization has received hundreds of thousands of dollars in funding from the Foundation to \nSupport Animal Protection.\n6. Arsenic in Rice Amounts of arsenic in samples of rice grown in Texas were measured by ",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 27
  },
  {
    "child_id": "ddc1cf49-788c-4956-a9cc-c03dc50e404a",
    "parent_id": "b07de4ed-7142-4ae3-9942-db3d40a25a93",
    "text": "In Exercises 5\u20138, determine whether the given source has the \n potential to create a bias in a statistical study.\n5. Physicians Committee for Responsible Medicine The Physicians Committee for Re-\nsponsible Medicine tends to oppose the use of meat and dairy products in our diets, and that \norganization has received hundreds of thousands of dollars in funding from the Foundation to \nSupport Animal Protection.\n6. Arsenic in Rice Amounts of arsenic in samples of rice grown in Texas were measured by \nthe Food and Drug Administration (FDA).\n7. Brain Size A data set in Appendix B includes brain volumes from 10 pairs of monozygotic \n(identical) twins. The data were collected by researchers at Harvard University, Massachusetts \nGeneral Hospital, Dartmouth College, and the University of California at Davis.\n8. Chocolate An article in Journal of Nutrition (Vol. 130, No. 8) noted that chocolate is rich \nin flavonoids. The article notes \u201cregular consumption of foods rich in flavonoids may reduce \nthe risk of coronary heart disease.\u201d The study received funding from Mars, Inc., the candy com-\npany, and the Chocolate Manufacturers Association.\nSampling Method. In Exercises 9\u201312, determine whether the sampling method appears \nto be sound or is flawed.\n9. Nuclear Power Plants In a survey of 1368 subjects, the following question was posted \non the USA Today website: \u201cIn your view, are nuclear plants safe?\u201d The survey subjects \nwere Internet users who chose to respond to the question posted on the electronic edition of \nUSA Today.\n10. Clinical Trials Researchers at Yale University conduct a wide variety of clinical trials by \nusing subjects who volunteer after reading advertisements soliciting paid volunteers.\n11. NHANES Examinations In a recent year, the National Health and Nutrition Examina-\ntion Survey (NHANES), sponsored by the National Center for Health Statistics, selected \nmore than 9000 subjects who were given physical exams. Subjects were selected through \na somewhat complicated procedure designed to obtain results that are representative of the \npopulation.\n12. Health In a survey of 3014 randomly selected U.S. adults, 45% reported that they have \nat least one chronic health condition, such as diabetes or high blood pressure. The survey was \nconducted by Princeton Survey Research Associates International.\nStatistical Significance and Practical Significance. In Exercises 13\u201316, determine \nwhether the results appear to have statistical significance, and also determine whether the \nresults appear to have practical significance.\n13. Diet and Exercise Program In a study of the Kingman diet and exercise program, \n40 \u00a0subjects lost an average of 22 pounds. There is about a 1% chance of getting such results \nwith a program that has no effect.\n\n1-1 Statistical and Critical Thinking \n11\n14. MCAT The Medical College Admissions Test (MCAT) is commonly used as part of the \n decision-making process for determining which students to accept into medical schools. To test \nt",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 27
  },
  {
    "child_id": "9844d0c2-6669-42fb-a0a8-796f5989edc1",
    "parent_id": "b07de4ed-7142-4ae3-9942-db3d40a25a93",
    "text": "whether the \nresults appear to have practical significance.\n13. Diet and Exercise Program In a study of the Kingman diet and exercise program, \n40 \u00a0subjects lost an average of 22 pounds. There is about a 1% chance of getting such results \nwith a program that has no effect.\n\n1-1 Statistical and Critical Thinking \n11\n14. MCAT The Medical College Admissions Test (MCAT) is commonly used as part of the \n decision-making process for determining which students to accept into medical schools. To test \nthe effectiveness of the Siena MCAT preparation course, 16 students take the MCAT test, then \nthey complete the preparatory course, and then they retake the MCAT test, with the result that the \naverage (mean) score for this group rises from 25 to 30. There is a 0.3% chance of getting those \nresults by chance. Does the course appear to be effective?\n15. Gender Selection In a study of the Gender Aide method of gender selection used to \n increase the likelihood of a baby being born a girl, 2000 users of the method gave birth to \n980\u00a0boys and 1020 girls. There is about a 19% chance of getting that many girls if the method \nhad no effect.\n16. Systolic Blood Pressure High systolic blood pressure is 140 mm Hg or higher.  (Normal \nvalues are less than 120 mm Hg, and prehypertension levels are between 120 mm Hg and \n139\u00a0mm Hg.) Subjects with high blood pressure are encouraged to take action to lower it. A \npharmaceutical company develops a new medication designed to lower blood pressure, and \ntests on 25 subjects result in an average (mean) decrease of 2 mm Hg. Analysis of the results \nshows that there is a 15% chance of getting such results if the medication has no effect.\nIn Exercises 17\u201320, refer to the sample of body temperatures (degrees Fahrenheit) in the \ntable below. (The body temperatures are recorded on the same day from a sample of five \nrandomly selected males listed in a data set in Appendix B.)\nSubject\n1\n2\n3\n4\n5\n8 AM\n97.0\n98.5\n97.6\n97.7\n98.7\n12 AM\n97.6\n97.8\n98.0\n98.4\n98.4\n17. Context of the Data Refer to the table of body temperatures. Is there some meaning-\nful way in which each body temperature recorded at 8 AM is matched with the 12 AM \n temperature?\n18. Source The listed body temperatures were obtained from Dr. Steven Wasserman, Dr. \nPhilip Mackowiak, and Dr. Myron Levine, who were researchers at the University of Maryland. \nIs the source of the data likely to be biased?\n19. Conclusion Given the body temperatures in the table, what issue can be addressed by con-\nducting a statistical analysis of the data?\n20. Conclusion If we analyze the listed body temperatures with suitable methods of statistics, \nwe conclude that when the differences are found between the 8 AM body temperatures and \nthe 12 AM body temperatures, there is a 64% chance that the differences can be explained by \nrandom results obtained from populations that have the same 8 AM and 12 AM body tempera-\ntures. What should we conclude about the statistical significance of those difference",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 27
  },
  {
    "child_id": "2aef4eb2-dc14-4c2a-9b19-51dff7a73772",
    "parent_id": "b07de4ed-7142-4ae3-9942-db3d40a25a93",
    "text": "con-\nducting a statistical analysis of the data?\n20. Conclusion If we analyze the listed body temperatures with suitable methods of statistics, \nwe conclude that when the differences are found between the 8 AM body temperatures and \nthe 12 AM body temperatures, there is a 64% chance that the differences can be explained by \nrandom results obtained from populations that have the same 8 AM and 12 AM body tempera-\ntures. What should we conclude about the statistical significance of those differences?\nIn Exercises 21\u201324, refer to the data in the table below. The entries are white blood cell \ncounts (1000 cells,ML) and red blood cell counts (million cells,ML) from male subjects \n examined as part of a large health study conducted by the National Center for Health Statis-\ntics. The data are matched, so that the first subject has a white blood cell count of 8.7 and a \nred blood cell count of 4.91, and so on.\nSubject\n1\n2\n3\n4\n5\nWhite\n8.7\n5.9\n7.3\n6.2\n5.9\nRed\n4.91\n5.59\n4.44\n4.80\n5.17\ncontinued",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 27
  },
  {
    "child_id": "332831f4-f58d-41d4-a958-694170df0d7b",
    "parent_id": "1ca0ce28-b748-4169-aad2-03c11eb61fa6",
    "text": "12 \nCHAPTER 1 Introduction to Statistics\n21. Context Given that the data (on the bottom of the preceding page) are matched and consid-\nering the units of the data, does it make sense to use the difference between each white blood \ncell count and the corresponding red blood cell count? Why or why not?\n22. Analysis Given the context of the data in the table (on the bottom of the preceding page), \nwhat issue can be addressed by conducting a statistical analysis of the measurements?\n23. Source of the Data Considering the source of the data (on the bottom of the preceding \npage), does that source appear to be biased in some way?\n24. Conclusion If we analyze the sample data (on the bottom of the preceding page) and \nconclude that there is a correlation between white and red blood cell counts, does it follow that \nhigher white are the cause of higher red blood cell counts?\nWhat\u2019s Wrong? In Exercises 25\u201328, identify what is wrong.\n25. Potatoes In a poll sponsored by the Idaho Potato Commission, 1000 adults were asked to \nselect their favorite vegetables, and the favorite choice was potatoes, which were selected by \n26% of the respondents.\n26. Healthy Water In a USA Today online poll, 951 Internet users chose to respond, and 57% \nof them said that they prefer drinking bottled water instead of tap water.\n27. Cheese and Bedsheet Deaths In recent years, there has been a strong correlation be-\ntween per capita consumption of cheese in the United States and the numbers of people who \ndied from being tangled in their bedsheets. Really. Therefore, consumption of cheese causes \nbedsheet entanglement fatalities.\n28. Smokers The electronic cigarette maker V2 Cigs sponsored a poll showing that 55% of \nsmokers surveyed say that they feel ostracized \u201csometimes,\u201d \u201coften,\u201d or \u201calways.\u201d\nPercentages. In Exercises 29 and 30, answer the given questions, which are related to \npercentages.\n29. Health It was noted in Exercise 12 \u201cHealth\u201d that in a survey of 3014 randomly selected \nU.S. adults, 45% reported that they have at least one chronic health condition, such as diabetes \nor high blood pressure.\na. What is 45% of 3014 adults?\nb. Could the result from part (a) be the actual number of survey subjects who have at least one \nchronic condition?\nc. What is the actual number of survey subjects who have at least one chronic condition?\nd. Among those surveyed, 1808 were called by landline and 1206 were called by cell phone. \nWhat percentage of the survey subjects were called by cell phone?\n30. Chillax USA Today reported results from a Research Now for Keurig survey in which \n1458 men and 1543 women were asked this: \u201cIn a typical week, how often can you kick back \nand relax?\u201d\na. Among the women, 19% responded with \u201crarely, if ever.\u201d What is the exact value that is 19% \nof the number of women surveyed?\nb. Could the result from part (a) be the actual number of women who responded with \u201crarely, if \never\u201d? Why or why not?\nc. What is the actual number of women who responded with \u201crarely",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 30
  },
  {
    "child_id": "dbf2c919-fd36-4ef6-aff3-6c85e26fceac",
    "parent_id": "1ca0ce28-b748-4169-aad2-03c11eb61fa6",
    "text": "30. Chillax USA Today reported results from a Research Now for Keurig survey in which \n1458 men and 1543 women were asked this: \u201cIn a typical week, how often can you kick back \nand relax?\u201d\na. Among the women, 19% responded with \u201crarely, if ever.\u201d What is the exact value that is 19% \nof the number of women surveyed?\nb. Could the result from part (a) be the actual number of women who responded with \u201crarely, if \never\u201d? Why or why not?\nc. What is the actual number of women who responded with \u201crarely, if ever\u201d?\nd. Among the men who responded, 219 responded with \u201crarely, if ever.\u201d What is the percentage \nof men who responded with \u201crarely, if ever\u201d?\ne. Consider the question that the subjects were asked. Is that question clear and unambiguous so \nthat all respondents will interpret the question the same way? How might the survey be improved?\n\n1-2 Types of Data \n13\nIf we have more than one statistic, we have \u201cstatistics.\u201d Another meaning of \u201cstatis-\ntics\u201d was given in Section 1-1, where we defined statistics to be the science of plan-\nning studies and experiments; obtaining data; organizing, summarizing, presenting, \nanalyzing, and interpreting those data; and then drawing conclusions based on them. \nWe now have two different definitions of statistics, but we can determine which of \nthese two definitions applies by considering the context in which the term statistics is \nused, as in the following example.\n31. What\u2019s Wrong with This Picture? The Newport Chronicle ran a survey by asking read-\ners to call in their response to this question: \u201cDo you support a ban on electronic cigarettes, \nwhich foster smoking among our children?\u201d It was reported that 20 readers responded and that \n87% said \u201cno,\u201d while 13% said \u201cyes.\u201d Identify four major flaws in this survey.\n32. Falsifying Data A researcher at the Sloan-Kettering Cancer Research Center was once \ncriticized for falsifying data. Among his data were figures obtained from 6 groups of mice, \nwith 20 individual mice in each group. The following values were given for the percentage of \nsuccesses in each group: 53%, 58%, 63%, 46%, 48%, 67%. What\u2019s wrong with those values?\n1-1 Beyond the Basics\nDEFINITIONS\nA parameter is a numerical measurement describing some characteristic of a \npopulation.\nA statistic is a numerical measurement describing some characteristic of a sample.\nHINT The alliteration in \u201cpopulation parameter\u201d and \u201csample statistic\u201d helps us \nremember the meanings of these terms.\nEXAMPLE 1  Parameter, Statistic\nThere are 17,246,372 high school students in the United States. In a study of 8505 \nU.S. high school students 16 years of age or older, 44.5% of them said that they \ntexted while driving at least once during the previous 30 days (based on data in \nKey Concept A major use of statistics is to collect and use sample data to make con-\nclusions about populations. We should know and understand the meanings of the terms \nstatistic and parameter, as defined below. In this section we describe a few different",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 30
  },
  {
    "child_id": "6d61f842-93d6-4ddb-bd01-8cf805ad5d08",
    "parent_id": "1ca0ce28-b748-4169-aad2-03c11eb61fa6",
    "text": "e are 17,246,372 high school students in the United States. In a study of 8505 \nU.S. high school students 16 years of age or older, 44.5% of them said that they \ntexted while driving at least once during the previous 30 days (based on data in \nKey Concept A major use of statistics is to collect and use sample data to make con-\nclusions about populations. We should know and understand the meanings of the terms \nstatistic and parameter, as defined below. In this section we describe a few different \ntypes of data. The type of data is one of the key factors that determine the statistical \nmethods we use in our analysis.\nIn Part 1 of this section we describe the basics of different types of data, and then \nin Part 2 we consider \u201cbig data\u201d and missing data.\nPART 1\n Basic Types of Data\nParameter, Statistic\n \n1-2 \nTypes of Data\ncontinued\n\n14 \nCHAPTER 1 Introduction to Statistics\nQuantitative, Categorical\nSome data are numbers representing counts or measurements (such as a systolic blood \npressure of 118 mm Hg), whereas others are attributes (such as eye color of green or \nbrown) that are not counts or measurements. The terms quantitative data and cat-\negorical data distinguish between these types.\n\u201cTexting While Driving and Other Risky Motor Vehicle Behaviors Among U.S. \nHigh School Students,\u201d by Olsen, Shults, Eaton, Pediatrics, Vol. 131, No. 6).\n \n1. Parameter: The population size of all 17,246,372 high school students is a \nparameter, because it is the size of the entire population of all high school \nstudents in the United States. If we somehow knew the percentage of all \n17,246,372 high school students who reported they had texted while driving, \nthat percentage would also be a parameter.\n \n2. Statistic: The value of 44.5% is a statistic, because it is based on the sample, \nnot on the entire population.\nDEFINITIONS\nQuantitative (or numerical) data consist of numbers representing counts or mea-\nsurements.\nCategorical (or qualitative or attribute) data consist of names or labels (not num-\nbers that represent counts or measurements).\nCAUTION Categorical data are sometimes coded with numbers, with those num-\nbers replacing names. Although such numbers might appear to be quantitative, \nthey are actually categorical data. See the third part of Example 2.\nInclude Units of Measurement With quantitative data, it is important to use the \nappropriate units of measurement, such as dollars, hours, feet, or meters. We should \ncarefully observe information given about the units of measurement, such as \u201call \namounts are in thousands of dollars,\u201d or \u201call units are in kilograms.\u201d Ignoring such \nunits of measurement can be very costly. The National Aeronautics and Space Admin-\nistration (NASA) lost its $125 million Mars Climate Orbiter when the orbiter crashed \nbecause the controlling software had acceleration data in English units, but they were \nincorrectly assumed to be in metric units.\nEXAMPLE 2  Quantitative, Categorical\n \n1. Quantitative Data: The ages (in years",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 30
  },
  {
    "child_id": "3bbec8da-228e-4632-bb9f-2667da12ab95",
    "parent_id": "1ca0ce28-b748-4169-aad2-03c11eb61fa6",
    "text": "nits of measurement, such as \u201call \namounts are in thousands of dollars,\u201d or \u201call units are in kilograms.\u201d Ignoring such \nunits of measurement can be very costly. The National Aeronautics and Space Admin-\nistration (NASA) lost its $125 million Mars Climate Orbiter when the orbiter crashed \nbecause the controlling software had acceleration data in English units, but they were \nincorrectly assumed to be in metric units.\nEXAMPLE 2  Quantitative, Categorical\n \n1. Quantitative Data: The ages (in years) of subjects enrolled in a clinical trial\n \n2. Categorical Data as Labels: The genders (male>female) of subjects enrolled \nin a clinical trial\n \n3. Categorical Data as Numbers: The identi\ufb01cation numbers 1, 2, 3, . . . , 25 \nare assigned randomly to the 25 subjects in a clinical trial. Those numbers \nare substitutes for names. They don\u2019t measure or count anything, so they are \ncategorical data, not quantitative data.\n\n1-2 Types of Data \n15\nDiscrete, Continuous\nQuantitative data can be further described by distinguishing between discrete and con-\ntinuous types.\nDEFINITIONS\nDiscrete data result when the data values are quantitative and the number of \nvalues is finite or \u201ccountable.\u201d (If there are infinitely many values, the collection of \nvalues is countable if it is possible to count them individually, such as the number \nof tosses of a coin before getting tails or the number of births in Houston before \ngetting a male.)\nContinuous (numerical) data result from infinitely many possible quantitative \nvalues, where the collection of values is not countable. (That is, it is impossible \nto count the individual items because at least some of them are on a continuous \nscale, such as the lengths of distances from 0 cm to 12 cm.)\nCAUTION The concept of countable data plays a key role in the preceding defini-\ntions, but it is not a particularly easy concept to understand. Continuous data can \nbe measured, but not counted. If you select a particular data value from continuous \ndata, there is no \u201cnext\u201d data value. See Example 3.\n \n Continuous Data\n \n Discrete Data\nEXAMPLE 3  Discrete, Continuous\n \n1. Discrete Data of the Finite Type: Each of several physicians plans to count \nthe number of physical examinations given during the next full week. The \ndata are discrete data because they are \ufb01nite numbers, such as 27 and 46 that \nresult from a counting process.\n \n2. Discrete Data of the In\ufb01nite Type: Researchers plan to test the accuracy of a \nblood typing test by repeating the process of submitting a sample of the same \nblood (Type O+) until the test yields an error. It is possible that each research-\ner could repeat this test forever without ever getting an error, but they can \nstill count the number of tests as they proceed. The collection of the numbers \nof tests is countable, because you can count them, even though the counting \ncould go on forever.\n \n3. Continuous Data: When the typical patient has blood drawn as part of a \nroutine examination, the volume of blood dr",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 30
  },
  {
    "child_id": "eb48e8c9-4529-4f28-b884-ae5d517bce43",
    "parent_id": "1ca0ce28-b748-4169-aad2-03c11eb61fa6",
    "text": "ess of submitting a sample of the same \nblood (Type O+) until the test yields an error. It is possible that each research-\ner could repeat this test forever without ever getting an error, but they can \nstill count the number of tests as they proceed. The collection of the numbers \nof tests is countable, because you can count them, even though the counting \ncould go on forever.\n \n3. Continuous Data: When the typical patient has blood drawn as part of a \nroutine examination, the volume of blood drawn is between 0 mL and 50 mL. \nThere are in\ufb01nitely many values between 0 mL and 50 mL. Because it is im-\npossible to count the number of di\ufb00erent possible values on such a continuous \nscale, these amounts are continuous data.",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 30
  },
  {
    "child_id": "b74686fa-2260-44fb-abc2-733b94345e66",
    "parent_id": "a0d23156-baa3-4d18-b59f-523590f2c8ef",
    "text": "16 \nCHAPTER 1 Introduction to Statistics\nLevels of Measurement\nAnother common way of classifying data is to use four levels of measurement: nomi-\nnal, ordinal, interval, and ratio, all defined below. (Also see Table 1-2 for brief de-\nscriptions of the four levels of measurements.) When we are applying statistics to \nreal problems, the level of measurement of the data helps us decide which procedure \nto use. There will be references to these levels of measurement in this book, but the \nimportant point here is based on common sense: Don\u2019t do computations and don\u2019t use \nstatistical methods that are not appropriate for the data. For example, it would not \nmake sense to compute an average (mean) of Social Security numbers, because those \nnumbers are data used for identification, and they don\u2019t represent measurements or \ncounts of anything.\nGRAMMAR: FEWER VERSUS LESS When describing smaller amounts, it is \ncorrect grammar to use \u201cfewer\u201d for discrete amounts and \u201cless\u201d for continuous \namounts. It is correct to say that we drank fewer cans of cola and that, in the pro-\ncess, we drank less cola. The numbers of cans of cola are discrete data, whereas \nthe volume amounts of cola are continuous data.\nDEFINITION\nThe nominal level of measurement is characterized by data that consist of \nnames, labels, or categories only. It is not possible to arrange the data in some \norder (such as low to high).\nEXAMPLE 4  Nominal Level\nHere are examples of sample data at the nominal level of measurement.\n1. Yes, No, Undecided: Survey responses of yes, no, and undecided\n \n2. Coded Survey Responses: For an item on a survey, respondents are given a \nchoice of possible answers, and they are coded as follows: \u201cI agree\u201d is coded \nas 1; \u201cI disagree\u201d is coded as 2; \u201cI don\u2019t care\u201d is coded as 3; \u201cI refuse to \nanswer\u201d is coded as 4; \u201cGo away and stop bothering me\u201d is coded as 5. The \nnumbers 1, 2, 3, 4, 5 don\u2019t measure or count anything.\nBecause nominal data lack any ordering or numerical significance, they should \nnot be used for calculations. Numbers such as 1, 2, 3, and 4 are sometimes assigned \nto the different categories (especially when data are coded for computers), but these \nnumbers have no real computational significance and any average (mean) calculated \nfrom them is meaningless and possibly misleading.\nDEFINITION\nData are at the ordinal level of measurement if they can be arranged in some \norder, but differences (obtained by subtraction) between data values either cannot \nbe determined or are meaningless.\n\n1-2 Types of Data \n17\nOrdinal data provide information about relative comparisons, but not the magni-\ntudes of the differences. Usually, ordinal data should not be used for calculations such \nas an average (mean), but this guideline is sometimes disregarded (such as when we \nuse letter grades to calculate a grade-point average).\nEXAMPLE 5  Ordinal Level\nHere is an example of sample data at the ordinal level of measurement.\nCourse Grades: A biostatistics professor assigns",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 34
  },
  {
    "child_id": "d7602fbd-558f-43b2-b393-ef553d0bd393",
    "parent_id": "a0d23156-baa3-4d18-b59f-523590f2c8ef",
    "text": "ned or are meaningless.\n\n1-2 Types of Data \n17\nOrdinal data provide information about relative comparisons, but not the magni-\ntudes of the differences. Usually, ordinal data should not be used for calculations such \nas an average (mean), but this guideline is sometimes disregarded (such as when we \nuse letter grades to calculate a grade-point average).\nEXAMPLE 5  Ordinal Level\nHere is an example of sample data at the ordinal level of measurement.\nCourse Grades: A biostatistics professor assigns grades of A, B, C, D, or F. These \ngrades can be arranged in order, but we can\u2019t determine differences between the \ngrades. For example, we know that A is higher than B (so there is an ordering), but \nwe cannot subtract B from A (so the difference cannot be found).\nDEFINITION\nData are at the interval level of measurement if they can be arranged in order, and \ndifferences between data values can be found and are meaningful; but data at this \nlevel do not have a natural zero starting point at which none of the quantity is present.\nEXAMPLE 6  Interval Level\nThese examples illustrate the interval level of measurement.\n \n1. Temperatures: Body temperatures of 98.2\u00b0F and 98.8\u00b0F are examples of data \nat this interval level of measurement. Those values are ordered, and we can \ndetermine their di\ufb00erence of 0.6\u00b0F. However, there is no natural starting point. \nThe value of 0\u00b0F might seem like a starting point, but it is arbitrary and does \nnot represent the total absence of heat.\n \n2. Years: The years 1492 and 1776 can be arranged in order, and the di\ufb00erence \nof 284 years can be found and is meaningful. However, time did not begin in \nthe year 0, so the year 0 is arbitrary instead of being a natural zero starting \npoint representing \u201cno time.\u201d\nDEFINITION\nData are at the ratio level of measurement if they can be arranged in order, differ-\nences can be found and are meaningful, and there is a natural zero starting point \n(where zero indicates that none of the quantity is present). For data at this level, dif-\nferences and ratios are both meaningful.\nEXAMPLE 7  Ratio Level\nThe following are examples of data at the ratio level of measurement. Note the pres-\nence of the natural zero value, and also note the use of meaningful ratios of \u201ctwice\u201d \nand \u201cthree times.\u201d\n \n1. Heights of Students: Heights of 180 cm and 90 cm for a high school student and a \npreschool student (0 cm represents no height, and 180 cm is twice as tall as 90 cm.)\n \n2. Class Times: The times of 50 min and 100 min for a statistics class (0 min \nrepresents no class time, and 100 min is twice as long as 50 min.)\n\n18 \nCHAPTER 1 Introduction to Statistics\nSee Table 1-2 for brief descriptions of the four levels of measurements.\nTABLE 1-2 Levels of Measurement\nLevel of \nMeasurement\n \nBrief Description\n \nExample\nRatio\nThere is a natural zero starting point and \nratios make sense.\nHeights, lengths, distances, \nvolumes\nInterval\nDifferences are meaningful, but there is \nno natural zero starting point and ratios \nare",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 34
  },
  {
    "child_id": "ee70d5a0-657f-4230-a0f8-8d48f189baf2",
    "parent_id": "a0d23156-baa3-4d18-b59f-523590f2c8ef",
    "text": "or a statistics class (0 min \nrepresents no class time, and 100 min is twice as long as 50 min.)\n\n18 \nCHAPTER 1 Introduction to Statistics\nSee Table 1-2 for brief descriptions of the four levels of measurements.\nTABLE 1-2 Levels of Measurement\nLevel of \nMeasurement\n \nBrief Description\n \nExample\nRatio\nThere is a natural zero starting point and \nratios make sense.\nHeights, lengths, distances, \nvolumes\nInterval\nDifferences are meaningful, but there is \nno natural zero starting point and ratios \nare meaningless.\nBody temperatures in degrees \nFahrenheit or Celsius\nOrdinal\nData can be arranged in order, but dif-\nferences either can\u2019t be found or are \nmeaningless.\nRanks of colleges in U.S. News & \nWorld Report\nNominal\nCategories only. Data cannot be arranged \nin order.\nEye colors\nHINT The distinction between the interval and ratio levels of measurement can \nbe a bit tricky. Here are two tools for help with that distinction:\n \n1.  Ratio Test Focus on the term \u201cratio\u201d and know that the term \u201ctwice\u201d describes the \nratio of one value to be double the other value. To distinguish between the interval \nand ratio levels of measurement, use a \u201cratio test\u201d by asking this question: Does \nuse of the term \u201ctwice\u201d make sense? \u201cTwice\u201d makes sense for data at the ratio level \nof measurement, but it does not make sense for data at the interval level of mea-\nsurement.\n \n2.  True Zero For ratios to make sense, there must be a value of \u201ctrue zero,\u201d where \nthe value of zero indicates that none of the quantity is present, and zero is not \nsimply an arbitrary value on a scale. The temperature of 0\u00b0F is arbitrary and \ndoes not indicate that there is no heat, so temperatures on the Fahrenheit scale \nare at the interval level of measurement, not the ratio level.\nEXAMPLE 8   Distinguishing Between the Ratio Level and  \nInterval Level\nFor each of the following, determine whether the data are at the ratio level of mea-\nsurement or the interval level of measurement:\n \na. Times (minutes) it takes to complete a statistics test.\n \nb. Body temperatures (Celsius) of statistics students.\nSOLUTION\n \na. Apply the \u201cratio test\u201d described in the preceding hint. If one student completes \nthe test in 40 minutes and another student completes the test in 20 min, does it \nmake sense to say that the \ufb01rst student used twice as much time? Yes! So the \ntimes are at the ratio level of measurement. Also, a time of 0 minutes does repre-\nsent \u201cno time,\u201d so the value of 0 is a true zero indicating that no time was used.\n \nb. Apply the \u201cratio test\u201d described in the preceding hint. If one student has a \nbody temperature of 40\u00b0C and another student has a body temperature of \n20\u00b0C, does it make sense to say that the \ufb01rst student is twice as hot as the \nT\nSurvey Pitfalls\nSurveys con-\nstitute a huge \nand growing \nbusiness in the \nUnited States, \nbut survey \nresults can be \ncompromised by many factors. \nA growing number of people \nrefuse to respond; the average \nresponse rate is now about 22%, \ncompared to 36% aro",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 34
  },
  {
    "child_id": "2360f5f0-d07e-4dca-ba37-a9613544da72",
    "parent_id": "a0d23156-baa3-4d18-b59f-523590f2c8ef",
    "text": "ed.\n \nb. Apply the \u201cratio test\u201d described in the preceding hint. If one student has a \nbody temperature of 40\u00b0C and another student has a body temperature of \n20\u00b0C, does it make sense to say that the \ufb01rst student is twice as hot as the \nT\nSurvey Pitfalls\nSurveys con-\nstitute a huge \nand growing \nbusiness in the \nUnited States, \nbut survey \nresults can be \ncompromised by many factors. \nA growing number of people \nrefuse to respond; the average \nresponse rate is now about 22%, \ncompared to 36% around the \nyear 2000. A growing number of \npeople are more difficult to reach \nbecause they use cell phones \n(no directories); about 15% of \nadults now have cell phones and \nno landlines, and they tend to \nbe younger than average. There \nare obvious problems associated \nwith surveys that ask respon-\ndents about drug use, theft, or \nsexual behavior, and a social \ndesirability bias occurs when sur-\nvey respondents are not honest \nbecause they don\u2019t want to be \nviewed negatively by the person \nconducting the interview.",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 34
  },
  {
    "child_id": "55edde14-80b6-424b-af41-81a3655bd0e5",
    "parent_id": "660be240-334f-4c01-b1bf-9e20861f3b84",
    "text": "1-2 Types of Data \n19\nPART 2\n  Big Data and Missing Data:  \nToo Much and Not Enough\nWhen working with data, we might encounter some data sets that are excessively \nlarge, and we might also encounter some data sets with individual elements missing. \nHere in Part 2 we briefly discuss both cases.\nBig Data\nEdward Snowden used his employment at the NSA (National Security Agency) to re-\nveal substantial top secret documents that led to the realization that the NSA was con-\nducting telephone and Internet surveillance of U.S. citizens as well as world leaders. \nThe NSA was collecting massive amounts of data that were analyzed in an attempt to \nprevent terrorism. Monitoring telephone calls and Internet communications is made \npossible with modern technology. The NSA can compile big data, and such ginormous \ndata sets have led to the birth of data science. There is not universal agreement on the \nfollowing definitions, and various other definitions can be easily found elsewhere.\n second student? (Ignore subjective amounts of attractiveness and consider \nonly science.) No! So the body temperatures are not at the ratio level of \nmeasurement. Because the di\ufb00erence between 40\u00b0C and 20\u00b0C is the same as \nthe di\ufb00erence between 90\u00b0C and 70\u00b0C, the di\ufb00erences are meaningful, but be-\ncause ratios do not make sense, the body temperatures are at the interval level \nof measurement. Also, the temperature of 0\u00b0C does not represent \u201cno heat\u201d so \nthe value of 0 is not a true zero indicating that no heat is present.\nDEFINITIONS\nBig data refers to data sets so large and so complex that their analysis is beyond \nthe capabilities of traditional software tools. Analysis of big data may require soft-\nware simultaneously running in parallel on many different computers.\nData science involves applications of statistics, computer science, and software en-\ngineering, along with some other relevant fields (such as biology and epidemiology).\nExamples of Data Set Magnitudes We can see from the above definition of big \ndata that there isn\u2019t a fixed number that serves as an exact boundary for determining \nwhether a data set qualifies as being big data, but big data typically involves amounts \nof data such as the following.\n \n\u25a0Terabytes (1012 or 1,000,000,000,000 bytes) of data\n \n\u25a0Petabytes (1015 bytes) of data\n \n\u25a0Exabytes (1018 bytes) of data\n \n\u25a0Zettabytes (1021 bytes) of data\n \n\u25a0Yottabytes (1024 bytes) of data\nExamples of Applications of Big Data The following are a few examples involv-\ning big data:\n \n\u25a0Attempt to forecast flu epidemics by analyzing Internet searches of flu symptoms.\n \n\u25a0The Spatio Temporal Epidemiological Modeler developed by IBM is providing a \nmeans for using a variety of data that are correlated with disease data.\ne-\nl \no\nBig Data Instead  \nof a Clinical Trial\nNicholas \nTatonetti of \nColumbia \nUniversity \nsearched Food \nand Drug \nAdministration \ndatabases for \nadverse reactions in patients that \nresulted from different pairings \nof drugs. He discovered that \nthe paroxe",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 37
  },
  {
    "child_id": "d973b5a0-00ed-4ce4-aa5f-37018fdc7dfc",
    "parent_id": "660be240-334f-4c01-b1bf-9e20861f3b84",
    "text": "a:\n \n\u25a0Attempt to forecast flu epidemics by analyzing Internet searches of flu symptoms.\n \n\u25a0The Spatio Temporal Epidemiological Modeler developed by IBM is providing a \nmeans for using a variety of data that are correlated with disease data.\ne-\nl \no\nBig Data Instead  \nof a Clinical Trial\nNicholas \nTatonetti of \nColumbia \nUniversity \nsearched Food \nand Drug \nAdministration \ndatabases for \nadverse reactions in patients that \nresulted from different pairings \nof drugs. He discovered that \nthe paroxetine drug for depres-\nsion and the pravastatin drug \nfor high cholesterol interacted \nto create increases in glucose \n(blood sugar) levels. When taken \nseparately by patients, neither \ndrug raised glucose levels, but \nthe increase in glucose levels \noccurred when the two drugs \nwere taken together. This finding \nresulted from a general database \nsearch of interactions from many \npairings of drugs, not from a \nclinical trial involving patients \nusing Paxil and pravastatin.\ncontinued\n\n20 \nCHAPTER 1 Introduction to Statistics\n \n\u25a0A National Electronic Disease Surveillance System is used to monitor disease \ntrends and identify outbreaks of infectious disease.\n \n\u25a0Google provides live traffic maps by recording and analyzing GPS (global posi-\ntioning system) data collected from the smartphones of people traveling in their \nvehicles.\n \n\u25a0Amazon monitors and tracks 1.4 billion items in its store that are distributed \nacross hundreds of fulfillment centers around the world.\nExamples of Jobs According to Analytic Talent, there are 6000 companies hiring \ndata scientists, and here are some job posting examples:\n \n\u25a0Facebook: Data Scientist\n \n\u25a0IBM: Data Scientist\n \n\u25a0PayPal: Data Scientist\n \n\u25a0The College Board: SAS Programmer>Data Scientist\n \n\u25a0Netflix: Senior Data Engineer>Scientist\nStatistics in Data Science The modern data scientist has a solid background in \nstatistics and computer systems as well as expertise in fields that extend beyond sta-\ntistics. The modern data scientist might be skilled with Hadoop software, which uses \nparallel processing on many computers for the analysis of big data. The modern data \nscientist might also have a strong background in some other field, such as psychology, \nbiology, medicine, chemistry, or economics. Because of the wide range of disciplines \nrequired, a data science project might typically involve a team of collaborating indi-\nviduals with expertise in different fields. An introductory statistics course is a great \nfirst step in becoming a data scientist.\nMissing Data\nWhen collecting sample data, it is quite common to find that some values are miss-\ning. Ignoring missing data can sometimes create misleading results. If you make the \nmistake of skipping over a few different sample values when you are manually typ-\ning them into a statistics software program, the missing values are not likely to have \na serious effect on the results. However, if a survey includes many missing salary en-\ntries because those with very low incomes are ",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 37
  },
  {
    "child_id": "d603140b-39f9-4d24-9d2a-556119b58d78",
    "parent_id": "660be240-334f-4c01-b1bf-9e20861f3b84",
    "text": "data scientist.\nMissing Data\nWhen collecting sample data, it is quite common to find that some values are miss-\ning. Ignoring missing data can sometimes create misleading results. If you make the \nmistake of skipping over a few different sample values when you are manually typ-\ning them into a statistics software program, the missing values are not likely to have \na serious effect on the results. However, if a survey includes many missing salary en-\ntries because those with very low incomes are reluctant to reveal their salaries, those \nmissing low values will have the serious effect of making salaries appear higher than \nthey really are.\nFor an example of missing data, see the following table. The body temperature for \nSubject 2 at 12 AM on day 2 is missing. (The table below includes the first three rows \nof data from Data Set 2 \u201cBody Temperatures\u201d in Appendix B.)\n Body Temperatures (in degrees Fahrenheit) of Healthy Adults\nTemperature  \nDay 1\nTemperature  \nDay 2\nSubject\nAge\nSex\nSmoke\n8 AM\n12 AM\n8 AM\n12 AM\n1\n22\nM\nY\n98.0\n98.0\n98.0\n98.6\n2\n23\nM\nY\n97.0\n97.6\n97.4\n----\n3\n22\nM\nY\n98.6\n98.8\n97.8\n98.6\n\n1-2 Types of Data \n21\nThere are different categories of missing data. See the following definitions.\nDEFINITION\nA data value is missing completely at random if the likelihood of its being miss-\ning is independent of its value or any of the other values in the data set. That is, any \ndata value is just as likely to be missing as any other data value.\n(Note: More complete discussions of missing data will distinguish between missing \ncompletely at random and missing at random, which means that the likelihood of a \nvalue being missing is independent of its value after controlling for another variable. \nThere is no need to know this distinction in this book.)\nExample of Missing Data\u2014Random When using a keyboard to manually enter \nages of survey respondents, the operator is distracted by a colleague singing \u201cDay-\ndream Believer\u201d and makes the mistake of failing to enter the age of 37 years. This \ndata value is missing completely at random.\nDEFINITION\nA data value is missing not at random if the missing value is related to the reason \nthat it is missing.\nExample of Missing Data\u2014Not at Random A survey question asks each respon-\ndent to enter his or her annual income, but respondents with very low incomes skip \nthis question because they find it embarrassing.\nBiased Results? Based on the above two definitions and examples, it makes sense \nto conclude that if we ignore data missing completely at random, the remaining values \nare not likely to be biased and good results should be obtained. However, if we ignore \ndata that are missing not at random, it is very possible that the remaining values are \nbiased and results will be misleading.\nCorrecting for Missing Data There are different methods for dealing with missing \ndata.\n1. Delete Cases: One very common method for dealing with missing data is to \ndelete all subjects having any missing values.\n \n\u25a0If the data are miss",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 37
  },
  {
    "child_id": "bc430f9d-68bd-4aa6-8567-02ceefc1d273",
    "parent_id": "660be240-334f-4c01-b1bf-9e20861f3b84",
    "text": "ssing completely at random, the remaining values \nare not likely to be biased and good results should be obtained. However, if we ignore \ndata that are missing not at random, it is very possible that the remaining values are \nbiased and results will be misleading.\nCorrecting for Missing Data There are different methods for dealing with missing \ndata.\n1. Delete Cases: One very common method for dealing with missing data is to \ndelete all subjects having any missing values.\n \n\u25a0If the data are missing completely at random, the remaining values are not \nlikely to be biased and good results can be obtained, but with a smaller sam-\nple size.\n \n\u25a0If the data are missing not at random, deleting subjects having any missing \nvalues can easily result in a bias among the remaining values, so results can \nbe misleading.\n2. Impute Missing Values: We impute missing data values when we substitute \nvalues for them. There are different methods of determining the replacement \nvalues, such as using the mean of the other values, or using a randomly selected \nvalue from other similar cases, or using a method based on regression analysis \n(which will make more sense after studying Chapter 10).\nMeasuring  \nDisobedience\nHow are data \ncollected about \nsomething that \ndoesn\u2019t seem \nto be measur-\nable, such as \npeople\u2019s level of \ndisobedience? \nPsychologist Stanley Milgram \ndevised the following experi-\nment: A researcher instructed a \nvolunteer subject to operate a \ncontrol board that gave increas-\ningly painful \u201celectrical shocks\u201d \nto a third person. Actually, no real \nshocks were given, and the third \nperson was an actor. The volun-\nteer began with 15 volts and was \ninstructed to increase the shocks \nby increments of 15\u00a0volts. The \ndisobedience level was the point \nat which the subject refused to \nincrease the voltage. Surpris-\ningly, two-thirds of the subjects \nobeyed orders even when the \nactor screamed and faked a \nheart attack.",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 37
  },
  {
    "child_id": "09c96718-170b-49e6-b799-f2c25b430e45",
    "parent_id": "ae16e349-0f38-4281-8b30-61071cf5bc5d",
    "text": "22 \nCHAPTER 1 Introduction to Statistics\nIn this book we do not work much with missing data, but it is important to under-\nstand this:\nWhen analyzing sample data with missing values, try to determine why \nthey are missing, and then decide whether it makes sense to treat the \nremaining values as being representative of the population. If it appears \nthat there are missing values that are missing not at random (that is, \ntheir values are related to the reasons why they are missing), know that \nthe remaining data may well be biased and any conclusions based on \nthose remaining values may well be misleading.\nStatistical Literacy and Critical Thinking\n1. Health Survey In a survey of 1020 adults in the United States, 44% said that they wash \ntheir hands after riding public transportation (based on data from KRC Research).\na. Identify the sample and the population.\nb. Is the value of 44% a statistic or a parameter?\n2. Health Survey For the same survey from Exercise 1, answer the following.\na. What is the level of measurement of the value of 44%? (nominal, ordinal, interval, ratio)\nb. Are the numbers of subjects in such surveys discrete or continuous?\nc. The responses are \u201cyes,\u201d \u201cno,\u201d \u201cnot sure,\u201d or \u201crefused to answer.\u201d Are these responses quan-\ntitative data or categorical data?\n3. Quantitative, Categorical Data Identify each of the following as quantitative data or cat-\negorical data.\na. The platelet counts of exam subjects in Data Set 1 \u201cBody Data\u201d in Appendix B\nb. The names of the pharmaceutical companies that manufacture aspirin tablets\nc. The colors of pills\nd. The weights of aspirin tablets\n4. Discrete, Continuous Data Which of the following describe discrete data?\na. The numbers of people surveyed in each of the next several National Health and Nutrition \n Examination Surveys\nb. The exact foot lengths (cm) of a random sample of statistics students\nc. The exact times that randomly selected drivers spend texting while driving during the past 7 days\nIn Exercises 5\u201312, identify whether the given value is a statistic or a parameter.\n5. Brain Volume The average (mean) volume of the brains included in Data Set 9 \u201cIQ and \nBrain Size\u201d in Appendix B is 1126.0 cm3.\n6. CHIS A recent California Health Interview Survey (CHIS) included 2799 adolescent resi-\ndents of California.\n7. Cigarettes A data set in Appendix B includes measurements from 25 king-size cigarettes, \nand the average (mean) amount of nicotine in those 25 cigarettes is 1.26 mg.\n8. Triangle Fire Fatalities A deadly disaster in the United States was the Triangle Shirtwaist \nFactory Fire in New York City. A population of 146 garment workers died in that fire.\n1-2 Basic Skills and Concepts\n\n1-2 Types of Data \n23\n9. Birth Weight In a study of 400 babies born at four different hospitals in New York State, it \nwas found that the average (mean) weight at birth was 3152.0 grams.\n10. Birth Genders In the same study cited in the preceding exercise, 51% of the babies were girls.\n11. Titanic A study was cond",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 40
  },
  {
    "child_id": "0fa7f563-d044-43f3-af1c-f1e357f2df80",
    "parent_id": "ae16e349-0f38-4281-8b30-61071cf5bc5d",
    "text": " A deadly disaster in the United States was the Triangle Shirtwaist \nFactory Fire in New York City. A population of 146 garment workers died in that fire.\n1-2 Basic Skills and Concepts\n\n1-2 Types of Data \n23\n9. Birth Weight In a study of 400 babies born at four different hospitals in New York State, it \nwas found that the average (mean) weight at birth was 3152.0 grams.\n10. Birth Genders In the same study cited in the preceding exercise, 51% of the babies were girls.\n11. Titanic A study was conducted of all 2223 passengers aboard the Titanic when it sank.\n12. Periodic Table The average (mean) atomic weight of all elements in the periodic table is \n134.355 unified atomic mass units.\nIn Exercises 13\u201320, determine whether the data are from a discrete or continuous  \ndata set.\n13. Freshman 15 In a study of weight gains by college students in their freshman year, re-\nsearchers record the amounts of weight gained by randomly selected students (as in Data Set \n10 \u201cFreshman 15\u201d in Appendix B).\n14. Births Data Set 3 \u201cBirths\u201d in Appendix B includes the length of stay (in days) for each \nbaby in a sample of babies born in New York State. The first few values are 2, 2, 36, 5, and 2.\n15. CHIS Among the subjects surveyed as part of the California Health Interview Survey \n(CHIS), several subjects are randomly selected and their heights are recorded.\n16. Arm Circumference From Data Set 1 \u201cBody Data\u201d in Appendix B we see that a female \nhad an arm circumference of 32.49 cm.\n17. Families A sample of married couples is randomly selected and the number of children in \neach family is recorded.\n18. Criminal Forensics When studying the relationship between lengths of feet and heights \nso that footprint evidence at a crime scene can be used to estimate the height of the suspect, a \nresearcher records the exact lengths of feet from a large sample of random subjects.\n19. Stitch In Time The Emergency Room of the Albany Medical Center records the numbers \nof stitches used for patients in a week.\n20. Texting Fatalities The Insurance Institute for Highway Safety collects data consisting of \nthe numbers of motor vehicle fatalities caused by driving while texting.\nIn Exercises 21\u201328, determine which of the four levels of measurement (nominal, ordinal, \ninterval, ratio) is most appropriate.\n21. Brain Volumes Volumes (cm3) of brains listed in Data Set 9 \u201cIQ and Brain Size\u201d in \n Appendix B\n22. Blood Lead Level Blood lead levels of low, medium, and high used to describe the sub-\njects in Data Set 8 \u201cIQ and Lead\u201d in Appendix B\n23. Body Temperatures Body temperatures (in degrees Fahrenheit) listed in Data Set 2 \n\u201cBody Temperatures\u201d in Appendix B.\n24. Privacy Codes Instead of using actual names, subjects included in the National Health \nand Nutrition Examination Survey are coded with consecutive numbers.\n25. Hospitals A research project on the effectiveness of heart transplants begins with a compi-\nlation of the U.S. hospitals that provide heart transplants.\n26. Hospital Charges A rese",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 40
  },
  {
    "child_id": "05312131-0e4d-4339-82f3-0c1ab3312b19",
    "parent_id": "ae16e349-0f38-4281-8b30-61071cf5bc5d",
    "text": " Set 8 \u201cIQ and Lead\u201d in Appendix B\n23. Body Temperatures Body temperatures (in degrees Fahrenheit) listed in Data Set 2 \n\u201cBody Temperatures\u201d in Appendix B.\n24. Privacy Codes Instead of using actual names, subjects included in the National Health \nand Nutrition Examination Survey are coded with consecutive numbers.\n25. Hospitals A research project on the effectiveness of heart transplants begins with a compi-\nlation of the U.S. hospitals that provide heart transplants.\n26. Hospital Charges A research project on the effectiveness of heart transplants begins \nwith a compilation of the charges (dollars) for heart transplant procedures that were conducted \nwithin the past year.\n27. Physician Ranks A research project on the effectiveness of heart transplants includes \nrankings (scale of 1, 2, 3, 4, 5) of physicians who perform those procedures.\n28. Pharmaceuticals Pfizer records the years in which new products were launched, \n beginning with 1849.\n\n24 \nCHAPTER 1 Introduction to Statistics\nIn Exercises 29\u201332, identify the level of measurement of the data as nominal, ordinal, inter-\nval, or ratio. Also, explain what is wrong with the given calculation.\n29. Hospital ID The four hospitals included in Data Set 3 \u201cBirths\u201d in Appendix B are coded as \nfollows: Albany Medical Center (1); Bellevue Hospital Center (1438); Olean General Hospital \n(66); Strong Memorial Hospital (413). The average (mean) of those numbers is 479.5.\n30. Social Security Numbers As part of a clinical study, the Social Security number of each \nsubject is recorded and the average (mean) of the individual digits is computed to be 4.7.\n31. Temperatures A person has a body temperature of 98.0\u00b0F during the time when the out-\nside air temperature is 49.0\u00b0F, so the person is twice as warm as the outside air.\n32. Medical School Ranks As of this writing, U.S. News & World Report ranked medical \nschools, including these results: Harvard (1), Stanford (2), Johns Hopkins (3), University of \nCalifornia at San Francisco (4), and University of Pennsylvania (5). The difference between \nHarvard and Stanford is the same as the difference between Johns Hopkins and University of \nCalifornia at San Francisco.\n33. Countable For each of the following, categorize the nature of the data using one of these \nthree descriptions: (1) discrete because the number of possible values is finite; (2) discrete \nbecause the number of possible values is infinite but countable; (3) continuous because the \nnumber of possible values is infinite and not countable.\na. Exact lengths of the feet of members of the band the Monkees\nb. Shoe sizes of members of the band the Monkees (such as 9, 9\u00bd, and so on)\nc. The number of albums sold by the Monkees band\nd. The numbers of monkeys sitting at keyboards before one of them randomly types the lyrics \nfor the song \u201cDaydream Believer\u201d\n1-2 Beyond the Basics\nKey Concept When using statistics in a study, planning is very important, and it is \nessential to use an appropriate method for collecti",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 40
  },
  {
    "child_id": "3f932df2-b6fc-4291-8c8b-7f9ccc5b2141",
    "parent_id": "ae16e349-0f38-4281-8b30-61071cf5bc5d",
    "text": "nfinite and not countable.\na. Exact lengths of the feet of members of the band the Monkees\nb. Shoe sizes of members of the band the Monkees (such as 9, 9\u00bd, and so on)\nc. The number of albums sold by the Monkees band\nd. The numbers of monkeys sitting at keyboards before one of them randomly types the lyrics \nfor the song \u201cDaydream Believer\u201d\n1-2 Beyond the Basics\nKey Concept When using statistics in a study, planning is very important, and it is \nessential to use an appropriate method for collecting the sample data. This section \nincludes comments about various methods and sampling procedures. Of particular im-\nportance is the method of using a simple random sample. We will make frequent use \nof this sampling method throughout the remainder of this book.\nAs you read this section, remember this:\nIf sample data are not collected in an appropriate way, the data may be \nso utterly useless that no amount of statistical torturing can salvage them.\nPART 1\n  Basics of Design of Experiments and \nCollecting Sample Data\nThe Gold Standard Randomization with placebo>treatment groups is sometimes \ncalled the \u201cgold standard\u201d because it is so effective. (A placebo such as a sugar pill \nhas no medicinal effect.) The following example describes how the gold standard was \nused in the largest health experiment ever conducted.\n \n1-3 \nCollecting Sample Data",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 40
  },
  {
    "child_id": "8f4f0cc3-8e22-4be5-8d84-7c819eba6127",
    "parent_id": "cf82a77b-eb94-49e7-9d4b-1b4ef6219e3c",
    "text": "1-3 Collecting Sample Data \n25\nExample 1 describes an experiment because subjects were given a treatment, but ethi-\ncal, cost, time, and other considerations sometimes prohibit the use of an experiment. \nWe would never want to conduct a driving/texting experiment in which we ask sub-\njects to text while driving\u2014some of them could die. It would be far better to observe \npast crash results to understand the effects of driving while texting. See the following \ndefinitions.\nEXAMPLE 1  The Salk Vaccine Experiment\nIn 1954, an experiment was designed to test the effectiveness of the Salk vaccine in \npreventing polio, which had killed or paralyzed thousands of children. By random \nselection, 401,974 children were randomly assigned to two groups: (1) 200,745 \nchildren were given a treatment consisting of Salk vaccine injections; (2) 201,229 \nchildren were injected with a placebo that contained no drug. Children were as-\nsigned to the treatment or placebo group through a process of random selection, \nequivalent to flipping a coin. Among the children given the Salk vaccine, 33 later \ndeveloped paralytic polio, and among the children given a placebo, 115 later devel-\noped paralytic polio.\nDEFINITIONS\nIn an experiment, we apply some treatment and then proceed to observe its \n effects on the individuals. (The individuals in experiments are called experimental \nunits, and they are often called subjects when they are people.)\nIn an observational study, we observe and measure specific characteristics, but \nwe don\u2019t attempt to modify the individuals being studied.\nExperiments are often better than observational studies because well-planned experi-\nments typically reduce the chance of having the results affected by some variable that \nis not part of a study. A lurking variable is one that affects the variables included in \nthe study, but it is not included in the study.\nEXAMPLE 2  Ice Cream and Drownings\nObservational Study: Observe past data to conclude that ice cream causes drown-\nings (based on data showing that increases in ice cream sales are associated with \nincreases in drownings). The mistake is to miss the lurking variable of temperature \nand the failure to see that as the temperature increases, ice cream sales increase and \ndrownings increase because more people swim.\nExperiment: Conduct an experiment with one group treated with ice cream while \nanother group gets no ice cream. We would see that the rate of drowning victims \nis about the same in both groups, so ice cream consumption has no effect on \ndrownings.\nHere, the experiment is clearly better than the observational study.\nDesign of Experiments\nGood design of experiments includes replication, blinding, and randomization.\n \n\u25a0Replication is the repetition of an experiment on more than one individual. Good \nuse of replication requires sample sizes that are large enough so that we can see \nn \nClinical Trials vs. \nObservational Studies\nIn a New York \nTimes article \nabout hormone \ntherapy for \nwomen, repo",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 43
  },
  {
    "child_id": "19e63db3-85ae-43c8-9cc6-9049d1decf3d",
    "parent_id": "cf82a77b-eb94-49e7-9d4b-1b4ef6219e3c",
    "text": " cream consumption has no effect on \ndrownings.\nHere, the experiment is clearly better than the observational study.\nDesign of Experiments\nGood design of experiments includes replication, blinding, and randomization.\n \n\u25a0Replication is the repetition of an experiment on more than one individual. Good \nuse of replication requires sample sizes that are large enough so that we can see \nn \nClinical Trials vs. \nObservational Studies\nIn a New York \nTimes article \nabout hormone \ntherapy for \nwomen, reporter \nDenise Grady \nwrote about \nrandomized \nclinical trials that involve subjects \nwho were randomly assigned to \na treatment group and another \ngroup not given the treatment. \nSuch randomized clinical trials \nare often referred to as the \u201cgold \nstandard\u201d for medical research. \nIn contrast, observational studies \ncan involve patients who decide \nthemselves to undergo some \ntreatment. Subjects who decide \nthemselves to undergo treat-\nments are often healthier than \nother subjects, so the treatment \ngroup might appear to be more \nsuccessful simply because it \ninvolves healthier subjects, not \nnecessarily because the treat-\nment is effective. Researchers \ncriticized observational studies of \nhormone therapy for women by \nsaying that results might appear \nto make the treatment more ef-\nfective than it really is.\n\n26 \nCHAPTER 1 Introduction to Statistics\neffects of treatments. In the Salk experiment in Example 1, the experiment used \nsufficiently large sample sizes, so the researchers could see that the Salk vaccine \nwas effective.\n \n\u25a0Blinding is used when the subject doesn\u2019t know whether he or she is receiving a \ntreatment or a placebo. Blinding is a way to get around the placebo effect, which \noccurs when an untreated subject reports an improvement in symptoms. (The \nreported improvement in the placebo group may be real or imagined.) The Salk \nexperiment in Example 1 was double-blind, which means that blinding occurred \nat two levels: (1) The children being injected didn\u2019t know whether they were \ngetting the Salk vaccine or a placebo, and (2) the doctors who gave the injec-\ntions and evaluated the results did not know either. Codes were used so that the \nresearchers could objectively evaluate the effectiveness of the Salk vaccine.\n \n\u25a0Randomization is used when individuals are assigned to different groups \nthrough a process of random selection, as in the Salk vaccine experiment in \nExample 1. The logic behind randomization is to use chance as a way to create \ntwo groups that are similar. The following definition refers to one common and \neffective way to collect sample data in a way that uses randomization.\nDEFINITION\nA simple random sample of n subjects is selected in such a way that every pos-\nsible sample of  the same size n has the same chance of being chosen. (A simple \nrandom sample is often called a random sample, but strictly speaking, a random \nsample has the weaker requirement that all members of the population have the \nsame chance of being selecte",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 43
  },
  {
    "child_id": "14971150-05b0-4715-ab96-36d37faaa928",
    "parent_id": "cf82a77b-eb94-49e7-9d4b-1b4ef6219e3c",
    "text": "s that are similar. The following definition refers to one common and \neffective way to collect sample data in a way that uses randomization.\nDEFINITION\nA simple random sample of n subjects is selected in such a way that every pos-\nsible sample of  the same size n has the same chance of being chosen. (A simple \nrandom sample is often called a random sample, but strictly speaking, a random \nsample has the weaker requirement that all members of the population have the \nsame chance of being selected. That distinction is not so important in this text. \n(See Exercise 38 \u201cSimple Random Sample vs. Random Sample.\u201d)\nThroughout, we will use various statistical procedures, and we often have \na requirement that we have collected a simple random sample, as defined \nabove.\nUnlike careless or haphazard sampling, random sampling usually requires very \ncareful planning and execution.\nOther Sampling Methods In addition to simple random sampling, here are some \nother sampling methods commonly used for surveys. Figure 1-3 illustrates these dif-\nferent sampling methods.\nDEFINITIONS\nIn systematic sampling, we select some starting point and then select every kth \n(such as every 50th) element in the population.\nWith convenience sampling, we simply use data that are very easy to get.\nIn stratified sampling, we subdivide the population into at least two different \nsubgroups (or strata) so that subjects within the same subgroup share the same \ncharacteristics (such as gender). Then we draw a sample from each subgroup (or \nstratum).\nIn cluster sampling, we first divide the population area into sections (or clusters). \nThen we randomly select some of those clusters and choose all the members from \nthose selected clusters.\nHawthorne and \nExperimenter Effects\nThe well-\nknown \nplacebo effect \noccurs when \nan untreated \nsubject incor-\nrectly believes \nthat he or she is receiving a \nreal treatment and reports an \nimprovement in symptoms. The \nHawthorne effect occurs when \ntreated subjects somehow re-\nspond differently, simply because \nthey are part of an experiment. \n(This phenomenon was called \nthe \u201cHawthorne effect\u201d because \nit was first observed in a study \nof factory workers at Western \nElectric\u2019s Hawthorne plant.) An \nexperimenter effect (sometimes \ncalled a Rosenthal effect) occurs \nwhen the researcher or experi-\nmenter unintentionally influences \nsubjects through such factors as \nfacial expression, tone of voice, \nor attitude.\n\n1-3 Collecting Sample Data \n27\nMultistage Sampling Professional pollsters and government researchers often  collect \ndata by using some combination of the preceding sampling methods. In a  multistage \nsample design, pollsters select a sample in different stages, and each stage might use \ndifferent methods of sampling, as in the following example.\nMAIN\nCENTER\nHeritage\nSchool\nPark St.\nNorth St.\n1st St.\n2nd St.\n3rd St.\n82nd St.\n52nd St.\n36th St.\n43rd St.\nA St.\nB St.\nC St.\nD St.\nE St.\nF St.\nWay St.\n4th St.\n5th St.\nMLK PKWY\n555-867-5309\n555-606-0842\n555-",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 43
  },
  {
    "child_id": "8c65d378-e6c4-4e8e-82a1-626829d33ff6",
    "parent_id": "cf82a77b-eb94-49e7-9d4b-1b4ef6219e3c",
    "text": "essional pollsters and government researchers often  collect \ndata by using some combination of the preceding sampling methods. In a  multistage \nsample design, pollsters select a sample in different stages, and each stage might use \ndifferent methods of sampling, as in the following example.\nMAIN\nCENTER\nHeritage\nSchool\nPark St.\nNorth St.\n1st St.\n2nd St.\n3rd St.\n82nd St.\n52nd St.\n36th St.\n43rd St.\nA St.\nB St.\nC St.\nD St.\nE St.\nF St.\nWay St.\n4th St.\n5th St.\nMLK PKWY\n555-867-5309\n555-606-0842\n555-777-9311\nSimple Random Sample\nA sample of n subjects is selected \nso that every sample of the same \nsize n has the same chance of \nbeing selected.\nStrati\ufb01ed Sample\nSubdivide population into strata \n(groups) with the same \ncharacteristics, then randomly \nsample within those strata.\nCluster Sample\nPartition the population in clusters \n(groups), then randomly select \nsome clusters, then select all \nmembers of the selected clusters.\nSystematic Sample\nSelect every kth subject.\nConvenience Sample\nUse data that are very easy to get.\nMen\nWomen\n3rd\n6th\nFIGURE 1-3 Common Sampling Methods\nEXAMPLE 3  Multistage Sample Design\nThe U.S. government\u2019s unemployment statistics are based on surveys of house-\nholds. It is impractical to personally survey each household in a simple random \nsample, because they would be scattered all over the country. Instead, the U.S. \n Census Bureau and the Bureau of Labor Statistics collaborate to conduct a survey \ncalled the Current Population Survey. A recent survey incorporates a multistage \nsample design, roughly following these steps:\n \n1. The entire United States is partitioned into 2,007 di\ufb00erent regions called \nprimary sampling units (PSUs). The primary sampling units are metropolitan \nareas, large counties, or combinations of smaller counties. The 2,007 primary \nsampling units are then grouped into 824 di\ufb00erent strata.\nValue of a  \nStatistical Life\nThe value of a \nstatistical life \n(VSL) is a mea-\nsure routinely \ncalculated and \nused for making \ndecisions in \nfields such as \nmedicine, insurance, environ-\nmental health, and transportation \nsafety. As of this writing, the \nvalue of a statistical life is  \n$6.9 million.\nMany people oppose the con-\ncept of putting a value on a hu-\nman life, but the word statistical \nin the \u201cvalue of a statistical life\u201d \nis used to ensure that we don\u2019t \nequate it with the true worth \nof a human life. Some people \nlegitimately argue that every life \nis priceless, but others argue that \nthere are conditions in which it \nis impossible or impractical to \nsave every life, so a value must \nbe somehow assigned to a hu-\nman life in order that sound and \nrational decisions can be made. \nNot far from the author\u2019s home, a \nparkway was modified at a cost \nof about $3 million to improve \nsafety at a location where car \noccupants had previously died \nin traffic crashes. In the cost-\nbenefit analysis that led to this \nimprovement in safety, the value \nof a statistical life was surely \nconsidered.\ncontinued",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 43
  },
  {
    "child_id": "26589391-da3b-48d2-8fbc-76427f25f854",
    "parent_id": "3522f1a6-8282-49ae-9aff-7203fcd3ce15",
    "text": "28 \nCHAPTER 1 Introduction to Statistics\nPART 2\n  Beyond the Basics of Design of \nExperiments and Collecting Sample Data\nObservational Studies In Part 2 of this section, we discuss different types of ob-\nservational studies and different ways of designing experiments. The following defi-\nnitions identify the standard terminology used in professional journals for different \ntypes of observational studies. These definitions are illustrated in Figure 1-4.\n \n2. In each of the 824 di\ufb00erent strata, one of the primary sampling units is \nselected so that the probability of selection is proportional to the size of the \npopulation in each primary sampling unit.\n \n3. In each of the 824 selected primary sampling units, census data are used to \nidentify a census enumeration district, with each containing about 300 house-\nholds. Enumeration districts are then randomly selected.\n \n4. In each of the selected enumeration districts, clusters of about four addresses \n(contiguous whenever possible) are randomly selected.\n \n5. A responsible person in each of the 60,000 selected households is interviewed \nabout the employment status of each household member of age 16 or older.\nThis multistage sample design includes a combination of random, stratified, and \ncluster sampling at different stages. The end result is a very complicated sampling \ndesign, but it is much more practical, less expensive, and faster than using a simpler \ndesign, such as a simple random sample.\nWhen\nare the\nobservations\nmade?\nObservational Study:\nObserve and measure,\nbut do not modify.\nOne point in time\nRetrospective\n(or case-control) study:\nGo back in time to \ncollect data over some \npast period.\nCross-sectional \nstudy:\nData are\nmeasured at one \npoint in time.\nProspective\n(or longitudinal or cohort) study:\nGo forward in time and observe\ngroups sharing common factors,\nsuch as smokers and nonsmokers.\nForward in time\nPast period of time\nFIGURE 1-4 Types of Observational Studies\nDEFINITIONS\nIn a cross-sectional study, data are observed, measured, and collected at one \npoint in time, not over a period of time.\nIn a retrospective (or case-control) study, data are collected from a past time pe-\nriod by going back in time (through examination of records, interviews, and so on).\nIn a prospective (or longitudinal or cohort) study, data are collected in the future \nfrom groups that share common factors (such groups are called cohorts).\n\n1-3 Collecting Sample Data \n29\nExperiments In a study, confounding occurs when we can see some effect, but \nwe can\u2019t identify the specific factor that caused it, as in the ice cream and drowning \nobservational study in Example 2. See also the bad experimental design illustrated \nin  Figure 1-5(a), where confounding can occur when the treatment group of women \nshows strong positive results. Because the treatment group consists of women and the \nplacebo group consists of men, confounding has occurred because we cannot deter-\nmine whether the treatment or the gender of the subj",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 46
  },
  {
    "child_id": "07bf0017-be25-4e15-ac9d-793682006e7a",
    "parent_id": "3522f1a6-8282-49ae-9aff-7203fcd3ce15",
    "text": " can see some effect, but \nwe can\u2019t identify the specific factor that caused it, as in the ice cream and drowning \nobservational study in Example 2. See also the bad experimental design illustrated \nin  Figure 1-5(a), where confounding can occur when the treatment group of women \nshows strong positive results. Because the treatment group consists of women and the \nplacebo group consists of men, confounding has occurred because we cannot deter-\nmine whether the treatment or the gender of the subjects caused the positive results. \nThe Salk vaccine experiment in Example 1 illustrates one method for controlling the \neffect of the treatment variable: Use a completely randomized experimental design, \nwhereby randomness is used to assign subjects to the treatment group and the placebo \ngroup. A completely randomized experimental design is one of the following methods \nthat are used to control effects of variables.\nCompletely Randomized Experimental Design: Assign subjects to different treat-\nment groups through a process of random selection, as illustrated in Figure 1-5(b).\nTreatment Group: Women\nBad experimental design:\nTreat all women subjects\nand give the men a placebo.\n(Problem: We don\u2019t know if\ne\ufb00ects are due to sex or\nto treatment.)\nCompletely randomized\nexperimental design:\nUse randomness to\ndetermine who gets the\ntreatment and who gets\nthe placebo.\n  \nTreat all women subjects.\nPlacebo Group: Men\n  \nGive all men a placebo\nTreat these  randomly\nselected subjects and give\nthe others a placebo.\n(a)\n(b)\nBefore\nAfter\nAlex\nBob\nChris\nBlock of Women\nRandomized block design:\n1. Form a block of women\n \nand a block of men.\n2. Within each block,\n \nrandomly select subjects\n \nto be treated.\nMatched pairs design:\nGet measurements from the\nsame subjects before and after\nsome treatment.\n  \nTreat randomly selected\nwomen.\nBlock of Men\n  \nTreat randomly selected men.\n(c)\n(d)\nFIGURE 1-5 Designs of Experiments\n\n30 \nCHAPTER 1 Introduction to Statistics\nExperimental design requires much more thought and care than we can describe \nin this relatively brief section. Taking a complete course in the design of experiments \nis a good start in learning so much more about this important topic.\nRandomized Block Design: See Figure 1-5c. A block is a group of subjects that are \nsimilar, but blocks differ in ways that might affect the outcome of the experiment. Use \nthe following procedure, as illustrated in Figure 1-5(c):\n1. Form blocks (or groups) of subjects with similar characteristics.\n2. Randomly assign treatments to the subjects within each block.\nFor example, in designing an experiment to test the effectiveness of aspirin treatments \non heart disease, we might form a block of men and a block of women, because it is \nknown that the hearts of men and women can behave differently. By controlling for \ngender, this randomized block design eliminates gender as a possible source of con-\nfounding.\nA randomized block design uses the same basic idea as stratified sampling, but \nrandom",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 46
  },
  {
    "child_id": "c415a127-3746-4573-a4d2-7d35b97a5664",
    "parent_id": "3522f1a6-8282-49ae-9aff-7203fcd3ce15",
    "text": ". Randomly assign treatments to the subjects within each block.\nFor example, in designing an experiment to test the effectiveness of aspirin treatments \non heart disease, we might form a block of men and a block of women, because it is \nknown that the hearts of men and women can behave differently. By controlling for \ngender, this randomized block design eliminates gender as a possible source of con-\nfounding.\nA randomized block design uses the same basic idea as stratified sampling, but \nrandomized block designs are used when designing experiments, whereas stratified \nsampling is used for surveys.\nMatched Pairs Design: Compare two treatment groups (such as treatment and pla-\ncebo) by using subjects matched in pairs that are somehow related or have similar \ncharacteristics, as in the following cases.\n \n\u25a0Before/After: Matched pairs might consist of measurements from subjects before \nand after some treatment, as illustrated in Figure 1-5(d) on the preceding page. \nEach subject yields a \u201cbefore\u201d measurement and an \u201cafter\u201d measurement, and \neach before/after pair of measurements is a matched pair.\n \n\u25a0Twins: A test of Crest toothpaste used matched pairs of twins, where one twin \nused Crest and the other used another toothpaste.\nRigorously Controlled Design: Carefully assign subjects to different treatment \ngroups, so that those given each treatment are similar in the ways that are important to \nthe experiment. This can be extremely difficult to implement, and often we can never \nbe sure that we have accounted for all of the relevant factors.\nSampling Errors\nIn statistics, you could use a good sampling method and do everything correctly, and \nyet it is possible to get wrong results. No matter how well you plan and execute the \nsample collection process, there is likely to be some error in the results. The different \ntypes of sampling errors are described here.\nDEFINITIONS\nA sampling error (or random sampling error) occurs when the sample has been \nselected with a random method, but there is a discrepancy between a sample \nresult and the true population result; such an error results from chance sample \nfluctuations.\nA nonsampling error is the result of human error, including such factors as wrong \ndata entries, computing errors, questions with biased wording, false data provided \nby respondents, forming biased conclusions, or applying statistical methods that \nare not appropriate for the circumstances.\nA nonrandom sampling error is the result of using a sampling method that is not \nrandom, such as using a convenience sample or a voluntary response sample.\n\n1-3 Collecting Sample Data \n31\nStatistical Literacy and Critical Thinking\n1. Back Pain Treatment In a study designed to test the effectiveness of paracetamol (also \nknown as acetaminophen) as a treatment for lower back pain, 1643 patients were randomly \nassigned to one of three groups: (1) the 547 subjects in the placebo group were given pills \ncontaining no medication; (2) 550 subjects were in a grou",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 46
  },
  {
    "child_id": "422019a4-134e-4b51-9d00-a8e501359f45",
    "parent_id": "3522f1a6-8282-49ae-9aff-7203fcd3ce15",
    "text": "method that is not \nrandom, such as using a convenience sample or a voluntary response sample.\n\n1-3 Collecting Sample Data \n31\nStatistical Literacy and Critical Thinking\n1. Back Pain Treatment In a study designed to test the effectiveness of paracetamol (also \nknown as acetaminophen) as a treatment for lower back pain, 1643 patients were randomly \nassigned to one of three groups: (1) the 547 subjects in the placebo group were given pills \ncontaining no medication; (2) 550 subjects were in a group given pills with paracetamol taken \nat regular intervals; (3) 546 subjects were in a group given pills with paracetamol to be taken \nwhen needed for pain relief. (See \u201cEfficacy of Paracetamol for Acute Low-Back Pain,\u201d by \n Williams et al., Lancet.) Is this study an experiment or an observational study? Explain.\n2. Blinding What does it mean when we say that the study cited in Exercise 1 was \u201cdouble-blind\u201d?\n3. Replication In what specific way was replication applied in the study cited in Exercise 1?\n4. Sampling Method The patients included in the study cited in Exercise 1 were those \u201cwho \nsought care for low-back pain directly or in response to a community advertisement.\u201d What \ntype of sampling best describes the way in which the 1634 subjects were chosen: simple ran-\ndom sample, systematic sample, convenience sample, stratified sample, cluster sample? Does \nthe method of sampling appear to adversely affect the quality of the results?\nExercises 5\u20138 refer to the study of an association between which ear is used for cell phone \ncalls and whether the subject is left-handed or right-handed. The study is reported in \u201cHemi-\nspheric Dominance and Cell Phone Use,\u201d by Seidman et al., JAMA Otolaryngology\u2014Head \n& Neck Surgery, Vol. 139, No. 5. The study began with a survey e-mailed to 5000 people \nbelonging to an otology online group, and 717 surveys were returned. (Otology relates to the \near and hearing.)\n5. Sampling Method What type of sampling best describes the way in which the 717 subjects \nwere chosen: simple random sample, systematic sample, convenience sample, stratified sample, \ncluster sample? Does the method of sampling appear to adversely affect the quality of the results?\n6. Experiment or Observational Study Is the study an experiment or an observational \nstudy? Explain.\n7. Response Rate What percent of the 5000 surveys were returned? Does that response rate \nappear to be low? In general, what is a problem with a very low response rate?\n8. Sampling Method Assume that the population consists of all students currently in your \nstatistics class. Describe how to obtain a sample of six students so that the result is a sample of \nthe given type.\na. Simple random sample\nb. Systematic sample\nc. Stratified sample\nd. Cluster sample\nIn Exercises 9\u201320, identify which of these types of sampling is used: random, systematic, \nconvenience, stratified, or cluster.\n9. Cormorant Density Cormorant bird population densities were studied by using the \u201cline \ntransect method\u201d",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 46
  },
  {
    "child_id": "43548424-9c8c-4e80-9a21-5a66c8a78a47",
    "parent_id": "3522f1a6-8282-49ae-9aff-7203fcd3ce15",
    "text": " that the population consists of all students currently in your \nstatistics class. Describe how to obtain a sample of six students so that the result is a sample of \nthe given type.\na. Simple random sample\nb. Systematic sample\nc. Stratified sample\nd. Cluster sample\nIn Exercises 9\u201320, identify which of these types of sampling is used: random, systematic, \nconvenience, stratified, or cluster.\n9. Cormorant Density Cormorant bird population densities were studied by using the \u201cline \ntransect method\u201d with aircraft observers flying along the shoreline of Lake Huron and collecting \nsample data at intervals of every 20 km (based on data from Journal of Great Lakes Research).\n1-3 Basic Skills and Concepts",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 46
  },
  {
    "child_id": "ecd9dc21-d073-49e8-8715-d871ec7fce9f",
    "parent_id": "7937e6bd-c4f4-419d-8b00-84f9d3424211",
    "text": "32 \nCHAPTER 1 Introduction to Statistics\n10. Sexuality of Women The sexuality of women was discussed in Shere Hite\u2019s book Women \nand Love: A Cultural Revolution. Her conclusions were based on sample data that consisted of \n4500 mailed responses from 100,000 questionnaires that were sent to women.\n11. Acupuncture Study In a study of treatments for back pain, 641 subjects were randomly \nassigned to the four different treatment groups of individualized acupuncture, standardized \nacupuncture, simulated acupuncture, and usual care (based on data from \u201cA Randomized Trial \nComparing Acupuncture, Simulated Acupuncture, and Usual Care for Chronic Low Back \nPain,\u201d by Cherkin et al., Archives of Internal Medicine, Vol. 169, No. 9).\n12. Class Survey A professor surveys her statistics class by identifying groups of males and \nfemales, then randomly selecting five students from each of those two groups.\n13. Class Survey A professor conducts a survey by randomly selecting three different classes \nand surveying all of the students as they left those classes.\n14. Exercise Program In a study designed to test the effectiveness of exercise in lowering \nblood pressure, 532 subjects were randomly assigned to these two different groups: (1) group \ngiven regular exercise programs; (2) group given no exercise programs.\n15. Hospital Survey A researcher collects sample data by randomly selecting 20 hospital \n employees from each of the categories of physician, nurse, and administrator.\n16. Deforestation Rates Satellites are used to collect sample data for estimating deforesta-\ntion rates. The Forest Resources Assessment of the United Nations (UN) Food and Agriculture \nOrganization uses a method of selecting a sample of a 10-km-wide square at every 1\u00b0 intersec-\ntion of latitude and longitude.\n17. Testing Lipitor In a clinical trial of the cholesterol drug Lipitor (atorvastatin), subjects \nwere partitioned into groups given a placebo or Lipitor doses of 10 mg, 20 mg, 40 mg, or \n80\u00a0mg. The subjects were randomly assigned to the different treatment groups (based on data \nfrom Pfizer, Inc.).\n18. Blood Drives A researcher for the American Red Cross randomly selected five different \nblood donor sites and then interviewed all blood donors as they left the sites.\n19. Smoking Prevalence A medical student collects sample data on the prevalence of smok-\ning among adults by surveying all of the patients she encounters in the clinic where she is doing \nher residency.\n20. Health Survey The Texas Health and Human Services Commission obtains an alphabeti-\ncal listing of all 20,126,759 adults and constructs a sample by selecting every 10,000th name \non that list.\nCritical Thinking: What\u2019s Wrong? In Exercises 21\u201328, determine whether the study is \nan experiment or an observational study, and then identify a major problem with the study.\n21. Online Medical Information In a survey conducted by USA Today, 1072 Internet users \nchose to respond to this question posted on the USA Today electronic ",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 50
  },
  {
    "child_id": "bcc25c63-341b-4348-8c97-7c70e3f7d4e9",
    "parent_id": "7937e6bd-c4f4-419d-8b00-84f9d3424211",
    "text": "ealth and Human Services Commission obtains an alphabeti-\ncal listing of all 20,126,759 adults and constructs a sample by selecting every 10,000th name \non that list.\nCritical Thinking: What\u2019s Wrong? In Exercises 21\u201328, determine whether the study is \nan experiment or an observational study, and then identify a major problem with the study.\n21. Online Medical Information In a survey conducted by USA Today, 1072 Internet users \nchose to respond to this question posted on the USA Today electronic edition: \u201cHow often do \nyou seek medical information online?\u201d 38% of the respondents said \u201cfrequently.\u201d\n22. Physicians\u2019 Health Study The Physicians\u2019 Health Study involved 22,071 male physi-\ncians. Based on random selections, 11,037 of them were treated with aspirin and the other \n11,034 were given placebos. The study was stopped early because it became clear that aspirin \nreduced the risk of myocardial infarctions by a substantial amount.\n23. Drinking and Driving A researcher for a consortium of insurance companies plans to \ntest for the effects of drinking on driving ability by randomly selecting 1000 drivers and then \nrandomly assigning them to two groups: One group of 500 will drive in New York City after no \nalcohol consumption, and the second group will drive in New York City after consuming three \nshots of Jim Beam bourbon whiskey.\n\n1-3 Collecting Sample Data \n33\n24. Blood Pressure A medical researcher tested for a difference in systolic blood pressure \nlevels between male and female students who are 20 years of age. She randomly selected four \nmales and four females for her study.\n25. Salt Deprivation In a program designed to investigate the effects of salt deprivation in \ndiets, the original plan was to use a sample of 500 adults randomly selected throughout the \ncountry. The program managers know that they would get a biased sample if they limit their \nstudy to adults in New York City, so they planned to compensate for that bias by using a larger \nsample of 2000 adults in New York City.\n26. Atkins Weight Loss Program An independent researcher tested the effectiveness of the \nAtkins weight loss program by randomly selecting 1000 subjects using that program. Each of \nthe subjects was called to report his or her weight before the diet and after the diet.\n27. Crime Research A researcher has created a brief survey to be given to 2000 adults ran-\ndomly selected from the U.S. population. Here are her first two questions: (1) Have you ever \nbeen the victim of a felony crime? (2) Have you ever been convicted of a felony?\n28. Medications The Pharmaceutical Research and Manufacturers of America wants infor-\nmation about the consumption of various medications. An independent researcher conducts a \nsurvey by mailing 10,000 questionnaires to randomly selected adults in the United States, and \nshe receives 152 responses.\nIn Exercises 29\u201332, indicate whether the observational study used is cross-sectional, \n retrospective, or prospective.\n29. Nurses\u2019 Health Study",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 50
  },
  {
    "child_id": "7a8e8fc4-ecc5-4321-bde3-b109525e7aae",
    "parent_id": "7937e6bd-c4f4-419d-8b00-84f9d3424211",
    "text": "ony crime? (2) Have you ever been convicted of a felony?\n28. Medications The Pharmaceutical Research and Manufacturers of America wants infor-\nmation about the consumption of various medications. An independent researcher conducts a \nsurvey by mailing 10,000 questionnaires to randomly selected adults in the United States, and \nshe receives 152 responses.\nIn Exercises 29\u201332, indicate whether the observational study used is cross-sectional, \n retrospective, or prospective.\n29. Nurses\u2019 Health Study II Phase II of the Nurses\u2019 Health Study was started in 1989 with \n116,000 female registered nurses. The study is ongoing.\n30. Heart Health Study Samples of subjects with and without heart disease were selected, \nthen researchers looked back in time to determine whether they took aspirin on a regular basis.\n31. Marijuana Study Researchers from the National Institutes of Health want to determine the \ncurrent rates of marijuana consumption among adults living in states that have legalized the use \nof marijuana. They conduct a survey of 500 adults in those states.\n32. Framingham Heart Study The Framingham Heart Study was started in 1948 and is ongo-\ning. Its focus is on heart disease.\nIn Exercises 33\u201336, identify which of these designs is most appropriate for the given \nexperiment: completely randomized design, randomized block design, or matched pairs \ndesign.\n33. Lunesta Lunesta (eszopiclone) is a drug designed to treat insomnia. In a clinical trial of \nLunesta, amounts of sleep each night are measured before and after subjects have been treated \nwith the drug.\n34. Lipitor A clinical trial of Lipitor treatments is being planned to determine whether its \neffects on diastolic blood pressure are different for men and women.\n35. West Nile Vaccine Currently, there is no approved vaccine for the prevention of West Nile \nvirus infection. A clinical trial of a possible vaccine is being planned to include subjects treated \nwith the vaccine while other subjects are given a placebo.\n36. HIV Vaccine The HIV Trials Network is conducting a study to test the effectiveness of two \ndifferent experimental HIV vaccines. Subjects will consist of 80 pairs of twins. For each pair \nof twins, one of the subjects will be treated with the DNA vaccine and the other twin will be \ntreated with the adenoviral vector vaccine.\n1-3 Beyond the Basics\n\n34 \nCHAPTER 1 Introduction to Statistics\n37. Sample Design Literacy In \u201cCardiovascular Effects of Intravenous Triiodothyronine in \nPatients Undergoing Coronary Artery Bypass Graft Surgery\u201d (Journal of the American Medi-\ncal Association, Vol. 275, No. 9), the authors explain that patients were assigned to one of \nthree groups: (1) a group treated with triiodothyronine, (2) a group treated with normal saline \nbolus and dopamine, and (3) a placebo group given normal saline. The authors summarize the \nsample design as a \u201cprospective, randomized, double-blind, placebo-controlled trial.\u201d Describe \nthe meaning of each of those terms in the context of",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 50
  },
  {
    "child_id": "ca2fc2b6-08d6-4944-8365-41bf9cc27ad6",
    "parent_id": "7937e6bd-c4f4-419d-8b00-84f9d3424211",
    "text": "Coronary Artery Bypass Graft Surgery\u201d (Journal of the American Medi-\ncal Association, Vol. 275, No. 9), the authors explain that patients were assigned to one of \nthree groups: (1) a group treated with triiodothyronine, (2) a group treated with normal saline \nbolus and dopamine, and (3) a placebo group given normal saline. The authors summarize the \nsample design as a \u201cprospective, randomized, double-blind, placebo-controlled trial.\u201d Describe \nthe meaning of each of those terms in the context of this study.\n38. Simple Random Sample vs. Random Sample Refer to the definition of simple random \nsample in this section and the accompanying definition of random sample enclosed within pa-\nrentheses. Determine whether each of the following is a simple random sample and a random \nsample.\na. A statistics class with 36 students is arranged so that there are 6 rows with 6 students in each \nrow, and the rows are numbered from 1 through 6. A die is rolled and a sample consists of all \nstudents in the row corresponding to the outcome of the die.\nb. For the same class described in part (a), the 36 student names are written on 36 individual \nindex cards. The cards are shuffled and six names are drawn from the top.\nc. For the same class described in part (a), the six youngest students are selected.\n1. Clinical Study When conducting a clinical study, it is common to maintain the privacy of \nsubjects by assigning them number codes that will be used instead of their actual names. Sev-\neral subjects are assigned these codes: 1, 2, 3, 5, 6, 9, 11, 13, 16, 20, 22, 26, 32, and 40. Does it \nmake sense to calculate the average (mean) of these numbers?\n2. Clinical Study Which of the following best describes the level of measurement of the data \nlisted in Exercise 1: nominal, ordinal, interval, ratio?\n3. Waist Data Set 1 \u201cBody Data\u201d includes measurements of waist circumferences. Are waist \ncircumferences values that are discrete or continuous?\n4. Waist Are the waist circumferences described in Exercise 3 quantitative data or categorical \ndata?\n5. Waist Which of the following best describes the level of measurement of the waist \n circumferences described in Exercise 3: nominal, ordinal, interval, ratio?\n6. Waist If you construct a sample by selecting every sixth waist circumference from those \nlisted in Data Set 1 \u201cBody Data,\u201d is the result a simple random sample of the listed waist \n circumferences?\n7. Gallup Poll In a recent Gallup poll, pollsters randomly selected adults and asked them \nwhether they smoke. Because the subjects agreed to respond, is the sample a voluntary re-\nsponse sample?\n8. Parameter and Statistic In a recent Gallup poll, pollsters randomly selected adults and \nasked them whether they smoke. Among the adults who responded to the survey question, 21% \nsaid that they did smoke. Is that value of 21% an example of a statistic or a parameter?\n9. Observational Study or Experiment Are the data described in Exercise 8 the result of an \nobservational study or an e",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 50
  },
  {
    "child_id": "7ce09388-4141-46ef-bcaf-5e88d2ca8152",
    "parent_id": "7937e6bd-c4f4-419d-8b00-84f9d3424211",
    "text": "em \nwhether they smoke. Because the subjects agreed to respond, is the sample a voluntary re-\nsponse sample?\n8. Parameter and Statistic In a recent Gallup poll, pollsters randomly selected adults and \nasked them whether they smoke. Among the adults who responded to the survey question, 21% \nsaid that they did smoke. Is that value of 21% an example of a statistic or a parameter?\n9. Observational Study or Experiment Are the data described in Exercise 8 the result of an \nobservational study or an experiment?\n10. Statistical Significance and Practical Significance True or false: If data lead to a con-\nclusion with statistical significance, then the results also have practical significance.\nChapter Quick Quiz",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 50
  },
  {
    "child_id": "50849d59-bd25-4b54-87b9-4c069ddd9554",
    "parent_id": "97fd2979-b5c9-4de9-a1bb-7e83c9695d99",
    "text": "1. Hospitals Currently, there are 5723 registered hospitals in the United States.\na. Are the numbers of hospitals in different states discrete or continuous?\nb. What is the level of measurement for the numbers of hospitals in different years? (nominal, \nordinal, interval, ratio)\nc. If a survey is conducted by randomly selecting 10 patients in every hospital, what type of \nsampling is used? (random, systematic, convenience, stratified, cluster)\nd. If a survey is conducted by randomly selecting 20 hospitals and interviewing all of the mem-\nbers of each board of directors, what type of sampling is used? (random, systematic, conve-\nnience, stratified, cluster)\ne. What is wrong with surveying patient satisfaction by mailing questionnaires to 10,000 ran-\ndomly selected patients?\n2. What\u2019s Wrong? A survey sponsored by the American Laser Centers included responses \nfrom 575 adults, and 24% of the respondents said that the face is their favorite body part (based \non data from USA Today). What is wrong with this survey?\n3. What\u2019s Wrong? A survey included 2028 responses from Internet users who decided to \nrespond to a question posted by AOL. Here is the question: \u201cHow often do you drink soda?\u201d \nAmong the respondents, 33% said that they drink soda almost every day. What is wrong with \nthis survey?\n4. Sampling Seventy-two percent of Americans squeeze their toothpaste tube from the top. \nThis and other not-so-serious findings are included in The First Really Important Survey of \nAmerican Habits. Those results are based on 7000 responses from the 25,000 questionnaires \nthat were mailed.\na. What is wrong with this survey?\nb. As stated, the value of 72% refers to all Americans, so is that 72% a statistic or a parameter? \nExplain.\nc. Does the survey constitute an observational study or an experiment?\n5. Percentages\na. The labels on U-Turn protein energy bars include the statement that these bars contain \n\u201c125% less fat than the leading chocolate candy brands\u201d (based on data from Consumer \nReports magazine). What is wrong with that claim?\nb. In a Pew Research Center poll on driving, 58% of the 1182 respondents said that they like to \ndrive. What is the actual number of respondents who said that they like to drive?\nc. In a Pew Research Center poll on driving, 331 of the 1182 respondents said that driving is a \nchore. What percentage of respondents said that driving is a chore?\n6. Simple Random Sample Which of the following is>are simple random samples?\na. As Lipitor pills are being manufactured, a quality control plan is to select every 500th pill \nand test it to confirm that it contains 80 mg of atorvastatin.\nb. To test for a gender difference in the way that men and women make online purchases, \n Gallup surveys 500 randomly selected men and 500 randomly selected women.\nc. A list of all 10,877 adults in Trinity County, California, is obtained; the list is numbered from \n1 to 10,877; and then a computer is used to randomly generate 250 different numbers between \n1 a",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 53
  },
  {
    "child_id": "290330ea-13fb-477f-9149-f99940b23d67",
    "parent_id": "97fd2979-b5c9-4de9-a1bb-7e83c9695d99",
    "text": " being manufactured, a quality control plan is to select every 500th pill \nand test it to confirm that it contains 80 mg of atorvastatin.\nb. To test for a gender difference in the way that men and women make online purchases, \n Gallup surveys 500 randomly selected men and 500 randomly selected women.\nc. A list of all 10,877 adults in Trinity County, California, is obtained; the list is numbered from \n1 to 10,877; and then a computer is used to randomly generate 250 different numbers between \n1 and 10,877. The sample consists of the adults corresponding to the selected numbers.\nReview Exercises\nCHAPTER 1 Review Exercises \n35\n\n36 \nCHAPTER 1 Introduction to Statistics\n7. Statistical Significance and Practical Significance The Gengene Research Group has \ndeveloped a procedure designed to increase the likelihood that a baby will be born a girl. In a \nclinical trial of their procedure, 112 girls were born to 200 different couples. If the method has \nno effect, there is about a 4% chance that such extreme results would occur. Does the procedure \nappear to have statistical significance? Does the procedure appear to have practical signifi-\ncance?\n8. Marijuana Survey In a recent Pew poll of 1500 adults, 52% of the respondents said that the \nuse of marijuana should not be made legal. In the same poll, 23% of the respondents said that \nthe use of marijuana for medical purposes should not be legal.\na. The sample of 1500 adults was selected from the population of all adults in the United \nStates. The method used to select the sample was equivalent to placing the names of all adults \nin a giant bowl, mixing the names, and then drawing 1500 names. What type of sampling is \nthis? (random, systematic, convenience, stratified, cluster)\nb. If the sampling method consisted of a random selection of 30 adults from each of the 50 states, \nwhat type of sampling would this be? (random, systematic, convenience, stratified, cluster)\nc. What is the level of measurement of the responses of yes, no, don\u2019t know, and refused to \nrespond?\nd. Is the given value of 52% a statistic or a parameter? Why?\ne. What would be wrong with conducting the survey by mailing a questionnaire that respon-\ndents could complete and mail back?\n9. Marijuana Survey Identify the type of sampling (random, systematic, convenience, strati-\nfied, cluster) used when a sample of the 1500 survey responses is obtained as described. Then \ndetermine whether the sampling scheme is likely to result in a sample that is representative of \nthe population of all adults.\na. A complete list of all 241,472,385 adults in the United States is compiled, and every \n150,000th name is selected until the sample size of 1500 is reached.\nb. A complete list of all 241,472,385 adults in the United States is compiled, and 1500 adults \nare randomly selected from that list.\nc. The United States is partitioned into regions with 100 adults in each region. Then 15 of those \nregions are randomly selected, and all 100 people in each of thos",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 53
  },
  {
    "child_id": "1164d1b2-f41e-4908-81a2-9c0f6c5ed99b",
    "parent_id": "97fd2979-b5c9-4de9-a1bb-7e83c9695d99",
    "text": "entative of \nthe population of all adults.\na. A complete list of all 241,472,385 adults in the United States is compiled, and every \n150,000th name is selected until the sample size of 1500 is reached.\nb. A complete list of all 241,472,385 adults in the United States is compiled, and 1500 adults \nare randomly selected from that list.\nc. The United States is partitioned into regions with 100 adults in each region. Then 15 of those \nregions are randomly selected, and all 100 people in each of those regions are surveyed.\nd. The United States is partitioned into 150 regions with approximately the same number of \nadults in each region; then 10 people are randomly selected from each of the 150 regions.\ne. A survey is mailed to 10,000 randomly selected adults, and the 1500 responses are used.\n10. Marijuana Survey Exercise 8 referred to a Pew poll of 1500 adults, and 52% of the \n respondents said that the use of marijuana should not be made legal.\na. Among the 1500 adults who responded, what is the number of respondents who said that the \nuse of marijuana should not be made legal?\nb. In the same poll of 1500 adults, 345 of the respondents said that the use of marijuana for \nmedical purposes should not be legal. What is the percentage of respondents who said that the \nuse of marijuana for medical purposes should not be legal?\nc. In this survey of 1500 adults, 727 are men and 773 are women. Find the percentage of \n respondents who are men, and then find the percentage of respondents who are women.\nd. Does the difference between the two percentages from part (c) appear to have statistical \nsignificance?\ne. Does the difference between the two percentages from part (c) appear to have practical \n significance?\n\nFor Chapter 2 through Chapter 14, the Cumulative Review Exercises include topics from \npreceding chapters. For this chapter, we present a few calculator warm-up exercises, with \nexpressions similar to those found throughout this book. Use your calculator to find the \nindicated values.\n1. Birth Weights Listed below are the weights (grams) of newborn babies from Albany Medi-\ncal Center Hospital. What value is obtained when those weights are added and the total is di-\nvided by the number of weights? (This result, called the mean, is discussed in Chapter 3.) What \nis notable about these values, and what does it tell us about how the weights were measured?\n3600 1700 4000 3900 3100 3800\n2200 3000\n2. Six Children Jule Cole is a founder of Mabel\u2019s Labels, and she is the mother of six chil-\ndren. The probability that six randomly selected children are all girls is found by evaluating \n0.56. Find that value.\n3. Tallest Person Robert Wadlow (1918\u20131940) is the tallest known person to have lived. The \nexpression below converts his height of 272 cm to a standardized score. Find this value and \nround the result to two decimal places. Such standardized scores are considered to be signifi-\ncantly high if they are greater than 2 or 3. Is the result significantly high?\n27",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 53
  },
  {
    "child_id": "5ed4a872-6c03-4bad-ae84-ed7e3338e10d",
    "parent_id": "97fd2979-b5c9-4de9-a1bb-7e83c9695d99",
    "text": "mother of six chil-\ndren. The probability that six randomly selected children are all girls is found by evaluating \n0.56. Find that value.\n3. Tallest Person Robert Wadlow (1918\u20131940) is the tallest known person to have lived. The \nexpression below converts his height of 272 cm to a standardized score. Find this value and \nround the result to two decimal places. Such standardized scores are considered to be signifi-\ncantly high if they are greater than 2 or 3. Is the result significantly high?\n272 - 176\n6\n4. Body Temperature The given expression is used for determining the likelihood that the av-\nerage (mean) human body temperature is different from the value of 98.6\u00b0F that is commonly \nused. Find the given value and round the result to two decimal places.\n98.2 - 98.6\n0.62\n2106\n5. Determining Sample Size The given expression is used to determine the size of the sam-\nple necessary to estimate the proportion of college students who have the profound wisdom to \ntake a statistics course. Find the value and round the result to the nearest whole number.\n1.962 # 0.25\n0.032\n6. Standard Deviation One way to get a very rough approximation of the value of a standard \ndeviation of sample data is to find the range, then divide it by 4. The range is the difference be-\ntween the highest sample value and the lowest sample value. In using this approach, what value \nis obtained from the sample data listed in Exercise 1 \u201cBirth Weights\u201d?\n7. Standard Deviation The standard deviation is an extremely important concept introduced \nin Chapter 3. Using the sample data from Exercise 1 \u201cBirth Weights,\u201d part of the calculation of \nthe standard deviation is shown in the expression below. Evaluate this expression. (Fortunately, \ncalculators and software are designed to automatically execute such expressions, so our future \nwork with standard deviations will not be burdened with cumbersome calculations.)\n13600 - 3162.52 2\n7\n8. Standard Deviation The given expression is used to compute the standard deviation of \nthree randomly selected body temperatures. Perform the calculation and round the result to two \ndecimal places.\nB\n198.4 - 98.62 2 + 198.6 - 98.62 2 + 198.8 - 98.62 2\n3 - 1\nCumulative Review Exercises\nCHAPTER 1 Cumulative Review Exercises \n37",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 53
  },
  {
    "child_id": "a380d0f8-b205-47b6-bec4-e86d9845b652",
    "parent_id": "70bede9c-4c35-4604-b953-e036c954ede5",
    "text": "38 \nCHAPTER 1 Introduction to Statistics\nScientific Notation. In Exercises 9\u201312, the given expressions are designed to yield re-\nsults expressed in a form of scientific notation. For example, the calculator-displayed re-\nsult of 1.23E5 can be expressed as 123,000, and the result of 1.23E-4 can be expressed as \n0.000123. Perform the indicated operation and express the result as an ordinary number \nthat is not in scientific notation.\n9. 0.48  10. 911  11. 614  12. 0.312\nTechnology Project\nMissing Data The focus of this project is to download a data set and manipulate it to work \naround missing data.\na. First, download Data Set 2 \u201cBody Temperatures\u201d in Appendix B from www.TriolaStats.com. \nChoose the download format that matches your technology. (If you have no preferred technol-\nogy, you can download a free copy of Statdisk (from www.statdisk.org), which is designed for \nthis book and contains all Appendix B data sets.)\nb. Some statistical procedures, such as those involved with correlation and regression (dis-\ncussed in later chapters) require data that consist of matched pairs of values, and those proce-\ndures ignore pairs in which at least one of the data values in a matched pair is missing. Assume \nthat we want to conduct analyses for correlation and regression on the last two columns of \ndata in Data Set 2: body temperatures measured at 8 AM on day 2 and again at 12 AM on day \n2. For those last two columns, identify the rows with at least one missing value. Note that in \nsome technologies, such as TI-83>84 Plus calculators, missing data must be represented by a \nconstant such as -9 or 999.\nc. Here are two different strategies for reconfiguring the data set to work around the missing \ndata in the last two columns (assuming that we need matched pairs of data with no missing \nvalues):\ni. Manual Deletion Highlight rows with at least one missing value in the last two columns, \nthen delete those rows. This can be tedious if there are many rows with missing data and those \nrows are interspersed throughout instead of being adjacent rows.\nii. Sort Most technologies have a Sort feature that allows you to rearrange all rows using one \nparticular column as the basis for sorting (TI-83>84 Plus calculators do not have this type of sort \nfeature). The result is that all rows remain the same but they are in a different order. First use \nthe technology\u2019s Sort feature to rearrange all rows using the \u201c8 AM day 2\u201d column as the basis \nfor sorting (so that all missing values in the \u201c8 AM day 2\u201d column are at the beginning); then \nhighlight and delete all of those rows with missing values in the \u201c8 AM day 2\u201d column. Next, \nuse the technology\u2019s Sort feature to rearrange all rows using the \u201c12 AM day 2\u201d column as the \nbasis for sorting (so that all missing values in the \u201c12 AM day 2\u201d column are at the beginning); \nthen highlight and delete all of those rows with missing values in the \u201c12 AM day 2\u201d column. \nThe remaining rows will include matched pairs of body tempera",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 56
  },
  {
    "child_id": "b0a7c1b8-94b4-46b8-a675-573b230568b2",
    "parent_id": "70bede9c-4c35-4604-b953-e036c954ede5",
    "text": "s in the \u201c8 AM day 2\u201d column are at the beginning); then \nhighlight and delete all of those rows with missing values in the \u201c8 AM day 2\u201d column. Next, \nuse the technology\u2019s Sort feature to rearrange all rows using the \u201c12 AM day 2\u201d column as the \nbasis for sorting (so that all missing values in the \u201c12 AM day 2\u201d column are at the beginning); \nthen highlight and delete all of those rows with missing values in the \u201c12 AM day 2\u201d column. \nThe remaining rows will include matched pairs of body temperatures, and those rows will be \nsuitable for analyses such as correlation and regression. Print the resulting reconfigured data set.\n\nCooperative Group Activities\n1. In-class activity Working in groups of three or four, design an experiment to determine \nwhether pulse rates of college students are the same while the students are standing and sitting. \nConduct the experiment and collect the data. Save the data so that they can be analyzed with \nmethods presented in the following chapters.\n2. In-class activity Working in groups of three or four, construct a brief survey that includes \nonly a few questions that can be quickly asked. Include some objective questions along with \nsome that are biased, such as the first question below.\n\u2022\u2002 Should\u2002your\u2002college\u2002force\u2002all\u2002students\u2002to\u2002pay\u2002a\u2002$100\u2002activity\u2002fee?\n\u2022\u2002 Should\u2002your\u2002college\u2002fund\u2002activities\u2002by\u2002collecting\u2002a\u2002$100\u2002fee?\n Conduct the survey and try to detect the effect that the biased wording has on the  responses.\n3. In-class activity Identify problems with a mailing from Consumer Reports magazine that \nincluded an annual questionnaire about cars and other consumer products. Also included were \na request for a voluntary contribution of money and a voting ballot for the board of directors. \nResponses were to be mailed back in envelopes that required postage stamps.\n4. Out-of-class activity Find a report of a survey that used a voluntary response sample. De-\nscribe how it is quite possible that the results do not accurately reflect the population.\n5. Out-of-class activity Find a professional journal with an article that includes a statistical \nanalysis of an experiment. Describe and comment on the design of the experiment. Identify \none particular issue addressed by the study, and determine whether the results were found to \nbe statistically significant. Determine whether those same results have practical significance.\nFROM DATA TO DECISION\nCritical Thinking:  \nDo Male Symphony Conductors Really Live Longer?\nSeveral media reports made the interesting observation that \nmale symphony conductors live longer than other males. \nJohn Amaral wrote in Awaken that orchestra conductors \n\u201clive longer than almost any other group of people by three \nto seven years.\u201d Robert Levine wrote in Polyphonic.org that \nthey live longer \u201cbecause they stand up while working.\u201d \nSome provided other explanations for this phenomenon, \noften referring to cardiovascular activity. But do male sym-\nphony conductors really live longer than other group",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 56
  },
  {
    "child_id": "31e9d349-b759-4683-b9d4-bda3d16a1cfc",
    "parent_id": "70bede9c-4c35-4604-b953-e036c954ede5",
    "text": "ts made the interesting observation that \nmale symphony conductors live longer than other males. \nJohn Amaral wrote in Awaken that orchestra conductors \n\u201clive longer than almost any other group of people by three \nto seven years.\u201d Robert Levine wrote in Polyphonic.org that \nthey live longer \u201cbecause they stand up while working.\u201d \nSome provided other explanations for this phenomenon, \noften referring to cardiovascular activity. But do male sym-\nphony conductors really live longer than other groups of \nmales? The Internet can be researched for possible answers. \nLet\u2019s also consider the following.\nAnalysis\n1. Consider the statement that \u201cmale symphony conductors \nlive longer.\u201d Identify the specific group that they supposedly \nlive longer than. Does that other group consist of males ran-\ndomly selected from the general population?\n2. It is reasonable to assume that males do not become sym-\nphony conductors until they have reached at least the age \nof 40 years. When comparing life spans of male conduc-\ntors, should we compare them to other males in the general \n population, or should we compare them to other males who \nlived until at least 40 years of age? Explain.\n3. Without any disabilities, males qualify for Medicare if \nthey are 65 or older and meet a few other requirements. If \nwe compare life spans of males on Medicare to life spans \nof males randomly selected from the general population, \nwhy would we find that males on Medicare have longer life \nspans?\n4. Explain in detail how to design a study for collecting data \nto determine whether it is misleading to state that male sym-\nphony conductors live longer. Should the study be an experi-\nment or an observational study?\nCHAPTER 1 Cooperative Group Activities \n39\n\n40\nFrequency Distributions \nfor Organizing and \nSummarizing Data\nHistograms\nGraphs That Enlighten \nand Graphs That \nDeceive\nScatterplots, \nCorrelation, and \nRegression\n2-1\n2-2\n2-3\n2-4\nDoes Exposure to Lead Affect IQ Scores?\nCHAPTER \nPROBLEM\nExploring Data with \nTables and Graphs\nData Set 8 \u201cIQ and Lead\u201d in Appendix B includes full IQ scores \nfrom three groups of children who lived near a lead smelter. \nThe children in Group 1 had low levels of measured lead in \ntheir blood (with blood levels less than 40 micrograms>100 mL \nin each of two years). Group 2 had medium levels of measured \nlead in their blood (with blood levels of at least  \n40 micrograms/100 mL in exactly one of two years). Group 3 \nhad high levels of measured lead in their blood (with blood lev-\nels of at least 40 micrograms>100 mL in each of two years).\nLet\u2019s consider the measured full IQ scores from Group 1  \n(low lead level) and Group 3 (high lead level), as listed in \nTable 2-1. It is an exceptionally rare person who can look \nat both lists of IQ scores and form meaningful conclusions. \nAlmost all of us must work at describing, exploring, and \n2\n\ncomparing the two sets of data. In this chapter we pres-\nent methods that focus on summarizing the data and using \ngraphs that",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 56
  },
  {
    "child_id": "b808e399-7dac-4741-9feb-81fa5f26ca15",
    "parent_id": "70bede9c-4c35-4604-b953-e036c954ede5",
    "text": " blood lev-\nels of at least 40 micrograms>100 mL in each of two years).\nLet\u2019s consider the measured full IQ scores from Group 1  \n(low lead level) and Group 3 (high lead level), as listed in \nTable 2-1. It is an exceptionally rare person who can look \nat both lists of IQ scores and form meaningful conclusions. \nAlmost all of us must work at describing, exploring, and \n2\n\ncomparing the two sets of data. In this chapter we pres-\nent methods that focus on summarizing the data and using \ngraphs that enable us to understand important characteris-\ntics of the data, especially the distribution of the data. These \nmethods will help us compare the two sets of data so that we \ncan determine whether the IQ scores of the low lead group \nare somehow different from the IQ scores of the high lead \ngroup. Such comparisons will be helpful as we try to address \nthis important and key issue: Does exposure to lead have an \neffect on IQ score?\nThis chapter and the following chapter focus on important characteristics of data, \nincluding the following:\nCharacteristics of Data\n1. Center: A representative value that shows us where the middle of the data set is \nlocated.\n2. Variation: A measure of the amount that the data values vary.\n3. Distribution: The nature or shape of the spread of the data over the range of values \n(such as bell-shaped).\n4. Outliers: Sample values that lie very far away from the vast majority of the other \nsample values. (Later, a more objective definition of \u201coutlier\u201d will be given.)\n5. Time: Any change in the characteristics of the data over time.\nThis chapter provides tools that enable us to gain insight into data by organizing, sum-\nmarizing, and representing them in ways that enable us to see important characteristics \nof the data. Here are the chapter objectives:\nFrequency Distributions for Organizing and Summarizing Data\n\u2022 Develop an ability to summarize data in the format of a frequency distribution and a \nrelative frequency distribution.\n\u2022 For a frequency distribution, identify values of class width, class midpoint, class lim-\nits, and class boundaries.\n2-1\nChapter Objectives \n41\nCHAPTER OBJECTIVES\n>>>\nTABLE 2-1 Full IQ Scores of the Low Lead Group and the High Lead Group\nLow Lead Level (Group 1)\n70\n85\n86\n76\n84\n96\n94\n56\n115\n97\n77\n128\n99\n80\n118\n86\n141\n88\n96\n96\n107\n86\n80\n107\n101\n91\n125\n96\n99\n99\n115\n106\n105\n96\n50\n99\n85\n88\n120\n93\n87\n98\n78\n100\n105\n87\n94\n89\n80\n111\n104\n85\n94\n75\n73\n76\n107\n88\n89\n96\n72\n97\n76\n107\n104\n85\n76\n95\n86\n89\n76\n96\n101\n108\n102\n77\n74\n92\nHigh Lead Level (Group 3)\n82\n93\n85\n75\n85\n80\n101\n89\n80\n94\n88\n104\n88\n88\n83\n104\n96\n76\n80\n79\n75",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 56
  },
  {
    "child_id": "324da437-b5ec-495b-ad0d-a248435f36c1",
    "parent_id": "21fd437c-f0c2-4d51-802c-dbde99cce28c",
    "text": "42 \nCHAPTER 2 Exploring Data with Tables and Graphs\nHistograms\n\u2022 Develop the ability to picture the distribution of data in the format of a histogram or \nrelative frequency histogram.\n\u2022 Examine a histogram and identify common distributions, including a uniform distribu-\ntion and a normal distribution.\nGraphs That Enlighten and Graphs That Deceive\n\u2022 Develop an ability to graph data using a dotplot, stemplot, time-series graph, Pareto \nchart, pie chart, and frequency polygon.\n\u2022 Determine when a graph is deceptive through the use of a nonzero axis or a \n pictograph that uses an object of area or volume for one-dimensional data.\nScatterplots, Correlation, and Regression\n\u2022 Develop an ability to construct a scatterplot of paired data.\n\u2022 Analyze a scatterplot to determine whether there appears to be a correlation \n between two variables.\n2-2\n2-3\n2-4\nHistograms\n\u2022 Develop the ability to picture the distribution of data in the format of a histogram or \nrelative frequency histogram.\n\u2022 Examine a histogram and identify common distributions, including a uniform distribu-\ntion and a normal distribution.\nGraphs That Enlighten and Graphs That Deceive\n\u2022 Develop an ability to graph data using a dotplot, stemplot, time-series graph, Pareto\nchart, pie chart, and frequency polygon.\n\u2022 Determine when a graph is deceptive through the use of a nonzero axis or a\npictograph that uses an object of area or volume for one-dimensional data.\nScatterplots, Correlation, and Regression\n\u2022 Develop an ability to construct a scatterplot of paired data.\n\u2022 Analyze a scatterplot to determine whether there appears to be a correlation \nbetween two variables.\nKey Concept When working with large data sets, a frequency distribution (or frequency \ntable) is often helpful in organizing and summarizing data. A frequency distribution \nhelps us to understand the nature of the distribution of a data set.\n \n2-1\n \n Frequency Distributions for Organizing  \nand Summarizing Data\nDEFINITION\nA frequency distribution (or frequency table) shows how data are partitioned \namong several categories (or classes) by listing the categories along with the num-\nber (frequency) of data values in each of them.\nConsider the IQ scores of the low lead group listed in Table 2-1. Table 2-2 is a fre-\nquency distribution summarizing those IQ scores. The frequency for a particular class \nis the number of original values that fall into that class. For example, the first class in \nTable 2-2 has a frequency of 2, so 2 of the IQ scores are between 50 and 69 inclusive.\nThe following standard terms are often used in constructing frequency distributions \nand graphs.\nTABLE 2-2 IQ Scores of the \nLow Lead Group\nIQ Score\nFrequency\n50\u201369\n 2\n70\u201389\n33\n 90\u2013109\n35\n110\u2013129\n 7\n130\u2013149\n 1\nDEFINITIONS\nLower class limits are the smallest numbers that can belong to each of the differ-\nent classes. (Table 2-2 has lower class limits of 50, 70, 90, 110, and 130.)\nUpper class limits are the largest numbers that can belong to each of the different \nclas",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 60
  },
  {
    "child_id": "8db97dd3-d2cc-4b1d-b8f2-451e87a8468d",
    "parent_id": "21fd437c-f0c2-4d51-802c-dbde99cce28c",
    "text": "between 50 and 69 inclusive.\nThe following standard terms are often used in constructing frequency distributions \nand graphs.\nTABLE 2-2 IQ Scores of the \nLow Lead Group\nIQ Score\nFrequency\n50\u201369\n 2\n70\u201389\n33\n 90\u2013109\n35\n110\u2013129\n 7\n130\u2013149\n 1\nDEFINITIONS\nLower class limits are the smallest numbers that can belong to each of the differ-\nent classes. (Table 2-2 has lower class limits of 50, 70, 90, 110, and 130.)\nUpper class limits are the largest numbers that can belong to each of the different \nclasses. (Table 2-2 has upper class limits of 69, 89, 109, 129, and 149.)\nClass boundaries are the numbers used to separate the classes, but without the \ngaps created by class limits. In Figure 2-1 we see that the values of 69.5, 89.5, \n109.5, and 129.5 are in the centers of those gaps, and following the pattern of \nthose class boundaries, we see that the lowest class boundary is 49.5 and the\n\n2-1 Frequency Distributions for Organizing and Summarizing Data  \n43\nProcedure for Constructing a Frequency Distribution\nWe construct frequency distributions to (1) summarize large data sets, (2) see the dis-\ntribution and identify outliers, and (3) have a basis for constructing graphs (such as \nhistograms, introduced in Section 2-2). Technology can generate frequency distribu-\ntions, but here are the steps for manually constructing them:\n1. Select the number of classes, usually between 5 and 20. The number of classes \nmight be affected by the convenience of using round numbers.\n2. Calculate the class width.\nClass width \u22481maximum data value2 - 1minimum data value2\nnumber of classes\nRound this result to get a convenient number. (It\u2019s usually best to round up.) \nUsing a specific number of classes is not too important, and it\u2019s usually wise to \nchange the number of classes so that they use convenient values for the class \nlimits.\n3. Choose the value for the first lower class limit by using either the minimum \nvalue or a convenient value below the minimum.\nhighest class boundary is 149.5. Thus the complete list of class boundaries is 49.5, \n69.5, 89.5, 109.5, 129.5, and 149.5.\nClass midpoints are the values in the middle of the classes. Table 2-2 has class \nmidpoints of 59.5, 79.5, 99.5, 119.5, and 139.5. Each class midpoint is computed \nby adding the lower class limit to the upper class limit and dividing the sum by 2.\nClass width is the difference between two consecutive lower class limits (or two \nconsecutive lower class boundaries) in a frequency distribution. Table 2-2 uses a \nclass width of 20. (The first two lower class boundaries are 50 and 70, and their dif-\nference is 20.)\nCAUTION Finding the correct class width can be tricky. For class width, don\u2019t \nmake the most common mistake of using the difference between a lower class limit \nand an upper class limit. See Table 2-2 and note that the class width is 20, not 19.\n69.5\n49.5\n50\n69\n149.5\nSTEP 1:\nList the class limits\nfrom Table 2-2.\nSTEP 2:\nSplit the di\ufb00erence\nas shown.\nSTEP 3:\nFind the \ufb01rst and\nlast values of 49.5\na",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 60
  },
  {
    "child_id": "e95319c1-ff3b-4d59-ba62-dab6ecb227fe",
    "parent_id": "21fd437c-f0c2-4d51-802c-dbde99cce28c",
    "text": "ass width of 20. (The first two lower class boundaries are 50 and 70, and their dif-\nference is 20.)\nCAUTION Finding the correct class width can be tricky. For class width, don\u2019t \nmake the most common mistake of using the difference between a lower class limit \nand an upper class limit. See Table 2-2 and note that the class width is 20, not 19.\n69.5\n49.5\n50\n69\n149.5\nSTEP 1:\nList the class limits\nfrom Table 2-2.\nSTEP 2:\nSplit the di\ufb00erence\nas shown.\nSTEP 3:\nFind the \ufb01rst and\nlast values of 49.5\nand 149.5 by\nprojecting the\nsame pattern.\n70\n89\n89.5\n90\n109\n109.5\n110\n129\n129.5\n130\n149\nFIGURE 2-1 Finding Class Boundaries from Class Limits in Table 2-2\nGrowth Charts Updated\nPediatricians \ntypically use \nstandardized \ngrowth charts to \ncompare their \npatient\u2019s weight \nand height \nto a sample of other children. \nChildren are considered to be in \nthe normal range if their weight \nand height fall between the 5th \nand 95th percentiles. If they fall \noutside that range, they are often \ngiven tests to ensure that there \nare no serious medical problems. \nPediatricians became increas-\ningly aware of a major problem \nwith the charts: Because they \nwere based on children living be-\ntween 1929 and 1975, the growth \ncharts had become inaccurate. \nTo rectify this problem, the charts \nwere updated in 2000 to reflect \nthe current measurements of \nmillions of children. The weights \nand heights of children are good \nexamples of populations that \nchange over time. This is the \nreason for including changing \ncharacteristics of data over time \nas an important consideration for \na population.\nh\nhild\nCAUTION For class boundaries, remember that they split the difference between \nthe end of one class and the beginning of the next class, as shown in Figure 2-1.\ncontinued\n\n44 \nCHAPTER 2 Exploring Data with Tables and Graphs\n4. Using the first lower class limit and the class width, list the other lower class \nlimits. (Do this by adding the class width to the first lower class limit to get the \nsecond lower class limit. Add the class width to the second lower class limit to \nget the third lower class limit, and so on.)\n5. List the lower class limits in a vertical column and then determine and enter the \nupper class limits.\n6. Take each individual data value and put a tally mark in the appropriate \nclass. Add the tally marks to find the total frequency for each class.\nWhen constructing a frequency distribution, be sure the classes do not overlap. \nEach of the original values must belong to exactly one class. Include all classes, even \nthose with a frequency of zero. Try to use the same width for all classes, although it is \nsometimes impossible to avoid open-ended intervals, such as \u201c65 years or older.\u201d\nEXAMPLE 1  IQ Scores of Low Lead Group\nUsing the IQ scores of the low lead group in Table 2-1, follow the above procedure \nto construct the frequency distribution shown in Table 2-2. Use five classes.\nSOLUTION\nStep 1: Select 5 as the number of desired classes.\nStep 2: Calculate the c",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 60
  },
  {
    "child_id": "1ac10012-6de6-42b9-829e-2f17fa6cbf88",
    "parent_id": "21fd437c-f0c2-4d51-802c-dbde99cce28c",
    "text": "actly one class. Include all classes, even \nthose with a frequency of zero. Try to use the same width for all classes, although it is \nsometimes impossible to avoid open-ended intervals, such as \u201c65 years or older.\u201d\nEXAMPLE 1  IQ Scores of Low Lead Group\nUsing the IQ scores of the low lead group in Table 2-1, follow the above procedure \nto construct the frequency distribution shown in Table 2-2. Use five classes.\nSOLUTION\nStep 1: Select 5 as the number of desired classes.\nStep 2: Calculate the class width as shown below. Note that we round 18.2 up to 20, \nwhich is a much more convenient number.\n Class width \u22481maximum data value2 - 1minimum data value2\nnumber of classes\n = 141 - 50\n5\n= 18.2 \u224820 1rounded up to a convenient number2\nStep 3: The minimum data value is 50 and it is a convenient starting point, so use \n50 as the first lower class limit. (If the minimum value had been 52 or 53, we would \nhave rounded down to the more convenient starting point of 50.)\nStep 4: Add the class width of 20 to 50 to get the second lower class limit of 70. \nContinue to add the class width of 20 until we have five lower class limits. The \nlower class limits are therefore 50, 70, 90, 110, and 130.\nStep 5: List the lower class limits vertically, as shown in the margin. From this list, \nwe identify the corresponding upper class limits as 69, 89, 109, 129, and 149.\nStep 6: Enter a tally mark for each data value in the appropriate class. Then add the \ntally marks to find the frequencies shown in Table 2-2.\n 50\u2013\n 70\u2013\n 90\u2013\n110\u2013\n130\u2013\nCategorical Data So far we have discussed frequency distributions using only quan-\ntitative data sets, but frequency distributions can also be used to summarize categori-\ncal (or qualitative or attribute) data, as illustrated in Example 2.\nEXAMPLE 2   Emergency Room Visits for Injuries from Sports \nand Recreation \nTable 2-3 lists data for the highest seven sources of injuries resulting in a visit to \na hospital emergency room (ER) in a recent year (based on data from the Centers \nfor Disease Control and Prevention). The activity names are categorical data at",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 60
  },
  {
    "child_id": "1a38019b-94c8-43f4-b543-359174dbd3a5",
    "parent_id": "f3baba12-0132-4553-b957-b57cd24f125f",
    "text": "2-1 Frequency Distributions for Organizing and Summarizing Data  \n45\nRelative Frequency Distribution\nA variation of the basic frequency distribution is a relative frequency distribution or \npercentage frequency distribution, in which each class frequency is replaced by a \nrelative frequency (or proportion) or a percentage. In this text we use the term \u201crela-\ntive frequency distribution\u201d whether we use relative frequencies or percentages. Rela-\ntive frequencies and percentages are calculated as follows.\n Relative frequency for a class = frequency for a class\nsum of all frequencies\n Percentage for a class = frequency for a class\nsum of all frequencies * 100%\nTable 2-4 is an example of a relative frequency distribution. It is a variation of \nTable 2-2 in which each class frequency is replaced by the corresponding percent-\nage value. Because there are 78 data values, divide each class frequency by 78, and \nthen multiply by 100%. The first class of Table 2-2 has a frequency of 2, so divide \n2 by 78 to get 0.0256, and then multiply by 100% to get 2.56%, which we rounded \nto 2.6%. The sum of the percentages should be 100%, with a small discrepancy al-\nlowed for rounding errors, so a sum such as 99% or 101% is acceptable. The sum \nof the percentages in Table 2-4 is 100.1%.\nThe sum of the percentages in a relative frequency distribution must be \nvery close to 100%.\nCumulative Frequency Distribution\nAnother variation of a frequency distribution is a cumulative frequency distribu-\ntion in which the frequency for each class is the sum of the frequencies for that class \nand all previous classes. Table 2-5 is a cumulative frequency distribution based on \nTable 2-2. Using the original frequencies of 2, 33, 35, 7, and 1, we add 2 + 33 to get \nthe second cumulative frequency of 35; then we add 2 + 33 + 35 to get the third; \nand so on. See Table 2-5, and note that in addition to the use of cumulative frequen-\ncies, the class limits are replaced by \u201cless than\u201d expressions that describe the new \nranges of values.\nTABLE 2-3 Annual ER Visits for Injuries from Sports and Recreation\nActivity\nFrequency\nBicycling\n26,212\nFootball\n25,376\nPlayground\n16,706\nBasketball\n13,987\nSoccer\n10,436\nBaseball\n 9,634\nAll-terrain vehicle\n 6,337\nthe nominal level of measurement, but we can create the frequency distribution as \nshown. It might be surprising to see that bicycling is at the top of this list, but this \ndoesn\u2019t mean that bicycling is the most dangerous of these activities; many more \npeople bicycle than play football or ride an all-terrain vehicle or do any of the other \nlisted activities.\nTABLE 2-4 Relative  \nFrequency Distribution of IQ \nScores of Low Lead Group\nIQ Score\nFrequency\n50\u201369\n2.6%\n70\u201389\n42.3%\n 90\u2013109\n44.9%\n110\u2013129\n 9.0%\n130\u2013149\n 1.3%\nTABLE 2-5 Cumulative  \nFrequency Distribution of IQ \nScores of Low Lead Group\n \nIQ Score\nCumulative \nFrequency\nLess than 70\n 2\nLess than 90\n35\nLess than 110\n70\nLess than 130\n77\nLess than 150\n78\n\n46 \nCHAPTER 2 Exploring Data with Tables ",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 63
  },
  {
    "child_id": "15b2b568-9183-4132-93ab-72c813753ba7",
    "parent_id": "f3baba12-0132-4553-b957-b57cd24f125f",
    "text": "le bicycle than play football or ride an all-terrain vehicle or do any of the other \nlisted activities.\nTABLE 2-4 Relative  \nFrequency Distribution of IQ \nScores of Low Lead Group\nIQ Score\nFrequency\n50\u201369\n2.6%\n70\u201389\n42.3%\n 90\u2013109\n44.9%\n110\u2013129\n 9.0%\n130\u2013149\n 1.3%\nTABLE 2-5 Cumulative  \nFrequency Distribution of IQ \nScores of Low Lead Group\n \nIQ Score\nCumulative \nFrequency\nLess than 70\n 2\nLess than 90\n35\nLess than 110\n70\nLess than 130\n77\nLess than 150\n78\n\n46 \nCHAPTER 2 Exploring Data with Tables and Graphs\nCritical Thinking: Using Frequency Distributions  \nto Understand Data\nAt the beginning of this section we noted that a frequency distribution can help us un-\nderstand the distribution of a data set, which is the nature or shape of the spread of the \ndata over the range of values (such as bell-shaped). In statistics we are often interested \nin determining whether the data have a normal distribution. (Normal distributions are \ndiscussed extensively in Chapter 6.) Data that have an approximately normal distribu-\ntion are characterized by a frequency distribution with the following features:\nNormal Distribution\n1. The frequencies start low, then increase to one or two high frequencies, and \nthen decrease to a low frequency.\n2. The distribution is approximately symmetric: Frequencies preceding the \nmaximum frequency should be roughly a mirror image of those that follow \nthe maximum frequency.\nTable 2-6 satisfies these two conditions. The frequencies start low, increase to the max-\nimum of 56, and then decrease to a low frequency. Also, the frequencies of 1 and 10 \nthat precede the maximum are a mirror image of the frequencies 10 and 1 that follow \nthe maximum. Real data sets are usually not so perfect as Table 2-6, and judgment \nmust be used to determine whether the distribution comes \u201cclose enough\u201d to satisfying \nthe above two conditions. (There are more objective procedures included later.)\nTABLE 2-6 Frequency Distribution Showing a Normal Distribution\nScore\nFrequency\nNormal Distribution\n50\u201369\n 1\nd Frequencies start low, . . .\n70\u201389\n10\n 90\u2013109\n56\nd  Increase to a maximum, . . .\n110\u2013129\n10\n130\u2013149\n 1\nd  Decrease to become low again.\nAnalysis of Last Digits Example 3 illustrates this principle:\nFrequencies of last digits sometimes reveal how the data were collected \nor measured.\nEXAMPLE 3   Exploring Data: How Were the Weights Obtained in \nCalifornia? \nWhen collecting weights of people, it\u2019s better to actually weigh people than to \nask them what they weigh. People often tend to round way down, so that a weight \nof 196 lb might be reported as 170 lb. Table 2-7 summarizes the last digits of the \nweights of 100 people used in the California Health Interview Survey. If people are \nactually weighed on a scale, the last digits of weights tend to have frequencies that \nare approximately the same, but Table 2-6 shows that the vast majority of weights \nhave last digits of 0 or 5, and this is strong evidence that people reported their \nweights and were not phy",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 63
  },
  {
    "child_id": "e0d6081e-b831-4330-9581-7505eae835a2",
    "parent_id": "f3baba12-0132-4553-b957-b57cd24f125f",
    "text": "ople often tend to round way down, so that a weight \nof 196 lb might be reported as 170 lb. Table 2-7 summarizes the last digits of the \nweights of 100 people used in the California Health Interview Survey. If people are \nactually weighed on a scale, the last digits of weights tend to have frequencies that \nare approximately the same, but Table 2-6 shows that the vast majority of weights \nhave last digits of 0 or 5, and this is strong evidence that people reported their \nweights and were not physically weighed. (Also, the word \u201cinterview\u201d in the title \nof the California Health Interview Survey reveals that people were interviewed and \nwere not physically measured.)\n\n2-1 Frequency Distributions for Organizing and Summarizing Data  \n47\nGaps Example 4 illustrates this principle:\nThe presence of gaps can suggest that the data are from two or more \ndi\ufb00erent populations.\nThe converse of this principle is not true, because data from different populations do \nnot necessarily result in gaps.\nTABLE 2-7  Last Digits of Weights from the \nCalifornia Health Interview Survey\nLast Digit of Weight\nFrequency\n0\n46\n1\n 1\n2\n 2\n3\n 3\n4\n 3\n5\n30\n6\n 4\n7\n 0\n8\n 8\n9\n 3\nEXAMPLE 4  Exploring Data: What Does a Gap Tell Us?\nTable 2-8 is a frequency distribution of the heights (in.) of males. Examination of \nthe frequencies reveals a large gap between the shortest males and the tallest males. \nThis can be explained by the fact that half of the males are 7 years old and the other \nhalf are adults, so we really have samples from two different populations.\nTABLE 2-8 Heights of Males\nHeight (in.)\nFrequency\n40\u201344\n 3\n45\u201349\n17\n50\u201354\n29\n55\u201359\n 1\n60\u201364\n 0\n65\u201369\n24\n70\u201374\n23\n75\u201379\n 3\n\n48 \nCHAPTER 2 Exploring Data with Tables and Graphs\nTABLE 2-9 IQ Scores from the Low Lead Group and the High Lead Group\nIQ Score\nLow Lead Group\nHigh Lead Group\n50\u201369\n 2.6%\n70\u201389\n42.3%\n71.4%\n 90\u2013109\n44.9%\n28.6%\n110\u2013129\n 9.0%\n130\u2013149\n 1.3%\nEXAMPLE 5   Comparing IQ Scores of the Low Lead Group and \nthe High Lead Group \nTable 2-1, which is given with the Chapter Problem at the beginning of this chapter, \nlists IQ scores from the low lead group and the high lead group. Because the sample \nsizes of 78 and 21 are so different, a comparison of frequency distributions is not \neasy, but Table 2-9 shows the relative frequency distributions for those two groups. \nBy comparing those relative frequencies, we see that the majority of children in the \nlow lead group had IQ scores of 90 or higher, but the majority of children in the \nhigh lead group had IQ scores below 90. This suggests that perhaps high lead expo-\nsure has a detrimental effect on IQ scores.\nFrequency Distributions\nAccess tech instructions, videos, and data sets at www.TriolaStats.com\nTECH CENTER \nStatistical Literacy and Critical Thinking\n1. Cotinine in Smokers Refer to the accompanying table summarizing measured amounts \nof serum cotinine (ng/mL) from a sample of smokers (from Data Set 14 \u201cPassive and Active \nSmoke\u201d in Appendix B). When nicotine is absorbed b",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 63
  },
  {
    "child_id": "22a01ebf-5874-4b04-95c2-e4fe379175d2",
    "parent_id": "f3baba12-0132-4553-b957-b57cd24f125f",
    "text": "h lead group had IQ scores below 90. This suggests that perhaps high lead expo-\nsure has a detrimental effect on IQ scores.\nFrequency Distributions\nAccess tech instructions, videos, and data sets at www.TriolaStats.com\nTECH CENTER \nStatistical Literacy and Critical Thinking\n1. Cotinine in Smokers Refer to the accompanying table summarizing measured amounts \nof serum cotinine (ng/mL) from a sample of smokers (from Data Set 14 \u201cPassive and Active \nSmoke\u201d in Appendix B). When nicotine is absorbed by the body, cotinine is produced. How \nmany subjects are included in the summary? Is it possible to identify the exact values of all of \nthe original cotinine measurements?\n2-1 Basic Skills and Concepts \nCotinine (ng, mL)\nFrequency\n 0\u201399\n11\n100\u2013199\n12\n200\u2013299\n14\n300\u2013399\n 1\n400-499\n 2\n2. Cotinine in Smokers Refer to the accompanying frequency distribution. What problem is \ncreated by using classes of 0\u2013100, 100\u2013200, . . . ?\n3. Relative Frequency Distribution Use percentages to construct the relative frequency dis-\ntribution corresponding to the accompanying frequency distribution for cotinine amounts.\n4. What\u2019s Wrong? Heights of adult males are known to have a normal distribution, as de-\nscribed in this section. A researcher claims to have randomly selected adult males and mea-\nsured their heights with the resulting relative frequency distribution as shown here. Identify two \nmajor flaws with theses results.\nHeight \n(cm)\nRelative  \nFrequency\n130\u2013144\n23%\n145\u2013159\n25%\n160\u2013174\n22%\n175\u2013189\n27%\n190\u2013204\n28%\nComparisons Example 5 illustrates this principle:\nCombining two or more relative frequency distributions in one table \nmakes comparisons of data much easier.\n\n2-1 Frequency Distributions for Organizing and Summarizing Data  \n49\nIn Exercises 5\u20138, identify the class width, class midpoints, and class boundaries for the \ngiven frequency distribution. The frequency distributions are based on real data from \nAppendix B.\n5.\u00a0\nCotinine (NonSmokers  \nExposed to Smoke  \nin ng, mL)\n \n \nFrequency\n0\u201399\n34\n100\u2013199\n 2\n200\u2013299\n 1\n300\u2013399\n 1\n400\u2013499\n 0\n500\u2013599\n 2\n6.\u00a0\nBrain Volume (cm3)\nFrequency\n960\u20131049\n6\n1050\u20131139\n7\n1140\u20131229\n3\n1230\u20131319\n2\n1320\u20131409\n1\n1410\u20131499\n1\n7.\u00a0\nBlood Platelet \nCount of Males\n \nFrequency\n 0\u201399\n 1\n100\u2013199\n51\n200\u2013299\n90\n300\u2013399\n10\n400\u2013499\n 0\n500\u2013599\n 0\n600\u2013699\n 1\n8.\u00a0\nBlood Platelet \nCount of Females\n \nFrequency\n100\u2013199\n25\n200\u2013299\n92\n300\u2013399\n28\n400\u2013499\n 0\n500\u2013599\n 2\nNormal Distributions. In Exercises 9\u201312, answer the given questions, which are related \nto normal distributions.\n9. Cotinine Determine whether the frequency distribution given in Exercise 5 is approximately \na normal distribution. Explain.\n10. Brain Volume Refer to the frequency distribution given in Exercise 6 and ignore the given fre-\nquencies. Assume that the first three frequencies are 1, 3, and 6, respectively. Assuming that the dis-\ntribution of the 20 sample values is a normal distribution, identify the remaining three frequencies.\n11. Normal Distribution Refer to the frequency distributio",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 63
  },
  {
    "child_id": "0daab623-02fb-4237-b60a-55274aaf5cd3",
    "parent_id": "f3baba12-0132-4553-b957-b57cd24f125f",
    "text": "ibutions.\n9. Cotinine Determine whether the frequency distribution given in Exercise 5 is approximately \na normal distribution. Explain.\n10. Brain Volume Refer to the frequency distribution given in Exercise 6 and ignore the given fre-\nquencies. Assume that the first three frequencies are 1, 3, and 6, respectively. Assuming that the dis-\ntribution of the 20 sample values is a normal distribution, identify the remaining three frequencies.\n11. Normal Distribution Refer to the frequency distribution given in Exercise 7 and ignore \nthe given frequencies. Assume that the first three frequencies are 2, 12, and 18, respectively. \nAssuming that the distribution of the 153 sample values is a normal distribution, identify the \nremaining four frequencies.\n12.\u00a0Normal Distribution Refer to the frequency distribution given in Exercise 8 and deter-\nmine whether it appears to be a normal distribution. Explain.\nConstructing Frequency Distributions. In Exercises 13\u201322, use the indicated data and \nconstruct the frequency distribution. (The data for Exercises 13\u201322 can be downloaded at \nTriolaStats.com.)\n13.\u00a0Pulse Rates of Males Refer to Data Set 1 \u201cBody Data\u201d in Appendix B and use the pulse \nrates (beats per minute) of males. Begin with a lower class limit of 40 and use a class width of \n10. Do the pulse rates of males appear to have a normal distribution?\n14.\u00a0Pulse Rates of Females Refer to Data Set 1 \u201cBody Data\u201d in Appendix B and use the \npulse rates (beats per minute) of females. Begin with a lower class limit of 30 and use a class \nwidth of 10. Do the pulse rates of females appear to have a normal distribution?\n15.\u00a0Lead and IQ Refer to Data Set 8 \u201cIQ and Lead\u201d in Appendix B and use the verbal IQ \nscores of the low lead group. Begin with a lower class limit of 50 and use a class width of 10. \nDo these IQ scores appear to be normally distributed?",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 63
  },
  {
    "child_id": "1502f8ed-834d-42bc-b6d8-ffdc501a7769",
    "parent_id": "aadfaa6b-705a-4dad-9e18-b426b8bec492",
    "text": "50 \nCHAPTER 2 Exploring Data with Tables and Graphs\n16.\u00a0Lead and IQ Refer to Data Set 8 \u201cIQ and Lead\u201d in Appendix B and use the verbal IQ \nscores of the high lead group. Begin with a lower class limit of 60 and use a class width of 10. \nDo these IQ scores appear to be normally distributed?\n17.\u00a0Male Red Blood Cell Counts Refer to Data Set 1 \u201cBody Data\u201d in Appendix B and use \nthe red blood cell counts (million cells>mL) for males. Begin with a lower class limit of 3.00 \nand use a class width of 0.50. Using a very loose interpretation of the requirements for a nor-\nmal distribution, do the red blood cell counts appear to be normally distributed?\n18.\u00a0Female Red Blood Cell Counts Repeat the preceding exercise using the red blood cell \ncounts for females.\n19.\u00a0Freshman 15 Refer to Data Set 10 \u201cFreshman 15\u201d in Appendix B and use the weights (kg) \nof males in September of their freshman year. Begin with a lower class limit of 50 kg and use a \nclass width of 10 kg.\n20.\u00a0 Freshman 15 Repeat the preceding exercise using the weights (kg) of males in April. \nCompare the result to the frequency distribution from the preceding exercise. Does it appear \nthat males gain 15 lb (or 6.8 kg) during their freshman year?\n21.\u00a0Analysis of Last Digits Heights of statistics students were obtained by one of the authors \nas part of an experiment conducted for class. The last digits of those heights are listed below. \nConstruct a frequency distribution with 10 classes. Based on the distribution, do the heights ap-\npear to be reported or actually measured? What do you know about the accuracy of the results?\n0 0 0 0 0 0 0 0 0 1 1 2 3 3 3 4 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 6 6 8 8 8 9\n22.\u00a0Analysis of Last Digits Listed below are the last digits of weights of subjects. After con-\nstructing the frequency distribution, does it appear that the weights were reported or physically \nmeasured? Explain.\n2 7 7 3 2 8 5 9 7 2 8 6 9 2 7 5 6 4 0 7 6 8 4 0 4\n7 5 5 4 8 6 3 8 9 3 9 2 6 0 1 1 1 7 2 0 3 5 6 6 8\nRelative Frequencies for Comparisons. In Exercises 23 and 24, find the relative fre-\nquencies and answer the given questions.\n23. Cotinine Construct one table (similar to Table 2-9 on page 48) that includes relative fre-\nquencies based on the frequency distributions from Exercise 1 (smokers) and Exercise 5 (non-\nsmokers exposed to smoke), and then compare them. Are there notable differences?\n24. Blood Platelet Counts Construct one table (similar to Table 2-9 on page 48) that includes \nrelative frequencies based on the frequency distributions from Exercises 7 and 8, and then com-\npare them. Are there notable differences?\nCumulative Frequency Distributions. In Exercises 25 and 26, construct the cumulative \nfrequency distribution that corresponds to the frequency distribution in the exercise indicated.\n25.\u00a0Exercise 5\n26.\u00a0Exercise 6\n27. Interpreting Effects of Outliers Exercise 5 in this section involved cotinine levels of \nnonsmokers who were exposed to tobacco smoke. (See the middle column in Data",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 68
  },
  {
    "child_id": "db830a2e-f5e1-45d4-b206-0c63e5effca1",
    "parent_id": "aadfaa6b-705a-4dad-9e18-b426b8bec492",
    "text": " based on the frequency distributions from Exercises 7 and 8, and then com-\npare them. Are there notable differences?\nCumulative Frequency Distributions. In Exercises 25 and 26, construct the cumulative \nfrequency distribution that corresponds to the frequency distribution in the exercise indicated.\n25.\u00a0Exercise 5\n26.\u00a0Exercise 6\n27. Interpreting Effects of Outliers Exercise 5 in this section involved cotinine levels of \nnonsmokers who were exposed to tobacco smoke. (See the middle column in Data Set 14 \n \u201cPassive and Active Smoke\u201d in Appendix B.)\na. Identify any outliers.\nb. After adding another value of 999 to the cotinine levels of nonsmokers exposed to smoke, construct \nthe frequency distribution as in Exercise 5. How is the frequency distribution affected by the addition \nof the outlier 999? State a generalization about the effect of an outlier on a frequency distribution.\n2-1 Beyond the Basics\n\n2-2 Histograms \n51\nImportant Uses of a Histogram\n \n\u25a0Visually displays the shape of the distribution of the data\n \n\u25a0Shows the location of the center of the data\n \n\u25a0Shows the spread of the data\n \n\u25a0Identifies outliers\nA histogram is basically a graph of a frequency distribution. For example, \n Figure 2-2 shows the histogram corresponding to the frequency distribution given in \nTable 2-2 on page 42.\nClass frequencies should be used for the vertical scale and that scale should be la-\nbeled as in Figure 2-2. There is no universal agreement on the procedure for selecting \nwhich values are used for the bar locations along the horizontal scale, but it is com-\nmon to use class boundaries (as shown in Figure 2-2) or class midpoints or class limits \nor something else. It is often easier for us mere mortals to use class midpoints for the \nhorizontal scale. Histograms can usually be generated using technology.\nRelative Frequency Histogram\nA relative frequency histogram has the same shape and horizontal scale as a histo-\ngram, but the vertical scale uses relative frequencies (as percentages or proportions) \ninstead of actual frequencies. Figure 2-3 is the relative frequency histogram corre-\nsponding to Figure 2-2.\nPART 1\nBasic Concepts of Histograms\nKey Concept While a frequency distribution is a useful tool for summarizing data \nand investigating the distribution of data, an even better tool is a histogram, which is a \ngraph that is easier to interpret than a table of numbers.\n2-2 \nHistograms\nDEFINITION\nA histogram is a graph consisting of bars of equal width drawn adjacent to each \nother (unless there are gaps in the data). The horizontal scale represents classes of \nquantitative data values, and the vertical scale represents frequencies. The heights \nof the bars correspond to frequency values.\nFIGURE 2-2 Histogram\nFIGURE 2-3 Relative Frequency Histogram\n\n52 \nCHAPTER 2 Exploring Data with Tables and Graphs\nCritical Thinking: Interpreting Histograms\nThe ultimate objective of a histogram is to understand characteristics of the data. Ex-\nplore the data by analyzing t",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 68
  },
  {
    "child_id": "623ed756-2b8b-49c9-8f62-f5201025da7c",
    "parent_id": "aadfaa6b-705a-4dad-9e18-b426b8bec492",
    "text": "to each \nother (unless there are gaps in the data). The horizontal scale represents classes of \nquantitative data values, and the vertical scale represents frequencies. The heights \nof the bars correspond to frequency values.\nFIGURE 2-2 Histogram\nFIGURE 2-3 Relative Frequency Histogram\n\n52 \nCHAPTER 2 Exploring Data with Tables and Graphs\nCritical Thinking: Interpreting Histograms\nThe ultimate objective of a histogram is to understand characteristics of the data. Ex-\nplore the data by analyzing the histogram to see what can be learned about \u201cCVDOT\u201d: \nthe center of the data, the variation (which will be discussed at length in Section 3-2), \nthe shape of the distribution, whether there are any outliers (values far away from the \nother values), and time (whether there is any change in the characteristics of the data \nover time). Examining Figure 2-2, we see that the histogram is centered close to 90, \nthe values vary from around 50 to 150, and the distribution is roughly bell-shaped. \nThere aren\u2019t any outliers and any changes in time are irrelevant for these data.\nCommon Distribution Shapes\nThe histograms shown in Figure 2-4 depict four common distribution shapes.\nNormal Distribution\nWhen graphed as a histogram, data with a normal distribution have a \u201cbell\u201d shape \nsimilar to the one superimposed in Figure 2-5. Many collections of data have a dis-\ntribution that is approximately normal. Many statistical methods require that sample \ndata come from a population having a distribution that is approximately a normal dis-\ntribution, and we can often use a histogram to judge whether this requirement is satis-\nfied. There are more advanced and less subjective methods for determining whether \nthe distribution is a normal distribution. Normal quantile plots are very helpful for \nassessing normality: see Part 2 of this section.\n   \n   \nFIGURE 2-4 Common Distributions\n(a)\n(b)\n(c)\n(d)\n\n2-2 Histograms \n53\nUniform Distribution\nThe different possible values occur with approximately the same frequency, so the \nheights of the bars in the histogram are approximately uniform, as in Figure 2-4(b). \nFigure 2-4(b) depicts outcomes of last digits of weights from a large sample of ran-\ndomly selected subjects, and such a graph is helpful in determining whether the sub-\njects were actually weighed or whether they reported their weights.\nPopulation sizes of an organism are often uniformly distributed when they are \nfound in equally sized areas of a region where they must compete for a limited re-\nsource. For example, redwood trees must compete for light, and numbers of redwood \ntrees in equally sized areas of a region tend to be uniformly distributed.\nSkewness\nA distribution of data is skewed if it is not symmetric and extends more to one side \nthan to the other. Data skewed to the right (also called positively skewed) have a \nlonger right tail, as in Figure 2-4(c). Annual incomes of adult Americans are skewed \nto the right; death rates of nations are skewed to the right. Data ",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 68
  },
  {
    "child_id": "39380219-0533-48a2-8190-a123af5048a8",
    "parent_id": "aadfaa6b-705a-4dad-9e18-b426b8bec492",
    "text": "mited re-\nsource. For example, redwood trees must compete for light, and numbers of redwood \ntrees in equally sized areas of a region tend to be uniformly distributed.\nSkewness\nA distribution of data is skewed if it is not symmetric and extends more to one side \nthan to the other. Data skewed to the right (also called positively skewed) have a \nlonger right tail, as in Figure 2-4(c). Annual incomes of adult Americans are skewed \nto the right; death rates of nations are skewed to the right. Data skewed to the left \n(also called negatively skewed) have a longer left tail, as in Figure 2-4(d). Life span \ndata in humans are skewed to the left. (Here\u2019s a mnemonic for remembering skew-\nness: A distribution skewed to the right resembles the toes on your right foot, and \none skewed to the left resembles the toes on your left foot.) Distributions skewed to \nthe right are more common than those skewed to the left because it\u2019s often easier to \nget exceptionally large values than values that are exceptionally small. With annual \nincomes, for example, it\u2019s impossible to get values below zero, but there are a few \npeople who earn millions or billions of dollars in a year. Annual incomes therefore \ntend to be skewed to the right.\nPART 2\n  Assessing Normality with  \nNormal Quantile Plots\nSome methods presented in later chapters have a requirement that sample data must \nbe from a population having a normal distribution. Histograms can be helpful in de-\ntermining whether the normality requirement is satisfied, but they are not very help-\nful with small data sets. Section 6-5 discusses methods for assessing normality\u2014that \nis, determining whether the sample data are from a normally distributed population. \nSection 6-5 includes a procedure for constructing normal quantile plots, which are \nFIGURE 2-5  Bell-Shaped Distribution\nBecause this histogram is roughly bell-shaped, we say that the \ndata have a normal distribution. (A more rigorous de\ufb01nition will be \ngiven in Chapter 6.)\nRemembering Skewness:\nSkewed Left:   Resembles \ntoes on left \nfoot\nSkewed Right:  Resembles \ntoes on right \nfoot",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 68
  },
  {
    "child_id": "b5d65e2d-59e4-435e-b7ba-03ce4a3d08b7",
    "parent_id": "b12387b4-ecdb-4b6d-b1fb-11359eee60d1",
    "text": "54 \nCHAPTER 2 Exploring Data with Tables and Graphs\neasy to generate using technology such as Statdisk, SPSS, JMP, Minitab, XLSTAT, \nStatCrunch, or a TI-83>84 Plus calculator. Interpretation of a normal quantile plot is \nbased on the following criteria:\nCriteria for Assessing Normality with a Normal Quantile Plot\nNormal Distribution: The population distribution is normal if the pattern of the \npoints in the normal quantile plot is reasonably close to a straight line, and the \npoints do not show some systematic pattern that is not a straight-line pattern.\nNot a Normal Distribution: The population distribution is not normal if the \nnormal quantile plot has either or both of these two conditions:\n\u2022\u2002 The\u2002points\u2002do\u2002not\u2002lie\u2002reasonably\u2002close\u2002to\u2002a\u2002straight-line\u2002pattern.\n\u2022\u2002 The\u2002points\u2002show\u2002some\u2002systematic pattern that is not a straight-line pattern.\nThe following are examples of normal quantile plots. Procedures for creating such \nplots are described in Section 6-5.\nNormal Distribution: The points are  \nreasonably close to a straight-line pattern, \nand there is no other systematic pattern \nthat is not a straight-line pattern.\nNot a Normal Distribution: The \npoints do not lie reasonably close to a \nstraight line.\nNot a Normal Distribution: The \npoints show a systematic pattern that \nis not a straight-line pattern.\nHistograms\nAccess tech instructions, videos, and data sets at www.TriolaStats.com\nTECH CENTER \nStatistical Literacy and Critical Thinking\n1. Histogram Table 2-2 is a frequency distribution summarizing the IQ scores of the low lead \ngroup listed in Table 2-1 on page 41, and Figure 2-2 on page 51 is a histogram depicting that \nsame data set. When trying to better understand the IQ data, what is the advantage of examin-\ning the histogram instead of the frequency distribution?\n2. Voluntary Response Sample The histogram in Figure 2-2 on page 51 is constructed from \na simple random sample of children. If you construct a histogram with data collected from a \nvoluntary response sample, will the distribution depicted in the histogram reflect the true dis-\ntribution of the population? Why or why not?\n3. Blood Platelet Counts Listed below are blood platelet counts (1000 cells>mL) randomly \nselected from adults in the United States. Why does it not make sense to construct a histogram \nfor this data set?\n191 286 263 193 193 215 162 646 250 386\n2-2 Basic Skills and Concepts\n\n2-2 Histograms \n55\n4.\u00a0Normal Distribution When it refers to a normal distribution, does the term \u201cnormal\u201d have \nthe same meaning as in ordinary language? What criterion can be used to determine whether \nthe data depicted in a histogram have a distribution that is approximately a normal distribution? \nIs this criterion totally objective, or does it involve subjective judgment?\nInterpreting a Histogram. In Exercises 5\u20138, answer the questions by referring to the fol-\nlowing histogram, which represents the sepal widths (mm) of a sample of irises. (See Data \nSet 16 \u201cIris Measurements\u201d in Append",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 72
  },
  {
    "child_id": "10bc6b53-14de-4f46-a5c9-1422f3097b5a",
    "parent_id": "b12387b4-ecdb-4b6d-b1fb-11359eee60d1",
    "text": " \u201cnormal\u201d have \nthe same meaning as in ordinary language? What criterion can be used to determine whether \nthe data depicted in a histogram have a distribution that is approximately a normal distribution? \nIs this criterion totally objective, or does it involve subjective judgment?\nInterpreting a Histogram. In Exercises 5\u20138, answer the questions by referring to the fol-\nlowing histogram, which represents the sepal widths (mm) of a sample of irises. (See Data \nSet 16 \u201cIris Measurements\u201d in Appendix B.)\n5. Sample Size Based on the histogram, what is the approximate number of irises in \nthe sample?\n6. Class Width and Class Limits What is the class width? What are the approximate lower \nand upper class limits of the first class?\n7. Outlier? What is the largest possible value? Would that value be an outlier?\n8.\u00a0Normal Distribution Does it appear that the sample is from a population having a normal \ndistribution?\nConstructing Histograms. In Exercises 9\u201318, construct the histograms and answer the \ngiven questions. Use class midpoint values for the horizontal scale.\n9.\u00a0Pulse Rates of Males Use the frequency distribution from Exercise 13 in Section 2-1 on \npage 49 to construct a histogram. Do the pulse rates of males appear to have a normal distribution?\n10.\u00a0Pulse Rates of Females Use the frequency distribution from Exercise 14 in Section 2-1  \non page 49 to construct a histogram. Do the pulse rates of females appear to have a normal \ndistribution?\n11.\u00a0Lead and IQ Use the frequency distribution from Exercise 15 in Section 2-1 on page 49 to \nconstruct a histogram. Do the IQ scores appear to have a normal distribution?\n12.\u00a0Lead and IQ Use the frequency distribution from Exercise 16 in Section 2-1 on page 50 to \nconstruct a histogram. Do the IQ scores appear to have a normal distribution?\n13.\u00a0 Male Red Blood Cell Counts Use the frequency distribution from Exercise 17 in \nSection 2-1 on page 50 to construct a histogram. Do the red blood cell counts appear to have a \nnormal distribution?\n14.\u00a0Female Red Blood Cell Counts Use the frequency distribution from Exercise 18 in \nSection 2-1 on page 50 to construct a histogram. Do the red blood cell counts appear to have \na normal distribution?\n15.\u00a0Freshman 15 Use the frequency distribution from Exercise 19 in Section 2-1 on page 50 \nto construct a histogram.\n16.\u00a0Freshman 15 Use the frequency distribution from Exercise 20 in Section 2-1 on page 50 \nto construct a histogram.\n\n56 \nCHAPTER 2 Exploring Data with Tables and Graphs\n17. Last Digit Analysis Use the frequency distribution from Exercise 21 in Section 2-1 on \npage 50 to construct a histogram. What does the histogram suggest about the method used to \ncollect the heights?\n18. Last Digit Analysis Use the frequency distribution from Exercise 22 in Section 2-1 on \npage 50 to construct a histogram. What does the histogram suggest about the method used to \ncollect the weights?\n2-2 Beyond the Basics\nKey Concept Section 2-2 introduced the histogram, and this section intro",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 72
  },
  {
    "child_id": "12c15711-f453-45b3-8d04-424ded0b8c7c",
    "parent_id": "b12387b4-ecdb-4b6d-b1fb-11359eee60d1",
    "text": ". Last Digit Analysis Use the frequency distribution from Exercise 21 in Section 2-1 on \npage 50 to construct a histogram. What does the histogram suggest about the method used to \ncollect the heights?\n18. Last Digit Analysis Use the frequency distribution from Exercise 22 in Section 2-1 on \npage 50 to construct a histogram. What does the histogram suggest about the method used to \ncollect the weights?\n2-2 Beyond the Basics\nKey Concept Section 2-2 introduced the histogram, and this section introduces other \ncommon graphs that foster understanding of data. We also discuss some graphs that \nare deceptive because they create impressions about data that are somehow mislead-\ning or wrong.\nThe era of charming and primitive hand-drawn graphs has passed, and technol-\nogy now provides us with powerful tools for generating a wide variety of graphs. \nHere we go.\nGraphs That Enlighten\nDotplots\nA dotplot consists of a graph of quantitative data in which each data value is plotted \nas a point (or dot) above a horizontal scale of values. Dots representing equal values \nare stacked.\nFeatures of a Dotplot\n \n\u25a0Displays the shape of the distribution of data.\n \n\u25a0It is usually possible to recreate the original list of data values.\n2-3 \nGraphs That Enlighten and Graphs That Deceive\n19. Interpreting Normal Quantile Plots Which of the following normal quantile plots  appear \nto represent data from a population having a normal distribution? Explain.\n(a)\n(b)\n(c)\n(d)\n\n2-3 Graphs That Enlighten and Graphs That Deceive \n57\nStemplots\nA stemplot (or stem-and-leaf plot) represents quantitative data by separating each \nvalue into two parts: the stem (such as the leftmost digit) and the leaf (such as the \nrightmost digit). Better stemplots are often obtained by first rounding the original data \nvalues. Also, stemplots can be expanded to include more rows and can be condensed \nto include fewer rows.\nFeatures of a Stemplot\n \n\u25a0Shows the shape of the distribution of the data.\n \n\u25a0Retains the original data values.\n \n\u25a0The sample data are sorted (arranged in order).\nFIGURE 2-6 Dotplot of Pulse Rates of Males\nEXAMPLE 1  Dotplot of Pulse Rates of Males\nFigure 2-6 shows a dotplot of the pulse rates (beats per minute) of males from Data \nSet 1 \u201cBody Data\u201d in Appendix B. The two stacked dots above the position at 50 in-\ndicate that two of the pulse rates are 50. (In this dotplot, the horizontal scale allows \neven numbers only, but the original pulse rates are all even numbers.)\nEXAMPLE 2  Stemplot of Male Pulse Rates\nThe following stemplot displays the pulse rates of the males in Data Set 1 \u201cBody \nData\u201d in Appendix B. The lowest pulse rate of 40 is separated into the stem of 4 and \nthe leaf of 0. The stems and leaves are arranged in increasing order, not the order in \nwhich they occur in the original list. If you turn the stemplot on its side, you can see \nthe distribution of the IQ scores in the same way you would see it in a histogram or \ndotplot.\nPulse rates are 40 and 42\nPulse rates are 90",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 72
  },
  {
    "child_id": "e8f1af78-e5e5-4665-bc06-265ee8493243",
    "parent_id": "b12387b4-ecdb-4b6d-b1fb-11359eee60d1",
    "text": "le Pulse Rates\nThe following stemplot displays the pulse rates of the males in Data Set 1 \u201cBody \nData\u201d in Appendix B. The lowest pulse rate of 40 is separated into the stem of 4 and \nthe leaf of 0. The stems and leaves are arranged in increasing order, not the order in \nwhich they occur in the original list. If you turn the stemplot on its side, you can see \nthe distribution of the IQ scores in the same way you would see it in a histogram or \ndotplot.\nPulse rates are 40 and 42\nPulse rates are 90, 92, 94, 96, 96\nTime-Series Graph\nA time-series graph is a graph of time-series data, which are quantitative data that \nhave been collected at different points in time, such as monthly or yearly. An advan-\ntage of a time-series graph is that it reveals information about trends over time.\nFeatures of a Time-series Graph\n \n\u25a0Reveals information about trends over time\n\n58 \nCHAPTER 2 Exploring Data with Tables and Graphs\nBar Graphs\nA bar graph uses bars of equal width to show frequencies of categories of categori-\ncal (or qualitative) data. The bars may or may not be separated by small gaps.\nFeature of a Bar Graph\n \n\u25a0Shows the relative distribution of categorical data so that it is easier to compare \nthe different categories\nPareto Charts\nA Pareto chart is a bar graph for categorical data, with the added stipulation that the \nbars are arranged in descending order according to frequencies, so the bars decrease \nin height from left to right.\nFeatures of a Pareto Chart\n \n\u25a0Shows the relative distribution of categorical data so that it is easier to compare \nthe different categories\n \n\u25a0Draws attention to the more important categories\nFIGURE 2-7  Time-Series Graph of Law  \nEnforcement Fatalities\nEXAMPLE 3   Time-Series Graph of Fatalities of Law  \nEnforcement Officers\nThe time-series graph shown in Figure 2-7 depicts the yearly number of fatalities \nof law enforcement officers in the United States. See that a spike occurred in 2001, \nthe year of the September 11, 2001 terrorist attacks. Except for the data from 2001, \nthere appears to be a slight downward trend.\nEXAMPLE 4  Pareto Chart of Causes of Accidental Deaths\nFor the accidental deaths in a recent year, Figure 2-8 shows the most common \ncauses. We can see that deaths from poison represent the most serious problem. \n(Deaths from poison include deaths from drug overdoses.)\nThe Power of a Graph\nWith annual \nsales around \n$13 billion and \nwith roughly \n50 million \npeople using \nit, Pfizer\u2019s \nprescription drug Lipitor (ator-\nvastatin) has become the most \nprofitable and most widely used \nprescription drug ever marketed. \nIn the early stages of its develop-\nment, Lipitor was compared to \nother drugs (Zocor [simvastatin], \nMevacor [lovastatin], Lescol \n[fluvastatin], and Pravachol \npravastatin) in a process that \ninvolved controlled trials. The \nsummary report included a graph \nshowing a Lipitor curve that had \na steeper rise than the curves for \nthe other drugs, visually showing \nthat Lipitor was more effective \nin r",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 72
  },
  {
    "child_id": "b1955449-0ad1-4ee2-a837-809f23707804",
    "parent_id": "b12387b4-ecdb-4b6d-b1fb-11359eee60d1",
    "text": "vastatin) has become the most \nprofitable and most widely used \nprescription drug ever marketed. \nIn the early stages of its develop-\nment, Lipitor was compared to \nother drugs (Zocor [simvastatin], \nMevacor [lovastatin], Lescol \n[fluvastatin], and Pravachol \npravastatin) in a process that \ninvolved controlled trials. The \nsummary report included a graph \nshowing a Lipitor curve that had \na steeper rise than the curves for \nthe other drugs, visually showing \nthat Lipitor was more effective \nin reducing cholesterol than the \nother drugs. Pat Kelly, who was \nthen a senior marketing execu-\ntive for Pfizer, said, \u201cI will never \nforget seeing that chart\u2026. It was \nlike \u2018Aha!\u2019 Now I know what this \nis about. We can communicate \nthis!\u201d The Food and Drug Admin-\nistration approved Lipitor and al-\nlowed Pfizer to include the graph \nwith each prescription. Pfizer \nsales personnel also distributed \nthe graph to physicians.",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 72
  },
  {
    "child_id": "b5bba535-c48a-4953-a494-6685c3ddc0b1",
    "parent_id": "4c7e084a-4ad2-4287-a15d-80e8f5dfec34",
    "text": "2-3 Graphs That Enlighten and Graphs That Deceive \n59\nPie Charts\nA pie chart is a very common graph that depicts categorical data as slices of a circle, \nin which the size of each slice is proportional to the frequency count for the category. \nAlthough pie charts are very common, they are not as effective as Pareto charts.\nFeature of a Pie Chart\n \n\u25a0Shows the distribution of categorical data in a commonly used format\nFIGURE 2-8  Pareto Chart of Causes of \n Accidental Deaths\nEXAMPLE 5  Pie Chart of Causes of Accidental Deaths\nFigure 2-9 is a pie chart of the same cause of death data from Example 4. Construc-\ntion of a pie chart involves slicing up the circle into the proper proportions that rep-\nresent relative frequencies. For example, the category poison accounts for 34% of \nthe total, so the slice representing poison should be 34% of the total (with a central \nangle of 0.34 * 360\u00b0 = 122\u00b0).\nFIGURE 2-9  Pie Chart of Causes of \nAccidental Deaths\nThe Pareto chart in Figure 2-8 and the pie chart in Figure 2-9 depict the same data in \ndifferent ways, but the Pareto chart does a better job of showing the relative sizes of the \ndifferent components. Graphics expert Edwin Tufte makes the following suggestion:\nNever use pie charts because they waste ink on components that are not \ndata, and they lack an appropriate scale.\n\n60 \nCHAPTER 2 Exploring Data with Tables and Graphs\nFrequency Polygon\nA frequency polygon uses line segments connected to points located directly above \nclass midpoint values. A frequency polygon is very similar to a histogram, but a fre-\nquency polygon uses line segments instead of bars.\nA variation of the basic frequency polygon is the relative frequency polygon, \nwhich uses relative frequencies (proportions or percentages) for the vertical scale. An \nadvantage of relative frequency polygons is that two or more of them can be combined \non a single graph for easy comparison, as in Figure 2-11.\nFIGURE 2-10  Frequency Polygon of Full IQ \nScores of Low Lead Group\nEXAMPLE 6   Frequency Polygon of Full IQ Scores of  \nLow Lead Group\nSee Figure 2-10 for the frequency polygon corresponding to the full IQ scores of the \nlow lead group summarized in the frequency distribution of Table 2-2 on page 42 \n(from Data Set 8 in Appendix B). The heights of the points correspond to the class \nfrequencies, and the line segments are extended to the right and left so that the graph \nbegins and ends on the horizontal axis. The points are plotted directly above class \nmidpoint values.\nEXAMPLE 7   Relative Frequency Polygon: IQ Scores  \nof Lead Groups\nFigure 2-11 shows the relative frequency polygons for the full IQ scores of two \ngroups: (1) group with low blood lead levels; (2) group with high blood lead levels. \nHere, relative frequency polygons are much better than frequency polygons because \nthe different sample sizes of 21 and 78 would have made a comparison difficult, but \nthat difficulty is removed by using relative percentages.\nFigure 2-11 shows that t",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 77
  },
  {
    "child_id": "9f6480ae-a6f3-4edb-93cc-f92a9c84c63a",
    "parent_id": "4c7e084a-4ad2-4287-a15d-80e8f5dfec34",
    "text": "idpoint values.\nEXAMPLE 7   Relative Frequency Polygon: IQ Scores  \nof Lead Groups\nFigure 2-11 shows the relative frequency polygons for the full IQ scores of two \ngroups: (1) group with low blood lead levels; (2) group with high blood lead levels. \nHere, relative frequency polygons are much better than frequency polygons because \nthe different sample sizes of 21 and 78 would have made a comparison difficult, but \nthat difficulty is removed by using relative percentages.\nFigure 2-11 shows that the group with high blood lead levels has full IQ scores \nthat are somewhat lower than those in the low blood level group. This suggests that \nexposure to lead has an effect on IQ scores. Later chapters will provide us with \nmore tools that allow us to examine this issue beyond the subjective interpretation \nof a graph.\nF\nA\nc\nq\nFlorence Nightingale\nFlorence \nNightingale \n(1820\u20131910) \nis known to \nmany as the \nfounder of \nthe nursing \nprofession, but she also saved \nthousands of lives by using \nstatistics. When she encountered \nan unsanitary and undersup-\nplied hospital, she improved \nthose conditions and then used \nstatistics to convince others of \nthe need for more widespread \nmedical reform. She developed \noriginal graphs to illustrate that \nduring the Crimean War, more \nsoldiers died as a result of \nunsanitary conditions than were \nkilled in combat. Florence Night-\ningale pioneered the use of social \nstatistics as well as graphics \ntechniques.\n\n2-3 Graphs That Enlighten and Graphs That Deceive \n61\nGraphs That Deceive\nDeceptive graphs are commonly used to mislead people, and we really don\u2019t want \nstatistics students to be among those susceptible to such deceptions. Graphs should be \nconstructed in a way that is fair and objective. The readers should be allowed to make \ntheir own judgments, instead of being manipulated by misleading graphs. We present \ntwo of the ways in which graphs are commonly used to misrepresent data.\nNonzero Vertical Axis\nA common deceptive graph involves using a vertical scale that starts at some value \ngreater than zero to exaggerate differences between groups.\nFIGURE 2-11  Relative Frequency Polygons for Full IQ \nScores of High and Low Lead Groups\nNONZERO AXIS: Always examine a graph carefully to see whether a vertical axis \nbegins at some point other than zero so that differences are exaggerated.\nEXAMPLE 8  Nonzero Axis\nFigure 2-12(a) and Figure 2-12(b) are based on the same data from a clinical trial of \nOxyContin (oxycodone), a drug used to treat moderate to severe pain. The results of \nthat clinical trial included the percentage of subjects who experienced nausea in an \nOxyContin treatment group and the percentage in a group given a placebo.\n \nFIGURE 2-12 Nausea in a Clinical Trial\n(a)\n(b)\ncontinued\n\n62 \nCHAPTER 2 Exploring Data with Tables and Graphs\nPictographs\nDrawings of objects, called pictographs, are often misleading. Data that are one-\ndimensional in nature (such as budget amounts) are often depicted with two-dimension",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 77
  },
  {
    "child_id": "251519f6-ff66-4243-bd2e-c3ba3c8cfe77",
    "parent_id": "4c7e084a-4ad2-4287-a15d-80e8f5dfec34",
    "text": " to treat moderate to severe pain. The results of \nthat clinical trial included the percentage of subjects who experienced nausea in an \nOxyContin treatment group and the percentage in a group given a placebo.\n \nFIGURE 2-12 Nausea in a Clinical Trial\n(a)\n(b)\ncontinued\n\n62 \nCHAPTER 2 Exploring Data with Tables and Graphs\nPictographs\nDrawings of objects, called pictographs, are often misleading. Data that are one-\ndimensional in nature (such as budget amounts) are often depicted with two-dimensional \nobjects (such as dollar bills) or three-dimensional objects (such as stacks of coins, \nhomes, or barrels). With pictographs, artists can create false impressions that grossly \ndistort differences by using these simple principles of basic geometry: (1) When you \ndouble each side of a square, its area doesn\u2019t merely double; it increases by a factor \nof four. (2) When you double each side of a cube, its volume doesn\u2019t merely double; \nit increases by a factor of eight.\nBy using a vertical scale that starts at 10% instead of 0%, Figure 2-12(a) \ngrossly exaggerates the difference between the two groups. Figure 2-12(a) makes it \nappear that those using OxyContin experience nausea at a rate that is about 12 times \nhigher than the rate for those using a placebo, but Figure 2-12(b) shows that the true \nratio is about 2:1, not 12:1. Perhaps someone wants to discourage recreational use \nof OxyContin by misleading people into thinking that the problem with nausea is \nmuch greater than it really is. The objective might be sincere, but the use of a mis-\nleading graph is not the way to achieve that objective.\nPICTOGRAPHS: When examining data depicted with a pictograph, determine \nwhether the graph is misleading because objects of area or volume are used to \ndepict amounts that are actually one-dimensional. (Histograms and bar charts \nrepresent one-dimensional data with two-dimensional bars, but they use bars with \nthe same width so that the graph is not misleading.)\nEXAMPLE 9  Pictograph of Cigarette Smokers\nRefer to Figure 2-13 and see that the larger cigarette is about twice as long, twice as \ntall, and twice as deep as the smaller cigarette, so the volume of the larger cigarette \nis about eight times the volume of the smaller cigarette. (The data are from the Cen-\nters for Disease Control and Prevention.) The larger cigarette appears to be eight \ntimes as large as the smaller cigarette, but the actual percentages show that the 37% \nsmoking rate in 1970 is about twice that of the 18% rate in 2013.\n \nFIGURE 2-13 Smoking by U.S. Adults\n1970: 37% of U.S. adults smoked.       2013: 18% of U.S. adults smoked.\n\n2-3 Graphs That Enlighten and Graphs That Deceive \n63\nConcluding Thoughts\nIn addition to the graphs we have discussed in this section, there are many other useful \ngraphs\u2014some of which have not yet been created. The world desperately needs more \npeople who can create original graphs that enlighten us about the nature of data. In \nThe Visual Display of Quantitative ",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 77
  },
  {
    "child_id": "78f60b4f-a03b-4684-a3fb-5a5870fae4e9",
    "parent_id": "4c7e084a-4ad2-4287-a15d-80e8f5dfec34",
    "text": " the 18% rate in 2013.\n \nFIGURE 2-13 Smoking by U.S. Adults\n1970: 37% of U.S. adults smoked.       2013: 18% of U.S. adults smoked.\n\n2-3 Graphs That Enlighten and Graphs That Deceive \n63\nConcluding Thoughts\nIn addition to the graphs we have discussed in this section, there are many other useful \ngraphs\u2014some of which have not yet been created. The world desperately needs more \npeople who can create original graphs that enlighten us about the nature of data. In \nThe Visual Display of Quantitative Information, Edward Tufte offers these principles:\n \n\u25a0For small data sets of 20 values or fewer, use a table instead of a graph.\n \n\u25a0A graph of data should make us focus on the true nature of the data, not on other \nelements, such as eye-catching but distracting design features.\n \n\u25a0Do not distort data; construct a graph to reveal the true nature of the data.\n \n\u25a0Almost all of the ink in a graph should be used for the data, not for other design \nelements.\nGraphing Capabilities\nAccess tech instructions, videos, and data sets at www.TriolaStats.com\nTECH CENTER \nStatistical Literacy and Critical Thinking\n1. Body Temperatures Listed below are body temperatures (\u00b0F) of healthy adults. Why is it \nthat a graph of these data would not be very effective in helping us understand the data?\n98.6 98.6 98.0 98.0 99.0 98.4 98.4 98.4 98.4 98.6\n2. Voluntary Response Data If we have a large voluntary response sample consisting of \nweights of subjects who chose to respond to a survey posted on the Internet, can a graph help to \novercome the deficiency of having a voluntary response sample?\n3. Ethics There are data showing that smoking is detrimental to good health. Given that people \ncould be helped and lives could be saved by reducing smoking, is it ethical to graph the data in \na way that is misleading by exaggerating the health risks of smoking?\n4. CVDOT Section 2-1 introduced important characteristics of data summarized by the acro-\nnym CVDOT. What characteristics do those letters represent, and which graph does the best \njob of giving us insight into the last of those characteristics?\nDotplots. In Exercises 5 and 6, construct the dotplot.\n5. Pulse Rates Listed below are pulse rates (beats per minute) of females selected from Data \nSet 1 \u201cBody Data\u201d in Appendix B. All of those pulse rates are even numbers. Is there a pulse \nrate that appears to be an outlier? What is its value?\n80  94  58  66  56  82  78  86  88  56  36  66  84  76  78  64  66  78  60  64\n6. Diastolic Blood Pressure Listed below are diastolic blood pressure measurements \n(mm Hg) of females selected from Data Set 1 \u201cBody Data\u201d in Appendix B. All of the values are \neven numbers. Are there any outliers? If so, identify their values.\n62 70 72 88 70 66 68 70 82 74 90 62 70 76 90 86 60 78 82 78 84 76 60 64\nStemplots. In Exercises 7 and 8, construct the stemplot.\n7. Pulse Rates Refer to the data listed in Exercise 5. How are the data sorted in the stemplot?\n8. Diastolic Blood Pressure Refer to the data listed in E",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 77
  },
  {
    "child_id": "0e2decdc-b56c-491e-b912-dc5a53dee5ee",
    "parent_id": "4c7e084a-4ad2-4287-a15d-80e8f5dfec34",
    "text": "Listed below are diastolic blood pressure measurements \n(mm Hg) of females selected from Data Set 1 \u201cBody Data\u201d in Appendix B. All of the values are \neven numbers. Are there any outliers? If so, identify their values.\n62 70 72 88 70 66 68 70 82 74 90 62 70 76 90 86 60 78 82 78 84 76 60 64\nStemplots. In Exercises 7 and 8, construct the stemplot.\n7. Pulse Rates Refer to the data listed in Exercise 5. How are the data sorted in the stemplot?\n8. Diastolic Blood Pressure Refer to the data listed in Exercise 6. Identify the two values \nthat are closest to the middle when the data are sorted in order from lowest to highest. (These \nvalues are often used to find the median, which is defined in Section 3-1.)\n2-3 Basic Skills and Concepts",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 77
  },
  {
    "child_id": "aea4a477-b903-4fe5-b995-7cc5abfa81a5",
    "parent_id": "e46b7915-db52-4259-9226-6078c89c1b64",
    "text": "64 \nCHAPTER 2 Exploring Data with Tables and Graphs\nTime-Series Graphs. In Exercises 9 and 10, construct the time-series graph.\n9. Triplets Listed below are the numbers of triplets born in the United States each year beginning \nwith 1995. Is there a trend?\n4551 5298 6148 6919 6742 6742 6885 6898 7110\n6750 6208 6118 5967 5877 5905 5153 5137 4598\n10. Drunk Driving Fatalities Listed below are annual fatality rates (per 100,000 population) \nfrom drunk driving. The first entry represents the year 1991. Is there a trend? Any explanation?\n6.3 5.5 5.3 5.1 5.1 5.1 4.8 4.6 4.6 4.7 4.7\n4.7 4.5 4.5 4.6 4.5 4.3 3.9 3.5 3.3 3.2 3.3\nPareto Charts. In Exercises 11 and 12 construct the Pareto chart.\n11. Journal Retractions In a study of retractions in biomedical journals, 436 were due to \nerror, 201 were due to plagiarism, 888 were due to fraud, 291 were duplications of publica-\ntions, and 287 had other causes (based on data from \u201cMisconduct Accounts for the Majority \nof Retracted Scientific Publications,\u201d by Fang, Steen, Casadevall, Proceedings of the National \nAcademy of Sciences of the United States of America, Vol. 110, No. 3). Among such retrac-\ntions, does misconduct (fraud, duplication, plagiarism) appear to be a major factor?\n12. Getting a Job In a survey, subjects seeking a job were asked to whom they send a thank-\nyou note after having a job interview. Results were as follows: 40 said only the person they \nspent the most time with, 40 said only the most senior-level person, 396 said everyone that they \nmet, 15 said the person that they had the best conversation with, and 10 said that they don\u2019t \nsend thank-you notes (based on data from TheLadders.com). Comment on the results.\nPie Charts. In Exercises 13 and 14, construct the pie chart.\n13. Journal Retractions Use the data from Exercise 11 \u201cJournal Retractions.\u201d\n14. Getting a Job Use the data from Exercise 12 \u201cGetting a Job.\u201d\nFrequency Polygon. In Exercises 15 and 16, construct the frequency polygons.\n15. Pulse Rates of Males Use the frequency distribution for the pulse rates of males from \nExercise 13 in Section 2-1 on page 49 to construct a frequency polygon. Comment on the \nshape of the distribution.\n16. Pulse Rates of Females Use the frequency distribution for the pulse rates of females \nfrom Exercise 14 in Section 2-1 on page 49 to construct a frequency polygon. Comment on the \nshape of the distribution.\nDeceptive Graphs. In Exercises 17\u201318, identify how the graph is deceptive.\n17.\u00a0Self-Driving Vehicles In a survey of adults, subjects were asked if they felt comfortable \nbeing in a self-driving vehicle. The accompanying graph depicts the results (based on data from \nTE Connectivity).\n\n2-4 Scatterplots, Correlation, and Regression \n65\n18. Cost of Giving Birth According to the Agency for Healthcare Research and Quality \nHealthcare Cost and Utilization Project, the typical cost of a C-section baby delivery is $4500, \nand the typical cost of a vaginal delivery is $2600. See the accompanying illustration",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 82
  },
  {
    "child_id": "2469fd5b-51a3-4484-ab61-d4207cc981a2",
    "parent_id": "e46b7915-db52-4259-9226-6078c89c1b64",
    "text": "survey of adults, subjects were asked if they felt comfortable \nbeing in a self-driving vehicle. The accompanying graph depicts the results (based on data from \nTE Connectivity).\n\n2-4 Scatterplots, Correlation, and Regression \n65\n18. Cost of Giving Birth According to the Agency for Healthcare Research and Quality \nHealthcare Cost and Utilization Project, the typical cost of a C-section baby delivery is $4500, \nand the typical cost of a vaginal delivery is $2600. See the accompanying illustration.\nCost of C-Section Delivery: $4500\nCost of Vaginal Delivery: $2600\nKey Concept This section introduces the analysis of paired (or \u201cbivariate\u201d) sample \ndata, which are data from two different variables that are paired in some way, such \nas the variables of heights and weights from subjects. In Part 1 of this section we dis-\ncuss correlation and the role of a graph called a scatterplot. In Part 2 we provide an \nintroduction to the use of the linear correlation coefficient. In Part 3 we provide a very \nbrief discussion of linear regression, which involves the equation and graph of the \nstraight line that best fits the sample paired data.\nAll of the principles discussed in this section are discussed more fully in Chapter 10, \nbut this section serves as a quick introduction to some important concepts of correlation \nand regression. This section does not include details for executing manual calculations, \nand those calculations are rarely done. Instructions for using technology to obtain results \ncan be found at www.TriolaStats.com; refer to the instructions for Chapter 10.\nPART 1\n Scatterplot and Correlation \nOur objective in this section is to explore whether there is a correlation, or associa-\ntion, between two variables. We begin with basic definitions.\n2-4 \nScatterplots, Correlation, and Regression\nDEFINITIONS\nA correlation exists between two variables when the values of one variable are \nsomehow associated with the values of the other variable.\nA linear correlation exists between two variables when there is a correlation and \nthe plotted points of paired data result in a pattern that can be approximated by a \nstraight line.\nA scatterplot or scatter diagram is a plot of paired (x, y) quantitative data with a \nhorizontal x-axis and a vertical y-axis. The horizontal axis is used for the first vari-\nable (x), and the vertical axis is used for the second variable (y).\n\n66 \nCHAPTER 2 Exploring Data with Tables and Graphs\nA scatterplot can be used as a visual aid in determining whether there is a correlation \n(or relationship) between the two variables. (This issue is discussed at length when the \ntopic of correlation is considered in Section 10-1.)\nCAUTION: The presence of a correlation between two variables is not evidence \nthat one of the variables causes the other. We might find a correlation between beer \nconsumption and weight, but we cannot conclude from the statistical evidence that \ndrinking beer has a direct effect on weight.\nCorrelation does not imply",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 82
  },
  {
    "child_id": "0fc9ad68-692a-4255-921b-b6600a9e6abe",
    "parent_id": "e46b7915-db52-4259-9226-6078c89c1b64",
    "text": "mining whether there is a correlation \n(or relationship) between the two variables. (This issue is discussed at length when the \ntopic of correlation is considered in Section 10-1.)\nCAUTION: The presence of a correlation between two variables is not evidence \nthat one of the variables causes the other. We might find a correlation between beer \nconsumption and weight, but we cannot conclude from the statistical evidence that \ndrinking beer has a direct effect on weight.\nCorrelation does not imply causality!\nEXAMPLE 1  Correlation: Waist and Arm Circumference\nData Set 1 \u201cBody Data\u201d in Appendix B includes waist circumferences (cm) and arm \ncircumferences (cm) of randomly selected adult subjects. Figure 2-14 is a scatter-\nplot of the paired waist>arm measurements. The points show a pattern of increasing \nvalues from left to right. This pattern suggests that there is a correlation or relation-\nship between waist circumferences and arm circumferences.\nEXAMPLE 2  No Correlation: Weight and Pulse Rate\nData Set 1 \u201cBody Data\u201d in Appendix B includes weights (kg) and pulse rates (beats \nper minute) of randomly selected adult subjects. Figure 2-15 is a scatterplot of the \npaired weight>pulse rate measurements. The points in Figure 2-15 do not show any \nobvious pattern, and this lack of a pattern suggests that there is no correlation or re-\nlationship between weights and pulse rates.\nFIGURE 2-14  Waist and Arm Circumferences\nCorrelation: The distinct straight-line pattern of the plotted \npoints suggests that there is a correlation between waist \ncircumferences and arm circumference.\nFIGURE 2-15 Weights and Pulse Rates\nNo Correlation: The plotted points do not show a distinct \npattern, so it appears that there is no correlation between \nweights and pulse rates.\nThe preceding two examples involve making decisions about a correlation \nbased on subjective judgments of scatterplots, but Part 2 introduces the linear corre-\nlation coefficient as a numerical measure that can help us make such decisions more \nobjectively. Using paired data, we can calculate the value of the linear correlation \ncoefficient r.\n\n2-4 Scatterplots, Correlation, and Regression \n67\nPART 2\nLinear Correlation Coefficient r\nUsing paired data, we can calculate the value of the linear correlation coefficient r.\nDEFINITION\nThe linear correlation coefficient is denoted by r, and it measures the strength of \nthe linear association between two variables.\nThe value of a linear correlation coefficient r can be manually computed by applying \nFormula 10-1 or Formula 10-2 found in Section 10-1 on page 447, but in practice, r is \nalmost always found by using technology.\nUsing r for Determining Correlation\nThe computed value of the linear correlation coefficient is always between -1 and \n1. A value of exactly -1 or 1 implies that all of the data fall exactly on a line, which \nreflects a perfect correlation. If r is close to -1 or close to 1, there appears to be a \nstrong correlation, but if r is close to 0, ",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 82
  },
  {
    "child_id": "089bedbc-7b98-45c4-bbfe-3b655eb6c5f6",
    "parent_id": "e46b7915-db52-4259-9226-6078c89c1b64",
    "text": "nually computed by applying \nFormula 10-1 or Formula 10-2 found in Section 10-1 on page 447, but in practice, r is \nalmost always found by using technology.\nUsing r for Determining Correlation\nThe computed value of the linear correlation coefficient is always between -1 and \n1. A value of exactly -1 or 1 implies that all of the data fall exactly on a line, which \nreflects a perfect correlation. If r is close to -1 or close to 1, there appears to be a \nstrong correlation, but if r is close to 0, there appears to be a weak or no linear cor-\nrelation. For the data depicted in the scatterplot of Figure 2-14, r = 0.802 (somewhat \nclose to 1), and the data in the scatterplot of Figure 2-15 result in r = 0.082 (pretty \nclose to 0). These descriptions of \u201cclose to\u201d -1 or 1 or 0 are vague, but there are other \nobjective criteria discussed in Chapter 10. See the following example illustrating the \ninterpretation of the linear correlation coefficient r.\nTABLE 2-10 Shoe Print Lengths and Heights of Males\nShoe Print Length (cm)\n29.7\n29.7\n31.4\n31.8\n27.6\nHeight (cm)\n175.3\n177.8\n185.4\n175.3\n172.7\nEXAMPLE 3   Correlation Between Shoe Print  \nLengths and Heights?\nConsider the data in Table 2-10 (using data from Data Set 7 \u201cFoot and Height\u201d in \nAppendix B). From the accompanying scatterplot of the paired data in Table 2-10, it \nisn\u2019t very clear whether there is a linear correlation. The Statdisk display of the results \nshows that the linear correlation coefficient has the value of r = 0.591 (rounded).\nPolice Deaths in Car \nChases\nUSA Today \ninvestigated \nthe annual \nreporting of \nthe numbers of \npolice who were \nkilled during \ncar chases. It was found that the \nFederal Bureau of Investigation \n(FBI) counted 24 deaths in the \npast 35 years, but other records \nshow that there were 371 deaths \nduring that time period. USA \nToday reporter Thomas Frank \nwrote that \u201cthe undercount is one \nof the most extreme examples of \nthe federal government\u2019s inability \nto accurately track violent deaths \nand has led the FBI to minimize \nthe danger of police chasing \nmotorists.\u201d Apparently, the FBI \nwas categorizing these deaths \nas automobile accidents instead \nof designating them as police \ndeaths that occurred during a car \nchase.\nStatdisk\n\n68 \nCHAPTER 2 Exploring Data with Tables and Graphs\nIn Example 3, we know from the Statdisk display that using the five pairs of data from \nTable 2-10, the linear correlation coefficient is computed to be r = 0.591. The value \nof r = 0.591 is not very close to 0 or 1, so based on that value and the displayed scat-\nterplot, it does not appear that there is a strong correlation between shoeprint lengths \nand heights of males.\nEXAMPLE 4   Correlation Between Shoe Print Lengths  \nand Heights?\nExample 3 used only five pairs of data from Data Set 7 \u201cFoot and Height\u201d in Appendix B. \nIf we use the shoe print lengths and heights from all of the 40 subjects listed in Data Set 7 \nin Appendix B, we get the scatterplot shown in Figure 2-16 and we get the Min",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 82
  },
  {
    "child_id": "7e14d33a-a627-4de8-b7da-5e5f1c9cca00",
    "parent_id": "e46b7915-db52-4259-9226-6078c89c1b64",
    "text": "se to 0 or 1, so based on that value and the displayed scat-\nterplot, it does not appear that there is a strong correlation between shoeprint lengths \nand heights of males.\nEXAMPLE 4   Correlation Between Shoe Print Lengths  \nand Heights?\nExample 3 used only five pairs of data from Data Set 7 \u201cFoot and Height\u201d in Appendix B. \nIf we use the shoe print lengths and heights from all of the 40 subjects listed in Data Set 7 \nin Appendix B, we get the scatterplot shown in Figure 2-16 and we get the Minitab results \nshown in the accompanying display. The scatterplot does show a distinct pattern instead of \nhaving points scattered about willy-nilly. Also, we see that the value of the linear correla-\ntion coefficient is r = 0.813. Because r = 0.813 is reasonably close to 1 and because of \nthe pattern of points in the scatterplot, it appears that there is a linear  correlation between \nshoe print lengths and heights.\nIn Example 3 with only five pairs of data, we did not have enough evidence to \nconclude that there is a linear correlation, but in this example with 40 pairs of data, it \ndoes appear that there is a linear correlation between shoe print lengths and heights.\nPART 3\n Regression \nWhen we do conclude that there appears to be a linear correlation between two vari-\nables (as in Example 4), we can find the equation of the straight line that best fits the \nsample data, and that equation can be used to predict the value of one variable when \ngiven a specific value of the other variable. Based on the results from Example 4, we \ncan predict someone\u2019s height given the length of their shoe print (which may have \nbeen found at a crime scene).\nInstead of using the straight-line equation format of y = mx + b that we have all \nlearned in prior math courses, we use the format that follows.\nFIGURE 2-16 Scatterplot of 40 Pairs of Data\nMinitab",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 82
  },
  {
    "child_id": "1bc77b2b-c977-4805-970f-88f3292a9c1e",
    "parent_id": "4d5b70e1-b895-40b5-a430-e7ad7b32bb27",
    "text": "2-4 Scatterplots, Correlation, and Regression \n69\nThe regression equation\nyn = b0 + b1x\nalgebraically describes the regression line.\nSection 10-2 gives a good reason for using the format of yn = b0 + b1x instead of \nthe format of y = mx + b. Section 10-2 also provides formulas that could be used to \nidentify the values of the y-intercept b0 and the slope b1, but those values are usually \nfound by using technology.\nDEFINITION\nGiven a collection of paired sample data, the regression line (or line of  best fit or \nleast-squares line) is the straight line that \u201cbest\u201d fits the scatterplot of the data. (The \nspecific criterion for the \u201cbest\u201d-fitting straight line is the \u201cleast squares\u201d property \ndescribed in Section 10-2.)\nFIGURE 2-17 Regression Line\nEXAMPLE 5  Regression Line\nExample 4 included a scatterplot of the 40 pairs of shoe print lengths and heights \nfrom Data Set 7 \u201cFoot and Height\u201d in Appendix B. Figure 2-17 shown here is that \nsame scatterplot with the graph of the regression line included. Also shown is the \nStatdisk display from the 40 pairs of data.\nFrom the Statdisk display, we see that the general form of the regression equa-\ntion has a y-intercept of b0 = 80.9 (rounded) and slope b1 = 3.22 (rounded), so the \nequation of the regression line shown in Figure 2-17 is yn = 80.9 + 3.22x. It might \nbe helpful to express that equation more clearly by using the names of the variables:\nHeight = 80.9 + 3.22 1Shoe Print Length2\nNote that the equation shows the y-intercept of 80.9 that does not appear on the ver-\ntical scale in the graph. The leftmost vertical scale in Figure 2-19 is not the actual \ny-axis that passes through 0 on the x-axis. If the graph were extended to the left, the \nregression line would intercept the actual y-axis at the height of y = 80.9 cm.\nStatdisk\n\n70 \nCHAPTER 2 Exploring Data with Tables and Graphs\nStatistical Literacy and Critical Thinking\n1. Linear Correlation In this section we use r to denote the value of the linear correlation co-\nefficient. Why do we refer to this correlation coefficient as being linear?\n2. Causation A study has shown that there is a correlation between body weight and blood \npressure. Higher body weights are associated with higher blood pressure levels. Can we con-\nclude that gaining weight is a cause of increased blood pressure?\n3. Scatterplot What is a scatterplot and how does it help us?\n4. Estimating r For each of the following, estimate the value of the linear correlation coeffi-\ncient r for the given paired data obtained from 50 randomly selected adults.\na. Their heights are measured in inches (x) and those same heights are recorded in centimeters (y).\nb. Their IQ scores (x) are measured and their heights (y) are measured in centimeters.\nc. Their pulse rates (x) are measured and their IQ scores are measured (y).\nd. Their heights (x) are measured in centimeters and those same heights are listed again, but \nwith negative signs (y) preceding each of these second listings.\nScatterplot. In Exerc",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 87
  },
  {
    "child_id": "25307ee2-520b-4a5d-8ab6-36afcff70db0",
    "parent_id": "4d5b70e1-b895-40b5-a430-e7ad7b32bb27",
    "text": " paired data obtained from 50 randomly selected adults.\na. Their heights are measured in inches (x) and those same heights are recorded in centimeters (y).\nb. Their IQ scores (x) are measured and their heights (y) are measured in centimeters.\nc. Their pulse rates (x) are measured and their IQ scores are measured (y).\nd. Their heights (x) are measured in centimeters and those same heights are listed again, but \nwith negative signs (y) preceding each of these second listings.\nScatterplot. In Exercises 5\u20138, use the sample data to construct a scatterplot. Use the first vari-\nable for the x-axis. Based on the scatterplot, what do you conclude about a linear correlation?\n5.\u00a0Brain Volume and IQ The table lists brain volumes (cm3) and IQ scores of five males (from \nData Set 9 \u201cIQ and Brain Size\u201d in Appendix B).\nBrain volume (cm3)\n1173\n1067\n1347\n1029\n1204\nIQ\n 101\n  93\n  94\n  97\n 113\n6. Bear Measurements The table lists chest sizes (distance around chest in inches) and \nweights (pounds) of anesthetized bears that were measured (from Data Set 11 in Appendix B).\nChest (in.)\n26\n 45\n 54\n 49\n 35\n 41\n 41\nWeight (lb)\n80\n344\n416\n348\n166\n220\n262\n7. Body Temperatures The table lists body temperatures (\u00b0F) of seven healthy adults at 8 AM on \none day and at 8 AM  on the following day (from Data Set 2 \u201cBody Temperatures\u201d in Appendix B).\nDay 1  98.6  97.4  98.2  98.2  98.2  96.6  97.4\nDay 2  97.8  97.0  97.0  96.6  97.0  96.8  96.6\n8. Heights of Fathers and Sons The table lists heights (in.) of fathers and the heights (in.) of \ntheir first sons (from Francis Galton).\nHeight of father (in.)\n73.0\n75.5\n75.0\n75.0\n75.0\n74.0\n74.0\n73.0\n73.0\n78.5\nHeight of first son (in.)\n74.0\n73.5\n71.0\n70.5\n72.0\n76.5\n74.0\n71.0\n72.0\n73.2\nLinear Correlation Coefficient. In Exercises 9\u201312, the linear correlation coefficient r is \nprovided. What do you conclude about a linear correlation?\n9. Using the data from Exercise 5 \u201cBrain Volume and IQ,\u201d the linear correlation coefficient is \nr = 0.127.\n10.\u00a0Using the data from Exercise 6 \u201cBear Measurements,\u201d the linear correlation coefficient is \nr = 0.980.\n2-4 Basic Skills and Concepts\n\n11. Using the data from Exercise 7 \u201cBody Temperatures,\u201d the linear correlation coefficient is \nr = 0.520.\n12. Using the data from Exercise 8 \u201cHeights of Fathers and Sons,\u201d the linear correlation coef-\nficient is r = -0.017.\nChapter Quick Quiz\n1. BAC When constructing a table representing the frequency distribution of blood alcohol \ncontent (g>dL) of drunk drivers involved in fatal car crashes, the first two classes of a fre-\nquency distribution are 0.08 \u2013 0.11 and 0.12 \u2013 0.15. What is the class width?\n2. BAC Using the same first two classes from Exercise 1, identify the class boundaries of the \nfirst class.\n3. BAC The first class described in Exercise 1 has a frequency of 36. If you know only the class \nlimits given in Exercise 1 and the frequency of 36, can you identify the original 36 data values?\n4. BAC A stemplot is created from the ages of drunk drivers involved in fat",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 87
  },
  {
    "child_id": "e133b215-ace5-4800-8ab2-87dd7cfa19e2",
    "parent_id": "4d5b70e1-b895-40b5-a430-e7ad7b32bb27",
    "text": "r crashes, the first two classes of a fre-\nquency distribution are 0.08 \u2013 0.11 and 0.12 \u2013 0.15. What is the class width?\n2. BAC Using the same first two classes from Exercise 1, identify the class boundaries of the \nfirst class.\n3. BAC The first class described in Exercise 1 has a frequency of 36. If you know only the class \nlimits given in Exercise 1 and the frequency of 36, can you identify the original 36 data values?\n4. BAC A stemplot is created from the ages of drunk drivers involved in fatal car crashes and \nthe first row is 1 | 67889. Identify the values represented by that row.\n5. Reaction Times A large sample is randomly selected from a normally distributed popula-\ntion of reaction times, and a histogram is constructed from a frequency distribution. What is the \nshape of the histogram?\n6. Tylenol In testing samples of regular Tylenol pills to verify that they have close to the de-\nsired amount of 325 mg of acetaminophen, which important characteristic of data is missing \nfrom this list: center, distribution, outliers, changes over time?\n7. Tylenol A quality control manager wants to monitor the production of regular Tylenol pills \nto be sure that the mean amount of acetaminophen does not change over time. Which of the fol-\nlowing graphs is most helpful for that purpose: histogram, Pareto chart, pie chart, scatterplot, \ntime-series graph, dotplot?\n8. Blood Pressure In an investigation of the relationship between systolic blood pressure and \ndiastolic blood pressure, which of the following graphs is most helpful: histogram; pie chart; \nscatterplot; stemplot; dotplot?\n9. Blood Pressure Thing The W. A. Baum Company manufactures sphygmomanometers \nused to measure blood pressure. Quality control managers at such companies monitor defects \nand identify various causes, including worn machinery, human error, bad supplies, and packag-\ning mistreatment. Which of the following graphs would be best for describing the causes of \ndefects: histogram, scatterplot, Pareto chart, dotplot, stemplot?\n10. Frequency Distribution and Histogram What is the basic difference between a fre-\nquency distribution and a histogram?\n1. Frequency Distribution of Body Temperatures Construct a frequency distribution of the \n20 body temperatures 1\u00b0F2 listed below. (These data are from Data Set 2 \u201cBody Temperatures\u201d \nin Appendix B.) Use a class width of 0.5\u00b0F and a starting value of 97.0\u00b0F.\n97.1 97.2 97.5 97.6 97.6 97.8 98.0 98.0 98.2 98.2\n98.2 98.3 98.4 98.6 98.6 98.7 98.7 98.9 99.1 99.4\nReview Exercises\nCHAPTER 2 Review Exercises \n71\n\n72 \nCHAPTER 2 Exploring Data with Tables and Graphs\n2. Histogram of Body Temperatures Construct the histogram that corresponds to the fre-\nquency distribution from Exercise 1. Use class midpoint values for the horizontal scale. Does \nthe histogram suggest that the data are from a population having a normal distribution? Why or \nwhy not?\n3. Dotplot of Body Temperatures Construct a dotplot of the body temperatures listed in \n Exercise 1. Which do",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 87
  },
  {
    "child_id": "9620d819-ab53-419d-8394-379ed0008a8f",
    "parent_id": "4d5b70e1-b895-40b5-a430-e7ad7b32bb27",
    "text": ".4\nReview Exercises\nCHAPTER 2 Review Exercises \n71\n\n72 \nCHAPTER 2 Exploring Data with Tables and Graphs\n2. Histogram of Body Temperatures Construct the histogram that corresponds to the fre-\nquency distribution from Exercise 1. Use class midpoint values for the horizontal scale. Does \nthe histogram suggest that the data are from a population having a normal distribution? Why or \nwhy not?\n3. Dotplot of Body Temperatures Construct a dotplot of the body temperatures listed in \n Exercise 1. Which does a better job of illustrating the distribution of the data: the histogram \nfrom Exercise 2 or the dotplot?\n4. Stemplot of Body Temperatures Construct a stemplot of the body temperatures listed in \nExercise 1. Are there any outliers?\n5. Bears Listed below are the neck sizes (in.) and weights (lb) of bears (from Data Set 11 \n\u201cBear Measurements\u201d in Appendix B). Construct a scatterplot. Based on the graph, does there \nappear to be a relationship between neck sizes and weights of bears?\nNeck Size (in.)   16   28   31   31.5   22   21   26.5    27   20   18\nWeight (lb)     80  344  416  348.0  166  220  262.0  360  204  144\n6. Monitoring Weight\na. After collecting the average (mean) weight of adult males in the United States for each of the \nmost recent 100 years, we want to construct the graph that is most appropriate for these data. \nWhich graph is best?\nb. After collecting the average (mean) weight and height of males for the most recent 100 years, \nwe want to construct a graph to investigate the association between those two variables. Which \ngraph is best?\nc. An investigation of health problems associated with overweight males includes heart dis-\nease, stroke, high blood pressure, diabetes, and breathing problems. If we want to construct a \ngraph that illustrates the relative importance of these adverse effects, which graph is best?\n7. Medical School Enrollees The accompanying graph illustrates male and female enrollees \nin U.S. medical schools in a recent year. What is wrong with the graph?\nCumulative Review Exercises\n1. Hygiene Listed below are times (minutes) spent on hygiene and grooming in the morning \nby randomly selected subjects (based on data from a Svenska Cellulosa Aktiebolaget survey). \nConstruct a table representing the frequency distribution. Use the classes 0\u20139, 10\u201319, and so on.\n0  5  12  15  15  20  22  24  25  25  25  27  27  28  30  30  35  35  40  45\n2. Hygiene Histogram Use the frequency distribution from Exercise 1 to construct a histo-\ngram. Use class midpoint values for the horizontal scale. Based on the result, do the data ap-\npear to be from a population with a normal distribution? Explain.\n3. Hygiene Stemplot Use the data from Exercise 1 to construct a stemplot.\n4. Analysis of Last Digits Use the data from Exercise 1 and construct a frequency distribution \nof the last digits of the grooming times. What does the result suggest about the grooming times?\n5. Hygiene Refer to the grooming times given in Exercise 1.\na. What is the lev",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 87
  },
  {
    "child_id": "21f3e6ce-7b65-48d9-bf56-e8e4b1483b80",
    "parent_id": "4d5b70e1-b895-40b5-a430-e7ad7b32bb27",
    "text": "Use class midpoint values for the horizontal scale. Based on the result, do the data ap-\npear to be from a population with a normal distribution? Explain.\n3. Hygiene Stemplot Use the data from Exercise 1 to construct a stemplot.\n4. Analysis of Last Digits Use the data from Exercise 1 and construct a frequency distribution \nof the last digits of the grooming times. What does the result suggest about the grooming times?\n5. Hygiene Refer to the grooming times given in Exercise 1.\na. What is the level of measurement of those times? (nominal, ordinal, interval, ratio)\nb. Are the exact unrounded grooming times discrete data or continuous data?\nc. Are the grooming times categorical data?\nd. The average (mean) of the grooming times is 24.3 minutes. Is that value a statistic or a \n parameter?",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 87
  },
  {
    "child_id": "b73365a2-7b7a-49c3-9277-99ba8f4bbbe9",
    "parent_id": "e200d1e9-8d37-435d-84c2-f36ff9e1ce8b",
    "text": "6. Mother, Daughter Heights Refer to the following list of heights of mothers and the heights \nof their first daughters (from Data Set 6 \u201cFamily Heights\u201d in Appendix B). What issue would \nbe investigated with these data? Construct the best graph for investigating that issue. What does \nthat graph suggest?\nMother\u2019s Height (in.)    67.0  66.5  64  64  58.5  68.0  62  66.5  65.0  64.5\nDaughter\u2019s Height (in.)  69.2  65.5  68  67  66.5  70.5  68  66.7  68.7  66.5\nTechnology Project\nIt was stated in this chapter that the days of charming and primitive hand-drawn graphs are well \nbehind us, and technology now provides us with powerful tools for generating a wide variety of \ndifferent graphs. This project therefore serves as a good preparation for professional presenta-\ntions that will be inevitably made in the future.\nThe complete data sets in Appendix B can be downloaded from www.TriolaStats.com. \nThey can be opened by statistical software packages, such as Minitab, Excel, SPSS, and JMP. \nStatdisk already includes the data sets. Use a statistical software package to open Data Set 1 \n\u201cBody Data.\u201d Use this statistical software with the methods of this chapter to describe, explore, \nand compare the ages of males and females. Does there appear to be a difference? Reports \nof randomized clinical trials typically include \u201cbaseline characteristics\u201d of the subjects in the \ndifferent groups so that we can see whether the groups are similar in ways that are important. \nBased on ages, do the males and females in Data Set 1 appear to be similar? (Later chapters \nwill present more formal methods for making such comparisons.)\nFROM DATA TO DECISION\nCar crash fatalities are tragic losses of lives and they are \ndevastating to the families involved. Listed below are the \nages of 100 randomly selected drivers who were killed in car \ncrashes. Also given is a frequency distribution of licensed \ndrivers by age (based on recent data from the Insurance Insti-\ntute for Highway Safety).\nAges (in years) of Drivers Killed in Car Crashes\n \nAge\nLicensed Drivers  \n(millions)\n41 43 38 31 57 29 65 18 42 47\n16\u201319\n 9.7\n69 50 22 60 30 30 34 18 18 42\n20\u201329\n33.6\n18 16 74 25 41 43 50 34 54 45\n30\u201339\n40.2\n32 20 50 36 27 59 19 23 57 74\n40\u201349\n40.3\n27 38 29 24 56 72 21 22 74 20\n50\u201359\n29.6\n43 34 38 62 39 45 56 70 68 75\n60\u201369\n18.3\n37 49 25 24 21 25 31 21 76 69\n70\u201379\n13.4\n28 62 69 26 22 62 64 24 56 70\n80\u201389\n 5.4\n21 52 32 30 38 73 35 52 38 29\n23 17 44 25 24 70 16 49 45 34\nAnalysis\nConvert the given frequency distribution to a relative fre-\nquency distribution, then create a relative frequency distri-\nbution using the 100 ages of drivers killed in car crashes. \nCompare the two relative frequency distributions. Which age \ncategories appear to have substantially greater proportions \nof fatalities than the proportions of licensed drivers? If you \nwere responsible for establishing the rates for auto insurance, \nwhich age categories would you select for higher rates? Con-\nstruct a graph that is effective ",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 91
  },
  {
    "child_id": "71862183-ab68-4638-8056-6362623975e8",
    "parent_id": "e200d1e9-8d37-435d-84c2-f36ff9e1ce8b",
    "text": "distribution to a relative fre-\nquency distribution, then create a relative frequency distri-\nbution using the 100 ages of drivers killed in car crashes. \nCompare the two relative frequency distributions. Which age \ncategories appear to have substantially greater proportions \nof fatalities than the proportions of licensed drivers? If you \nwere responsible for establishing the rates for auto insurance, \nwhich age categories would you select for higher rates? Con-\nstruct a graph that is effective in identifying age categories \nthat are more prone to fatal car crashes.\nCHAPTER 2 Technology Project \n73\n\n74 \nCHAPTER 2 Exploring Data with Tables and Graphs\nCooperative Group Activities\n1. In-class activity In class, each student should record two pulse rates by counting the \nnumber of heartbeats in 1 minute. The first pulse rate should be measured while the student \nis seated, and the second pulse rate should be measured while the student is standing. Us-\ning the pulse rates measured while seated, construct a frequency distribution and histogram \nfor the pulse rates of males, and then construct another frequency distribution and histo-\ngram for the pulse rates of females. Using the pulse rates measured while standing, construct \na frequency distribution and histogram for the pulse rates of males, and then construct another \nfrequency distribution and histogram for the pulse rates of females. Compare the results. Do \nmales and females appear to have different pulse rates? Do pulse rates measured while seated \nappear to be different from pulse rates measured while standing? Use an appropriate graph to \ndetermine whether there is a relationship between sitting pulse rate and standing pulse rate.\n2. In-class activity Given below are the ages of motorcyclists at the time they were fatally \ninjured in traffic accidents (based on data from the U.S. Department of Transportation). If your \nobjective is to dramatize the dangers of motorcycles for young people, which graph would be \nmost effective: histogram, Pareto chart, pie chart, dotplot, stemplot, frequency polygon, time-\nseries graph? Construct the graph that best meets that objective. Is it okay to deliberately distort \ndata if the objective is one such as saving lives of motorcyclists?\n17 38 27 14 18 34 16 42 28 24 40 20 23 31\n37 21 30 25 17 28 33 25 23 19 51 18 29\n3. Out-of-class activity In each group of three or four students, select one of the following \nitems and construct a graph that is effective in addressing the question:\na. Is there a difference between the body mass index (BMI) values for men and for women? \n(See Data Set 1 \u201cBody Data\u201d in Appendix B.)\nb. Is there a relationship between the heights of sons (or daughters) and the heights of their \nfathers (or mothers)? (See Data Set 6 \u201cFamily Heights\u201d in Appendix B.)\n4. Out-of-class activity Search the Internet to find an example of a graph that is misleading. \nDescribe how the graph is misleading. Redraw the graph so that it depicts the informati",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 91
  },
  {
    "child_id": "d2bcc811-eade-41c6-8579-d6d7d08480d0",
    "parent_id": "e200d1e9-8d37-435d-84c2-f36ff9e1ce8b",
    "text": "g the question:\na. Is there a difference between the body mass index (BMI) values for men and for women? \n(See Data Set 1 \u201cBody Data\u201d in Appendix B.)\nb. Is there a relationship between the heights of sons (or daughters) and the heights of their \nfathers (or mothers)? (See Data Set 6 \u201cFamily Heights\u201d in Appendix B.)\n4. Out-of-class activity Search the Internet to find an example of a graph that is misleading. \nDescribe how the graph is misleading. Redraw the graph so that it depicts the information cor-\nrectly. If possible, please submit your graph to www.TriolaStats.com.\n5. Out-of-class activity Find Charles Joseph Minard\u2019s graph describing Napoleon\u2019s march to \nMoscow and back, and explain why Edward Tufte says that \u201cit may well be the best graphic \never drawn.\u201d (See The Visual Display of Quantitative Information by Edward Tufte, Graphics \nPress). Minard\u2019s graph can be seen at www.TriolaStats.com under \u201cTextbook Supplements.\u201d\n6. Out-of-class activity In The Visual Display of Quantitative Information by Edward Tufte \n(Graphics Press), find the graph that appeared in American Education, and explain why Tufte \nsays that \u201cthis may well be the worst graphic ever to find its way into print.\u201d The graph can be \nseen at www.TriolaStats.com under \u201cTextbook Supplements.\u201d Construct a graph that is effec-\ntive in depicting the same data.\n\n75\nCHAPTER \nPROBLEM\nData Set 1 \u201cBody Data\u201d in Appendix B includes pulse rates \nof men and women. The full data set contains measurements \nfrom 300 adults, and the first 5 cases are printed in Appendix B. \nFigure 3-1 shows dotplots of the pulse rates categorized ac-\ncording to gender. Close examination of Figure 3-1 reveals \nthat the pulse rates consist of even numbers only. This sug-\ngests that the pulse rates were measured for 30 seconds, \nand the result was doubled to provide a pulse rate in beats \nper minute. Examine Figure 3-1 closely to see that the pulse \nrates of males tend to be generally a little lower (farther to \nthe left) than the pulse rates of females. This observation \nsuggests a hypothesis: Males have lower pulse rates than \nfemales. A conclusion about such a hypothesis should not \nbe made on the basis of a graph alone. We should consider \nDo men and women have the same pulse rates?\nMeasures of Center\nMeasures of Variation\nMeasures of Relative \nStanding and Boxplots\n3-1\n3-2\n3-3\nDescribing, Exploring, \nand Comparing Data\n3\n\n>>>\nwhether the sample data were collected with an appropriate \nmethod. We should also consider whether the apparent dif-\nference between male pulse rates and female pulse rates is \nactually a significant difference and not just a random chance \nanomaly.\nInstead of relying solely on subjective interpretations of a \ngraph like Figure 3-1, this chapter introduces measures that \nare essential to any study of statistics. This chapter introduces \nthe mean, median, standard deviation, and variance, which \nare among the most important statistics presented in this book, \nand they are among the most",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 91
  },
  {
    "child_id": "543a6848-5111-4628-83bc-1367a3d8b44a",
    "parent_id": "e200d1e9-8d37-435d-84c2-f36ff9e1ce8b",
    "text": "hether the apparent dif-\nference between male pulse rates and female pulse rates is \nactually a significant difference and not just a random chance \nanomaly.\nInstead of relying solely on subjective interpretations of a \ngraph like Figure 3-1, this chapter introduces measures that \nare essential to any study of statistics. This chapter introduces \nthe mean, median, standard deviation, and variance, which \nare among the most important statistics presented in this book, \nand they are among the most important statistics in the study \nof statistics. We will use these statistics for describing, explor-\ning, and comparing the measured pulse rates for males and \nfemales in Data Set 1 \u201cBody Data.\u201d\nCHAPTER OBJECTIVES\nCritical Thinking and Interpretation: Going Beyond Formulas and Arithmetic\nIn this modern biostatistics course, it isn\u2019t so important to memorize formulas or manu-\nally do messy arithmetic. We can get results with a calculator or software so that we \ncan focus on making practical sense of results through critical thinking. Although this \nchapter includes detailed steps for important procedures, it isn\u2019t always necessary to \nmaster those steps. It is, however, generally helpful to perform a few manual calcula-\ntions before using technology, so that understanding is enhanced.\nThe methods and tools presented in this chapter are often called methods of \ndescriptive statistics, because they summarize or describe relevant characteristics of \ndata. In later chapters we use inferential statistics to make inferences, or generaliza-\ntions, about populations. Here are the chapter objectives:\nMeasures of Center\n\u2022 Develop the ability to measure the center of data by finding the mean, median, \nmode, and midrange.\n\u2022 Determine whether an outlier has a substantial effect on the mean and median.\nMeasures of Variation\n\u2022 Develop the ability to measure variation in a set of sample data by finding values of \nthe range, variance, and standard deviation.\n3-1\n3-2\nFIGURE 3-1 Dotplot of Pulse Rates of Males and Females\n76 \nCHAPTER 3 Describing, Exploring, and Comparing Data",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 91
  },
  {
    "child_id": "6b9d1610-57f1-4fe4-8bf2-07112a855a08",
    "parent_id": "da2ff993-134f-4440-8b8f-8afecdd661f2",
    "text": "3-1 Measures of Center \n77\nThere are different approaches for measuring the center, so we have different defi-\nnitions for those different approaches. We begin with the mean.\nMean\nThe mean (or arithmetic mean) is generally the most important of all numerical mea-\nsurements used to describe data, and it is what many people call an average.\nKey Concept The focus of this section is to obtain a value that measures the center of \na data set. We present measures of center, including mean and median. Our objective \nhere is not only to find the value of each measure of center, but also to interpret and \nmake sense of those values. Part 1 of this section includes core concepts that should \nbe understood before considering Part 2.\nPART 1\n Basic Concepts of Measures of Center \nIn Part 1 of this section, we introduce the mean, median, mode, and midrange as dif-\nferent measures of center. Measures of center are widely used to provide representa-\ntive values that \u201csummarize\u201d data sets.\n3-1 \nMeasures of Center\nDEFINITION\nA measure of center is a value at the center or middle of a data set.\nDEFINITION\nThe mean (or arithmetic mean) of a set of data is the measure of center found by \nadding all of the data values and dividing the total by the number of data values.\nImportant Properties of the Mean\n \n\u25a0Sample means drawn from the same population tend to vary less than other mea-\nsures of center.\n \n\u25a0The mean of a data set uses every data value.\n\u2022 Develop the ability to interpret values of the standard deviation by applying the \nrange rule of  thumb to determine whether a particular value is significantly low or \nsignificantly high.\nMeasures of Relative Standing and Boxplots\n\u2022 Develop the ability to compute a z score and use the result to determine whether a \ngiven value x is significantly low or significantly high.\n\u2022 Identify percentile values and quartile values from a set of data.\n\u2022 Develop the ability to construct a boxplot from a set of data.\n3-3\n\u2022 Develop the ability to interpret values of the standard deviation by applying the\nrange rule of  thumb to determine whether a particular value is significantly low or \nw\nsignificantly high.\nMeasures of Relative Standing and Boxplots\n\u2022 Develop the ability to compute a z score and use the result to determine whether a\nz z\ngiven value x is \nx\nsignificantly low or \nw\nsignificantly high.\n\u2022 Identify percentile\nrc\nr\nvalues and quartile values from a set of data.\n\u2022 Develop the ability to construct a boxplot from a set of data.\ncontinued\n\n78 \nCHAPTER 3 Describing, Exploring, and Comparing Data\nCalculation and Notation of the Mean\nThe definition of the mean can be expressed as Formula 3-1, in which the Greek letter \n\u03a3 (uppercase sigma) indicates that the data values should be added, so \u03a3  x represents \nthe sum of all data values. The symbol n denotes the sample size, which is the number \nof data values.\nFORMULA 3-1\nMean = \u03a3  x\nn  d sum of all data values\nd number of data values\nIf the data are a sample from a population, the mea",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 95
  },
  {
    "child_id": "b0e04e1a-ca8e-4f31-956b-1e6a955494a4",
    "parent_id": "da2ff993-134f-4440-8b8f-8afecdd661f2",
    "text": "\n\n78 \nCHAPTER 3 Describing, Exploring, and Comparing Data\nCalculation and Notation of the Mean\nThe definition of the mean can be expressed as Formula 3-1, in which the Greek letter \n\u03a3 (uppercase sigma) indicates that the data values should be added, so \u03a3  x represents \nthe sum of all data values. The symbol n denotes the sample size, which is the number \nof data values.\nFORMULA 3-1\nMean = \u03a3  x\nn  d sum of all data values\nd number of data values\nIf the data are a sample from a population, the mean is denoted by x (pronounced \n\u201cx-bar\u201d); if the data are the entire population, the mean is denoted by m (lowercase \nGreek mu).\nDEFINITION\nA statistic is resistant if the presence of extreme values (outliers) does not cause it \nto change very much.\n \n\u25a0A disadvantage of the mean is that just one extreme value (outlier) can change \nthe value of the mean substantially. (Using the following definition, we say that \nthe mean is not resistant.)\nNOTATION Hint: Sample statistics are usually represented by English letters, \nsuch as x, and population parameters are usually represented by Greek letters, \nsuch as m.\n\u03a3 \ndenotes the sum of a set of data values.\nx \nis the variable usually used to represent the individual data values.\nn \nrepresents the number of data values in a sample.\nN \nrepresents the number of data values in a population.\nx = \u03a3  x\nn  \nis the mean of a set of sample values.\nm = \u03a3  x\nN  \nis the mean of all values in a population.\nEXAMPLE 1  Mean\nData Set 1 \u201cBody Data\u201d in Appendix B includes measures of pulse rates. Find the \nmean of the first five pulse rates for males: 84, 74, 50, 60, 52 (all in beats per minute, \nor BPM).\nSOLUTION\nThe mean is computed by using Formula 3-1. First add the data values, then divide \nby the number of data values:\n x = \u03a3x\nn\n= 84 + 74 + 50 + 60 + 52\n5\n= 320\n5\n = 64.0 BPM\nThe mean of the first five male pulse rates is 64.0 BPM.\n\n3-1 Measures of Center \n79\nMedian\nThe median can be thought of loosely as a \u201cmiddle value\u201d in the sense that about half \nof the values in a data set are less than the median and half are greater than the me-\ndian. The following definition is more precise.\nCAUTION Never use the term average when referring to a measure of center. \nThe word average is often used for the mean, but it is sometimes used for other \nmeasures of center. The term average is not used by statisticians, it is not used in \nprofessional journals, and it will not be used throughout the remainder of this book \nwhen referring to a specific measure of center.\nDEFINITION\nThe median of a data set is the measure of center that is the middle value when the \noriginal data values are arranged in order of increasing (or decreasing) magnitude.\nImportant Properties of the Median\n \n\u25a0The median does not change by large amounts when we include just a few ex-\ntreme values, so the median is a resistant measure of center.\n \n\u25a0The median does not directly use every data value. (For example, if the largest \nvalue is changed to a much larger value, the me",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 95
  },
  {
    "child_id": "a81537db-1795-4344-a24d-11f93616c9fd",
    "parent_id": "da2ff993-134f-4440-8b8f-8afecdd661f2",
    "text": "re of center.\nDEFINITION\nThe median of a data set is the measure of center that is the middle value when the \noriginal data values are arranged in order of increasing (or decreasing) magnitude.\nImportant Properties of the Median\n \n\u25a0The median does not change by large amounts when we include just a few ex-\ntreme values, so the median is a resistant measure of center.\n \n\u25a0The median does not directly use every data value. (For example, if the largest \nvalue is changed to a much larger value, the median does not change.)\nCalculation and Notation of the Median\nThe median of a sample is sometimes denoted by x\u223c (pronounced \u201cx-tilde\u201d) or M or \nMed; there isn\u2019t a commonly accepted notation and there isn\u2019t a special symbol for \nthe median of a population. To find the median, first sort the values (arrange them in \norder), and then follow one of these two procedures:\n1. If the number of data values is odd, the median is the number located in the ex-\nact middle of the sorted list.\n2. If the number of data values is even, the median is found by computing the \nmean of the two middle numbers in the sorted list.\nEXAMPLE 2  Median with an Odd Number of Data Values\nFind the median of the first five pulse rates for males: 84, 74, 50, 60, 52 (all in \nBPM).\nSOLUTION\nFirst sort the data values by arranging them in ascending order, as shown below:\n50 52 60 74 84\nBecause there are 5 data values, the number of data values is an odd number (5), \nso the median is the number located in the exact middle of the sorted list, which is \n60.0 BPM. The median is therefore 60.0 BPM. Note that the median of 60.0 BPM \nis different from the mean of 64.0 BPM found in Example 1.\nWhat the Median Is Not\nHarvard  \nbiologist Ste-\nphen Jay Gould \nwrote, \u201cThe \nMedian Isn\u2019t the \nMessage.\u201d In \nit, he describes \nhow he learned that he had ab-\ndominal mesothelioma, a form of \ncancer. He went to the library to \nlearn more, and he was shocked \nto find that mesothelioma was \nincurable, with a median survival \ntime of only eight months after \nit was discovered. Gould wrote \nthis: \u201cI suspect that most people, \nwithout training in statistics, \nwould read such a statement as \n\u2018I will probably be dead in eight \nmonths\u2019 the very conclusion that \nmust be avoided, since it isn\u2019t \nso, and since attitude (in fighting \nthe cancer) matters so much.\u201d \nGould went on to carefully \ninterpret the value of the median. \nHe knew that his chance of liv-\ning longer than the median was \ngood because he was young, his \ncancer was diagnosed early, and \nhe would get the best medical \ntreatment. He also reasoned that \nsome could live much longer \nthan eight months, and he saw \nno reason why he could not be \nin that group. Armed with this \nthoughtful interpretation of the \nmedian and a strong positive \nattitude, Gould lived for 20 years \nafter his diagnosis. He died of \nanother cancer not related to the \nmesothelioma.\n\n80 \nCHAPTER 3 Describing, Exploring, and Comparing Data\nMode\nThe mode isn\u2019t used much with quantitative data,",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 95
  },
  {
    "child_id": "f5595e89-a235-4e34-8da1-6923b6d776e0",
    "parent_id": "da2ff993-134f-4440-8b8f-8afecdd661f2",
    "text": "agnosed early, and \nhe would get the best medical \ntreatment. He also reasoned that \nsome could live much longer \nthan eight months, and he saw \nno reason why he could not be \nin that group. Armed with this \nthoughtful interpretation of the \nmedian and a strong positive \nattitude, Gould lived for 20 years \nafter his diagnosis. He died of \nanother cancer not related to the \nmesothelioma.\n\n80 \nCHAPTER 3 Describing, Exploring, and Comparing Data\nMode\nThe mode isn\u2019t used much with quantitative data, but it\u2019s the only measure of center \nthat can be used with qualitative data (consisting of names, labels, or categories only).\nEXAMPLE 3  Median with an Even Number of Data Values\nRepeat Example 2 after including the sixth pulse rate of 62 BPM. That is, find the \nmedian of these pulse rates: 84, 74, 50, 60, 52, 62 (all in BPM).\nSOLUTION\nFirst arrange the values in ascending order: 50, 52, 60, 62, 74, 84.\nBecause the number of data values is an even number (6), the median is found by \ncomputing the mean of the two middle numbers, which are 60 and 62.\nMedian = 60 + 62\n2\n= 122\n2\n= 61.0 BPM\nThe median is 61.0 BPM.\nDEFINITION\nThe mode of a data set is the value(s) that occurs with the greatest frequency.\nImportant Properties of the Mode\n \n\u25a0The mode can be found with qualitative data.\n \n\u25a0A data set can have no mode or one mode or multiple modes.\nFinding the Mode: A data set can have one mode, more than one mode, or no mode.\n \n\u25a0When two data values occur with the same greatest frequency, each one is a \nmode and the data set is said to be bimodal.\n \n\u25a0When more than two data values occur with the same greatest frequency, each is \na mode and the data set is said to be multimodal.\n \n\u25a0When no data value is repeated, we say that there is no mode.\nEXAMPLE 4  Mode\nFind the mode of these pulse rates (in BPM):\n58 58 58 58 60 60 62 64\nSOLUTION\nThe mode is 58 BPM, because it is the pulse rate occurring most often (four times).\nIn Example 4, the mode is a single value. Here are other possible circumstances:\nTwo modes:  The pulse rates (BPM) of 58, 58, 58, 60, 60, 60, 62, 64 have two \nmodes: 58 BPM and 60 BPM.\nNo mode: \n The pulse rates of 58, 60, 64, 68, 72 have no mode because no \nvalue is repeated.\n\n3-1 Measures of Center \n81\nMidrange\nAnother measure of center is the midrange.\nDEFINITION\nThe midrange of a data set is the measure of center that is the value midway be-\ntween the maximum and minimum values in the original data set. It is found by add-\ning the maximum data value to the minimum data value and then dividing the sum \nby 2, as in the following formula:\nMidrange = maximum data value + minimum data value\n2\nImportant Properties of the Midrange\n \n\u25a0Because the midrange uses only the maximum and minimum values, it is very \nsensitive to those extremes so the midrange is not resistant.\n \n\u25a0In practice, the midrange is rarely used, but it has three redeeming features:\n1. The midrange is very easy to compute.\n2. The midrange helps reinforce the very important point that ther",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 95
  },
  {
    "child_id": "51286bb6-90d2-40bd-a130-fa8171110529",
    "parent_id": "da2ff993-134f-4440-8b8f-8afecdd661f2",
    "text": "minimum data value and then dividing the sum \nby 2, as in the following formula:\nMidrange = maximum data value + minimum data value\n2\nImportant Properties of the Midrange\n \n\u25a0Because the midrange uses only the maximum and minimum values, it is very \nsensitive to those extremes so the midrange is not resistant.\n \n\u25a0In practice, the midrange is rarely used, but it has three redeeming features:\n1. The midrange is very easy to compute.\n2. The midrange helps reinforce the very important point that there are several \ndifferent ways to define the center of a data set.\n3. The value of the midrange is sometimes used incorrectly for the median, so con-\nfusion can be reduced by clearly defining the midrange along with the median.\nEXAMPLE 5  Midrange\nFind the midrange of these five pulse rates for males used in Example 1: 84, 74, 50, \n60, 52 (BPM).\nSOLUTION\nThe midrange is found as follows:\n Midrange = maximum data value + minimum data value\n2\n = 84 + 50\n2\n= 67.0 BPM\nThe midrange is 67.0 BPM.\nRounding Measures of Center\nWhen calculating measures of center, we often need to round the result. We use the \nfollowing rule.\nROUND-OFF RULES FOR MEASURES OF CENTER:\n \n\u25a0For the mean, median, and midrange, carry one more decimal place than is \npresent in the original set of values.\n \n\u25a0For the mode, leave the value as is without rounding (because values of the \nmode are the same as some of the original data values).",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 95
  },
  {
    "child_id": "d640c60c-f206-446c-abca-8e71d4536efc",
    "parent_id": "382fae27-d28f-448c-b512-42eefd4a918d",
    "text": "82 \nCHAPTER 3 Describing, Exploring, and Comparing Data\nWhen applying any rounding rules, round only the final answer, not intermedi-\nate values that occur during calculations. For example, the mean of 2, 3, and 5 is \n3.333333. . . , which is rounded to 3.3, which has one more decimal place than the origi-\nnal values of 2, 3, and 5. As another example, the mean of 80.4 and 80.6 is 80.50 (one \nmore decimal place than was used for the original values). Because the mode is one or \nmore of the original data values, we do not round values of the mode; we simply use \nthe same original values that are modes.\nCritical Thinking\nWe can always calculate measures of center from a sample of numbers, but we should \nalways think about whether it makes sense to do that. In Section 1-2 we noted that it \nmakes no sense to do numerical calculations with data at the nominal level of mea-\nsurement, because those data consist of names, labels, or categories only, so statistics \nsuch as the mean and median are meaningless for such data. We should also think \nabout the sampling method used to collect the data. If the sampling method is not \nsound, the statistics we obtain may be very misleading.\nEXAMPLE 6  Critical Thinking and Measures of Center\nEach of the following illustrates data for which the mean and median are not mean-\ningful statistics.\na. Zip codes of the hospitals in the United States. (The zip codes don\u2019t measure \nor count anything. The numbers are just labels for geographic locations.)\n \nb. Ranks of selected medical schools: 2, 3, 7, 10, 14. (The ranks re\ufb02ect an order-\ning, but they don\u2019t measure or count anything.)\n \nc. Numbers on the jerseys of the starting defense for the Seattle Seahawks when \nthey won Super Bowl XLVIII: 31, 28, 41, 56, 25, 54, 69, 50, 91, 72, 29. (The \nnumbers on the football jerseys don\u2019t measure or count anything; they are just \nsubstitutes for names.)\n \nd. Top 5 incomes of hospital chief executive o\ufb03cers. (Such \u201ctop 5\u201d or \u201ctop 10\u201d \nlists include data that are not at all representative of the larger population.)\n \ne. The 50 mean ages computed from the means in each of the 50 states. (If you \ncalculate the mean of those 50 values, the result is not the mean age of people \nin the entire United States. The population sizes of the 50 di\ufb00erent states must \nbe taken into account, as described in the weighted mean introduced in Part 2 \nof this section.)\nIn the spirit of describing, exploring, and comparing data, we provide Table 3-1, \nwhich summarizes the different measures of center for the 300 pulse rates referenced \nin the Chapter Problem. Figure 3-1 on page 76 suggests that males have lower pulse \nrates, and comparison of the means and medians in Table 3-1 also suggests that males \nhave lower pulse rates. The following chapters will describe other tools that can be \nused for an effective comparison.\n\n3-1 Measures of Center \n83\nPART 2\n Beyond the Basics of Measures of Center\nCalculating the Mean from a Frequency Distribution\nFormula 3-2",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 100
  },
  {
    "child_id": "f2b35d1d-10da-46d3-b0b2-3e61a4051210",
    "parent_id": "382fae27-d28f-448c-b512-42eefd4a918d",
    "text": "es the different measures of center for the 300 pulse rates referenced \nin the Chapter Problem. Figure 3-1 on page 76 suggests that males have lower pulse \nrates, and comparison of the means and medians in Table 3-1 also suggests that males \nhave lower pulse rates. The following chapters will describe other tools that can be \nused for an effective comparison.\n\n3-1 Measures of Center \n83\nPART 2\n Beyond the Basics of Measures of Center\nCalculating the Mean from a Frequency Distribution\nFormula 3-2 is the same calculation for the mean that was presented in Part 1, but it \nincorporates this approach: When working with data summarized in a frequency dis-\ntribution, we make calculations possible by pretending that all sample values in each \nclass are equal to the class midpoint. Formula 3-2 is not really a new concept; it is \nsimply a variation of Formula 3-1 for the mean.\nFORMULA 3-2 MEAN FROM A FREQUENCY DISTRIBUTION\nFirst multiply each frequency and\nclass midpoint; then add the products. \n T \nx = \u03a3 1f \u00b7x2\n\u03a3 f   1Result is an approximation2\n c \nSum of frequencies\n(equal to n)\nExample 7 illustrates the procedure for finding the mean from a frequency distribution.\nTABLE 3-1 Male and Female Pulse Rates\nMale\nFemale\nMean\n69.6\n  74.0\nMedian\n68.0\n  74.0\nMode\n    66\n72, 74, 82\nMidrange\n72.0\n  70.0\nEXAMPLE 7  Computing the Mean from a Frequency Distribution\nThe first two columns of Table 3-2 on the next page constitute a frequency distribution \nsummarizing the pulse rates from males in Data Set 1 \u201cBody Data\u201d from Appendix B. \nUse the frequency distribution in the first two columns to find the mean.\nSOLUTION\nRemember, when working with data summarized in a frequency distribution, we \nmake calculations possible by pretending that all sample values in each class are \nequal to the class midpoint. For example, see Table 3-2 and consider the first class \ninterval of 40\u201354 with a frequency of 15. We pretend that each of the 15 pulse rates \nis 47 (the class midpoint). With the pulse rate of 47 repeated 15 times, we have a \ntotal of 47 # 15 = 705, as shown in the last column of Table 3-2. We can then add \nthose results to find the sum of all sample values.\nThe bottom row of Table 3-2 shows the two components we need for the cal-\nculation of the mean (as in Formula 3-2): \u03a3f = 153 and \u03a31f # x2 =  10,611. We \ncalculate the mean using Formula 3-2 as follows:\nx = \u03a31 f # x2\n\u03a3f\n= 10,611\n153\n= 69.4 BPM\ncontinued\n\n84 \nCHAPTER 3 Describing, Exploring, and Comparing Data\nCalculating a Weighted Mean\nWhen different x data values are assigned different weights w, we can compute a \nweighted mean. Formula 3-3 can be used to compute the weighted mean.\nFORMULA 3-3\nWeighted mean: x = \u03a3(w # x)\n\u03a3w\nFormula 3-3 tells us to first multiply each weight w by the corresponding value \nx, then to add the products, and then finally to divide that total by the sum of the \nweights, \u03a3w.\nThe result of x = 69.4 BPM is an approximation because it is based on the use  \nof class midpoint values instead of ",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 100
  },
  {
    "child_id": "51c1a656-b9ba-4b53-9ab8-0207925be51a",
    "parent_id": "382fae27-d28f-448c-b512-42eefd4a918d",
    "text": "ghted Mean\nWhen different x data values are assigned different weights w, we can compute a \nweighted mean. Formula 3-3 can be used to compute the weighted mean.\nFORMULA 3-3\nWeighted mean: x = \u03a3(w # x)\n\u03a3w\nFormula 3-3 tells us to first multiply each weight w by the corresponding value \nx, then to add the products, and then finally to divide that total by the sum of the \nweights, \u03a3w.\nThe result of x = 69.4 BPM is an approximation because it is based on the use  \nof class midpoint values instead of the original list of pulse rates. The mean of \n69.6 BPM found by using all of the original pulse rates for males is a more accu-\nrate result.\nTABLE 3-2 Pulse Rates (BPM) of Males\nPulse Rate\nFrequency f\nClass Midpoint x\nf ~ x\n40\u201354\n15\n 47\n 705\n55\u201369\n63\n 62\n3906\n70\u201384\n62\n 77\n4774\n85\u201399\n11\n 92\n1012\n100\u2013114\n 2\n107\n 214\nTotals:\n\ud6baf =  153\n\ud6ba1f ~ x2 = 10,611\nEXAMPLE 8  Computing Grade-Point Average\nIn her first semester of college, a student of one of the authors took five courses. \nHer final grades along with the number of credits for each course were A (3 cred-\nits), A (4 credits), B (3 credits), C (3 credits), and F (1 credit). The grading system \nassigns quality points to letter grades as follows: A = 4; B = 3; C = 2; D = 1; \nF = 0. Compute her grade-point average.\nSOLUTION\nUse the numbers of credits as weights: w = 3, 4, 3, 3, 1. Replace the letter grades \nof A, A, B, C, and F with the corresponding quality points: x = 4, 4, 3, 2, and 0. \nWe now use Formula 3-3 as shown below. The result is a first-semester grade-point \naverage of 3.07. (In using the preceding round-off rule, the result should be rounded \nto 3.1, but it is common to round grade-point averages to two decimal places.)\n x = \u03a31w # x2\n\u03a3w\n = 13 * 42 + 14 * 42 + 13 * 32 + 13 * 22 + 11 * 02\n3 + 4 + 3 + 3 + 1\n = 43\n14 = 3.07\n\n3-1 Measures of Center \n85\nDescriptive Statistics\nAccess tech instructions, videos, and data sets at www.TriolaStats.com\nTECH CENTER \nStatistical Literacy and Critical Thinking \n1.\u00a0Average A report includes a statement that the \u201caverage\u201d Medical College Admission Test \n(MCAT) score of applicants to medical schools is 28.4. What is the role of the term average in \nstatistics? Should another term be used in place of average?\n2.\u00a0What\u2019s Wrong? The Centers for Disease Control and Prevention (CDC) publishes a list of \nsmoking rates in each state. If we add the 50 percentages and then divide by 50, we get 19.67%. \nIs the value of 19.67% the mean smoking rate for all of the United States? Why or why not?\n3.\u00a0Measures of Center In what sense are the mean, median, mode, and midrange measures \nof \u201ccenter\u201d?\n4.\u00a0Resistant Measures Here are five pulse rates (BPM) of females: 80, 94, 58, 66, 56. Find \nthe mean and median of these five values. Then find the mean and median after including a \nsixth value of 740, which is an outlier. (One of the female pulse rates is 74, but 740 is used here \nas an error resulting from an incorrect data entry.) Compare the two sets of results. How much \nwas the mean",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 100
  },
  {
    "child_id": "249e1636-696e-4a63-9562-5b0d3e23931a",
    "parent_id": "382fae27-d28f-448c-b512-42eefd4a918d",
    "text": "hy not?\n3.\u00a0Measures of Center In what sense are the mean, median, mode, and midrange measures \nof \u201ccenter\u201d?\n4.\u00a0Resistant Measures Here are five pulse rates (BPM) of females: 80, 94, 58, 66, 56. Find \nthe mean and median of these five values. Then find the mean and median after including a \nsixth value of 740, which is an outlier. (One of the female pulse rates is 74, but 740 is used here \nas an error resulting from an incorrect data entry.) Compare the two sets of results. How much \nwas the mean affected by the inclusion of the outlier? How much is the median affected by the \ninclusion of the outlier?\nCritical Thinking. Each of Exercises 5\u201316 involves some feature that is somewhat tricky. \nFind the (a) mean, (b) median, (c) mode, and (d) midrange, and then answer the given \nquestion.\n5.\u00a0Charges for Births Data Set 3 \u201cBirths\u201d in Appendix B includes total charges for births at \nfour hospitals in New York State, and the top 10 highest amounts (in dollars) are listed below. \nWhat do the results tell us about the population of all such charges?\n471,062 359,091 290,837 271,863 255,788\n247,477 232,782 197,912 183,271 155,857\n6.\u00a0MCAT Score Listed below are mean MCAT scores listed in order by year, starting with the \nyear 2002. What important feature of the data is not revealed by any of the measures of center?\n27.0 26.8 27.1 27.3 27.4 27.7 28.1 27.9 28.3 28.2 28.3 28.4\n7.\u00a0Football Player Numbers Listed below are the jersey numbers of 11 players randomly \nselected from the roster of the Seattle Seahawks when they won Super Bowl XLVIII. What do \nthe results tell us?\n89 91 55 7 20 99 25 81 19 82 60\n8.\u00a0Football Player Weights Listed below are the weights in pounds of 11 players randomly \nselected from the roster of the Seattle Seahawks when they won Super Bowl XLVIII (the same \nplayers from the preceding exercise). Are the results likely to be representative of all National \nFootball League (NFL) players?\n189 254 235 225 190 305 195 202 190 252 305\n9.\u00a0 Peas in a Pod Biologists conducted experiments to determine whether a deficiency \nof carbon dioxide in the soil affects the phenotypes of peas. Listed below are the pheno-\ntype codes, where 1 = smooth@yellow, 2 = smooth@green, 3 = wrinkled@yellow, and \n3-1 Basic Skills and Concepts\ncontinued",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 100
  },
  {
    "child_id": "2d865307-c4ca-44fb-a9e0-4a3be6101d0a",
    "parent_id": "a3fd8d2c-550d-43d7-a3e5-04ecc90c16d7",
    "text": "86 \nCHAPTER 3 Describing, Exploring, and Comparing Data\n4 = wrinkled@green. Can the measures of center be obtained for these values? Do the results \nmake sense?\n2 1 1 1 1 1 1 4 1 2 2 1 2 3 3 2 3 1 3 1 3 1 3 2 2\n10.\u00a0TV Prices A physician plans to buy a television for her large waiting room. Listed below \nare selling prices in dollars of TVs that are 60 inches or larger and rated as a \u201cbest buy\u201d by \nConsumer Reports magazine. Are the resulting statistics representative of the population of all \nTVs that are 60 inches and larger? If you decide to buy one of these TVs, what statistic is most \nrelevant, other than the measures of central tendency?\n1800 1500 1200 1500 1400 1600 1500 950 1600 1150 1500 1750\n11. Cell Phone Radiation Listed below are the measured radiation absorption rates (in W>kg) \ncorresponding to these cell phones: iPhone 5S, BlackBerry Z30, Sanyo Vero, Optimus V, Droid \nRazr, Nokia N97, Samsung Vibrant, Sony Z750a, Kyocera Kona, LG G2, and Virgin Mobile \nSupreme. The data are from the Federal Communications Commission (FCC). The media often \nreport about the dangers of cell phone radiation as a cause of cancer. The FCC has a standard \nthat a cell phone absorption rate must be 1.6 W>kg or less. If you are planning to purchase a cell \nphone, are any of the measures of center the most important statistic? Is there another statistic \nthat is most relevant? If so, which one?\n1.18 1.41 1.49 1.04 1.45 0.74 0.89 1.42 1.45 0.51 1.38\n12.\u00a0Caffeine in Soft Drinks Listed below are measured amounts of caffeine (mg per 12 oz \nof drink) obtained in one can from each of 20 brands (7-UP, A&W Root Beer, Cherry Coke, \n. . . , Tab). Are the statistics representative of the population of all cans of the same 20 brands \nconsumed by Americans?\n0 0 34 34 34 45 41 51 55 36 47 41 0 0 53 54 38 0 41 47\n13.\u00a0Firefighter Fatalities Listed below are the numbers of heroic firefighters who lost their \nlives in the United States each year while fighting forest fires. The numbers are listed in order \nby year, starting with the year 2000. What important feature of the data is not revealed by any \nof the measures of center?\n20 18 23 30 20 12 24 9 25 15 8 11 15 34\n14.\u00a0Foot Lengths Listed below are foot lengths in inches of randomly selected Army women \nmeasured in the 1988 Anthropometric Survey (ANSUR). Are the statistics representative of the \ncurrent population of all Army women?\n10.4 9.3 9.1 9.3 10.0 9.4 8.6 9.8 9.9 9.1 9.1\n15.\u00a0Medical School Tuition Listed below in dollars are the annual costs of tuition at the 10 \nmost expensive private medical schools in the United States for a recent year (based on data \nfrom U.S. News & World Report). What does this \u201ctop 10\u201d list tell us about those costs for the \npopulation of all U.S. private medical school tuitions?\n57,261 56,784 55,196 54,976 54,653 54,528 54,268 54,050 53,581 53,323\n16.\u00a0California Smokers In the California Health Interview Survey, randomly selected adults \nare interviewed. One of the questions asks how many ci",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 104
  },
  {
    "child_id": "cbfe8fad-64f2-44ae-8e8f-cfb8a33f101b",
    "parent_id": "a3fd8d2c-550d-43d7-a3e5-04ecc90c16d7",
    "text": "he annual costs of tuition at the 10 \nmost expensive private medical schools in the United States for a recent year (based on data \nfrom U.S. News & World Report). What does this \u201ctop 10\u201d list tell us about those costs for the \npopulation of all U.S. private medical school tuitions?\n57,261 56,784 55,196 54,976 54,653 54,528 54,268 54,050 53,581 53,323\n16.\u00a0California Smokers In the California Health Interview Survey, randomly selected adults \nare interviewed. One of the questions asks how many cigarettes are smoked per day, and results \nare listed below for 50 randomly selected respondents. How well do the results reflect the \nsmoking behavior of California adults?\n9\n10\n10\n20\n40\n50\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n3-1 Measures of Center \n87\nIn Exercises 17\u201320, find the mean and median for each of the two samples, then compare \nthe two sets of results.\n17.\u00a0 Blood Pressure A sample of blood pressure measurements is taken from Data Set \n1 \u201cBody Data\u201d in Appendix B, and those values (mm Hg) are listed below. The values are \nmatched so that 10 subjects each have systolic and diastolic measurements. (Systolic is a mea-\nsure of the force of blood being pushed through arteries, but diastolic is a measure of blood \npressure when the heart is at rest between beats.) Are the measures of center the best statistics \nto use with these data? What else might be better?\nSystolic:\n118\n128\n158\n96\n156\n122\n116\n136\n126\n120\nDiastolic:\n 80\n 76\n 74\n52\n 90\n 88\n 58\n 64\n 72\n 82\n18.\u00a0White>Red Blood Counts Listed below are white blood cell counts (1000 cells>mL) \nand red blood cell counts (million cells>mL) from different subjects (from Data Set 1 \u201cBody \nData\u201d in Appendix B). The values are matched so that each of the 12 subjects has a white blood \ncell count and a red blood cell count. Are the measures of center the best statistics to use with \nthese data? What else might be better?\nWhite:\n8.7\n4.9\n6.9\n7.5\n6.1\n5.7\n4.1\n8.1\n8.0\n5.6\n8.3\n6.9\nRed:\n4.8\n4.7\n4.5\n4.3\n5.0\n4.0\n4.7\n4.6\n4.1\n5.5\n4.4\n4.2\n19.\u00a0White Blood Counts Listed below are white blood cell counts (1000 cells>mL) from \nmales and females (from Data Set 1 \u201cBody Data\u201d in Appendix B). Do they appear to be  different?\nFemale:\n8.7\n6.9\n8.1\n8.0\n6.9\n8.1\n6.4\n6.3\n10.9\n4.8\n5.9\n7.2\nMale:\n4.9\n7.5\n6.1\n5.7\n4.1\n5.6\n8.3\n5.1\n 9.5\n6.1\n5.7\n5.4\n20.\u00a0Queues A Providence Hospital experiment involves two different waiting line configura-\ntions for patients arriving for admission. The waiting times (in seconds) are recorded with a \nsingle line configuration that feeds four stations and another configuration with individual lines \nat the four stations. Determine whether there is a difference between the two data sets that is \nnot apparent from a comparison of the measures of center. If so, what is it?\nSingle Line\n390\n396\n402\n408\n426\n438\n444\n462\n462\n462\nIndividual Lines\n252\n324\n348\n372\n402\n462\n462\n510\n558\n600\nLarge Data Sets from Appendix B. In Exercises 21\u201324, refer to the indicated data set in",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 104
  },
  {
    "child_id": "b67da5f4-0e07-4290-98fc-3dd442cf1eb5",
    "parent_id": "a3fd8d2c-550d-43d7-a3e5-04ecc90c16d7",
    "text": "seconds) are recorded with a \nsingle line configuration that feeds four stations and another configuration with individual lines \nat the four stations. Determine whether there is a difference between the two data sets that is \nnot apparent from a comparison of the measures of center. If so, what is it?\nSingle Line\n390\n396\n402\n408\n426\n438\n444\n462\n462\n462\nIndividual Lines\n252\n324\n348\n372\n402\n462\n462\n510\n558\n600\nLarge Data Sets from Appendix B. In Exercises 21\u201324, refer to the indicated data set in \nAppendix B. Use software or a calculator to find the means and medians.\n21.\u00a0HDL Use the high-density lipoprotein (HDL) cholesterol measurements (mg>dL) from the \n300 subjects included in Data Set 1 \u201cBody Data\u201d in Appendix B. Identify the highest value. \nDoes it appear to be an outlier? Do the mean and median change much when that highest value \nis deleted?\n22.\u00a0LDL Repeat the preceding exercise using the low-density lipoprotein (LDL) measurements \n(mg>dL).\n23.\u00a0Body Temperatures Refer to Data Set 2 \u201cBody Temperatures\u201d in Appendix B and use \nthe body temperatures for 12:00 AM on day 2. Do the results support or contradict the common \nbelief that the mean body temperature is 98.6oF?\n24.\u00a0Births Use the birth weights (grams) of the 400 babies listed in Data Set 3 \u201cBirths\u201d in \n Appendix B. Examine the list of birth weights to make an observation about those numbers. \nHow does that observation affect the way that the results should be rounded?\n\n88 \nCHAPTER 3 Describing, Exploring, and Comparing Data\nIn Exercises 25 and 26, find the mean of the data summarized in the frequency distribution. \nAlso, compare the computed means to the actual means obtained by using the original list \nof data values, which are as follows: (Exercise 25) 224.3; (Exercise 26) 255.1.\n25.\u00a0\nBlood Platelet \nCount of Males\n \nFrequency\n 0\u201399\n 1\n100\u2013199\n51\n200\u2013299\n90\n300\u2013399\n10\n400\u2013499\n 0\n500\u2013599\n 0\n600\u2013699\n 1\n26.\u00a0\nBlood Platelet Count \nof Females\n \nFrequency\n100\u2013199\n25\n200\u2013299\n92\n300\u2013399\n28\n400\u2013499\n 0\n500\u2013599\n 2\n27.\u00a0Weighted Mean A student of one of the authors earned grades of A, C, B, A, and D. \nThose courses had these corresponding numbers of credit hours: 3, 3, 3, 4, and 1. The grad-\ning system assigns quality points to letter grades as follows: A = 4; B = 3; C = 2; D = 1;\nF = 0. Compute the grade-point average (GPA) and round the result with two decimal places. \nIf the dean\u2019s list requires a GPA of 3.00 or greater, did this student make the dean\u2019s list?\n28.\u00a0Weighted Mean A student of one of the authors earned grades of 63, 91, 88, 84, and 79 \non her five regular statistics tests. She earned a grade of 86 on the final exam and 90 on her \nclass projects. Her combined homework grade was 70. The five regular tests count for 60% \nof the final grade, the final exam counts for 10%, the project counts for 15%, and homework \ncounts for 15%. What is her weighted mean grade? What letter grade did she earn (A, B, C, D, \nor F)? Assume that a mean of 90 or above is an A, a mean of 80 to 89 is a B, and ",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 104
  },
  {
    "child_id": "2738d823-492f-4446-b1b7-5dffe1b33e92",
    "parent_id": "a3fd8d2c-550d-43d7-a3e5-04ecc90c16d7",
    "text": "hors earned grades of 63, 91, 88, 84, and 79 \non her five regular statistics tests. She earned a grade of 86 on the final exam and 90 on her \nclass projects. Her combined homework grade was 70. The five regular tests count for 60% \nof the final grade, the final exam counts for 10%, the project counts for 15%, and homework \ncounts for 15%. What is her weighted mean grade? What letter grade did she earn (A, B, C, D, \nor F)? Assume that a mean of 90 or above is an A, a mean of 80 to 89 is a B, and so on.\n29. Degrees of Freedom Five pulse rates randomly selected from Data Set 1 \u201cBody Data\u201d in \nAppendix B have a mean of 78.0 beats per minute. Four of the pulse rates are 82, 78, 56, and 84.\na. Find the missing value.\nb. We need to create a list of n values that have a specific known mean. We are free to select \nany values we desire for some of the n values. How many of the n values can be freely assigned \nbefore the remaining values are determined? (The result is referred to as the number of degrees \nof freedom.)\n30. Censored Data Recently, five U.S. presidents were still alive and after their first inaugura-\ntion, they have lived 37 years, 25 years, 21 years, 13 years, and 5 years so far. We might use the \nvalues of 37+, 25+, 21+, 13+, and 5+, where the positive signs indicate that the actual value \nis equal to or greater than the current value. (These values are said to be censored at the current \ntime that this list was compiled.) If we ignore the presidents who took office because of an as-\nsassination or resignation and if we ignore the five presidents who are still alive, the mean of \nthe 33 remaining presidents is 15.0 years. What do we know about the mean if we include the \ncensored values of 37+, 25+, 21+, 13+, and 5+? Do the two results differ by much?\n31. Trimmed Mean Because the mean is very sensitive to extreme values, we say that it is \nnot a resistant measure of center. By deleting some low values and high values, the trimmed \nmean (or truncated mean) is more resistant. To find the 10% trimmed mean for a data set, first \narrange the data in order, next delete the bottom 10% of the values and delete the top 10% of \nthe values, and then calculate the mean of the remaining values. Use the LDL measurements \nof the 300 subjects from Data Set 1 \u201cBody Data\u201d in Appendix B. Compare the mean, the 10% \ntrimmed mean, and the 20% trimmed mean.\n3-1 Beyond the Basics\n\n3-2 Measures of Variation \n89\nPART 1\nBasic Concepts of Variation \nTo visualize the property of variation, see Figure 3-2, which illustrates pulse rates \n(beats per minute or BPM) for subjects given a treatment and subjects given a pla-\ncebo. (A high priority is placed on using real data, but these pulse rates are fabricated \nfor the purposes of making an important point here.) Verify this important observa-\ntion: The pulse rates in the treatment group (top dotplot) have more variation than \nthose in the placebo group (bottom dotplot). Both sets of pulse rates have the same \nmean of 70.2 B",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 104
  },
  {
    "child_id": "bd6d7d5f-d10d-42f0-8bab-e07716cd45e2",
    "parent_id": "a3fd8d2c-550d-43d7-a3e5-04ecc90c16d7",
    "text": "variation, see Figure 3-2, which illustrates pulse rates \n(beats per minute or BPM) for subjects given a treatment and subjects given a pla-\ncebo. (A high priority is placed on using real data, but these pulse rates are fabricated \nfor the purposes of making an important point here.) Verify this important observa-\ntion: The pulse rates in the treatment group (top dotplot) have more variation than \nthose in the placebo group (bottom dotplot). Both sets of pulse rates have the same \nmean of 70.2 BPM, they have the same median of 70.0 BPM, and they have the same \nmode of 70 BPM. Those measures of center do not \u201csee\u201d the difference in variation.\nTo keep our round-off rules as consistent and as simple as possible, we will round \nthe measures of variation using this rule:\nKey Concept Variation is the single most important topic in statistics, so this is the \nsingle most important section in this book. This section presents three important \nmeasures of variation: range, standard deviation, and variance. These statistics are \nnumbers, but our focus is not just computing those numbers but developing the abil-\nity to interpret and understand them. This section is not a study of arithmetic; it is \nabout understanding and interpreting measures of variation, especially the standard \ndeviation.\n3-2 \nMeasures of Variation\nSTUDY HINT: Part 1 of this section presents basic concepts of variation, and \nPart 2 presents additional concepts related to the standard deviation. Part 1 \nand Part 2 both include formulas for computation, but do not spend too much \ntime memorizing formulas or doing arithmetic calculations. Instead, focus on \nunderstanding and interpreting values of standard deviation.\nROUND-OFF RULE FOR MEASURES OF VARIATION When rounding the value \nof a measure of variation, carry one more decimal place than is present in the \noriginal set of data.\nFIGURE 3-2 Dotplots of Pulse Rates",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 104
  },
  {
    "child_id": "91804b08-ba8e-4e37-81a0-f858c1097fc5",
    "parent_id": "b0e8bbda-dd61-4886-83ca-1416ddc4abd8",
    "text": "90 \nCHAPTER 3 Describing, Exploring, and Comparing Data\nRange\nLet\u2019s begin with the range because it is quick and easy to compute, but it is not as im-\nportant as other measures of variation.\nDEFINITION\nThe range of a set of data values is the difference between the maximum data \nvalue and the minimum data value.\nRange =  1maximum data value2 \u2212 1minimum data value2\nImportant Properties of the Range\n \n\u25a0The range uses only the maximum and the minimum data values, so it is very \nsensitive to extreme values. The range is not resistant.\n \n\u25a0Because the range uses only the maximum and minimum values, it does not take \nevery value into account and therefore does not truly reflect the variation among \nall of the data values.\nEXAMPLE 1  Range\nFind the range of the first five pulse rates for males from Data Set 1 \u201cBody Data\u201d in \nAppendix B: 84, 74, 50, 60, 52 (all in BPM).\nSOLUTION\nThe range is found by subtracting the lowest value from the largest value, so we get\nRange = 1maximum value2 - 1minimum value2 = 84 - 50 = 34.0 BPM\nThe range of 34.0 BPM is shown with one more decimal place than is present in the \noriginal data values.\nStandard Deviation of a Sample\nThe standard deviation is the measure of variation most commonly used in statistics.\nDEFINITION\nThe standard deviation of a set of sample values, denoted by s, is a measure  \nof how much data values deviate away from the mean. It is calculated by using  \nFormula 3-4 or 3-5. Formula 3-5 is just a different version of Formula 3-4; both for-\nmulas are algebraically the same.\nThe standard deviation found from sample data is a statistic denoted by s, but the stan-\ndard deviation found from population data is a parameter denoted by s. The formula \nfor s is slightly different with division by the population size N used instead of divi-\nsion by n - 1. The population standard deviation s will be discussed later.\nNotation\ns = sample standard deviation\ns = population standard deviation\nR\nL\np\nGot a Second?\nThe time unit \nof 1 second \nis defined \nto be \u201cthe \nduration of \n9,192,631,770 \nperiods of the \nradiation corresponding to the \ntransition between the two hy-\nperfine levels of the ground state \nof the cesium-133 atom.\u201d That \ndefinition redefines time to be \nbased on the behavior of atoms \ninstead of the earth\u2019s motion. It \nresults in accuracy of \u00b11 second \nin 10,000,000 years, which is the \nmost accurate measurement we \nuse. Because it is so accurate, the \nsecond is being used to define \nother quantities, such as the me-\nter. The meter was once defined \nas 1>10,000,000 of the distance \nalong the surface of the earth \nbetween the North Pole and the \nequator (passing through Paris). \nThe meter is now defined as the \nlength of the distance traveled by \nlight in a vacuum during a time \ninterval of 1>299,792,458 sec.\nWhen dealing with time mea-\nsurement devices, the traditional \nstandard deviation has been \nfound to be poor because of a \ntrend in which the mean changes \nover time. Instead, other special \nmeasures of",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 108
  },
  {
    "child_id": "761a4c78-2e65-46e1-9759-8f6a38540c97",
    "parent_id": "b0e8bbda-dd61-4886-83ca-1416ddc4abd8",
    "text": "\nter. The meter was once defined \nas 1>10,000,000 of the distance \nalong the surface of the earth \nbetween the North Pole and the \nequator (passing through Paris). \nThe meter is now defined as the \nlength of the distance traveled by \nlight in a vacuum during a time \ninterval of 1>299,792,458 sec.\nWhen dealing with time mea-\nsurement devices, the traditional \nstandard deviation has been \nfound to be poor because of a \ntrend in which the mean changes \nover time. Instead, other special \nmeasures of variation are used, \nsuch as Allan variance, total vari-\nance, and TheoH.\nUnrelated to statistics but \nnonetheless interesting is the \nfact that ads for watches usually \nshow a watch with a time close \nto 10:10. That time allows the \nbrand name to be visible, and it \ncreates a subliminal image of a \nhappy face. The time of 10:10 \nhas been the industry standard \nsince the 1940s.\n\n3-2 Measures of Variation \n91\nFORMULA 3-4\ns = B\n\u03a31x - x2 2\nn - 1\n sample standard deviation\nFORMULA 3-5\ns = B\nn1\u03a3  x22 - 1\u03a3  x2 2\nn1n - 12\n shortcut formula for sample standard\n  deviation (used by calculators and software)\nLater we give the reasoning behind these formulas, but for now we recommend \nthat you use Formula 3-4 for an example or two, and then learn how to find standard \ndeviation values using a calculator or software.\nImportant Properties of Standard Deviation\n \n\u25a0The standard deviation is a measure of how much data values deviate away from \nthe mean.\n \n\u25a0The value of the standard deviation s is never negative. It is zero only when all of \nthe data values are exactly the same.\n \n\u25a0Larger values of s indicate greater amounts of variation.\n \n\u25a0The standard deviation s can increase dramatically with one or more outliers.\n \n\u25a0The units of the standard deviation s (such as minutes, feet, pounds) are the same \nas the units of the original data values.\n \n\u25a0The sample standard deviation s is a biased estimator of the population standard \ndeviation s, which means that values of the sample standard deviation s do not \ncenter around the value of s. (This is explained in Part 2.)\nExample 2 illustrates a calculation using Formula 3-4 because that formula better \nillustrates that the standard deviation is based on deviations of sample values away \nfrom the mean.\nEXAMPLE 2  Calculating Standard Deviation with Formula 3-4\nUse Formula 3-4 to find the standard deviation of the first five pulse rates for males \nfrom Data Set 1 \u201cBody Data\u201d in Appendix B: 84, 74, 50, 60, 52 (all in BPM).\nSOLUTION\nThe left column of Table 3-3 on the next page summarizes the general procedure \nfor finding the standard deviation using Formula 3-4, and the right column illus-\ntrates that procedure using the sample values 84, 74, 50, 60, 52. The result shown \nin Table 3-3 is 14.6 BPM, which is rounded to one more decimal place than is \npresent in the original list of sample values. Also, the units for the standard devia-\ntion are the same as the units of the original data. Because the original data values \nare all i",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 108
  },
  {
    "child_id": "d0c9c59c-10b6-4763-ba27-072a08c37ea4",
    "parent_id": "b0e8bbda-dd61-4886-83ca-1416ddc4abd8",
    "text": "t column of Table 3-3 on the next page summarizes the general procedure \nfor finding the standard deviation using Formula 3-4, and the right column illus-\ntrates that procedure using the sample values 84, 74, 50, 60, 52. The result shown \nin Table 3-3 is 14.6 BPM, which is rounded to one more decimal place than is \npresent in the original list of sample values. Also, the units for the standard devia-\ntion are the same as the units of the original data. Because the original data values \nare all in units of BPM, the standard deviation is 14.6 BPM.\nVariation in Faces\nResearchers \ncommented \nthat \u201cif everyone \nlooked more or \nless the same, \nthere would be \ntotal chaos.\u201d \nThey studied \nhuman body measurements and \nfound that facial traits varied \nmore than other body traits, \nand the greatest variation oc-\ncurred within the triangle formed \nby the eyes and mouth. They \nlearned that facial traits vary \nindependently of each other. For \nexample, there is no relationship \nbetween the distance between \nyour eyes and how big your \nmouth is. The researchers stated \nthat our facial variation played an \nimportant role in human evolu-\ntion. (See \u201cMorphological and \nPopulation Genomic Evidence \nThat Human Faces Have Evolved \nto Signal Individual Identity,\u201d by \nSheehan and Nachman, Nature \nCommunications, Vol. 5,  \nNo. 4800.)\n\n92 \nCHAPTER 3 Describing, Exploring, and Comparing Data\nTABLE 3-3\nGeneral Procedure for Finding Standard  \nDeviation with Formula 3-4\nSpecific Example Using These Sample  \nValues: 84, 74, 50, 60, 52\nStep 1: Compute the mean x.\nThe sum of 84, 74, 50, 60, 52 is 320; therefore:\n x = \u03a3  x\nn\n= 84 + 74 + 50 + 60 + 52\n5\n = 320\n5\n= 64.0\nStep 2: Subtract the mean from each individual \nsample value. [The result is a list of deviations \nof the form 1x - x2.]\nSubtract the mean of 64.0 from each sample \nvalue to get these deviations away from the \nmean: 20, 10, \u221214, \u22124, \u221212.\nStep 3: Square each of the deviations obtained \nfrom Step 2. [This produces numbers of the \nform 1x - x2 2.]\nThe squares of the deviations from Step 2 are: \n400, 100, 196, 16, 144.\nStep 4: Add all of the squares obtained from \nStep 3. The result is \u03a31x - x2 2.\nThe sum of the squares from Step 3 is 856.\nStep 5: Divide the total from Step 4 by the num-\nber n - 1, which is 1 less than the total number \nof sample values present.\nWith n = 5 data values, n - 1 = 4, so we \ndivide 856 by 4 to get this result:\n856\n4\n= 214\nStep 6: Find the square root of the result of \nStep 5. The result is the standard deviation, \ndenoted by s.\nThe standard deviation is 2214 = 14.6287. \nRounding the result, we get s = 14.6 BPM.\nEXAMPLE 3  Calculating Standard Deviation with Formula 3-5\nUse Formula 3-5 to find the standard deviation of the first five pulse rates of males \nfrom Data Set 1 \u201cBody Data\u201d: 84, 74, 50, 60, 52.\nSOLUTION\nHere are the components needed in Formula 3-5.\nn = 5 (because there are 5 values in the sample)\n\u03a3  x = 320 (found by adding the original sample values)\n\u03a3  x2 = 21,336 (found by addi",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 108
  },
  {
    "child_id": "58734677-1028-461f-93d8-cecd68a9a9fc",
    "parent_id": "b0e8bbda-dd61-4886-83ca-1416ddc4abd8",
    "text": "ard deviation, \ndenoted by s.\nThe standard deviation is 2214 = 14.6287. \nRounding the result, we get s = 14.6 BPM.\nEXAMPLE 3  Calculating Standard Deviation with Formula 3-5\nUse Formula 3-5 to find the standard deviation of the first five pulse rates of males \nfrom Data Set 1 \u201cBody Data\u201d: 84, 74, 50, 60, 52.\nSOLUTION\nHere are the components needed in Formula 3-5.\nn = 5 (because there are 5 values in the sample)\n\u03a3  x = 320 (found by adding the original sample values)\n\u03a3  x2 = 21,336 (found by adding the squares of the sample values, as in\n842 + 742 + 502 + 602 + 522 = 21,336)\nUsing Formula 3-5, we get\ns = B\nn1\u03a3  x22 - 1\u03a3  x2 2\nn1n - 12\n= B\n5121,3362 - 13202 2\n515 - 12\n= B\n4280\n20\n= 14.6 BPM\nThe result of s = 14.6 BPM is the same as the result in Example 2.\nRange Rule of Thumb for Understanding Standard Deviation\nThe range rule of thumb is a crude but simple tool for understanding and interpreting \nstandard deviation. It is based on the principle that for many data sets, the vast major-\nity (such as 95%) of sample values lie within 2 standard deviations of the mean. We \ncould improve the accuracy of this rule by taking into account such factors as the size \nof the sample and the distribution, but here we sacrifice accuracy for the sake of sim-\nplicity. The concept of significance as given below will be enhanced in later chapters, \nespecially those that include the topic of hypothesis tests, which are also called tests\n\n3-2 Measures of Variation \n93\nof significance. The following range rule of thumb is based on the population mean m\nand the population standard deviation s, but for large and representative samples, we \ncould use x and s instead.\nRange Rule of Thumb for Identifying Significant Values\nSigni\ufb01cantly low values are m - 2s or lower.\nSignificantly high values are m + 2s or higher.\nValues not signi\ufb01cant: Between 1m - 2s2 and 1m + 2s2\nSee Figure 3-3, which illustrates the above criteria.\nValues not signi\ufb01cant\nSigni\ufb01cantly\nlow values\nSigni\ufb01cantly\nhigh values\nm\nm \u2212 2s\nm + 2s\nFIGURE 3-3  Range Rule of Thumb for Identifying \nSignificant Values\nRange Rule of Thumb for Estimating a Value of the Standard Deviation s\nTo roughly estimate the standard deviation from a collection of known sample \ndata, use\ns \u2248range\n4\nEXAMPLE 4  Range Rule of Thumb for Interpreting s\nUsing the 153 pulse rates of males listed in Data Set 1 \u201cBody Data\u201d in Appendix B, \nthe mean is x = 69.6 BPM and the standard deviation is s = 11.3 BPM. Use x and \ns as estimates of m and s, and use the range rule of thumb to find the limits separat-\ning values that are significantly low or significantly high. Then determine whether a \nmale pulse rate of 100 BPM is significantly high.\nSOLUTION\nWith a mean of 69.6 and a standard deviation of 11.3, we use the range rule of \nthumb to find values that are significantly low or significantly high as follows:\nSignificantly low values are 169.6 - 2 * 11.32 or lower, \nso significantly low values are 47.0 BPM or lower.\nSignificantly high values are 169",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 108
  },
  {
    "child_id": "e68440a7-0110-4da5-af09-c753006b3322",
    "parent_id": "b0e8bbda-dd61-4886-83ca-1416ddc4abd8",
    "text": "e range rule of thumb to find the limits separat-\ning values that are significantly low or significantly high. Then determine whether a \nmale pulse rate of 100 BPM is significantly high.\nSOLUTION\nWith a mean of 69.6 and a standard deviation of 11.3, we use the range rule of \nthumb to find values that are significantly low or significantly high as follows:\nSignificantly low values are 169.6 - 2 * 11.32 or lower, \nso significantly low values are 47.0 BPM or lower.\nSignificantly high values are 169.6 + 2 * 11.32 or higher, \nso significantly high values are 92.2 BPM or higher.\nValues not significant: Between 47.0 and 92.2 BPM\nINTERPRETATION\nBased on these results, we expect that typical pulse rates of males are between \n47.0 BPM and 92.2 BPM. Because the given value of 100 BPM falls above \n92.2\u00a0BPM, we consider it to be a significantly high pulse rate for a male.",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 108
  },
  {
    "child_id": "4bbda566-0c71-4bb1-a1b9-f9a6dbcad5c6",
    "parent_id": "35967645-821e-4119-89f0-1f7b94c803b2",
    "text": "94 \nCHAPTER 3 Describing, Exploring, and Comparing Data\nStandard Deviation of a Population\nThe definition of standard deviation and Formulas 3-4 and 3-5 apply to the standard \ndeviation of sample data. A slightly different formula is used to calculate the standard \ndeviation s (lowercase sigma) of a population: Instead of dividing by n - 1, we di-\nvide by the population size N, as shown here:\nPopulation standard deviation s = B\n\u03a31x - m2 2\nN\nBecause we generally deal with sample data, we will usually use Formula 3-4, in \nwhich we divide by n - 1. Many calculators give both the sample standard deviation \nand the population standard deviation, but they use a variety of different notations.\nEXAMPLE 5  Range Rule of Thumb for Estimating s\nUse the range rule of thumb to estimate the standard deviation of the sample of \n153 pulse rates of males listed in Data Set 1 \u201cBody Data\u201d in Appendix B. Those \n153 values have a minimum of 40 BPM and a maximum of 104 BPM.\nSOLUTION\nThe range rule of thumb indicates that we can estimate the standard deviation by \nfinding the range and dividing it by 4. With a minimum of 40 BPM and a maximum \nof 104 BPM, the range rule of thumb can be used to estimate the standard deviation \ns as follows:\ns \u2248range\n4\n= 104 - 40\n4\n= 16.0 BPM\nINTERPRETATION\nThe actual value of the standard deviation is s = 11.3 BPM, so the estimate of \n16.0\u00a0BPM is very roughly in the general neighborhood of the exact result. Because \nthis estimate is based on only the minimum and maximum values, it might be off by \na considerable amount.\nCAUTION When using a calculator to find standard deviation, identify the notation \nused by your particular calculator so that you get the sample standard deviation, \nnot the population standard deviation.\nVariance of a Sample and a Population\nSo far, we have used the term variation as a general description of the amount that val-\nues vary among themselves. (The terms dispersion and spread are sometimes used in-\nstead of variation.) Unlike the term variation, the term variance has a specific meaning.\nDEFINITION\nThe variance of a set of values is a measure of variation equal to the square of the \nstandard deviation.\n\u2022\u2002 Sample\u2002variance:\u2002s2 =  square of the standard deviation s.\n\u2022\u2002 Population\u2002variance:\u2002s2 =  square of the population standard deviation s.\n\n3-2 Measures of Variation \n95\nNotation Here is a summary of notation for the standard deviation and variance:\ns = sample standard deviation\ns2 = sample variance\ns = population standard deviation\ns2 = population variance\nNote: Articles in professional journals and reports often use SD for standard deviation \nand VAR for variance.\nImportant Properties of Variance\n \n\u25a0The units of the variance are the squares of the units of the original data values. \n(If the original data values are in feet, the variance will have units of ft2; if the \noriginal data values are in seconds, the variance will have units of  sec2.)\n \n\u25a0The value of the variance can increase dramatically with the inc",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 112
  },
  {
    "child_id": "437bd2f5-00aa-4a3e-8101-e2e910830e55",
    "parent_id": "35967645-821e-4119-89f0-1f7b94c803b2",
    "text": "d deviation\ns2 = population variance\nNote: Articles in professional journals and reports often use SD for standard deviation \nand VAR for variance.\nImportant Properties of Variance\n \n\u25a0The units of the variance are the squares of the units of the original data values. \n(If the original data values are in feet, the variance will have units of ft2; if the \noriginal data values are in seconds, the variance will have units of  sec2.)\n \n\u25a0The value of the variance can increase dramatically with the inclusion of outliers. \n(The variance is not resistant.)\n \n\u25a0The value of the variance is never negative. It is zero only when all of the data \nvalues are the same number.\n \n\u25a0The sample variance s2 is an unbiased estimator of the population variance s2, \nas described in Part 2 of this section. (The sample standard deviation s is a biased \nestimator of the population standard deviation s.)\nThe variance is a statistic used in some statistical methods, but for our present pur-\nposes, the variance has the serious disadvantage of using units that are different than \nthe units of the original data set. This makes it difficult to understand variance as it \nrelates to the original data set. Because of this property, it is better to first focus on the \nstandard deviation when trying to develop an understanding of variation.\nPART 2\nBeyond the Basics of Variation\nIn Part 2, we focus on making sense of the standard deviation so that it is not some \nmysterious number devoid of any practical significance. We begin by addressing com-\nmon questions that relate to the standard deviation.\nWhy Is Standard Deviation Defined as in Formula 3-4?\nIn measuring variation in a set of sample data, it makes sense to begin with the indi-\nvidual amounts by which values deviate from the mean. For a particular data value x, \nthe amount of deviation is x - x. It makes sense to somehow combine those devia-\ntions into one number that can serve as a measure of the variation. Adding the devia-\ntions isn\u2019t good, because the sum will always be zero. To get a statistic that measures \nvariation, it\u2019s necessary to avoid the canceling out of negative and positive numbers. \nOne approach is to add absolute values, as in \u03a3\u001ax - x \u001a. If we find the mean of that \nsum, we get the mean absolute deviation (or MAD), which is the mean distance of \nthe data from the mean:\nMean absolute deviation = \u03a3\u001ax - x \u001a\nn\nWhy Not Use the Mean Absolute Deviation Instead of the Standard \nDeviation? Computation of the mean absolute deviation uses absolute values, \nso it uses an operation that is not \u201calgebraic.\u201d (The algebraic operations include\n\n96 \nCHAPTER 3 Describing, Exploring, and Comparing Data\naddition, multiplication, extracting roots, and raising to powers that are integers \nor fractions.) The use of absolute values would be simple, but it would create \nalgebraic difficulties in inferential methods of statistics discussed in later chap-\nters. The standard deviation has the advantage of using only algebraic opera-\ntions. ",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 112
  },
  {
    "child_id": "037534c8-5d7d-4306-ac35-499d0efb2185",
    "parent_id": "35967645-821e-4119-89f0-1f7b94c803b2",
    "text": "n uses absolute values, \nso it uses an operation that is not \u201calgebraic.\u201d (The algebraic operations include\n\n96 \nCHAPTER 3 Describing, Exploring, and Comparing Data\naddition, multiplication, extracting roots, and raising to powers that are integers \nor fractions.) The use of absolute values would be simple, but it would create \nalgebraic difficulties in inferential methods of statistics discussed in later chap-\nters. The standard deviation has the advantage of using only algebraic opera-\ntions. Because it is based on the square root of a sum of squares, the standard \ndeviation closely parallels distance formulas found in algebra. There are many \ninstances where a statistical procedure is based on a similar sum of squares. \nConsequently, instead of using absolute values, we square all deviations 1x - x2\nso that they are nonnegative, and those squares are used to calculate the standard \ndeviation.\nWhy Divide by n \u22121? After finding all of the individual values of 1x - x2 2 we \ncombine them by finding their sum. We then divide by n - 1 because there are only \nn - 1 values that can assigned without constraint. With a given mean, we can use any \nnumbers for the first n - 1 values, but the last value will then be automatically deter-\nmined. With division by n - 1, sample variances s2 tend to center around the value of \nthe population variance s2; with division by n, sample variances s2 tend to underesti-\nmate the value of the population variance s2.\nComparing Variation in Different Samples or Populations\nIt\u2019s a good practice to compare two sample standard deviations only when the sample \nmeans are approximately the same. When comparing variation in samples or popula-\ntions with very different means, it is better to use the coefficient of variation. Also use \nthe coefficient of variation to compare variation from two samples or populations with \ndifferent scales or units of values, such as the comparison of variation of pulse rates of \nmen and heights of men. (See Example 6.)\nDEFINITION\nThe coefficient of variation (or CV) for a set of nonnegative sample or popula-\ntion data, expressed as a percent, describes the standard deviation relative to the \nmean, and is given by the following:\n \nSample \nPopulation\n \nCV = s\nx # 100% \nCV = s\nm # 100%\nROUND-OFF RULE FOR THE COEFFICIENT OF VARIATION Round the \ncoefficient of variation to one decimal place (such as 25.3%).\nEXAMPLE 6  Pulse Rates and Heights\nCompare the variation of the 153 male pulse rates listed in Data Set 1 \u201cBody \nData\u201d in Appendix B and the heights of the same males. For the male pulse \nrates, x = 69.6 BPM and s = 11.3 BPM; for their heights, x = 174.12 cm and \ns = 7.10 cm. Note that we want to compare variation among pulse rates to varia-\ntion among heights.\n\n3-2 Measures of Variation \n97\nBiased and Unbiased Estimators\nThe sample standard deviation s is a biased estimator of the population standard de-\nviation s, which means that values of the sample standard deviation s do not tend \nto center ar",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 112
  },
  {
    "child_id": "0f5c2330-4b07-4b88-a9d7-1f44aa2a1cdb",
    "parent_id": "35967645-821e-4119-89f0-1f7b94c803b2",
    "text": "\u201cBody \nData\u201d in Appendix B and the heights of the same males. For the male pulse \nrates, x = 69.6 BPM and s = 11.3 BPM; for their heights, x = 174.12 cm and \ns = 7.10 cm. Note that we want to compare variation among pulse rates to varia-\ntion among heights.\n\n3-2 Measures of Variation \n97\nBiased and Unbiased Estimators\nThe sample standard deviation s is a biased estimator of the population standard de-\nviation s, which means that values of the sample standard deviation s do not tend \nto center around the value of the population standard deviation s. While individual \nvalues of s could equal or exceed s, values of s generally tend to underestimate the \nvalue of s. For example, consider an IQ test designed so that the population standard \ndeviation is 15. If you repeat the process of randomly selecting 100 subjects, giving \nthem IQ tests, and calculating the sample standard deviation s in each case, the sample \nstandard deviations that you get will tend to be less than 15, which is the population \nstandard deviation. There is no correction that allows us to fix the bias for all distribu-\ntions of data. There is a correction that allows us to fix the bias for normally distrib-\nuted populations, but it is rarely used because it is too complex and makes relatively \nminor corrections.\nThe sample variance s2 is an unbiased estimator of the population variance s2,\nwhich means that values of s2 tend to center around the value of s2 instead of system-\natically tending to overestimate or underestimate s2. Consider an IQ test designed so \nthat the population variance is 225. If you repeat the process of randomly selecting \n100 subjects, giving them IQ tests, and calculating the sample variance s2 in each \ncase, the sample variances that you obtain will tend to center around 225, which is the \npopulation variance.\nBiased estimators and unbiased estimators will be discussed more in Section 6-3.\nSOLUTION\nWe can compare the standard deviations if the same scales and units are used and \nthe two means are approximately equal, but here we have different scales and differ-\nent units of measurement, so we use the coefficients of variation:\n Male Pulse Rates:   CV = s\nx # 100% = 11.3 BPM\n69.6 BPM # 100% = 16.2%\n Male Heights:  \n CV = s\nx # 100% =\n7.10 cm\n174.12 cm # 100% = 4.1%\nWe can now see that the male pulse rates (with CV = 16.2%) vary more than male \nheights (with CV = 4.1%).\nMeasures of Variation\nAccess tech instructions, videos, and data sets at www.TriolaStats.com\nTECH CENTER \nStatistical Literacy and Critical Thinking \n1.\u00a0Range Rule of Thumb for Estimating s The 20 brain volumes (cm3) from Data Set 9 \n\u201cIQ and Brain Size\u201d in Appendix B vary from a low of 963 cm3 to a high of 1439 cm3. Use \nthe range rule of thumb to estimate the standard deviation s and compare the result to the exact \nstandard deviation of 124.9 cm3.\n3-2 Basic Skills and Concepts",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 112
  },
  {
    "child_id": "0ffbf60d-c160-4f12-b132-4e88ee861ff8",
    "parent_id": "000b50ac-f984-443a-a4c7-5cad9632a7e8",
    "text": "98 \nCHAPTER 3 Describing, Exploring, and Comparing Data\n2.\u00a0Range Rule of Thumb for Interpreting s The 20 brain volumes (cm3) from Data Set 9 \n\u201cIQ and Brain Size\u201d in Appendix B have a mean of 1126.0 cm3 and a standard deviation of \n124.9 cm3. Use the range rule of thumb to identify the limits separating values that are signifi-\ncantly low or significantly high. For such data, would a brain volume of 1440 cm3 be signifi-\ncantly high?\n3.\u00a0 Variance The 20 subjects used in Data Set 9 \u201cIQ and Brain Size\u201d in Appendix B have \nweights with a standard deviation of 20.0414 kg. What is the variance of their weights? Include \nthe appropriate units with the result.\n4.\u00a0Symbols Identify the symbols used for each of the following: (a) sample standard devia-\ntion; (b) population standard deviation; (c) sample variance; (d) population variance.\nIn Exercises 5\u201320, find the range, variance, and standard deviation for the given sample \ndata. Include appropriate units (such as \u201cminutes\u201d) in your results. (The same data were \nused in Section 3-1 where we found measures of center. Here we find measures of varia-\ntion.) Then answer the given questions.\n5. Charges for Births Data Set 3 \u201cBirths\u201d in Appendix B includes total charges for births at \nfour hospitals in New York State, and the top 10 highest amounts (in dollars) are listed below. \nWhat do the results tell us about the population of all such charges?\n471,062 359,091 290,837 271,863 255,788\n247,477 232,782 197,912 183,271 155,857\n6. MCAT Score Listed below are mean MCAT scores listed in order by year, starting with the \nyear 2002. What important feature of the data is not revealed by any of the measures of center?\n27.0 26.8 27.1 27.3 27.4 27.7 28.1 27.9 28.3 28.2 28.3 28.4\n7.\u00a0Football Player Numbers Listed below are the jersey numbers of 11 players randomly \nselected from the roster of the Seattle Seahawks when they won Super Bowl XLVIII. What do \nthe results tell us?\n89 91 55 7 20 99 25 81 19 82 60\n8.\u00a0Football Player Weights Listed below are the weights (lb) of 11 players randomly selected \nfrom the roster of the Seattle Seahawks when they won Super Bowl XLVIII (the same players \nfrom the preceding exercise). Are the results likely to be representative of all NFL players?\n189 254 235 225 190 305 195 202 190 252 305\n9.\u00a0 Peas in a Pod Biologists conducted experiments to determine whether a deficiency \nof carbon dioxide in the soil affects the phenotypes of peas. Listed below are the pheno-\ntype codes, where 1 = smooth @ yellow, 2 = smooth @ green, 3 = wrinkled @yellow, and \n4 = wrinkled @ green. Do the results make sense?\n2  1  1  1  1  1  1  4  1  2  2  1  2  3  3  2  3  1  3  1  3  1  3  2  2\n10.\u00a0TV Prices A physician plans to buy a television for her large waiting room. Listed below \nare selling prices (in dollars) of TVs that are 60 inches or larger and rated as a \u201cbest buy\u201d by \nConsumer Reports magazine. Are the resulting statistics representative of the population of all \nTVs that are 60 inches and larger?\n180",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 116
  },
  {
    "child_id": "f97bb8fa-d87e-4406-9a8c-d409cc83c5b8",
    "parent_id": "000b50ac-f984-443a-a4c7-5cad9632a7e8",
    "text": "w, 2 = smooth @ green, 3 = wrinkled @yellow, and \n4 = wrinkled @ green. Do the results make sense?\n2  1  1  1  1  1  1  4  1  2  2  1  2  3  3  2  3  1  3  1  3  1  3  2  2\n10.\u00a0TV Prices A physician plans to buy a television for her large waiting room. Listed below \nare selling prices (in dollars) of TVs that are 60 inches or larger and rated as a \u201cbest buy\u201d by \nConsumer Reports magazine. Are the resulting statistics representative of the population of all \nTVs that are 60 inches and larger?\n1800 1500 1200 1500 1400 1600 1500 950 1600 1150 1500 1750\n11.\u00a0Cell Phone Radiation Listed below are the measured radiation absorption rates (in W>kg) \ncorresponding to these cell phones: iPhone 5S, BlackBerry Z30, Sanyo Vero, Optimus V, Droid \nRazr, Nokia N97, Samsung Vibrant, Sony Z750a, Kyocera Kona, LG G2, and Virgin Mobile \nSupreme. The data are from the Federal Communications Commission. If one of each model of \ncell phone is measured for radiation and the results are used to find the measures of variation, \nare the results typical of the population of cell phones that are in use?\n1.18 1.41 1.49 1.04 1.45 0.74 0.89 1.42 1.45 0.51 1.38\n\n3-2 Measures of Variation \n99\n12.\u00a0Caffeine in Soft Drinks Listed below are measured amounts of caffeine (mg per 12 oz of \ndrink) obtained in one can from each of 20 brands (7-UP, A&W Root Beer, Cherry Coke, . . . , \nTab). Are the statistics representative of the population of all cans of the same 20 brands consumed \nby Americans?\n0  0  34  34  34  45  41  51  55  36  47  41 0  0  53  54  38  0  41  47\n13.\u00a0Firefighter Fatalities Listed below are the numbers of heroic firefighters who lost their \nlives in the United States each year while fighting forest fires. The numbers are listed in order \nby year, starting with the year 2000. What important feature of the data is not revealed by any \nof the measures of variation?\n20 18 23 30 20 12 24 9 25 15 8 11 15 34\n14.\u00a0Foot Lengths Listed below are foot lengths in inches of randomly selected Army women \nmeasured in the 1988 Anthropometric Survey (ANSUR). Are the statistics representative of the \ncurrent population of all Army women?\n10.4 9.3 9.1 9.3 10.0 9.4 8.6 9.8 9.9 9.1 9.1\n15.\u00a0Medical School Tuition Listed below in dollars are the annual costs of tuition at the 10 \nmost expensive private medical schools in the United States for a recent year (based on data \nfrom U.S. News & World Report). What does this \u201ctop 10\u201d list tell us about those costs for the \npopulation of all U.S. private medical school tuitions?\n57,261 56,784 55,196 54,976 54,653 54,528 54,268 54,050 53,581 53,323\n16.\u00a0California Smokers In the California Health Interview Survey, randomly selected adults \nare interviewed. One of the questions asks how many cigarettes are smoked per day, and results \nare listed below for 50 randomly selected respondents. How well do the results reflect the \nsmoking behavior of California adults?\n9 10 10 20 40 50 1Plus 44 other values that are all 02\nIn Exercises 17\u201320, find the coeffi",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 116
  },
  {
    "child_id": "3f527b78-f0a3-4c09-9294-0af8dd019bcd",
    "parent_id": "000b50ac-f984-443a-a4c7-5cad9632a7e8",
    "text": "cal school tuitions?\n57,261 56,784 55,196 54,976 54,653 54,528 54,268 54,050 53,581 53,323\n16.\u00a0California Smokers In the California Health Interview Survey, randomly selected adults \nare interviewed. One of the questions asks how many cigarettes are smoked per day, and results \nare listed below for 50 randomly selected respondents. How well do the results reflect the \nsmoking behavior of California adults?\n9 10 10 20 40 50 1Plus 44 other values that are all 02\nIn Exercises 17\u201320, find the coefficient of variation for each of the two samples; then com-\npare the variation. (The same data were used in Section 3-1.)\n17.\u00a0 Blood Pressure A sample of blood pressure measurements is taken from Data Set \n1 \u201cBody Data\u201d in Appendix B, and those values (mm Hg) are listed below. The values are \nmatched so that 10 subjects each have systolic and diastolic measurements.\nSubject:\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\nSystolic:\n118\n128\n158\n96\n156\n122\n116\n136\n126\n120\nDiastolic:\n 80\n 76\n 74\n52\n 90\n 88\n 58\n 64\n 72\n 82\n18.\u00a0White , Red Blood Counts Listed below are white blood cell counts (1000 cells>mL) \nand red blood cell counts (million cells>mL) from different subjects (from Data Set 1 \u201cBody \nData\u201d in Appendix B). The values are matched so that each of the 12 subjects has a white blood \ncell count and a red blood cell count.\nWhite:\n8.7\n4.9\n6.9\n7.5\n6.1\n5.7\n4.1\n8.1\n8.0\n5.6\n8.3\n6.9\nRed:\n4.8\n4.7\n4.5\n4.3\n5.0\n4.0\n4.7\n4.6\n4.1\n5.5\n4.4\n4.2\n19.\u00a0 White Blood Counts Listed below are white blood cell counts (1000 cells>mL) from \nmales and females (from Data Set 1 \u201cBody Data\u201d in Appendix B). Do they appear to be different?\nFemale:\n8.7\n6.9\n8.1\n8.0\n6.9\n8.1\n6.4\n6.3\n10.9\n4.8\n5.9\n7.2\nMale:\n4.9\n7.5\n6.1\n5.7\n4.1\n5.6\n8.3\n5.1\n 9.5\n6.1\n5.7\n5.4\n\n100 \nCHAPTER 3 Describing, Exploring, and Comparing Data\n20.\u00a0Queues A Providence Hospital experiment involves two different waiting line configura-\ntions for patients arriving for admission. The waiting times (in seconds) are recorded with a \nsingle line configuration that feeds four stations and another configuration with individual lines \nat the four stations.\nSingle Line\n390\n396\n402\n408\n426\n438\n444\n462\n462\n462\nIndividual Lines\n252\n324\n348\n372\n402\n462\n462\n510\n558\n600\nLarge Data Sets from Appendix B. In Exercises 21\u201324, refer to the indicated data set in \nAppendix B. Use software or a calculator to find the range, variance, and standard devia-\ntion. Express answers using appropriate units, such as \u201cminutes.\u201d\n21.\u00a0HDL Use the HDL cholesterol measurements (mg>dL) from the 300 subjects included in \nData Set 1 \u201cBody Data\u201d in Appendix B. Identify the highest value. Does it appear to be an out-\nlier? Do the measures of variation change much when that highest value is deleted?\n22.\u00a0LDL Repeat the preceding exercise using the LDL measurements (mg>dL).\n23.\u00a0Body Temperatures Refer to Data Set 2 \u201cBody Temperatures\u201d in Appendix B and use \nthe body temperatures for 12:00 AM on day 2.\n24.\u00a0Births Use the birth weights (grams) of the 400 babies listed in Data Set 3 \u201cBirths\u201d in \n App",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 116
  },
  {
    "child_id": "5ebc0263-24e4-444b-908e-03957f644b56",
    "parent_id": "000b50ac-f984-443a-a4c7-5cad9632a7e8",
    "text": "ubjects included in \nData Set 1 \u201cBody Data\u201d in Appendix B. Identify the highest value. Does it appear to be an out-\nlier? Do the measures of variation change much when that highest value is deleted?\n22.\u00a0LDL Repeat the preceding exercise using the LDL measurements (mg>dL).\n23.\u00a0Body Temperatures Refer to Data Set 2 \u201cBody Temperatures\u201d in Appendix B and use \nthe body temperatures for 12:00 AM on day 2.\n24.\u00a0Births Use the birth weights (grams) of the 400 babies listed in Data Set 3 \u201cBirths\u201d in \n Appendix B. Examine the list of birth weights to make an observation about those numbers. \nHow does that observation affect the way that the results should be rounded?\nEstimating Standard Deviation with the Range Rule of Thumb. In Exercises 25\u201328, \nrefer to the data in the indicated exercise. After finding the range of the data, use the range \nrule of thumb to estimate the value of the standard deviation. Compare the result to the \nstandard deviation computed with all of the data.\n25.\u00a0HDL Exercise 21\n26.\u00a0LDL Exercise 22\n27.\u00a0Body Temperatures Exercise 23\n28.\u00a0Births Exercise 24\nIdentifying Significant Values with the Range Rule of Thumb. In Exercises 29\u201332, \nuse the range rule of thumb to identify the limits separating values that are significantly low \nor significantly high.\n29.\u00a0Pulse Rates of Females Based on Data Set 1 \u201cBody Data\u201d in Appendix B, females \nhave pulse rates with a mean of 74.0 beats per minute and a standard deviation of 12.5 beats \nper minute. Is a female pulse rate of 44 beats per minute significantly low or significantly high? \n(All of these pulse rates are measured at rest.)\n30.\u00a0Pulse Rates of Males Based on Data Set 1 \u201cBody Data\u201d in Appendix B, males have \npulse rates with a mean of 69.6 beats per minute and a standard deviation of 11.3 beats per \nminute. Is a male pulse rate of 50 beats per minute significantly low or significantly high? (All \nof these pulse rates are measured at rest.) Explain.\n31.\u00a0Foot Lengths Based on Data Set 7 \u201cFoot and Height\u201d in Appendix B, adult males have \nfoot lengths with a mean of 27.32 cm and a standard deviation of 1.29 cm. Is the adult male \nfoot length of 30 cm significantly low or significantly high? Explain.\n32.\u00a0Body Temperatures Based on Data Set 2 \u201cBody Temperatures\u201d in Appendix B, body \ntemperatures of adults have a mean of 98.20oF and a standard deviation of 0.62oF. Is an adult \nbody temperature of 100oF significantly low or significantly high?",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 116
  },
  {
    "child_id": "56ad5921-781b-440c-b9e3-6a9d4ab2b07d",
    "parent_id": "2c96f882-84c6-46f8-a557-ad7a65c638ab",
    "text": "3-2 Measures of Variation \n101\nFinding Standard Deviation from a Frequency Distribution. In Exercises 33 and 34, \nrefer to the frequency distribution in the given exercise and find the standard deviation by \nusing the formula below, where x represents the class midpoint, f represents the class fre-\nquency, and n represents the total number of sample values. Also, compare the computed \nstandard deviations to these standard deviations obtained by using Formula 3-4 with the \noriginal list of data values: (Exercise 33) 59.5; (Exercise 34) 65.4.\ns = B\nn3\u03a31f # x22 4 - 3\u03a31f # x2 42\nn1n - 12\n33.\u00a0\nBlood Platelet \nCount of Males\n \nFrequency\n 0\u201399\n 1\n100\u2013199\n51\n200\u2013299\n90\n300\u2013399\n10\n400\u2013499\n 0\n500\u2013599\n 0\n600\u2013699\n 1\n34.\u00a0\nBlood Platelet \nCount of Females\n \nFrequency\n100\u2013199\n25\n200\u2013299\n92\n300\u2013399\n28\n400\u2013499\n 0\n500\u2013599\n 2\n35. Why Divide by n \u22121? Let a population consist of these values: 9 cigarettes, 10 \ncigarettes, and 20 cigarettes smoked in a day (based on data from the California Health \nInterview Survey). Assume that samples of two values are randomly selected with replace-\nment from this population. (That is, a selected value is replaced before the second selection \nis made.)\na. Find the variance s2 of the population {9 cigarettes, 10 cigarettes, 20 cigarettes}.\nb. After listing the nine different possible samples of two values selected with replacement, \nfind the sample variance s2 (which includes division by n - 1) for each of them; then find the \nmean of the nine sample variances s2.\nc. For each of the nine different possible samples of two values selected with replacement, find \nthe variance by treating each sample as if it is a population (using the formula for population \nvariance, which includes division by n); then find the mean of those nine population variances.\nd. Which approach results in values that are better estimates of s2: part (b) or part (c)? Why? \nWhen computing variances of samples, should you use division by n or n - 1?\ne. The preceding parts show that s2 is an unbiased estimator of s2. Is s an unbiased estimator \nof s? Explain.\n36. Mean Absolute Deviation Use the same population of {9 cigarettes, 10 cigarettes, \n20 cigarettes} from Exercise 35. Show that when samples of size 2 are randomly selected \nwith replacement, the samples have mean absolute deviations that do not center about the \nvalue of the mean absolute deviation of the population. What does this indicate about a \nsample mean absolute deviation being used as an estimator of the mean absolute deviation \nof a population?\n3-2  Beyond the Basics\n\n102 \nCHAPTER 3 Describing, Exploring, and Comparing Data\nKey Concept This section introduces measures of relative standing, which are num-\nbers showing the location of data values relative to the other values within the same \ndata set. The most important concept in this section is the z score, which will be used \noften in following chapters. We also discuss percentiles and quartiles, which are com-\nmon statistics, as well as another ",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 119
  },
  {
    "child_id": "db78364f-3cd0-423c-8d56-636925d7abf3",
    "parent_id": "2c96f882-84c6-46f8-a557-ad7a65c638ab",
    "text": "n absolute deviation \nof a population?\n3-2  Beyond the Basics\n\n102 \nCHAPTER 3 Describing, Exploring, and Comparing Data\nKey Concept This section introduces measures of relative standing, which are num-\nbers showing the location of data values relative to the other values within the same \ndata set. The most important concept in this section is the z score, which will be used \noften in following chapters. We also discuss percentiles and quartiles, which are com-\nmon statistics, as well as another statistical graph called a boxplot.\nPART 1\n  Basics of z Scores, Percentiles, Quartiles, \nand Boxplots \nz Scores\nA z score is found by converting a value to a standardized scale, as given in the fol-\nlowing definition. This definition shows that a z score is the number of standard devia-\ntions that a data value is away from the mean. The z score is used often in Chapter 6 \nand later chapters.\n3-3 \nMeasures of Relative Standing and Boxplots\nDEFINITION\nA z score (or standard score or standardized value) is the number of standard \ndeviations that a given value x is above or below the mean. The z score is calcu-\nlated by using one of the following:\nSample\nPopulation\nz = x - x\ns\nor\nz = x - m\ns\nROUND-OFF RULE FOR z SCORES Round z scores to two decimal places  \n(such as 2.31).\nThis round-off rule is motivated by the format of standard tables in which z scores \nare expressed with two decimal places, as in Table A-2 in Appendix A. Example 1 il-\nlustrates how z scores can be used to compare values, even if they come from different \npopulations.\nImportant Properties of z Scores\n1. A z score is the number of standard deviations that a given value x is above or \nbelow the mean.\n2. z Scores are expressed as numbers with no units of measurement.\n3. A data value is significantly low if its z score is less than or equal to -2 or the \nvalue is significantly high if its z score is greater than or equal to +2.\n4. If an individual data value is less than the mean, its corresponding z score \nis a negative number.\n\n3-3 Measures of Relative Standing and Boxplots \n103\nUsing z Scores to Identify Significant Values In Section 3-2 we used the range \nrule of thumb to conclude that a value is significantly low or significantly high if it is \nat least 2 standard deviations away from the mean. It follows that significantly low \nvalues have z scores less than or equal to -2 and significantly high values have z \nscores greater than or equal to +2, as illustrated in Figure 3-4. Using this criterion \nwith the two individual values used in Example 1 above, we see that neither value is \nsignificant because both z scores are between -2 and +2.\nEXAMPLE 1   Comparing a Baby\u2019s Weight and  \nAdult Body Temperature\nWhich of the following two data values is more extreme relative to the data set from \nwhich it came?\n \n\u25a0The 4000 g weight of a newborn baby (among 400 weights with sample mean \nx = 3152.0 g and sample standard deviation s = 693.4 g)\n \n\u25a0The 99\u00b0F temperature of an adult (among 106 adults wit",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 119
  },
  {
    "child_id": "114f7660-0a49-49f8-9cc4-35a54377661f",
    "parent_id": "2c96f882-84c6-46f8-a557-ad7a65c638ab",
    "text": "with the two individual values used in Example 1 above, we see that neither value is \nsignificant because both z scores are between -2 and +2.\nEXAMPLE 1   Comparing a Baby\u2019s Weight and  \nAdult Body Temperature\nWhich of the following two data values is more extreme relative to the data set from \nwhich it came?\n \n\u25a0The 4000 g weight of a newborn baby (among 400 weights with sample mean \nx = 3152.0 g and sample standard deviation s = 693.4 g)\n \n\u25a0The 99\u00b0F temperature of an adult (among 106 adults with sample mean \nx = 98.20\u00b0F and sample standard deviation s = 0.62\u00b0F)\nSOLUTION\nThe 4000 g weight and the 99\u00b0F body temperature can be standardized by convert-\ning each of them to z scores as shown below.\n4000 g birth weight:\nz = x - x\ns\n= 4000 g - 3152.0 g\n693.4 g\n= 1.22\n99\u00b0F body temperature:\nz = x - x\ns\n= 99\u00b0F - 98.20\u00b0F\n0.62\u00b0F\n= 1.29\nINTERPRETATION\nThe z scores show that the 4000 g birth weight is 1.22 standard deviations above the \nmean, and the 99\u00b0F body temperature is 1.29 standard deviations above the mean. \nBecause the body temperature is farther above the mean, it is the more extreme \nvalue, but not by much. A 99\u00b0F body temperature is slightly more extreme than a \nbirth weight of 4000 g.\nValues not signi\ufb01cant\nSigni\ufb01cantly\nlow values\nSigni\ufb01cantly\nhigh values\nz\n\u22122\n\u22121\n2\n\u22123\n3\n0\n1\nFIGURE 3-4  Interpreting z Scores \nSignificant values are those with z scores \u2026  -2.00 or \u00da 2.00.\n\n104 \nCHAPTER 3 Describing, Exploring, and Comparing Data\nA z score is a measure of position, in the sense that it describes the location of a \nvalue (in terms of standard deviations) relative to the mean. Percentiles and quartiles \nare other measures of position useful for comparing values within the same data set or \nbetween different sets of data.\nPercentiles\nPercentiles are one type of quantiles\u2014or fractiles\u2014which partition data into groups \nwith roughly the same number of values in each group.\nEXAMPLE 2  Is a Platelet Count of 75 Significantly Low?\nThe lowest platelet count in Data Set 1 \u201cBody Data\u201d in Appendix B is 75. (The \nplatelet counts are measured in 1000 cells>mL). Is that value significantly low? \nBased on the platelet counts from Data Set 1 in Appendix B, assume that platelet \ncounts have a mean of x = 239.4 and a standard deviation of s = 64.2.\nSOLUTION\nThe platelet count of 75 is converted to a z score as shown below:\nz = x - x\ns\n= 75 - 239.4\n64.2\n= -2.56\nINTERPRETATION\nThe platelet count of 75 converts to the z score of -2.56. Refer to Figure 3-4 to \nsee that z = -2.56 is less than -2, so the platelet count of 75 is significantly low. \n(Low platelet counts are called thrombocytopenia. What a wonderful name.)\nDEFINITION\nPercentiles are measures of location, denoted P1, P2, . . . , P99, which divide a set of \ndata into 100 groups with about 1% of the values in each group.\nThe 50th percentile, denoted P50, has about 50% of the data values below it and about \n50% of the data values above it, so the 50th percentile is the same as the median. \nThere is not universal agr",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 119
  },
  {
    "child_id": "eb477cc2-4d30-4f80-99d2-bc7bd087c731",
    "parent_id": "2c96f882-84c6-46f8-a557-ad7a65c638ab",
    "text": "ess than -2, so the platelet count of 75 is significantly low. \n(Low platelet counts are called thrombocytopenia. What a wonderful name.)\nDEFINITION\nPercentiles are measures of location, denoted P1, P2, . . . , P99, which divide a set of \ndata into 100 groups with about 1% of the values in each group.\nThe 50th percentile, denoted P50, has about 50% of the data values below it and about \n50% of the data values above it, so the 50th percentile is the same as the median. \nThere is not universal agreement on a single procedure for calculating percentiles, but \nwe will describe relatively simple procedures for (1) finding the percentile of a data \nvalue and (2) converting a percentile to its corresponding data value. We begin with \nthe first procedure.\nFinding the Percentile of a Data Value\nThe process of finding the percentile that corresponds to a particular data value x \nis given by the following (round the result to the nearest whole number):\nPercentile of value x = number of values less than x\ntotal number of values\n# 100\nDetecting Phony Data\nA class is \ngiven the \nhomework \nassignment of \nrecording the \nresults when a \ncoin is tossed \n500 times. One dishonest stu-\ndent decides to save time by just \nmaking up the results instead of \nactually flipping a coin. Because \npeople generally cannot make \nup results that are really random, \nwe can often identify such phony \ndata. With 500 tosses of an ac-\ntual coin, it is extremely likely that \nyou will get a run of six heads or \nsix tails, but people almost never \ninclude such a run when they \nmake up results.\nAnother way to detect fab-\nricated data is to establish that \nthe results violate Benford\u2019s law: \nFor many collections of data, the \nleading digits are not uniformly \ndistributed. Instead, the leading \ndigits of 1, 2,\u2026, 9 occur with \nrates of 30%, 18%, 12%, 10%, \n8%, 7%, 6%, 5%, and 5%, re-\nspectively. (See \u201cThe Difficulty of \nFaking Data,\u201d by Theodore Hill, \nChance, Vol. 12, No. 3.)\n\n3-3 Measures of Relative Standing and Boxplots \n105\nExample 3 shows how to convert from a given sample value to the corresponding \npercentile. There are several different methods for the reverse procedure of converting \na given percentile to the corresponding value in the data set. The procedure we will \nuse is summarized in Figure 3-5 on the next page, which uses the following notation.\nNotation\nn \ntotal number of values in the data set\nk \npercentile being used (Example: For the 25th percentile, k = 25.)\nL \n locator that gives the position of a value (Example: For the 12th value in \nthe sorted list, L = 12.)\nPk \nkth percentile (Example: P25 is the 25th percentile.)\nTABLE 3-4 Sorted Cotinine Measures of Smokers\n  0\n  1\n  1\n  3\n 17\n 32\n 35\n 44\n 48\n 86\n 87\n103\n112\n121\n123\n130\n131\n149\n164\n167\n173\n173\n198\n208\n210\n222\n227\n234\n245\n250\n253\n265\n266\n277\n284\n289\n290\n313\n477\n491\nEXAMPLE 3  Finding a Percentile\nTable 3-4 lists the 40 cotinine measures (ng>mL) of smokers from Data Set 14 \n\u201cPassive and Active Smoke\u201d in Appendix B, ",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 119
  },
  {
    "child_id": "5a155e12-7a2e-481a-8abf-86c39d5f9c16",
    "parent_id": "2c96f882-84c6-46f8-a557-ad7a65c638ab",
    "text": " the position of a value (Example: For the 12th value in \nthe sorted list, L = 12.)\nPk \nkth percentile (Example: P25 is the 25th percentile.)\nTABLE 3-4 Sorted Cotinine Measures of Smokers\n  0\n  1\n  1\n  3\n 17\n 32\n 35\n 44\n 48\n 86\n 87\n103\n112\n121\n123\n130\n131\n149\n164\n167\n173\n173\n198\n208\n210\n222\n227\n234\n245\n250\n253\n265\n266\n277\n284\n289\n290\n313\n477\n491\nEXAMPLE 3  Finding a Percentile\nTable 3-4 lists the 40 cotinine measures (ng>mL) of smokers from Data Set 14 \n\u201cPassive and Active Smoke\u201d in Appendix B, and they are listed in order. Find the \npercentile for the cotinine level of 198 ng>mL.\nSOLUTION\nFrom the sorted list of cotinine levels in Table 3-4, we see that there are 22 values \nless than 198 ng>mL, so\nPercentile of 198 ng>mL = 22\n40 # 100 = 55\nINTERPRETATION\nA cotinine level of 198 ng>mL is in the 55th percentile. This can be interpreted \nloosely as this: A cotinine level of 198 ng>mL separates the lowest 55% of values \nfrom the highest 45% of values. We have P55 = 198 ng>mL.\nEXAMPLE 4  Converting a Percentile to a Data Value\nRefer to the sorted cotinine levels of smokers in Table 3-4 and use the procedure in \nFigure 3-5 to find the value of the 33rd percentile, P33.\ncontinued",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 119
  },
  {
    "child_id": "7c32c6df-4399-415c-a676-a52250709ea9",
    "parent_id": "37430693-3fe9-480c-9696-e918affe5f78",
    "text": "106 \nCHAPTER 3 Describing, Exploring, and Comparing Data\nThe value of Pk is the Lth\nvalue, counting from\nthe lowest.\nIs L a whole\nnumber?\nYes\nNo\nChange L by rounding it\nup to the next larger\nwhole number.\nCompute\nn 5 number of values\nk 5 percentile in question\nSort the data.\n(Arrange the data in order\nof lowest to highest.)\nStart\nL 5\nn   where\nk\n100\nThe value of the kth percentile is \nmidway between the Lth value \nand the next value in the sorted \nset of data. Find Pk by adding \nthe Lth value and the next value \nand dividing the total by 2. \nFIGURE 3-5  Converting from the kth percentile to the \ncorresponding data value\nSOLUTION\nFrom Figure 3-5, we see that the sample data are already sorted, so we can proceed \nto find the value of the locator L. In this computation we use k = 33 because we are \ntrying to find the value of the 33rd percentile. We use n = 40 because there are 40 \ndata values.\nL =\nk\n100 # n = 33\n100 # 40 = 13.2\nSince L = 13.2 is not a whole number, we proceed to the next lower box in Figure 3-5 \nwhere we change L by rounding it up from 13.2 to the next larger whole number: 14. \n(In this book we typically round off the usual way, but this is one of two cases where \nwe round up instead of rounding off.) From the bottom box we see that the value of P33 \nis the 14th value, counting from the lowest. In Table 3-4, the 14th value is 121. That is, \nP33 = 121 ng>mL. Roughly speaking, about 33% of the cotinine levels in Table 3-4 \nare less than 121 ng>mL and 67% of them are more than 121 ng>mL.\n\n3-3 Measures of Relative Standing and Boxplots \n107\nQuartiles\nJust as there are 99 percentiles that divide the data into 100 groups, there are three \nquartiles that divide the data into four groups.\nEXAMPLE 5  Converting a Percentile to a Data Value\nRefer to the sorted pulse rates in Table 3-4. Use Figure 3-5 to find the 25th percen-\ntile, denoted by P25.\nSOLUTION\nReferring to Figure 3-5, we see that the sample data are already sorted, so we can \nproceed to compute the value of the locator L. In this case, we use k = 25 because \nwe are attempting to find the value of the 25th percentile, and we use n = 40 be-\ncause there are 40 data values.\nL =\nk\n100 # n = 25\n100 # 40 = 10\nSince L = 10 is a whole number, we proceed to the box in Figure 3-5 located at the \nright. We now see that the value of the 25th percentile is midway between the Lth \n(10th) value and the next higher value in the original set of data. That is, the value \nof the 25th percentile is midway between the 10th value and the 11th value. The \n10th value in Table 3-4 is 86 and the 11th value is 87, so the value midway between \nthem is 86.5 ng>mL. We conclude that the 25th percentile is P25 = 86.5 ng>mL.\nDEFINITION\nQuartiles are measures of location, denoted Q1, Q2, and Q3,which divide a set of \ndata into four groups with about 25% of the values in each group.\nHere are descriptions of quartiles that are more accurate than those given in the \npreceding definition:\nQ1 (First quartile): \n Same v",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 124
  },
  {
    "child_id": "eec38765-09d5-4e61-b0cd-de25b806cdca",
    "parent_id": "37430693-3fe9-480c-9696-e918affe5f78",
    "text": "een the 10th value and the 11th value. The \n10th value in Table 3-4 is 86 and the 11th value is 87, so the value midway between \nthem is 86.5 ng>mL. We conclude that the 25th percentile is P25 = 86.5 ng>mL.\nDEFINITION\nQuartiles are measures of location, denoted Q1, Q2, and Q3,which divide a set of \ndata into four groups with about 25% of the values in each group.\nHere are descriptions of quartiles that are more accurate than those given in the \npreceding definition:\nQ1 (First quartile): \n Same value as P25. It separates the bottom 25% of the \nsorted values from the top 75%. (To be more precise, \nat least 25% of the sorted values are less than or equal \nto Q1, and at least 75% of the values are greater than or \nequal to Q1.)\nQ2 (Second quartile):  Same as P50 and same as the median. It separates the \nbottom 50% of the sorted values from the top 50%.\nQ3 (Third quartile): \n Same as P75. It separates the bottom 75% of the sorted val-\nues from the top 25%. (To be more precise, at least 75% of \nthe sorted values are less than or equal to Q3, and at least \n25% of the values are greater than or equal to Q3.)\nFinding values of quartiles can be accomplished with the same procedure used for \nfinding percentiles. Simply use the relationships shown in the margin. In Example 4 \nwe found that P25 = 86.5 ng>mL, so it follows that Q1 = 86.5 ng>mL.\nQ1 = P25\nQ2 = P50\nQ3 = P75\n\n108 \nCHAPTER 3 Describing, Exploring, and Comparing Data\nIn earlier sections of this chapter we described several statistics, including the \nmean, median, mode, range, and standard deviation. Some other statistics are defined \nusing quartiles and percentiles, as in the following:\nInterquartile range (or IQR) \n= Q3 - Q1\nSemi-interquartile range \n= Q3 - Q1\n2\nMidquartile \n= Q3 + Q1\n2\n10\u201390 percentile range \n= P90 - P10\n5-Number Summary and Boxplot\nThe values of the minimum, maximum and three quartiles 1Q1, Q2, Q32 are used for \nthe 5-number summary and the construction of boxplot graphs.\nCAUTION Just as there is not universal agreement on a procedure for finding \npercentiles, there is not universal agreement on a single procedure for calculating \nquartiles, and different technologies often yield different results. If you use a \ncalculator or software for exercises involving quartiles, you may get results that differ \nsomewhat from the answers obtained by using the procedures described here.\nDEFINITION\nFor a set of data, the 5-number summary consists of these five values:\n1. Minimum\n2. First quartile, Q1\n3. Second quartile, Q2 (same as the median)\n4. Third quartile, Q3\n5. Maximum\nEXAMPLE 6  Finding a 5-Number Summary\nUse the cotinine measurements in Table 3-4 to find the 5-number summary.\nSOLUTION\nBecause the cotinine measurements in Table 3-4 are sorted, it is easy to see that \nthe minimum is 0 ng>mL and the maximum is 491 ng>mL. The value of the first \nquartile is Q1 = 86.5 ng>mL (from Example 5). The median is equal to Q2, and it \nis 170.0 ng>mL. Also, we can find that Q3 = 251.5 ng>mL by usin",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 124
  },
  {
    "child_id": "e7e8221c-58bb-456a-8be7-52722af3489d",
    "parent_id": "37430693-3fe9-480c-9696-e918affe5f78",
    "text": ". Second quartile, Q2 (same as the median)\n4. Third quartile, Q3\n5. Maximum\nEXAMPLE 6  Finding a 5-Number Summary\nUse the cotinine measurements in Table 3-4 to find the 5-number summary.\nSOLUTION\nBecause the cotinine measurements in Table 3-4 are sorted, it is easy to see that \nthe minimum is 0 ng>mL and the maximum is 491 ng>mL. The value of the first \nquartile is Q1 = 86.5 ng>mL (from Example 5). The median is equal to Q2, and it \nis 170.0 ng>mL. Also, we can find that Q3 = 251.5 ng>mL by using the procedure \nfor finding P75 (as summarized in Figure 3-5). The 5-number summary is therefore \n0, 86.5, 170.0, 251.5, and 491 (all in units of ng>mL).\nDEFINITION\nA boxplot (or box-and-whisker diagram) is a graph of a data set that consists of a \nline extending from the minimum value to the maximum value, and a box with lines \ndrawn at the first quartile Q1, the median, and the third quartile Q3. (See Figure 3-6.)\n\n3-3 Measures of Relative Standing and Boxplots \n109\nProcedure for Constructing a Boxplot\n1. Find the 5-number summary (minimum value, Q1, Q2, Q3, maximum value).\n2. Construct a line segment extending from the minimum data value to the maxi-\nmum data value.\n3. Construct a box (rectangle) extending from Q1 to Q3, and draw a line in the \nbox at the value of Q2 (median).\nCAUTION Because there is not universal agreement on procedures for finding \nquartiles, and because boxplots are based on quartiles, different technologies may \nyield different boxplots.\nEXAMPLE 7  Constructing a Boxplot\nUse the cotinine measurements listed in Table 3-4 to construct a boxplot.\nSOLUTION\nThe boxplot uses the 5-number summary found in Example 6: 0, 86.5, 170.0, 251.5, \nand 491 (all in units of ng>mL). Figure 3-6 is the boxplot representing the cotinine \nmeasurements listed in Table 3-4.\nFIGURE 3-6 Boxplot of Cotinine Measurements (ng, mL)\nSkewness A boxplot can often be used to identify skewness (discussed in \n Section 2-2). The boxplot in Figure 3-6 isn\u2019t exactly symmetric; it shows that the \ndata are slightly skewed to the right.\nBecause the shape of a boxplot is determined by the five values from the 5-number \nsummary, a boxplot is not a graph of the distribution of the data, and it doesn\u2019t show \nas much detailed information as a histogram or stemplot. However, boxplots are often \ngreat for comparing two or more data sets. When using two or more boxplots for com-\nparing different data sets, graph the boxplots on the same scale so that comparisons \ncan be easily made. Methods discussed later in this book allow us to analyze com-\nparisons of data sets more formally than subjective conclusions based on a graph. It is \nalways wise to construct suitable graphs, such as histograms, dotplots, and boxplots, \nbut we should not rely solely on subjective judgments based on graphs.\nEXAMPLE 8  Comparing the Pulse Rates of Men and Women\nThe Chapter Problem involves pulse rates of men and women, and the data are \nfound in Data Set 1 \u201cBody Data\u201d in Appendix B. Construct boxplots ",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 124
  },
  {
    "child_id": "4bc604a9-3be2-4e06-a728-1f1d78ced406",
    "parent_id": "37430693-3fe9-480c-9696-e918affe5f78",
    "text": "s discussed later in this book allow us to analyze com-\nparisons of data sets more formally than subjective conclusions based on a graph. It is \nalways wise to construct suitable graphs, such as histograms, dotplots, and boxplots, \nbut we should not rely solely on subjective judgments based on graphs.\nEXAMPLE 8  Comparing the Pulse Rates of Men and Women\nThe Chapter Problem involves pulse rates of men and women, and the data are \nfound in Data Set 1 \u201cBody Data\u201d in Appendix B. Construct boxplots of those two \ndifferent sets of pulse rates.\ncontinued\n\n110 \nCHAPTER 3 Describing, Exploring, and Comparing Data\nOutliers\nWhen analyzing data, it is important to identify and consider outliers because they \ncan strongly affect values of some important statistics (such as the mean and standard \ndeviation), and they can also strongly affect important methods discussed later in this \nbook. In Chapter 2 we described outliers as sample values that lie very far away from \nthe vast majority of the other values in a set of data, but that description is vague and \nit does not provide specific objective criteria. Part 2 of this section includes a descrip-\ntion of modified boxplots along with a more precise definition of outliers used in the \ncontext of creating modified boxplots.\nSOLUTION\nThe Statdisk-generated boxplots are shown in Figure 3-7. The three quartiles for \nmales are all lower than the corresponding three quartiles for females, which sug-\ngests that males generally have lower pulse rates than females. The minimums and \nmaximums are not very different in the two boxplots, and we shouldn\u2019t place too \nmuch importance on those differences because they are not very reliable measures.\nFIGURE 3-7 Boxplots of Pulse Rates of Men and Women\nCAUTION When analyzing data, always identify outliers and consider their effects, \nwhich can be substantial.\nPART 2\n Outliers and Modified Boxplots \nWe noted that the description of outliers is somewhat vague, but for the purposes of \nconstructing modified boxplots, we can consider outliers to be data values meeting \nspecific criteria based on quartiles and the interquartile range. (The interquartile range \nis often denoted by IQR, and IQR = Q3 - Q1.)\nIdentifying Outliers for Modified Boxplots\n1. Find the quartiles Q1, Q2, and Q3.\n2. Find the interquartile range (IQR), where IQR = Q3 - Q1.\n3. Evaluate 1.5 * IQR.\n4. In a modified boxplot, a data value is an outlier if it is\nabove Q3, by an amount greater than 1.5 : IQR\nor below Q1, by an amount greater than 1.5 : IQR\nModified Boxplots\nThe boxplots described earlier in Part 1 are called skeletal (or regular) boxplots, but \nsome statistical software packages provide modified boxplots, which represent outliers as",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 124
  },
  {
    "child_id": "16d49d5a-45f3-4f0f-ae9a-9c4277645a45",
    "parent_id": "b0e147d3-814e-418f-81e2-c3f099277dc2",
    "text": "3-3 Measures of Relative Standing and Boxplots \n111\nspecial points. A modified boxplot is a regular boxplot constructed with these modifi-\ncations: (1) A special symbol (such as an asterisk or point) is used to identify outliers \nas defined above, and (2) the solid horizontal line extends only as far as the minimum \ndata value that is not an outlier and the maximum data value that is not an outlier. \n(Note: Exercises involving modified boxplots are found in the \u201cBeyond the Basics\u201d \nexercises only.)\nEXAMPLE 9  Constructing Modified Boxplots\nUse the pulse rates of males in Data Set 1 \u201cBody Data\u201d from Appendix B to con-\nstruct a modified boxplot. The five-number summary is 40, 62.0, 68.0, 76.0, 104 (all \nin BPM).\nSOLUTION\nLet\u2019s begin with the four steps for identifying outliers in a modified boxplot.\n1. Using the pulse rates of males, the three quartiles are Q1 = 62.0, the median \nis Q2 = 68.0, and Q3 = 76.0.\n2. The interquartile range is IQR = Q3 - Q1 = 76.0 - 62.0 = 14.0.\n3. 1.5 * IQR = 1.5 * 14.0 = 21.0.\n \n4. Any outliers are\n \n\u25a0Greater than Q3 = 76.0 by more than 21.0 or\n \n\u25a0Less than Q1 = 62.0 by more than 21.0.\nThis means that any outliers are greater than 97.0 or less than 41.0. We can now \nexamine the original pulse rates of males to identify any that are greater than 97.0 or \nless than 41.0. We find that the pulse rates of 102 and 104 are greater than 97.0, and \nthe pulse rate of 40 is less than 41.0. The outliers are 102, 104, and 40.\nWe can now construct the modified boxplot shown in Figure 3-8. In Figure 3-8, \nthe three outliers (40, 102, 104) are identified as special points, the three quartiles \n(62.0, 68.0, 76.0) are shown as in a regular boxplot, and the horizontal line extends \nfrom the lowest data value that is not an outlier (42) to the highest data value that is \nnot an outlier (96).\nFIGURE 3-8 Modified Boxplot of Male Pulse Rates (BPM)\nCAUTION Because there is not universal agreement on procedures for finding \nquartiles, and because modified boxplots are based on quartiles, different \ntechnologies may yield different modified boxplots.\n\n112 \nCHAPTER 3 Describing, Exploring, and Comparing Data\nBoxplots, 5-Number Summary, Outliers\nAccess tech instructions, videos, and data sets at www.TriolaStats.com\nTECH CENTER \nStatistical Literacy and Critical Thinking \n1.\u00a0 z Scores LeBron James, one of the most successful basketball players of all time, has \na height of 6 feet 8 inches, or 203 cm. Based on statistics from Data Set 1 \u201cBody Data\u201d in \n Appendix B, his height converts to the z score of 4.07. How many standard deviations is his \nheight above the mean?\n2.\u00a0Heights The boxplot shown below results from the heights (cm) of males listed in Data Set \n1 \u201cBody Data\u201d in Appendix B. What do the numbers in that boxplot tell us?\n3.\u00a0Boxplot Comparison Refer to the boxplots shown below that are drawn on the same scale. \nOne boxplot represents weights of men and the other boxplot represents weights of women. \nWhich boxplot represents weights of wom",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 129
  },
  {
    "child_id": "94634325-9e70-4fee-a633-431bef8501c7",
    "parent_id": "b0e147d3-814e-418f-81e2-c3f099277dc2",
    "text": "ndix B, his height converts to the z score of 4.07. How many standard deviations is his \nheight above the mean?\n2.\u00a0Heights The boxplot shown below results from the heights (cm) of males listed in Data Set \n1 \u201cBody Data\u201d in Appendix B. What do the numbers in that boxplot tell us?\n3.\u00a0Boxplot Comparison Refer to the boxplots shown below that are drawn on the same scale. \nOne boxplot represents weights of men and the other boxplot represents weights of women. \nWhich boxplot represents weights of women? Explain.\n4.\u00a0z Scores If your score on your next statistics test is converted to a z score, which of these z \nscores would you prefer: -2.00,-1.00, 0, 1.00, 2.00? Why?\nz Scores. In Exercises 5\u20138, express all z scores with two decimal places.\n5.\u00a0Female Pulse Rates For the pulse rates of females listed in Data Set 1 \u201cBody Data\u201d in \nAppendix B, the mean is 74.0 BPM, the standard deviation is 12.5 BPM, and the maximum is \n104 BPM.\na. What is the difference between the maximum and the mean?\nb. How many standard deviations is that [the difference found in part (a)]?\nc. Convert the maximum pulse rate to a z score.\nd. If we consider pulse rates that convert to z scores between -2 and 2 to be neither signifi-\ncantly low nor significantly high, is the maximum pulse rate significant?\n6.\u00a0Female Pulse Rates For the pulse rates of females listed in Data Set 1 \u201cBody Data\u201d in \nAppendix B, the mean is 74.0 BPM, the standard deviation is 12.5 BPM, and the minimum is \n36 BPM.\na. What is the difference between the minimum and the mean?\nb. How many standard deviations is that [the difference found in part (a)]?\n3-3 Basic Skills and Concepts\n\n3-3 Measures of Relative Standing and Boxplots \n113\nc. Convert the minimum pulse rate to a z score.\nd. If we consider pulse rates that convert to z scores between -2 and 2 to be neither significantly \nlow nor significantly high, is the minimum pulse rate significantly low or significantly high?\n7.\u00a0Body Temperatures For the body temperatures at 12 AM on day 2 (listed in Data Set 2 \n\u201cBody Temperatures\u201d in Appendix B), the mean is 98.20oF, the standard deviation is 0.62oF, \nand the minimum is 96.5oF.\na. What is the difference between the minimum and the mean?\nb. How many standard deviations is that [the difference found in part (a)]?\nc. Convert the minimum temperature to a z score.\nd. If we consider body temperatures that convert to z scores between -2 and 2 to be neither \nsignificantly low nor significantly high, is the minimum body temperature significant?\n8.\u00a0Body Temperatures For the body temperatures at 12 AM on day 2 (listed in Data Set 2 \n\u201cBody Temperatures\u201d in Appendix B), the mean is 98.20\u00b0F, the standard deviation is 0.62\u00b0F,\nand Q3 = 98.60\u00b0F.\na. What is the difference between Q3 and the mean?\nb. How many standard deviations is that [the difference found in part (a)]?\nc. Convert Q3 to a z score.\nd. If we consider temperatures that convert to z scores between -2 and 2 to be neither signifi-\ncantly low nor significantly high, is Q3 s",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 129
  },
  {
    "child_id": "cd8b8b74-2b4a-4685-b38e-04b8c5bb5f92",
    "parent_id": "b0e147d3-814e-418f-81e2-c3f099277dc2",
    "text": "nificant?\n8.\u00a0Body Temperatures For the body temperatures at 12 AM on day 2 (listed in Data Set 2 \n\u201cBody Temperatures\u201d in Appendix B), the mean is 98.20\u00b0F, the standard deviation is 0.62\u00b0F,\nand Q3 = 98.60\u00b0F.\na. What is the difference between Q3 and the mean?\nb. How many standard deviations is that [the difference found in part (a)]?\nc. Convert Q3 to a z score.\nd. If we consider temperatures that convert to z scores between -2 and 2 to be neither signifi-\ncantly low nor significantly high, is Q3 significant?\nSignificant Values. In Exercises 9\u201312, consider a value to be significantly low if its z \nscore is less than or equal to \u22122 or consider the value to be significantly high if its z score \nis greater than or equal to 2.\n9.\u00a0ACT The ACT test is used to assess readiness for college. In a recent year, the mean ACT \nscore was 21.1 and the standard deviation was 5.1. Identify the ACT scores that are signifi-\ncantly low or significantly high.\n10.\u00a0MCAT In a recent year, scores on the MCAT had a mean of 25.2 and a standard deviation \nof 6.4. Identify the MCAT scores that are significantly low or significantly high.\n11.\u00a0Birth Weights Data Set 3 \u201cBirths\u201d lists birth weights (g) of 400 babies. Those weights \nhave a mean of 3152.0 g and a standard deviation of 693.4 g. Identify birth weights that are \nsignificantly low or significantly high.\n12.\u00a0Ergonomics in Aircraft Seats In the process of designing aircraft seats, it was found \nthat men have hip breadths with a mean of 36.6 cm and a standard deviation of 2.5 cm (based \non anthropometric survey data from Gordon, Clauser, et al.). Identify the hip breadths of men \nthat are significantly low or significantly high.\nComparing Values. In Exercises 13\u201316, use z scores to compare the given values.\n13.\u00a0Tallest and Shortest Men The tallest living man at the time of this writing is Sultan \nKosen, who has a height of 251 cm. The shortest living man is Chandra Bahadur Dangi, who \nhas a height of 54.6 cm. Heights of men have a mean of 174.12 cm and a standard deviation of \n7.10 cm. Which of these two men has the height that is more extreme?\n14.\u00a0Red Blood Cell Counts Based on Data Set 1 \u201cBody Data\u201d in Appendix B, males have \nred blood cell counts with a mean of 4.719 and a standard deviation of 0.490, while females \nhave red blood cell counts with a mean of 4.349 and a standard deviation of 0.402. Who has the \nhigher count relative to the sample from which it came: a male with a count of 5.58 or a female \nwith a count of 5.23? Explain.\n15.\u00a0Birth Weights Based on Data Set 3 \u201cBirths\u201d in Appendix B, newborn males have weights \nwith a mean of 3272.8 g and a standard deviation of 660.2 g. Newborn females have weights \nwith a mean of 3037.1 g and a standard deviation of 706.3 g. Who has the weight that is more \ncontinued\n\n114 \nCHAPTER 3 Describing, Exploring, and Comparing Data\nextreme relative to the group from which they came: a male who weighs 1500 g or a female \nwho weighs 1500 g? Who has the larger weight relative to the ",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 129
  },
  {
    "child_id": "6c135092-0996-4585-9700-e7a96f9b5245",
    "parent_id": "b0e147d3-814e-418f-81e2-c3f099277dc2",
    "text": "lain.\n15.\u00a0Birth Weights Based on Data Set 3 \u201cBirths\u201d in Appendix B, newborn males have weights \nwith a mean of 3272.8 g and a standard deviation of 660.2 g. Newborn females have weights \nwith a mean of 3037.1 g and a standard deviation of 706.3 g. Who has the weight that is more \ncontinued\n\n114 \nCHAPTER 3 Describing, Exploring, and Comparing Data\nextreme relative to the group from which they came: a male who weighs 1500 g or a female \nwho weighs 1500 g? Who has the larger weight relative to the group from which they came?\n16.\u00a0Oscars In the 87th Academy Awards, Eddie Redmayne won for best actor at the age of \n33 and Julianne Moore won for best actress at the age of 54. For all best actors, the mean age \nis 44.1 years and the standard deviation is 8.9 years. For all best actresses, the mean age is \n36.2 years and the standard deviation is 11.5 years. (All ages are determined at the time of the \nawards ceremony.) Relative to their genders, who had the more extreme age when winning the \nOscar: Eddie Redmayne or Julianne Moore? Explain.\nPercentiles. In Exercises 17\u201320, use the following lengths (inches) of bears (from Data \nSet 11 \u201cBear Measurements\u201d in Appendix B). Find the percentile corresponding to the \ngiven length.\n36.0 37.0 40.0 40.0 41.0 43.0 43.5 46.0 46.0 47.0 48.0 48.0\n49.0 50.0 52.0 52.5 53.0 53.0 54.0 57.3 57.5 58.0 59.0 59.0\n59.0 60.0 60.5 61.0 61.0 61.5 62.0 63.0 63.0 63.0 63.5 64.0\n64.0 64.0 65.0 65.0 66.5 67.0 67.5 68.5 70.0 70.5 72.0 72.0\n72.0 72.0 73.0 73.5 75.0 76.5\n17.\u00a061.0 in.  18.\u00a047.0 in.  19.\u00a070.0 in.  20.\u00a058.0 in.\nIn Exercises 21\u201328, use the same list of bear lengths (in.) given for Exercises 17\u201320. Find \nthe indicated percentile or quartile.\n21.\u00a0P60   22.\u00a0Q1\n23.\u00a0Q3   24.\u00a0P40\n25.\u00a0P50   26.\u00a0P75\n27.\u00a0P25   28.\u00a0P85\nBoxplots. In Exercises 29\u201332, use the given data to construct a boxplot and identify the \n5-number summary.\n29.\u00a0Foot Lengths The following are the foot lengths (cm) of 19 males (from Data Set 7 \u201cFoot \nand Height\u201d in Appendix B).\n 25.1 25.4 25.7 25.9 26.4 26.7 26.7 26.7 26.8 27.5\n 27.8 27.9 27.9 28.1 28.6 28.7 28.8 29.2 29.2\n30.\u00a0 Cell Phone Radiation Listed below are the measured radiation absorption rates (in \nW>kg) corresponding to these cell phones: iPhone 5S, BlackBerry Z30, Sanyo Vero, Optimus \nV, Droid Razr, Nokia N97, Samsung Vibrant, Sony Z750a, Kyocera Kona, LG G2, and Virgin \nMobile Supreme. The data are from the Federal Communications Commission.\n1.18 1.41 1.49 1.04 1.45 0.74 0.89 1.42 1.45 0.51 1.38\n31.\u00a0Radiation in Baby Teeth Listed below are amounts of strontium-90 (in millibecquerels, \nor mBq) in a simple random sample of baby teeth obtained from Pennsylvania residents born \nafter 1979 (based on data from \u201cAn Unexpected Rise in Strontium-90 in U.S. Deciduous Teeth \nin the 1990s,\u201d by Mangano et. al., Science of the Total Environment).\n 128 130 133 137 138 142 142 144 147 149 151 151 151 155\n 156 161 163 163 166 172\n32. Blood Pressure Measurements Fourteen different second-year medical students \nat  Bellevu",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 129
  },
  {
    "child_id": "66d47358-d447-43e3-9aa6-cad2b12763c1",
    "parent_id": "b0e147d3-814e-418f-81e2-c3f099277dc2",
    "text": "aby Teeth Listed below are amounts of strontium-90 (in millibecquerels, \nor mBq) in a simple random sample of baby teeth obtained from Pennsylvania residents born \nafter 1979 (based on data from \u201cAn Unexpected Rise in Strontium-90 in U.S. Deciduous Teeth \nin the 1990s,\u201d by Mangano et. al., Science of the Total Environment).\n 128 130 133 137 138 142 142 144 147 149 151 151 151 155\n 156 161 163 163 166 172\n32. Blood Pressure Measurements Fourteen different second-year medical students \nat  Bellevue Hospital measured the blood pressure of the same person. The systolic readings \n(mm Hg) are listed below.\n138 130 135 140 120 125 120 130 130 144 143 140 130 150",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 129
  },
  {
    "child_id": "f851eacd-e412-4e22-9b19-2fbb898fab65",
    "parent_id": "9b498a68-815e-4e9b-af14-75de08502061",
    "text": "Boxplots from Large Data Sets in Appendix B. In Exercises 33 and 34, use the given \ndata sets from Appendix B. Use the boxplots to compare the two data sets.\n33. BMI Use the body mass indexes (BMI) for males and use the BMI measures for females \nlisted in Data Set 1 \u201cBody Data.\u201d\n34. Lead and IQ Use the same scale to construct boxplots for the full IQ scores (IQF) for the \nlow lead level group and the high lead level group in Data Set 8 \u201cIQ and Lead\u201d in Appendix B.\n35. Outliers and Modified Boxplots Repeat Exercise 33 \u201cBMI\u201d using modified boxplots. \nIdentify any outliers as defined in Part 2 of this section.\n3-3 Beyond the Basics\nChapter Quick Quiz\n1.\u00a0Sleep Mean As part of the National Health and Nutrition Examination Survey, subjects \nwere asked how long they slept the preceding night and the following times (hours) were re-\nported: 8, 7, 5, 7, 4, 7, 6, 7, 8, 8, 8, 6. Find the mean.\n2.\u00a0Sleep Median What is the median of the sample values listed in Exercise 1?\n3.\u00a0Sleep Mode What is the mode of the sample values listed in Exercise 1?\n4.\u00a0Sleep Variance The standard deviation of the sample values in Exercise 1 is 1.3 hours. \nWhat is the variance (including units)?\n5.\u00a0Sleep Outlier If the sleep time of 0 hours is included with the sample data given in Exercise 1, \nis it an outlier? Why or why not?\n6.\u00a0Sleep z Score A larger sample of 50 sleep times (hours) has a mean of 6.3 hours and a stan-\ndard deviation of 1.4 hours. What is the z score for a sleep time of 5 hours?\n7.\u00a0Sleep Q3 For a sample of 80 sleep times, approximately how many of those times are less \nthan Q3?\n8.\u00a0Sleep 5-Number Summary For a sample of 100 sleep times, give the names of the val-\nues that constitute the 5-number summary. (The actual values can\u2019t be identified; just give the \nnames of those values.)\n9.\u00a0Estimating s A large sample of sleep times includes values ranging from a low of 4 hours \nto a high of 10 hours. Use the range rule of thumb to estimate the standard deviation.\n10.\u00a0Sleep Notation Consider a sample of sleep times taken from the population of all adults \nliving in Alaska. Identify the symbols used for the sample mean, population mean, sample stan-\ndard deviation, population standard deviation, sample variance, and the population variance.\nReview Exercises\n1.\u00a0Ergonomics When designing an eye-recognition security device, engineers must consider \nthe eye heights of standing women. (It\u2019s easy for men to bend lower, but it\u2019s more difficult for \nwomen to rise higher.) Listed below are the eye heights (in millimeters) obtained from a simple \nrandom sample of standing adult women (based on anthropometric survey data from Gordon, \nChurchill, et al.). Use the given eye heights to find the (a) mean; (b) median; (c) mode; (d) mid-\nrange; (e) range; (f) standard deviation; (g) variance.\n1550 1642 1538 1497 1571\nCHAPTER 3 Review Exercises \n115\n\n116 \nCHAPTER 3 Describing, Exploring, and Comparing Data\n2.\u00a0z Score Using the sample data from Exercise 1, find the z score corresponding to",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 133
  },
  {
    "child_id": "9fc33d69-2074-41e0-9105-e208cfcd4c9e",
    "parent_id": "9b498a68-815e-4e9b-af14-75de08502061",
    "text": " the eye heights (in millimeters) obtained from a simple \nrandom sample of standing adult women (based on anthropometric survey data from Gordon, \nChurchill, et al.). Use the given eye heights to find the (a) mean; (b) median; (c) mode; (d) mid-\nrange; (e) range; (f) standard deviation; (g) variance.\n1550 1642 1538 1497 1571\nCHAPTER 3 Review Exercises \n115\n\n116 \nCHAPTER 3 Describing, Exploring, and Comparing Data\n2.\u00a0z Score Using the sample data from Exercise 1, find the z score corresponding to the eye \nheight of 1642 mm. Is that eye height significantly low or significantly high? Why or why not?\n3.\u00a0ER Codes In an analysis of activities that resulted in brain injuries presenting at hospital \nemergency rooms (ERs), the following activities were identified by the code shown in paren-\ntheses: bicycling (12); football (14); playground (22); basketball (27); swimming (40). Find the \nmean of 12, 14, 22, 27, and 40. What is wrong with this result?\n4.\u00a0Comparing Birth Weights The birth weights of a sample of males have a mean of 3273 g and \na standard deviation of 660 g. The birth weights of a sample of females have a mean of 3037 g \nand a standard deviation of 706 g (based on Data Set 3 \u201cBirths\u201d in Appendix B). When consid-\nered among members of the same gender, which baby has the relatively larger birth weight: a \nboy with a birth weight of 3400 g or a girl with a birth weight of 3200 g? Why?\n5.\u00a0Effects of an Outlier Listed below are platelet counts (1000 cells>mL) from subjects in-\ncluded in Data Set 1 \u201cBody Data.\u201d Identify the outlier and then comment on the effect it has \non the mean and standard deviation by finding the values of those statistics with the outlier \nincluded and then with the outlier excluded.\n263 206 185 246 188 191 308 262 198 253 646\n6.\u00a0Interpreting a Boxplot Shown below is a boxplot of a sample of 30 maximal skull breadths \n(mm) measured from Egyptian skulls from around 4000 B.C. What do the numbers in the box-\nplot represent?\n7.\u00a0Interpreting Standard Deviation A physician routinely makes physical examinations of \nchildren. She is concerned that a three-year-old girl has a height of only 87.8 cm. Heights of \nthree-year-old girls have a mean of 97.5 cm and a standard deviation of 6.9 cm (based on data \nfrom the National Health and Nutrition Examination Survey). Use the range rule of thumb to \nfind the limits separating heights of three-year-old girls that are significantly low or signifi-\ncantly high. Based on the result, is the height of 87.8 cm significant? Should the physician be \nconcerned?\n8.\u00a0Mean or Median? A biostatistics class consists of 30 students with no income, 10 students \nwith small incomes from part-time jobs, plus a professor with a very large income that is well \ndeserved. Which is better for describing the income of a typical person in this class: mean or \nmedian? Explain.\nCumulative Review Exercises\n1.\u00a0Arsenic in Rice Listed below are measured amounts (mg per serving) of arsenic in a sample \nof servings of brow",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 133
  },
  {
    "child_id": "2102a71b-6be5-479f-80e1-ee2b5a7c5c93",
    "parent_id": "9b498a68-815e-4e9b-af14-75de08502061",
    "text": "7.8 cm significant? Should the physician be \nconcerned?\n8.\u00a0Mean or Median? A biostatistics class consists of 30 students with no income, 10 students \nwith small incomes from part-time jobs, plus a professor with a very large income that is well \ndeserved. Which is better for describing the income of a typical person in this class: mean or \nmedian? Explain.\nCumulative Review Exercises\n1.\u00a0Arsenic in Rice Listed below are measured amounts (mg per serving) of arsenic in a sample \nof servings of brown rice [data from the Food and Drug Administration (FDA)]. Construct a \nfrequency distribution. Use a class width of 2 mg, and use 0 mg as the lower class limit of the \nfirst class.\n6.1 5.4 6.9 4.9 6.6 6.3 6.7 8.2 7.8 1.5 5.4 7.3\n2.\u00a0Histogram Use the frequency distribution from Exercise 1 to construct a histogram. Use \nclass midpoint values for the horizontal scale.\n3. Stemplot Use the amounts of arsenic from Exercise 1 to construct a stemplot.\n4. Descriptive Statistics Use amounts of arsenic in Exercise 1 and find the following: (a) \nmean; (b) median; (c) standard deviation; (d) variance; (e) range. Include the appropriate units \nof measurement.\n\nCHAPTER 3 Cooperative Group Activities \n117\n5. a. A medical researcher has a collection of data at the nominal level of measurement and she \nwants to obtain a representative data value. Which of the following is most appropriate: mean, \nmedian, mode, or midrange? Why?\nb. A botanist wants to obtain data about the plants being grown in homes. If a sample is ob-\ntained by telephoning the first 250 people listed in the local telephone directory, what type of \nsampling is being used? (random, stratified, systematic, cluster, convenience)\nc. A botanist is experimenting with fertilizer sticks used for growing plants. She finds that the \namounts of fertilizer placed in the sticks are not very consistent, so that some fertilization lasts \nlonger than claimed, but others don\u2019t last long enough. She wants to improve quality by making \nthe amounts of fertilizer in the sticks more consistent. When analyzing the amounts of fertil-\nizer for that purpose, which of the following statistics is most relevant: mean, median, mode, \nmidrange, standard deviation, first quartile, third quartile? Should the value of that statistic be \nraised, lowered, or left unchanged?\nTechnology Project\nFreshman 15 Refer to Data Set 10 \u201cFreshman 15\u201d in Appendix B, which includes results from \na study of the legend that college freshmen tend to gain around 15 pounds (or 6.8 kilograms) \nduring their freshman year. That data set includes 5 columns of data from 67 subjects. Use the \nmethods of this chapter to make relevant comparisons, then form a subjective conclusion about \nthe 15-pound (or 6.8-kilogram) weight gain. Write a brief report including your conclusions \nwith supporting graphs and statistics.\nFROM DATA TO DECISION\nSecond-Hand Smoke\nData Set 14 \u201cPassive and Active Smoke\u201d in Appendix B \nlists measures of cotinine from three groups of subjects: \n",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 133
  },
  {
    "child_id": "ca1186d9-f97d-447f-8dbc-f079f50e64db",
    "parent_id": "9b498a68-815e-4e9b-af14-75de08502061",
    "text": "nds (or 6.8 kilograms) \nduring their freshman year. That data set includes 5 columns of data from 67 subjects. Use the \nmethods of this chapter to make relevant comparisons, then form a subjective conclusion about \nthe 15-pound (or 6.8-kilogram) weight gain. Write a brief report including your conclusions \nwith supporting graphs and statistics.\nFROM DATA TO DECISION\nSecond-Hand Smoke\nData Set 14 \u201cPassive and Active Smoke\u201d in Appendix B \nlists measures of cotinine from three groups of subjects: \n(1) smokers; (2) nonsmokers exposed to environmental to-\nbacco smoke; and (3) nonsmokers not exposed to environ-\nmental tobacco smoke. Cotinine is an indicator of nicotine \nabsorption.\nCritical Thinking\nUse the methods from this chapter to explore and compare \nthe cotinine measures in the three groups. Are there any \nnotable differences? Are there any outliers? What do you \nconclude about the effects that smokers have on nonsmok-\ners? Write a brief report of your conclusions, and provide \nsupporting statistical evidence.\nCooperative Group Activities\n1.\u00a0In-class activity In class, each student should record two pulse rates by counting the num-\nber of heartbeats in 1 minute. The first pulse rate should be measured while the student is \nseated, and the second pulse rate should be measured while the student is standing. Use the \nmethods of this chapter to compare results. Do males and females appear to have different \npulse rates? Do pulse rates measured while seated appear to be different from pulse rates mea-\nsured while standing?\n2.\u00a0Out-of-class activity Appendix B includes many real and interesting data sets. In each \ngroup of three or four students, select a data set from Appendix B and analyze it using the \nmethods discussed so far in this book. Write a brief report summarizing key conclusions.\n3.\u00a0Out-of-class activity In each group of three or four students, collect an original data set of \nvalues at the interval or ratio level of measurement. Provide the following: (1) a list of sample \nvalues; (2) printed software results of descriptive statistics and graphs; and (3) a written de-\nscription of the nature of the data, the method of collection, and important characteristics.\n\n118\nBasic Concepts of \nProbability\nAddition Rule and \nMultiplication Rule\nComplements, \nConditional Probability, \nand Bayes\u2019 Theorem\nRisks and Odds\nRates of Mortality, \nFertility, and Morbidity\nCounting\n4-1\n4-2\n4-3\n4-4\n4-5\n4-6\nDrug Testing of Job Applicants\nCHAPTER \nPROBLEM\nProbability\nApproximately 85% of U. S. companies test employees  \nand>or job applicants for drug use. A common and inexpen-\nsive (around $50) urine test is the EMIT (enzyme multiplied \nimmunoassay technique) test, which tests for the presence of \nany of five drugs: marijuana, cocaine, amphetamines, opiates, \nor phencyclidine. Most companies require that positive test \nresults be confirmed by a more reliable GC-MS (gas chroma-\ntography mass spectrometry) test.\nLike nearly all medical tests, drug tests are sometim",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 133
  },
  {
    "child_id": "c6b28d7a-3a48-4080-af04-a67d172a1fde",
    "parent_id": "9b498a68-815e-4e9b-af14-75de08502061",
    "text": "ximately 85% of U. S. companies test employees  \nand>or job applicants for drug use. A common and inexpen-\nsive (around $50) urine test is the EMIT (enzyme multiplied \nimmunoassay technique) test, which tests for the presence of \nany of five drugs: marijuana, cocaine, amphetamines, opiates, \nor phencyclidine. Most companies require that positive test \nresults be confirmed by a more reliable GC-MS (gas chroma-\ntography mass spectrometry) test.\nLike nearly all medical tests, drug tests are sometimes \nwrong. Wrong results are of two different types: (1) false posi-\ntive results and (2) false negative results. In today\u2019s society, \nthese terms should be clearly understood. A job applicant or \n4",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 133
  },
  {
    "child_id": "0649c3cb-3512-4f38-93e5-f5d60fac2333",
    "parent_id": "d00ec6b1-9df4-451b-beda-f2e92971ac7c",
    "text": "employee who gets a false positive result is someone who \nincorrectly appears to be using drugs when he or she is not \nactually using drugs. This type of mistake can unfairly result in \njob denial or termination of employment.\nAnalyzing the Results\nTable 4-1 includes results from 555 adults in the United States. \nIf one of the subjects from Table 4-1 is randomly selected \nfrom those who do not use drugs, what is the probability of a \nfalse positive result? If one of the subjects from Table 4-1 is \nrandomly selected from those who do not use drugs, what is \nthe probability of a true negative result? We will address such \nquestions in this chapter.\n\u2022 Prevalence: Proportion of the population having the condi-\ntion (such as drug use or disease) being considered.\n\u2022 False positive: Wrong test result that incorrectly indicates \nthat the subject has a condition when the subject does not \nhave that condition.\n\u2022 False negative: Wrong test result that incorrectly indicates \nthat the subject does not have a condition when the subject \ndoes have that condition.\n\u2022 True positive: Correct test result that indicates that a \n subject has a condition when the subject does have the \ncondition.\n\u2022 True negative: Correct test result that indicates that a sub-\nject does not have a condition when the subject does not \nhave the condition.\n\u2022 Test sensitivity: The probability of a true positive test \n result, given that the subject actually has the condition \n being tested.\n\u2022 Test specificity: The probability of a true negative test \n result, given that the subject does not have the condition \nbeing tested.\n\u2022 Positive predictive value: Probability that a subject actu-\nally has the condition, given that the test yields a positive \nresult (indicating that the condition is present).\n\u2022 Negative predictive value: Probability that the subject \ndoes not actually have the condition, given that the test \nyields a negative result (indicating that the condition is not \npresent).\nChapter Objectives \n119\nTABLE 4-1 Results from Drug Tests of Job Applicants\nPositive Test Result \n(Test shows drug use.)\nNegative Test Result \n(Test shows no drug use.)\nSubject Uses Drugs\n45\n(True Positive)\n5\n(False Negative)\nSubject Does Not Use Drugs\n25\n(False Positive)\n480\n(True Negative)\nThe main objective of this chapter is to develop a sound understanding of probability \nvalues, because those values constitute the underlying foundation on which methods \nof inferential statistics are built. The important methods of hypothesis testing com-\nmonly use P-values, which are probability values expressed as numbers between 0 \nand 1, inclusive. Smaller probability values, such as 0.01, correspond to events that \nare very unlikely. Larger probability values, such as 0.99, correspond to events that are \nvery likely. Here are the chapter objectives:\nBasic Concepts of Probability\n\u2022 Identify probabilities as values between 0 and 1, and interpret those values as \n expressions of likelihood of events.\n\u2022 Develop the abili",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 137
  },
  {
    "child_id": "0e621592-212b-41d5-bf94-82d49cb2757d",
    "parent_id": "d00ec6b1-9df4-451b-beda-f2e92971ac7c",
    "text": " hypothesis testing com-\nmonly use P-values, which are probability values expressed as numbers between 0 \nand 1, inclusive. Smaller probability values, such as 0.01, correspond to events that \nare very unlikely. Larger probability values, such as 0.99, correspond to events that are \nvery likely. Here are the chapter objectives:\nBasic Concepts of Probability\n\u2022 Identify probabilities as values between 0 and 1, and interpret those values as \n expressions of likelihood of events.\n\u2022 Develop the ability to calculate probabilities of events.\n\u2022 Define the complement of an event and calculate the probability of that \n complement.\n4-1\nCHAPTER OBJECTIVES\n>>>\n\n120 \nCHAPTER 4 Probability\nKey Concept The single most important objective of this section is to learn how to \ninterpret probability values, which are expressed as values between 0 and 1. A small \nprobability, such as 0.001, corresponds to an event that rarely occurs.\nRole of Probability in Statistics\nProbability plays a central role in the important statistical method of hypothesis \ntesting introduced later in Chapter 8. Statisticians make decisions using data by \nrejecting explanations (such as chance) based on very low probabilities. See the \nfollowing example illustrating the role of probability and a fundamental way that \nstatisticians think.\n4-1 \nBasic Concepts of Probability\nAddition Rule and Multiplication Rule\n\u2022 Develop the ability to calculate the probability that in a single trial, some event A oc-\ncurs or some event B occurs or they both occur. Apply the addition rule by correctly \nadjusting for events that are not disjoint (or are overlapping).\n\u2022 Develop the ability to calculate the probability of an event A occurring in a first trial \nand an event B occurring in a second trial. Apply the multiplication rule by adjusting \nfor events that are not independent.\n\u2022 Distinguish between independent events and dependent events.\nComplements, Conditional Probability, and Bayes\u2019 Theorem\n\u2022 Compute the probability of \u201cat least one\u201d occurrence of an event A.\n\u2022 Apply the multiplication rule by computing the probability of some event, given that \nsome other event has already occurred.\nRisks and Odds\n\u2022 Compare two probabilities using measures of absolute risk reduction and  \nrelative risk.\n\u2022 Obtain a measure of risk by calculating the odds ratio.\n\u2022 Measure the practical effectiveness of a treatment by determining the \u201cnumber \nneeded to treat,\u201d which is the number of subjects that must be treated in order to \nprevent one occurrence of some event.\nRates of Mortality, Fertility, and Morbidity\n\u2022 Use rates to describe the likelihood of an event.\n\u2022 Determine mortality rates, fertility rates, and morbidity rates.\nCounting\n\u2022 Develop the ability to apply the fundamental counting rule, factorial rule, permuta-\ntions rule, and combinations rule.\n\u2022 Distinguish between circumstances requiring the permutations rule and those \n requiring the combinations rule.\n4-2\n4-3\n4-4\n4-5\n4-6\nAddition Rule and Multiplication Rule\n\u2022 D",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 137
  },
  {
    "child_id": "f3b6ab55-3a5b-4c0a-8c86-52359926e74c",
    "parent_id": "d00ec6b1-9df4-451b-beda-f2e92971ac7c",
    "text": " one occurrence of some event.\nRates of Mortality, Fertility, and Morbidity\n\u2022 Use rates to describe the likelihood of an event.\n\u2022 Determine mortality rates, fertility rates, and morbidity rates.\nCounting\n\u2022 Develop the ability to apply the fundamental counting rule, factorial rule, permuta-\ntions rule, and combinations rule.\n\u2022 Distinguish between circumstances requiring the permutations rule and those \n requiring the combinations rule.\n4-2\n4-3\n4-4\n4-5\n4-6\nAddition Rule and Multiplication Rule\n\u2022 Develop the ability to calculate the probability that in a single trial, some event A oc-\ncurs or some event B occurs or they both occur. Apply the addition rule by correctly\nadjusting for events that are not disjoint (or are overlapping).\n\u2022 Develop the ability to calculate the probability of an event A occurring in a first trial\nand an event B occurring in a second trial. Apply the multiplication rule by adjusting\nfor events that are not independent.\n\u2022 Distinguish between independent events and dependent events.\nComplements, Conditional Probability, and Bayes\u2019 Theorem\n\u2022 Compute the probability of \u201cat least one\u201d occurrence of an event A.\n\u2022 Apply the multiplication rule by computing the probability of some event, given that\nsome other event has already occurred.\nRisks and Odds\n\u2022 Compare two probabilities using measures of absolute risk reduction and  \nrelative risk.\n\u2022 Obtain a measure of risk by calculating the odds ratio.\n\u2022 Measure the practical effectiveness of a treatment by determining the \u201cnumber \nneeded to treat,\u201d which is the number of subjects that must be treated in order to\nprevent one occurrence of some event.\nRates of Mortality, Fertility, and Morbidity\n\u2022 Use rates to describe the likelihood of an event.\n\u2022 Determine mortality rates, fertility rates, and morbidity rates.\nCounting\n\u2022 Develop the ability to apply the fundamental counting rule, factorial rule, permuta-\ntions rule, and combinations rule.\n\u2022 Distinguish between circumstances requiring the permutations rule and those\nrequiring the combinations rule.\n\n4-1 Basic Concepts of Probability \n121\nINTERPRETATION\nAmong the 100 babies, 75 girls and 55 girls are both greater than the 50 girls that \nwe typically expect, but only the event of 75 girls leads us to believe that the gender \nselection method is effective. Even though there is a chance of getting 75 girls (or \nmore) in 100 births with no special treatment, the probability of that happening is so \nsmall (0.0000003) that we should reject chance as a reasonable explanation. Instead, \nit would be generally recognized that the results provide strong support for the claim \nthat the gender selection method is effective. This is exactly how statisticians think: \nThey reject explanations (such as chance) based on very low probabilities.\nEXAMPLE 1  Analyzing a Claim\nResearchers have made this claim (really, they have):\nClaim: \u201cWe have developed a gender selection method that greatly increases \nthe likelihood of a baby being a girl.\u201d\nHypothesis Used W",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 137
  },
  {
    "child_id": "001767e8-5129-40fe-b825-75b42dec33aa",
    "parent_id": "d00ec6b1-9df4-451b-beda-f2e92971ac7c",
    "text": "asonable explanation. Instead, \nit would be generally recognized that the results provide strong support for the claim \nthat the gender selection method is effective. This is exactly how statisticians think: \nThey reject explanations (such as chance) based on very low probabilities.\nEXAMPLE 1  Analyzing a Claim\nResearchers have made this claim (really, they have):\nClaim: \u201cWe have developed a gender selection method that greatly increases \nthe likelihood of a baby being a girl.\u201d\nHypothesis Used When Testing the Preceding Claim: The method of gender \nselection has no e\ufb00ect, so that for couples using this method, about 50% of the \nbirths result in girls.\n(The probability of a girl in the United States is actually 0.488, but here we assume \nthat boys and girls are equally likely.)\nFigure 4-1 shows the sample data from two tests of 100 couples using the \n gender selection method and the conclusion reached for each test.\n75\nGirls\nStatisticians reject explanations based on\nvery low probabilities\nTest A Result\nProbability of 75 (or more) Girls by\nchance 5 3 in 10,000,000\n5 0.0000003\nChance rejected as\nreasonable explanation\nGender selection method\nappears to be e\ufb00ective\n25\nBoys\n55\nGirls\nTest B Result\nProbability of 55 (or more) Girls by\nchance 5 184 in 1,000\n5 0.184\nChance not rejected as\nreasonable explanation\nCannot conclude gender\nselection method is e\ufb00ective\n45\nBoys\nDi\ufb00erent Gender Selection Methods\nTested with 100 Births\nFIGURE 4-1 Gender Selection Method Test Data and Conclusions\nBasics of Probability\nIn probability, we deal with procedures (such as generating male>female births or \nmanufacturing defective>nondefective pregnancy test kits) that produce outcomes.\nProbabilities That \nChallenge Intuition\nIn certain cases, \nour subjective \nestimates of \nprobability val-\nues are dramati-\ncally different \nfrom the actual \nprobabilities. \nHere is a classical example: If \nyou take a deep breath, there is \nbetter than a 99% chance that \nyou will inhale a molecule that \nwas exhaled in dying Caesar\u2019s \nlast breath. In that same morbid \nand unintuitive spirit, if Socrates\u2019 \nfatal cup of hemlock was mostly \nwater, then the next glass of \nwater you drink will likely contain \none of those same molecules. \nHere\u2019s another, less morbid \nexample that can be verified: In \nclasses of 25 students, there is \nbetter than a 50% chance that \nat least 2 students will share the \nsame birthday (day and month).",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 137
  },
  {
    "child_id": "5701ba71-7747-4803-975a-0ccf667a51b6",
    "parent_id": "07868fc5-5412-4db6-8a05-961164cb6948",
    "text": "122 \nCHAPTER 4 Probability\nExample 2 illustrates the concepts defined above.\nDEFINITIONS\nAn event is any collection of results or outcomes of a procedure.\nA simple event is an outcome or an event that cannot be further broken down into \nsimpler components.\nThe sample space for a procedure consists of all possible simple events. That is, \nthe sample space consists of all outcomes that cannot be broken down any further.\nEXAMPLE 2  Simple Event and Sample Spaces\nIn the following display, we use \u201cb\u201d to denote a baby boy and \u201cg\u201d to denote a \nbaby\u00a0girl.\n \nProcedure\n \nExample of Event\nSample Space: Complete \nList of Simple Events\nSingle birth\n1 girl (simple event)\n{b, g}\n3 births\n2 boys and 1 girl (bbg, \nbgb, and gbb are all \nsimple events resulting in \n2 boys and 1 girl)\n{bbb, bbg, bgb, bgg, gbb, \ngbg, ggb, ggg}\nSimple Events:\n \n\u25a0With one birth, the result of 1 girl is a simple event and the result of 1 boy is \nanother simple event. They are individual simple events because they cannot be \nbroken down any further.\n \n\u25a0With three births, the result of 2 girls followed by a boy (ggb) is a simple event.\n \n\u25a0When rolling a single die, the outcome of 5 is a simple event, but the outcome \nof an even number is not a simple event.\nNot a Simple Event: With three births, the event of \u201c2 girls and 1 boy\u201d is not  \na simple event because it can occur with these di\ufb00erent simple events: ggb,  \ngbg, bgg.\nSample Space: With three births, the sample space consists of the eight  di\ufb00erent \nsimple events listed in the above table.\nThree Common Approaches to Finding the Probability of an Event\nWe first list some basic notation, and then we present three common approaches to \nfinding the probability of an event.\nNotation for Probabilities\nP denotes a probability.\nA, B, and C denote specific events.\nP(A) denotes the \u201cprobability of event A occurring.\u201d\nThe following three approaches for finding probabilities result in values between 0 \nand 1: 0 \u2026 P1A2 \u2026 1. Figure 4-2 shows the possible values of probabilities and the \nmore familiar and common expressions of likelihood.\nCertain\nLikely\n50\u201350 Chance\nUnlikely\nImpossible\n0\n0.5\n1\nFIGURE 4-2 Possible \nValues for Probabilities\n\n4-1 Basic Concepts of Probability \n123\n1. Relative Frequency Approximation of Probability Conduct (or observe) a \nprocedure and count the number of times that event A occurs. P(A) is then ap-\nproximated as follows:\nP1A2 =\nnumber of times A occurred\nnumber of times the procedure was repeated\nWhen referring to relative frequency approximations of probabilities, this text \nwill not distinguish between results that are exact probabilities and those that \nare approximations, so an instruction to \u201cfind the probability\u201d could actually \nmean \u201cestimate the probability.\u201d\n2. Classical Approach to Probability (Requires Equally Likely Outcomes) \nIf a procedure has n different simple events that are equally likely, and if \nevent A can occur in s different ways, then\nP1A2 =\nnumber of ways A occurs\nnumber of different simple eve",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 140
  },
  {
    "child_id": "4b9ad57c-0864-4da5-8794-36e0673adbec",
    "parent_id": "07868fc5-5412-4db6-8a05-961164cb6948",
    "text": "ency approximations of probabilities, this text \nwill not distinguish between results that are exact probabilities and those that \nare approximations, so an instruction to \u201cfind the probability\u201d could actually \nmean \u201cestimate the probability.\u201d\n2. Classical Approach to Probability (Requires Equally Likely Outcomes) \nIf a procedure has n different simple events that are equally likely, and if \nevent A can occur in s different ways, then\nP1A2 =\nnumber of ways A occurs\nnumber of different simple events = s\nn\nCAUTION When using the classical approach, always confirm that the outcomes \nare equally likely.\n3. Subjective Probabilities P(A), the probability of event A, is estimated by \nusing knowledge of the relevant circumstances.\nFigure 4-3 illustrates the approaches of the preceding three definitions.\n1. Relative Frequency Approach: When trying to de-\ntermine the probability that an individual car crashes in a \nyear, we must examine past results to determine the num-\nber of cars in use in a year and the number of them that \ncrashed; then we \ufb01nd the ratio of the number of cars that \ncrashed to the total number of cars. For a recent year, the \nresult is a probability of 0.0480. (See Example 3.)\n2. Classical Approach: When trying to determine the \nprobability of randomly selecting three children who are \nof the same gender, there are two ways to get the same \ngenders (boy/boy/boy and girl/girl/girl) among the eight \nequally likely outcomes, so the probability is 2/8 or 1/4. \n(See Example 4.)\n3. Subjective Probability: When trying to estimate the \nprobability of someone with an appendix getting acute \nappendicitis in the next year, we know from personal ex-\nperience that the probability is quite small. Let\u2019s estimate \nit to be, say, 0.001 (equivalent to 1 chance in 1000). (See \nExample 5.)\nFIGURE 4-3 Three Approaches to Finding a Probability\n\n124 \nCHAPTER 4 Probability\nSimulations Sometimes none of the preceding three approaches can be used. A simu-\nlation of a procedure is a process that behaves in the same ways as the procedure itself \nso that similar results are produced. Probabilities can sometimes be found by using a \nsimulation. See the Technology Project near the end of this chapter.\nRounding Probabilities Although it is difficult to develop a universal rule for round-\ning off probabilities, the following guide will apply to most problems in this text.\nROUNDING PROBABILITIES\nWhen expressing the value of a probability, either give the exact fraction or deci-\nmal or round off final decimal results to three significant digits. (Suggestion: When \na probability is not a simple fraction such as 2>3 or 5>9, express it as a decimal so \nthat the number can be better understood.) All digits in a number are significant ex-\ncept for the zeros that are included for proper placement of the decimal point. See \nthe following examples.\n \n\u25a0The probability of 0.4450323339 (from Example 6) has ten significant digits \n(4450323339), and it can be rounded to three signifi",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 140
  },
  {
    "child_id": "063c4e45-d5be-47b2-b367-50acb4e91100",
    "parent_id": "07868fc5-5412-4db6-8a05-961164cb6948",
    "text": "al or round off final decimal results to three significant digits. (Suggestion: When \na probability is not a simple fraction such as 2>3 or 5>9, express it as a decimal so \nthat the number can be better understood.) All digits in a number are significant ex-\ncept for the zeros that are included for proper placement of the decimal point. See \nthe following examples.\n \n\u25a0The probability of 0.4450323339 (from Example 6) has ten significant digits \n(4450323339), and it can be rounded to three significant digits as 0.445.\n \n\u25a0The probability of 1>3 can be left as a fraction or rounded to 0.333. (Do not \nround to 0.3.)\n \n\u25a0The probability of 2>8 can be expressed as 1>4 or 0.25. (Because 0.25 is exact, \nthere\u2019s no need to express it with three significant digits as 0.250.)\nProbabilities Expressed as Percentages? Mathematically, a probability of 0.25 is \nequivalent to 25%, but there are good reasons for sticking with fractions and decimals \nand not using percentages. Professional journals almost universally express probabili-\nties as decimals, not as percentages. Later in this book, we will use probability values \ngenerated from statistical software, and they will always be in the form of decimals.\nWhen finding probabilities with the relative frequency approach, we obtain an ap-\nproximation instead of an exact value. As the total number of observations increases, \nthe corresponding approximations tend to get closer to the actual probability. This \nproperty is commonly referred to as the law of large numbers.\nLAW OF LARGE NUMBERS\nAs a procedure is repeated again and again, the relative frequency probability of \nan event tends to approach the actual probability.\nThe law of large numbers tells us that relative frequency approximations tend to get \nbetter with more observations. This law reflects a simple notion supported by common \nsense: A probability estimate based on only a few trials can be off by a substantial amount, \nbut with a very large number of trials, the estimate tends to be much more accurate.\nCAUTIONS\n1.  The law of large numbers applies to behavior over a large number of trials, and it \ndoes not apply to any one individual outcome. Gamblers sometimes foolishly lose \nlarge sums of money by incorrectly thinking that a string of losses increases the \nchances of a win on the next bet, or that a string of wins is likely to continue.\n2.  If we know nothing about the likelihood of different possible outcomes, we \nshould not assume that they are equally likely. For example, we should not think \nthat the probability of passing the next statistics test is 1>2, or 0.5 (because we \neither pass the test or do not). The actual probability depends on factors such \nas the amount of preparation and the difficulty of the test.\n\n4-1 Basic Concepts of Probability \n125\nEXAMPLE 3  Relative Frequency Probability: Skydiving\nFind the probability of dying when making a skydiving jump.\nSOLUTION\nIn a recent year, there were about 3,000,000 skydiving jumps and 21 of them \n",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 140
  },
  {
    "child_id": "9650000f-90d4-4b93-93f5-494c360ab05d",
    "parent_id": "07868fc5-5412-4db6-8a05-961164cb6948",
    "text": "For example, we should not think \nthat the probability of passing the next statistics test is 1>2, or 0.5 (because we \neither pass the test or do not). The actual probability depends on factors such \nas the amount of preparation and the difficulty of the test.\n\n4-1 Basic Concepts of Probability \n125\nEXAMPLE 3  Relative Frequency Probability: Skydiving\nFind the probability of dying when making a skydiving jump.\nSOLUTION\nIn a recent year, there were about 3,000,000 skydiving jumps and 21 of them \n resulted in deaths. We use the relative frequency approach as follows:\nP1skydiving death2 =\nnumber of skydiving deaths\ntotal number of skydiving jumps =\n21\n3,000,0000 = 0.000007\nHere the classical approach cannot be used because the two outcomes (dying, \n surviving) are not equally likely. A subjective probability can be estimated in the \nabsence of historical data.\nEXAMPLE 4   Classical Probability: Three Children of the  \nSame Gender\nWhen three children are born, the sample space of genders is as shown in Example 1: \n{bbb, bbg, bgb, bgg, gbb, gbg, ggb, ggg}. If boys and girls are equally likely, then \nthose eight simple events are equally likely. Assuming that boys and girls are equally \nlikely, find the probability of getting three children all of the same gender when three \nchildren are born. (In reality, the probability of a boy is 0.512 instead of 0.5.)\nSOLUTION\nThe sample space {bbb, bbg, bgb, bgg, gbb, gbg, ggb, ggg} includes eight equally \nlikely outcomes, and there are exactly two outcomes in which the three children are \nof the same gender: bbb and ggg. We can use the classical approach to get\nP1three children of the same gender2 = 2\n8 = 1\n4  or  0.25\nEXAMPLE 5  Subjective Probability: Acute Appendicitis\nWhat is the probability that you will get acute appendicitis next year?\nSOLUTION\nWe could probably find past results and use the relative frequency approach, but for \nnow, in the absence of historical data on acute appendicitis, we make a subjective \nestimate. Experience suggests that the probability is quite small. Let\u2019s estimate it to \nbe, say, 0.001 (equivalent to 1 chance in 1000). Depending on our knowledge of the \nrelevant circumstances, that subjective estimate might be reasonably accurate or it \nmight be grossly wrong.\nCAUTION Don\u2019t make the common mistake of finding a probability value by \nmindlessly dividing a smaller number by a larger number. Instead, think carefully \nabout the numbers involved and what they represent. Carefully identify the total \nnumber of items being considered, as illustrated in Example 6.",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 140
  },
  {
    "child_id": "0cf3a9b1-b1ae-4e04-b7b2-2e9379ffd4fb",
    "parent_id": "cbcd5e2e-1bfd-471b-8840-90b98cc7a0a5",
    "text": "126 \nCHAPTER 4 Probability\nInstead of trying to determine an answer directly from the given statement, first sum-\nmarize the information in a format that allows clear understanding, such as this format:\n 3785 texted while driving\n 4720 did not text while driving\n 8505 total number of drivers in the sample\nWe can now use the relative frequency approach as follows:\n P1texting while driving2 = number of drivers who texted while driving\ntotal number of drivers in the sample\n= 3785\n8505\n = 0.445\nINTERPRETATION\nThere is a 0.445 probability that if a high school driver is randomly selected, he or \nshe texted while driving during the previous 30 days.\nEXAMPLE 6  Texting and Driving\nIn a study of U.S. high school drivers, it was found that 3785 texted while driving \nduring the previous 30 days, and 4720 did not text while driving during that same \ntime period (based on data from \u201cTexting While Driving . . . . ,\u201d by Olsen, Shults, \nEaton, Pediatrics, Vol. 131, No. 6). Based on these results, if a high school driver is \nrandomly selected, find the probability that he or she texted while driving during the \nprevious 30 days.\nSOLUTION\nCAUTION A common mistake is to blindly plug in numbers to get the wrong \nprobability of 3785>4720 = 0.802. We should think about what we are doing, as \nfollows.\nEXAMPLE 7  Thanksgiving Day\nIf a year is selected at random, find the probability that Thanksgiving Day in the \nUnited States will be (a) on a Wednesday or (b) on a Thursday.\nSOLUTION\na. In the United States, Thanksgiving Day always falls on the fourth Thursday  \nin\u00a0November. It is therefore impossible for Thanksgiving to be on \na  Wednesday. When an event is impossible, its probability is 0. \nP(Thanksgiving on Wednesday) = 0.\nb. It is certain that a Thanksgiving Day in the United States will be on \na  Thursday. When an event is certain to occur, its probability is 1. \nP(Thanksgiving on Thursday) = 1.\nBecause any event imaginable is impossible, certain, or somewhere in between, \nit\u00a0follows that the mathematical probability of any event A is 0, 1, or a number \nbetween 0 and 1 (as shown in Figure 4-2). That is, 0 \u2026 P1A2 \u2026 1.\n\n4-1 Basic Concepts of Probability \n127\nComplementary Events\nSometimes we need to find the probability that an event A does not occur.\nDEFINITION\nThe complement of event A, denoted by A, consists of all outcomes in which event \nA does not occur.\nEXAMPLE 8  Complement of Death from Skydiving\nExample 3 shows that in a recent year, there were 3,000,000 skydiving jumps and \n21 of them resulted in death. Find the probability of not dying when making a \nskydiving jump.\nSOLUTION\nAmong 3,000,000 jumps there were 21 deaths, so it follows that the other 2,999,979 \njumps were survived. We get\nP1not dying when making a skydiving jump2 = 2,999,979\n3,000,000 = 0.999993\nINTERPRETATION\nThe probability of not dying when making a skydiving jump is 0.999993.\nRelationship Between P1A2 and P1A2 If we denote the event of dying in a \n skydiving jump by D, Example 3 showed th",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 144
  },
  {
    "child_id": "ad7b90e6-fd36-41b5-b30d-21b846befbee",
    "parent_id": "cbcd5e2e-1bfd-471b-8840-90b98cc7a0a5",
    "text": "mps and \n21 of them resulted in death. Find the probability of not dying when making a \nskydiving jump.\nSOLUTION\nAmong 3,000,000 jumps there were 21 deaths, so it follows that the other 2,999,979 \njumps were survived. We get\nP1not dying when making a skydiving jump2 = 2,999,979\n3,000,000 = 0.999993\nINTERPRETATION\nThe probability of not dying when making a skydiving jump is 0.999993.\nRelationship Between P1A2 and P1A2 If we denote the event of dying in a \n skydiving jump by D, Example 3 showed that P1D2 = 0.000007 and Example 8 \nshowed that P1D2 = 0.999993. The probability of P1D2 could be found by just sub-\ntracting P(D) from 1.\nIdentifying Significant Results with Probabilities:  \nThe Rare Event Rule for Inferential Statistics\nIf, under a given assumption, the probability of a particular observed event is \nvery small and the observed event occurs signi\ufb01cantly less than or signi\ufb01cantly \ngreater than what we typically expect with that assumption, we conclude that \nthe assumption is probably not correct.\nWe can use probabilities to identify values that are significantly low or significantly \nhigh as follows.\nUsing Probabilities to Determine When Results Are Significantly High or \nSignificantly Low\n \n\u25a0Significantly high number of successes: x successes among n trials is a signifi-\ncantly high number of successes if the probability of x or more successes is un-\nlikely with a probability of 0.05 or less. That is, x is a significantly high number \nof successes if P(x or more) \u2026 0.05.*\n \n\u25a0Significantly low number of successes: x successes among n trials is a sig-\nnificantly low number of successes if the probability of x or fewer successes is \nunlikely with a probability of 0.05 or less. That is, x is a significantly low number \nof successes if P(x or fewer) \u2026 0.05.*\n*The value 0.05 is not absolutely rigid. Other values, such as 0.01, could be used to distinguish between results \nthat can easily occur by chance and events that are significant.\n\n128 \nCHAPTER 4 Probability\nSee Example 1 on page 121, which illustrates the following:\n \n\u25a0Among 100 births, 75 girls is significantly high because the probability of 75 \nor more girls is 0.0000003, which is less than or equal to 0.05 (so the gender \nselection method appears to be effective).\n \n\u25a0Among 100 births, 55 girls is not significantly high because the probability of 55 \nor more girls is 0.184, which is greater than 0.05 (so the gender selection does \nnot appear to be effective).\nProbability Review\nImportant Principles and Notation for Probability\n \n\u25a0The probability of an event is a fraction or decimal number between 0 and 1 \ninclusive.\n \n\u25a0The probability of an impossible event is 0.\n \n\u25a0The probability of an event that is certain to occur is 1.\n \n\u25a0Notation: P1A2 = the probability of event A.\n \n\u25a0Notation: P1A2 = the probability that event A does not occur.\nStatistical Literacy and Critical Thinking \n1.\u00a0Probability Rewrite the following statement with the probability expressed as a number \nwith a decimal form",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 144
  },
  {
    "child_id": "a7ee1652-f01d-4e3f-a70a-60bc7c0dbb52",
    "parent_id": "cbcd5e2e-1bfd-471b-8840-90b98cc7a0a5",
    "text": "es and Notation for Probability\n \n\u25a0The probability of an event is a fraction or decimal number between 0 and 1 \ninclusive.\n \n\u25a0The probability of an impossible event is 0.\n \n\u25a0The probability of an event that is certain to occur is 1.\n \n\u25a0Notation: P1A2 = the probability of event A.\n \n\u25a0Notation: P1A2 = the probability that event A does not occur.\nStatistical Literacy and Critical Thinking \n1.\u00a0Probability Rewrite the following statement with the probability expressed as a number \nwith a decimal format: \u201cThe probability of selecting someone with blue eyes is 35%.\u201d\n2.\u00a0Probability Given that the following statement is incorrect, rewrite it correctly: \u201cThe prob-\nability of a baby being born a boy is 50-50.\u201d\n3.\u00a0Births In Example 4 \u201cThree Children of the Same Gender\u201d it was noted that in reality, the \nprobability of a boy is 0.512 instead of 0.5. Let A denote the event of getting a boy when a baby \nis born. What is the value of P1A2?\n4.\u00a0Subjective Probability Estimate the probability that the next time a physician walks into \na patient\u2019s room and turns on a light switch, she discovers that the light bulb does work.\n5.\u00a0Identifying Probability Values Which of the following are probabilities?\n0 3>5 5>3 -0.25 250% 7:3 1 50@50 5:1 0.135 2.017\n6.\u00a0Penicillin \u201cWho discovered penicillin: Sean Penn, William Penn, Penn Jillette, Alexander \nFleming, or Louis Pasteur?\u201d If you make a random guess for the answer to that question, what \nis the probability that your answer is the correct answer of Alexander Fleming?\n7.\u00a0Avogadro Constant If you are asked on a quiz to give the first (leftmost) nonzero digit \nof the Avogadro constant and, not knowing the answer, you make a random guess, what is the \nprobability that your answer is the correct answer of 6?\n8.\u00a0Births Example 2 in this section includes the sample space for genders from three births. \nIdentify the sample space for the genders from two births.\nIn Exercises 9\u201312, assume that 50 births are randomly selected. Use subjective judgment to \ndescribe the given number of girls as (a) significantly low, (b) significantly high, or (c) nei-\nther significantly low nor significantly high.\n9.\u00a047 girls.   10.\u00a026 girls.   11.\u00a023 girls.   12.\u00a05 girls.\n4-1 Basic Skills and Concepts\n\n4-1 Basic Concepts of Probability \n129\nIn Exercises 13\u201320, express the indicated degree of likelihood as a probability value \nbetween 0 and 1.\n13.\u00a0Testing If you make a random guess for the answer to a true>false test question, there is a \n50-50 chance of being correct.\n14.\u00a0MCAT Test When making a random guess for an answer to a multiple-choice question on \nan MCAT test, the possible answers are a, b, c, d, e, so there is 1 chance in 5 of being correct.\n15.\u00a0Genes One of the four DNA bases of A, G, C, and T is randomly selected, and the result is \nG. Assume that the four DNA bases are equally likely.\n16.\u00a0Sleepwalking Based on a report in Neurology magazine, 29.2% of survey respondents \nhave sleepwalked.\n17.\u00a0Randomness When using a computer to randomly gen",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 144
  },
  {
    "child_id": "d53bed91-f64e-40ca-b3a8-1fcf159fcee1",
    "parent_id": "cbcd5e2e-1bfd-471b-8840-90b98cc7a0a5",
    "text": "rrect.\n14.\u00a0MCAT Test When making a random guess for an answer to a multiple-choice question on \nan MCAT test, the possible answers are a, b, c, d, e, so there is 1 chance in 5 of being correct.\n15.\u00a0Genes One of the four DNA bases of A, G, C, and T is randomly selected, and the result is \nG. Assume that the four DNA bases are equally likely.\n16.\u00a0Sleepwalking Based on a report in Neurology magazine, 29.2% of survey respondents \nhave sleepwalked.\n17.\u00a0Randomness When using a computer to randomly generate the last digit of a phone \nnumber to be called for a survey, there is 1 chance in 10 that the last digit is zero.\n18.\u00a0 Job Applicant Mistakes Based on an Adecco survey of hiring managers who were \nasked to identify the biggest mistakes that job candidates make during an interview, there is a \n50-50 chance that they will identify \u201cinappropriate attire.\u201d\n19. Square Peg Sydney Smith wrote in \u201cOn the Conduct of the Understanding\u201d that it is im-\npossible to fit a square peg in a round hole.\n20. Death and Taxes Benjamin Franklin said that death is a certainty of life.\nIn Exercises 21\u201324, refer to the sample data in Table 4-1, which is included with the \n Chapter Problem. Assume that 1 of the 555 subjects included in Table 4-1 is randomly selected.\nTABLE 4-1 Results from Drug Tests of Job Applicants\nPositive Test Result \n(Test shows drug use.)\nNegative Test Result\n(Test shows no drug use.)\nSubject Uses Drugs\n45\n(True Positive)\n5\n(False Negative)\nSubject Does Not Use Drugs\n25\n(False Positive)\n480\n(True Negative)\n21.\u00a0Drug Testing Job Applicants Find the probability of selecting someone who got a re-\nsult that is a false negative. Who would suffer from a false negative result? Why?\n22.\u00a0Drug Testing Job Applicants Find the probability of selecting someone who got a re-\nsult that is a false positive. Who would suffer from a false positive result? Why?\n23.\u00a0 Drug Testing Job Applicants Find the probability of selecting someone who uses \ndrugs. Does the result appear to be reasonable as an estimate of the \u201cprevalence rate\u201d described \nin the Chapter Problem?\n24.\u00a0Drug Testing Job Applicants Find the probability of selecting someone who does not \nuse drugs. Does the result appear to be reasonable as an estimate of the proportion of the adult \npopulation that does not use drugs?\nIn Exercises 25\u201332, find the probability and answer the questions.\n25. XSORT Gender Selection MicroSort\u2019s XSORT gender selection technique was designed \nto increase the likelihood that a baby will be a girl. At one point before clinical trials of the \nXSORT gender selection technique were discontinued, 945 births consisted of 879 baby girls \nand 66 baby boys (based on data from the Genetics & IVF Institute). Based on these results, \nwhat is the probability of a girl born to a couple using MicroSort\u2019s XSORT method? Does it ap-\npear that the technique is effective in increasing the likelihood that a baby will be a girl?",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 144
  },
  {
    "child_id": "4042aa62-10b3-4e4f-bc55-e8848a671123",
    "parent_id": "bb4cf393-ace0-413c-bf00-4c21ae251737",
    "text": "130 \nCHAPTER 4 Probability\n26.\u00a0 YSORT Gender Selection MicroSort\u2019s YSORT gender-selection technique is de-\nsigned to increase the likelihood that a baby will be a boy. At one point before clinical trials \nof the YSORT gender-selection technique were discontinued, 291 births consisted of 239 \nbaby boys and 52 baby girls (based on data from the Genetics & IVF Institute). Based on \nthese results, what is the probability of a boy born to a couple using MicroSort\u2019s YSORT \nmethod? Does it appear that the technique is effective in increasing the likelihood that a baby \nwill be a boy?\n27.\u00a0Mendelian Genetics When Mendel conducted his famous genetics experiments with \npeas, one sample of offspring consisted of 428 green peas and 152 yellow peas. Based on those \nresults, estimate the probability of getting an offspring pea that is green. Is the result reasonably \nclose to the expected value of 3>4, as Mendel claimed?\n28.\u00a0Guessing Birthdays On their first date, Kelly asks Mike to guess the date of her birth, \nnot including the year.\na. What is the probability that Mike will guess correctly? (Ignore leap years.)\nb. Would it be unlikely for him to guess correctly on his first try?\nc. If you were Kelly, and Mike did guess correctly on his first try, would you believe his claim \nthat he made a lucky guess, or would you be convinced that he already knew when you were \nborn?\nd. If Kelly asks Mike to guess her age, and Mike\u2019s guess is too high by 15 years, what is the \nprobability that Mike and Kelly will have a second date?\n29.\u00a0Online Medicine In a survey, 933 respondents say that they seek medical information \nonline and 139 other respondents say that they never seek medical information online. What is \nthe probability that a randomly selected person never seeks medical information online? Is it \nunlikely for someone to never seek medical information online? How are these results affected \nby the fact that the responses are from subjects who decided to respond to the survey posted on \nthe Internet by AOL?\n30.\u00a0Car Rollovers In a recent year in the United States, 83,600 passenger cars rolled over \nwhen they crashed, and 5,127,400 passenger cars did not roll over when they crashed. Find the \nprobability that a randomly selected passenger car crash results in a rollover. Is it unlikely for a \ncar to roll over in a crash?\n31.\u00a0Genetics: Eye Color Each of two parents has the genotype brown>blue, which con-\nsists of the pair of alleles that determine eye color, and each parent contributes one of those \nalleles to a child. Assume that if the child has at least one brown allele, that color will domi-\nnate and the eyes will be brown. (The actual determination of eye color is more complicated \nthan that.)\na. List the different possible outcomes. Assume that these outcomes are equally likely.\nb. What is the probability that a child of these parents will have the blue>blue genotype?\nc. What is the probability that the child will have brown eyes?\n32.\u00a0X-Linked Genetic Disease Me",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 148
  },
  {
    "child_id": "aa42ee1b-87f6-4b36-814b-793db476e581",
    "parent_id": "bb4cf393-ace0-413c-bf00-4c21ae251737",
    "text": "tributes one of those \nalleles to a child. Assume that if the child has at least one brown allele, that color will domi-\nnate and the eyes will be brown. (The actual determination of eye color is more complicated \nthan that.)\na. List the different possible outcomes. Assume that these outcomes are equally likely.\nb. What is the probability that a child of these parents will have the blue>blue genotype?\nc. What is the probability that the child will have brown eyes?\n32.\u00a0X-Linked Genetic Disease Men have XY (or YX) chromosomes and women have XX \nchromosomes. X-linked recessive genetic diseases (such as juvenile retinoschisis) occur when \nthere is a defective X chromosome that occurs without a paired X chromosome that is not defec-\ntive. In the following, represent a defective X chromosome with lowercase x, so a child with the \nxY or Yx pair of chromosomes will have the disease and a child with XX or XY or YX or xX or \nXx will not have the disease. Each parent contributes one of the chromosomes to the child.\na. If a father has the defective x chromosome and the mother has good XX chromosomes, \nwhat is the probability that a son will inherit the disease?\nb. If a father has the defective x chromosome and the mother has good XX chromosomes, \nwhat is the probability that a daughter will inherit the disease?\ncontinued\n\n4-2 Addition Rule and Multiplication Rule \n131\nc. If a mother has one defective x chromosome and one good X chromosome and the father \nhas good XY chromosomes, what is the probability that a son will inherit the disease?\nd. If a mother has one defective x chromosome and one good X chromosome and the father \nhas good XY chromosomes, what is the probability that a daughter will inherit the disease?\nProbability from a Sample Space. In Exercises 33\u201336, use the given sample space or \nconstruct the required sample space to find the indicated probability.\n33.\u00a0Three Children Use this sample space listing the eight simple events that are possible when \na couple has three children (as in Example 2 on page 122): {bbb, bbg, bgb, bgg, gbb, gbg, ggb, \nggg}. Assume that boys and girls are equally likely, so that the eight simple events are equally \nlikely. Find the probability that when a couple has three children, there is exactly one girl.\n34.\u00a0Three Children Using the same sample space and assumption from Exercise 33, find the \nprobability that when a couple has three children, there are exactly two girls.\n35.\u00a0Four Children Exercise 33 lists the sample space for a couple having three children. After \nidentifying the sample space for a couple having four children, find the probability of getting \nthree girls and one boy (in any order).\n36.\u00a0Four Children Using the same sample space and assumption from Exercise 35, find the \nprobability that when a couple has four children, all four are of the same gender.\nUsing Probability to Form Conclusions. In Exercises 37\u201340, use the given probability value \nto determine whether the sample results could easily occur b",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 148
  },
  {
    "child_id": "0515bb44-d265-4503-ae3f-e0cb4145270b",
    "parent_id": "bb4cf393-ace0-413c-bf00-4c21ae251737",
    "text": "a couple having three children. After \nidentifying the sample space for a couple having four children, find the probability of getting \nthree girls and one boy (in any order).\n36.\u00a0Four Children Using the same sample space and assumption from Exercise 35, find the \nprobability that when a couple has four children, all four are of the same gender.\nUsing Probability to Form Conclusions. In Exercises 37\u201340, use the given probability value \nto determine whether the sample results could easily occur by chance, then form a conclusion.\n37.\u00a0Predicting Gender A study addressed the issue of whether pregnant women can cor-\nrectly predict the gender of their baby. Among 104 pregnant women, 57 correctly predicted the \ngender of their baby (based on data from \u201cAre Women Carrying \u2018Basketballs\u2019\u2026,\u201d by Perry, \nDiPietro, Constigan, Birth, Vol. 26, No. 3). If pregnant women have no such ability, there is a \n0.327 probability of getting such sample results by chance. What do you conclude?\n38.\u00a0Clinical Trial of Tamiflu Clinical trials involved the use of Tamiflu (oseltamivir phos-\nphate) for treating flu patients. Among 724 patients treated with Tamiflu, 72 (or about 10%) \nexperienced nausea. (An untreated group experienced a 6% rate of nausea.) If Tamiflu really \nhas no effect on nausea, there is a 0.00000246 probability of getting these sample results by \nchance. What do you conclude about the effect of Tamiflu on nausea?\n39.\u00a0Sleepiness In a clinical trial of OxyContin (oxycodone) used for pain relief, 227 sub-\njects were treated with OxyContin and 52 of them experienced sleepiness (based on data from \nPurdue Pharma L.P.). If OxyContin has no effect on sleepiness, the probability of getting these \nsample results by chance is less than 0.001 (when comparing this sample group with another \ngroup not treated with OxyContin). What do you conclude?\n40.\u00a0Cell Phones and Cancer A study of 420,095 Danish cell phone users resulted in 135 \nwho developed cancer of the brain or nervous system (based on data from the Journal of the \nNational Cancer Institute). When comparing this sample group to another group of people who \ndid not use cell phones, it was found that there is a probability of 0.512 of getting such sample \nresults by chance. What do you conclude?\nKey Concepts In this section we present the addition rule as a tool for finding \nP(A or B), which is the probability that either event A occurs or event B occurs (or they \nboth occur) as the single outcome of a procedure. To find P(A or B), we begin by add-\ning the number of ways that A can occur and the number of ways that B can occur, but \nadd without double counting. The word \u201cor\u201d in the addition rule is associated with the \naddition of probabilities.\n4-2 \nAddition Rule and Multiplication Rule\n\n132 \nCHAPTER 4 Probability\nThis section also presents the basic multiplication rule used for finding P(A and B), \nwhich is the probability that event A occurs and event B occurs. If the outcome of \nevent A somehow affects the prob",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 148
  },
  {
    "child_id": "fa3eea4c-fc4e-4f6e-91ae-d8207b2d18fd",
    "parent_id": "bb4cf393-ace0-413c-bf00-4c21ae251737",
    "text": " or B), we begin by add-\ning the number of ways that A can occur and the number of ways that B can occur, but \nadd without double counting. The word \u201cor\u201d in the addition rule is associated with the \naddition of probabilities.\n4-2 \nAddition Rule and Multiplication Rule\n\n132 \nCHAPTER 4 Probability\nThis section also presents the basic multiplication rule used for finding P(A and B), \nwhich is the probability that event A occurs and event B occurs. If the outcome of \nevent A somehow affects the probability of event B, it is important to adjust the prob-\nability of B to reflect the occurrence of event A. The rule for finding P(A and B) is \ncalled the multiplication rule because it involves the multiplication of the probability \nof event A and the probability of event B (where, if necessary, the probability of event \nB is adjusted because of the outcome of event A). The word \u201cand\u201d in the multiplica-\ntion rule is associated with the multiplication of probabilities.\nIn Section 4-1 we considered only simple events, but in this section we consider \ncompound events.\nDEFINITION\nA compound event is any event combining two or more simple events.\nAddition Rule\nNotation for Addition Rule\nP1A or B2 = P1in a single trial, event A occurs or event B occurs or they \nboth occur2\nThe word \u201cor\u201d used in the preceding notation is the inclusive or, which means ei-\nther one or the other or both. The formal addition rule is often presented as a formula, \nbut blind use of formulas is not recommended. Instead, understand the spirit of the \nrule and use that understanding, as in the intuitive addition rule that follows.\nINTUITIVE ADDITION RULE\nTo find P(A or B), add the number of ways event A can occur and the number of \nways event B can occur, but add in such a way that every outcome is counted only \nonce. P(A or B) is equal to that sum, divided by the total number of outcomes in the \nsample space.\nFORMAL ADDITION RULE\nP1A or B2 = P1A2 + P1B2 - P1A and B2\nwhere P(A and B) denotes the probability that A and B both occur at the same time \nas an outcome in a trial of a procedure.\nOne way to apply the addition rule is to add the probability of event A and the \nprobability of event B and, if there is any overlap that causes double-counting, com-\npensate for it by subtracting the probability of outcomes that are included twice. This \napproach is reflected in the above formal addition rule.\nEXAMPLE 1  Drug Testing of Job Applicants\nRefer to Table 4-1, reproduced here for your convenience and viewing pleasure. \nIf 1\u00a0subject is randomly selected from the 555 subjects given a drug test, find the \nprobability of selecting a subject who had a positive test result or uses drugs.\nw\nev\nab\nProportions of  \nMales, Females\nIt is well \nknown that \nwhen a baby is \nborn, boys and \ngirls are not \nequally likely. It \nis currently be-\nlieved that 105 boys are born for \nevery 100 girls, so the probability \nof a boy is 0.512. Kristen Navara \nof the University of Georgia \nconducted a study showing that ",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 148
  },
  {
    "child_id": "461fb8fc-8daf-41ad-a087-931c25212221",
    "parent_id": "bb4cf393-ace0-413c-bf00-4c21ae251737",
    "text": "iewing pleasure. \nIf 1\u00a0subject is randomly selected from the 555 subjects given a drug test, find the \nprobability of selecting a subject who had a positive test result or uses drugs.\nw\nev\nab\nProportions of  \nMales, Females\nIt is well \nknown that \nwhen a baby is \nborn, boys and \ngirls are not \nequally likely. It \nis currently be-\nlieved that 105 boys are born for \nevery 100 girls, so the probability \nof a boy is 0.512. Kristen Navara \nof the University of Georgia \nconducted a study showing that \naround the world, more boys are \nborn than girls, but the difference \nbecomes smaller as people are \nlocated closer to the equator. \nShe used latitudes, tempera-\ntures, unemployment rates, and \ngross national products from \n200 countries and conducted a \nstatistical analysis showing that \nthe proportions of boys appear \nto be affected only by latitude \nand its related weather. So far, no \none has identified a reasonable \nexplanation for this phenomenon.",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 148
  },
  {
    "child_id": "e8ddde00-8ecc-40be-b287-7f88fbd46a30",
    "parent_id": "f8cf6e18-c039-41e8-8499-5b7b4ddb1744",
    "text": "4-2 Addition Rule and Multiplication Rule \n133\nDisjoint Events and the Addition Rule\nThe addition rule is simplified when the events are disjoint.\nTABLE 4-1 Results from Drug Tests of Job Applicants\nPositive Test Result\n(Test shows drug use.)\nNegative Test Result\n(Test shows no drug use.)\nSubject Uses Drugs\n45\n(True Positive)\n5\n(False Negative)\nSubject Does Not Use Drugs\n25\n(False Positive)\n480\n(True Negative)\n*Numbers in red correspond to positive test results or subjects who use drugs, and the total of  \nthose numbers is 75.\nSOLUTION\nRefer to Table 4-1 and carefully count the number of subjects who tested positive \n(first column) or use drugs (first row), but be careful to count subjects exactly once, \nnot twice. When adding the frequencies from the first column and the first row, \ninclude the frequency of 45 only once. In Table 4-1, there are 45 + 25 + 5 = 75 \nsubjects who had positive test results or use drugs. We get this result:\nP1positive test result or subject uses drugs2 = 75>555 = 0.135\nDEFINITION\nEvents A and B are disjoint (or mutually exclusive) if they cannot occur at the \nsame time. (That is, disjoint events do not overlap.)\nEXAMPLE 2  Disjoint Events\nDisjoint events:\nEvent A\u2014Randomly selecting someone \nfor a clinical trial who is a male\nEvent B\u2014Randomly selecting someone \nfor a clinical trial who is a female\n(The selected person cannot be both.)\nEvents that are not disjoint:\nEvent A\u2014Randomly selecting someone \ntaking a statistics course\nEvent B\u2014Randomly selecting someone \nwho is a female\n(The selected person can be both.)\nWhenever A and B are disjoint, P(A and B) becomes zero in the formal addition \nrule, so for disjoint events A and B we have P1A or B2 = P1A2 + P1B2. But again, \ninstead of blind use of a formula, it is better to understand and use the intuitive addi-\ntion rule.\nHere is a summary of the key points of the addition rule:\n1. To find P(A or B), first associate the word or with addition.\n2. To find the value of P(A or B), add the number of ways A can occur and the \nnumber of ways B can occur, but be careful to add without double counting.\n\n134 \nCHAPTER 4 Probability\nComplementary Events and the Addition Rule\nIn Section 4-1 we used A to indicate that event A does not occur. Common sense dic-\ntates this principle: We are certain (with probability 1) that either an event A occurs or \nit does not occur, so it follows that P1A or A2 = 1. Because events A and A must be \ndisjoint, we can use the addition rule to express this principle as follows:\nP1A or A2 = P1A2 + P1A2 = 1\nThis result of the addition rule leads to the following three expressions that are \u201cequiv-\nalent\u201d in the sense that they are just different forms of the same principle.\nRULE OF COMPLEMENTARY EVENTS\nP1A2 + P1A2 = 1   P1A2 = 1 - P1A2  P1A2 = 1 - P1A2\nEXAMPLE 3  Sleepwalking\nBased on a journal article, the probability of randomly selecting someone who has \nsleepwalked is 0.292, so P(sleepwalked) = 0.292 (based on data from \u201cPrevalence \nand Comorbidity of Noct",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 151
  },
  {
    "child_id": "c2f34d63-f863-47fd-a7a9-97a9797ca990",
    "parent_id": "f8cf6e18-c039-41e8-8499-5b7b4ddb1744",
    "text": "as follows:\nP1A or A2 = P1A2 + P1A2 = 1\nThis result of the addition rule leads to the following three expressions that are \u201cequiv-\nalent\u201d in the sense that they are just different forms of the same principle.\nRULE OF COMPLEMENTARY EVENTS\nP1A2 + P1A2 = 1   P1A2 = 1 - P1A2  P1A2 = 1 - P1A2\nEXAMPLE 3  Sleepwalking\nBased on a journal article, the probability of randomly selecting someone who has \nsleepwalked is 0.292, so P(sleepwalked) = 0.292 (based on data from \u201cPrevalence \nand Comorbidity of Nocturnal Wandering in the U.S. General Population,\u201d by \nOhayon et al., Neurology, Vol. 78, No. 20). If a person is randomly selected, find the \nprobability of getting someone who has not sleepwalked.\nSOLUTION\nUsing the rule of complementary events, we get\nP1has not sleepwalked2 = 1 - P1sleepwalked2 = 1 - 0.292 = 0.708\nThe probability of randomly selecting someone who has not sleepwalked is 0.708.\nMultiplication Rule\nNotation for Multiplication Rule\nWe begin with basic notation followed by the multiplication rule. We strongly suggest \nusing the intuitive multiplication rule, because it is based on understanding instead of \nblind use of a formula.\nNotation\nP1A and B2 = P1event A occurs in one trial and event B occurs in a  \n      different trial2\nP1B\u001eA2 represents the probability of event B occurring after it is assumed that \nevent A has already occurred. (Interpret B\u001eA as \u201cevent B occurs after event A has \nalready occurred.\u201d)\nCAUTION The notation P(A and B) has two meanings, depending on its context. \nFor the multiplication rule, P(A and B) denotes that event A occurs in one trial and \nevent B occurs in another trial; for the addition rule we use P(A and B) to denote \nthat events A and B both occur in the same trial.\n\n4-2 Addition Rule and Multiplication Rule \n135\nINTUITIVE MULTIPLICATION RULE\nTo find the probability that event A occurs in one trial and event B occurs in an-\nother trial, multiply the probability of event A by the probability of event B, but be \nsure that the probability of event B is found by assuming that event A has already \noccurred.\nFORMAL MULTIPLICATION RULE\nP1A and B2 = P1A2 # P1B\u001e A2\nIndependence and the Multiplication Rule\nWhen applying the multiplication rule and considering whether the probability of \nevent B must be adjusted to account for the previous occurrence of event A, we are \nfocusing on whether events A and B are independent.\nDEFINITIONS\nTwo events A and B are independent if the occurrence of one does not affect the \nprobability of the occurrence of the other. (Several events are independent if the \noccurrence of any does not affect the probabilities of the occurrence of the oth-\ners.) If A and B are not independent, they are said to be dependent.\nCAUTION Don\u2019t think that dependence of two events means that one is the direct \ncause of the other. Having a working light in your kitchen and having a working \nlight in your bedroom are dependent events because they share the same power \nsource. One of the lights may stop working ",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 151
  },
  {
    "child_id": "c7e712b9-d5c4-4404-9c17-b627e6ab8a03",
    "parent_id": "f8cf6e18-c039-41e8-8499-5b7b4ddb1744",
    "text": "e occurrence of the other. (Several events are independent if the \noccurrence of any does not affect the probabilities of the occurrence of the oth-\ners.) If A and B are not independent, they are said to be dependent.\nCAUTION Don\u2019t think that dependence of two events means that one is the direct \ncause of the other. Having a working light in your kitchen and having a working \nlight in your bedroom are dependent events because they share the same power \nsource. One of the lights may stop working for many reasons, but if one light is out, \nthere is a higher probability that the other light will be out (because of the common \npower source).\nExample 4 illustrates the basic multiplication rule, with independent events in part (a) \nand dependent events in part (b).\nEXAMPLE 4  Drug Screening and the Basic Multiplication Rule\nLet\u2019s use only the 50 test results from the subjects who use drugs (from Table 4-1), \nas shown below:\nPositive Test Results: \n45\nNegative Test Results: \n5\nTotal: \n50\na. If 2 of these 50 subjects are randomly selected with replacement, \ufb01nd the \n probability that the \ufb01rst selected person had a positive test result and the sec-\nond selected person had a negative test result.\n \nb. Repeat part (a) by assuming that the two subjects are selected without \n replacement.\ncontinued\n\n136 \nCHAPTER 4 Probability\nThe key point of part (b) in Example 4 is this: We must adjust the probability of the \nsecond event to reflect the outcome of the first event. Because selection of the second \nsubject is made without replacement of the first subject, the second probability must \ntake into account the fact that the first selection removed a subject who tested positive, \nso only 49 subjects are available for the second selection, and 5 of them had a negative \ntest result. Part (a) of Example 4 involved sampling with replacement, so the events \nare independent; part (b) of Example 4 involved sampling without replacement, so the \nevents are dependent. See the following.\nSampling In the wonderful world of statistics, sampling methods are critically impor-\ntant, and the following relationships hold:\n \n\u25a0Sampling with replacement: Selections are independent events.\n \n\u25a0Sampling without replacement: Selections are dependent events.\nException: Treating Dependent Events as Independent\nSome cumbersome calculations can be greatly simplified by using the common prac-\ntice of treating events as independent when small samples are drawn without replace-\nment from large populations. (In such cases, it is rare to select the same item twice.) \nHere is a common guideline routinely used with applications such as analyses of sur-\nvey results:\nTREATING DEPENDENT EVENTS AS INDEPENDENT:  \n5% GUIDELINE FOR CUMBERSOME CALCULATIONS\nWhen sampling without replacement and the sample size is no more than 5% of the \nsize of the population, treat the selections as being independent (even though they \nare actually dependent).\nSOLUTION\na. With Replacement: First selection (with 45 positive re",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 151
  },
  {
    "child_id": "cebee96a-acbe-4323-9adb-298f4b229a34",
    "parent_id": "f8cf6e18-c039-41e8-8499-5b7b4ddb1744",
    "text": "(In such cases, it is rare to select the same item twice.) \nHere is a common guideline routinely used with applications such as analyses of sur-\nvey results:\nTREATING DEPENDENT EVENTS AS INDEPENDENT:  \n5% GUIDELINE FOR CUMBERSOME CALCULATIONS\nWhen sampling without replacement and the sample size is no more than 5% of the \nsize of the population, treat the selections as being independent (even though they \nare actually dependent).\nSOLUTION\na. With Replacement: First selection (with 45 positive results among 50 total \nresults):\nP1positive test result2 = 45\n50\nSecond selection (with 5 negative test results among the same 50 total results):\nP1negative test result2 = 5\n50\nWe now apply the multiplication rule as follows:\nP11st selection is positive and 2nd is negative2 = 45\n50 # 5\n50 = 0.0900\nb. Without Replacement: Without replacement of the \ufb01rst subject, the calcula-\ntions are the same as in part (a), except that the second probability must be \nadjusted to re\ufb02ect the fact that the \ufb01rst selection was positive and is not avail-\nable for the second selection. After the \ufb01rst positive result is selected, we have \n49 test results remaining, and 5 of them are negative. The second probability \nis therefore 5>49, as shown below:\nP11st selection is positive and 2nd is negative2 = 45\n50 # 5\n49 = 0.0918\n\n4-2 Addition Rule and Multiplication Rule \n137\nExample 5 illustrates use of the 5% guideline for cumbersome calculations and it also \nillustrates that the basic multiplication rule extends easily to three or more events.\nEXAMPLE 5   Drug Screening and the 5% Guideline for  \nCumbersome Calculations\nAssume that three adults are randomly selected without replacement from the \n247,436,830 adults in the United States. Also assume that 10% of adults in the United \nStates use drugs. Find the probability that the three selected adults all use drugs.\nSOLUTION\nBecause the three adults are randomly selected without replacement, the three \nevents are dependent, but here we can treat them as being independent by applying \nthe 5% guideline for cumbersome calculations. The sample size of 3 is clearly no \nmore than 5% of the population size of 247,436,830. We get\n P1all 3 adults use drugs2 = P1first uses drugs and second uses drugs and\n third uses drugs2\n = P1first uses drugs2 #  P1second uses drugs2 #  \nP1third uses drugs2\n = 10.10210.10210.102 = 0.00100\nThere is a 0.00100 probability that all three selected adults use drugs.\nCAUTION In any probability calculation, it is extremely important to carefully \nidentify the event being considered. See Example 6, where parts (a) and (b) might \nseem quite similar but their solutions are very different.\nEXAMPLE 6  Birthdays\nWhen two different people are randomly selected from those in your class, find the \nindicated probability by assuming that birthdays occur on the days of the week with \nequal frequencies.\n \na. Find the probability that the two people are born on the same day of the week.\n \nb. Find the probability that the two people ",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 151
  },
  {
    "child_id": "feec49cb-5ba9-4aa2-9a85-503d2c7c0008",
    "parent_id": "f8cf6e18-c039-41e8-8499-5b7b4ddb1744",
    "text": "tant to carefully \nidentify the event being considered. See Example 6, where parts (a) and (b) might \nseem quite similar but their solutions are very different.\nEXAMPLE 6  Birthdays\nWhen two different people are randomly selected from those in your class, find the \nindicated probability by assuming that birthdays occur on the days of the week with \nequal frequencies.\n \na. Find the probability that the two people are born on the same day of the week.\n \nb. Find the probability that the two people are both born on Monday.\nIn Example 5, if we treat the events as dependent without using the 5% guideline, \nwe get the following cumbersome calculation that begins with 247,436,830 adults, \nwith 10% of them (or 24,743,683) using drugs:\n a 24,743,683\n247,436,830ba 24,743,682\n247,436,829ba 24,743,681\n247,436,828b = 0.0009999998909\n = 0.00100 1rounded2\nJust imagine randomly selecting 1000 adults instead of just 3, as is commonly done \nin typical polls. Extending the above calculation to include 1000 factors instead of 3 \nfactors would be what statisticians refer to as \u201cpainful.\u201d\ncontinued",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 151
  },
  {
    "child_id": "70d1304f-57a9-4ccd-87bf-56464188cb53",
    "parent_id": "6e582e37-e60d-4ab3-b215-cd8a1900203a",
    "text": "138 \nCHAPTER 4 Probability\nRedundancy: Important Application of Multiplication Rule\nThe principle of redundancy is used to increase the reliability of many systems. Our \neyes have passive redundancy in the sense that if one of them fails, we continue to see. \nAn important finding of modern biology is that genes in an organism can often work \nin place of each other. Engineers often design redundant components so that the whole \nsystem will not fail because of the failure of a single component, as in the following \nexample.\nSOLUTION\na. Because no particular day of the week is speci\ufb01ed, the \ufb01rst person can be \nborn\u00a0on any one of the seven weekdays. The probability that the second \n person is born on the same day as the \ufb01rst person is 1>7. The probability that \ntwo people are born on the same day of the week is therefore 1>7.\n \nb. The probability that the \ufb01rst person is born on Monday is 1>7 and the prob-\nability that the second person is also born on Monday is 1>7. Because the two \nevents are independent, the probability that both people are born on Monday is\n1\n7 # 1\n7 = 1\n49\nWATCH YOUR LANGUAGE! Example 6 illustrates that finding correct or relevant \nprobability values often requires greater language skills than computational skills. \nIn Example 6, what exactly do we mean by \u201csame day of the week\u201d? See how parts \n(a) and (b) in Example 6 are very different.\nEXAMPLE 7  Airbus 310: Redundancy for Better Safety\nModern aircraft are now highly reliable, and one design feature contributing to that \nreliability is the use of redundancy, whereby critical components are duplicated so \nthat if one fails, the other will work. For example, the Airbus 310 twin-engine air-\nliner has three independent hydraulic systems, so if any one system fails, full flight \ncontrol is maintained with another functioning system. For this example, we will as-\nsume that for a typical flight, the probability of a hydraulic system failure is 0.002.\n \na. If the Airbus 310 were to have one hydraulic system, what is the probability \nthat the aircraft\u2019s \ufb02ight control would work for a \ufb02ight?\n \nb. Given that the Airbus 310 actually has three independent hydraulic systems, \nwhat is the probability that on a typical \ufb02ight, control can be maintained with \na working hydraulic system?\nSOLUTION\n \na. The probability of a hydraulic system failure is 0.002, so the probability that \nit does not fail is 0.998. That is, the probability that \ufb02ight control can be main-\ntained is as follows:\nP11 hydraulic system does not fail2\n     \n= 1 - P1failure2 = 1 - 0.002 = 0.998\n\n4-2 Addition Rule and Multiplication Rule \n139\nRationale for the Multiplication Rule\nTo see the reasoning that underlies the multiplication rule, consider a pop quiz consist-\ning of these two questions:\n1. True or false: A pound of feathers is heavier than a pound of gold.\n2. Who said, \u201cBy a small sample, we may judge of the whole piece\u201d?  \n(a) Judge Judy; (b) Judge Dredd; (c) Miguel de Cervantes; (d) George \nGallup; (e) Gandhi\nThe answ",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 156
  },
  {
    "child_id": "bf8c6d74-851e-4a00-8dc8-c3544ec13912",
    "parent_id": "6e582e37-e60d-4ab3-b215-cd8a1900203a",
    "text": " does not fail2\n     \n= 1 - P1failure2 = 1 - 0.002 = 0.998\n\n4-2 Addition Rule and Multiplication Rule \n139\nRationale for the Multiplication Rule\nTo see the reasoning that underlies the multiplication rule, consider a pop quiz consist-\ning of these two questions:\n1. True or false: A pound of feathers is heavier than a pound of gold.\n2. Who said, \u201cBy a small sample, we may judge of the whole piece\u201d?  \n(a) Judge Judy; (b) Judge Dredd; (c) Miguel de Cervantes; (d) George \nGallup; (e) Gandhi\nThe answers are T (true) and c. (The first answer is true, because weights of feath-\ners are in avoirdupois units where a pound is 453.59 g, but weights of gold and other \nprecious metals are in troy units where a pound is 373.24 g. The second answer is \nfrom Don Quixote by Cervantes.)\nHere is the sample space for the different possible answers:\nTa Tb Tc Td Te Fa Fb Fc Fd Fe\nIf both answers are random guesses, then the above 10 possible outcomes are equally \nlikely, so\nP1both correct2 = P1T and c2 = 1\n10 = 0.1\nWith P1T and c2 = 1>10, P1T2 = 1>2, and P1c2 = 1>5, we see that\n1\n10 = 1\n2 # 1\n5\nA tree diagram is a graph of the possible outcomes of a procedure, as in Figure 4-4. \nFigure 4-4 shows that if both answers are random guesses, all 10 branches are equally \nlikely and the probability of getting the correct pair (T, c) is 1>10. For each response to \nthe first question, there are 5 responses to the second. The total number of outcomes is 5 \ntaken 2 times, or 10. The tree diagram in Figure 4-4 therefore provides a visual illustra-\ntion for using multiplication.\n \nb. With three independent hydraulic systems, \ufb02ight control will be maintained if \nthe three systems do not all fail. The probability of all three hydraulic systems \nfailing is 0.002 #  0.002 #  0.002 = 0.000000008. It follows that the probabil-\nity of maintaining \ufb02ight control is as follows:\nP1it does not happen that all three hydraulic systems fail2\n= 1 - 0.000000008 = 0.999999992\nINTERPRETATION\nWith only one hydraulic system we have a 0.002 probability of failure, but with \nthree independent hydraulic systems, there is only a 0.000000008 probability that \nflight control cannot be maintained because all three systems failed. By using three \nhydraulic systems instead of only one, risk of failure is decreased not by a factor of \n1>3, but by a factor of 1>250,000. By using three independent hydraulic systems, \nrisk is dramatically decreased and safety is dramatically increased.\nTa\nTb\nTc\nTd\nTe\nFa\nFb\nFc\nFd\nFe\na\nb\nc\nd\ne\na\nb\nc\nd\ne\nT\nF\n10\n5\n5\n2\n3\nFIGURE 4-4 Tree Diagram \nof Test Answers\n\n140 \nCHAPTER 4 Probability\nSummary of Addition Rule and Multiplication Rule\nAddition Rule for P(A or B): The word or suggests addition, and when adding \nP(A) and P(B), we must add in such a way that every outcome is counted only \nonce.\nMultiplication Rule for P(A and B): The word and for two trials suggests \nmultiplication, and when multiplying P(A) and P(B), we must be sure that the \nprobability of event B takes into account the",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 156
  },
  {
    "child_id": "267df2fb-10b2-4a2d-a159-a0ec3a4e2c67",
    "parent_id": "6e582e37-e60d-4ab3-b215-cd8a1900203a",
    "text": "a\nb\nc\nd\ne\nT\nF\n10\n5\n5\n2\n3\nFIGURE 4-4 Tree Diagram \nof Test Answers\n\n140 \nCHAPTER 4 Probability\nSummary of Addition Rule and Multiplication Rule\nAddition Rule for P(A or B): The word or suggests addition, and when adding \nP(A) and P(B), we must add in such a way that every outcome is counted only \nonce.\nMultiplication Rule for P(A and B): The word and for two trials suggests \nmultiplication, and when multiplying P(A) and P(B), we must be sure that the \nprobability of event B takes into account the previous occurrence of event A.\nStatistical Literacy and Critical Thinking\n1.\u00a0Notation When randomly selecting an adult, A denotes the event of selecting someone with \nblue eyes. What do P(A) and P1A2 represent?\n2.\u00a0Notation When randomly selecting adults, let M denote the event of randomly selecting \na male and let B denote the event of randomly selecting someone with blue eyes. What does \nP1M0 B2 represent? Is P1M0 B2 the same as P1B0 M2?\n3.\u00a0Sample for a Poll There are 15,524,971 adults in Florida. If The Gallup organization ran-\ndomly selects 1068 adults without replacement, are the selections independent or dependent? \nIf the selections are dependent, can they be treated as being independent for the purposes of \ncalculations?\n4.\u00a0Rule of Complements When randomly selecting an adult, let B represent the event of \nrandomly selecting someone with Group B blood. Write a sentence describing what the rule of \ncomplements is telling us: P1B or B2 = 1.\nFinding Complements. In Exercises 5\u20138, find the indicated complements.\n5.\u00a0LOL A U.S. Cellular survey of smartphone users showed that 26% of respondents answered \n\u201cyes\u201d when asked if abbreviations (such as LOL) are annoying when texting. What is the prob-\nability of randomly selecting a smartphone user and getting a response other than \u201cyes\u201d?\n6.\u00a0Color Blindness Women have a 0.25% rate of red>green color blindness. If a woman is \nrandomly selected, what is the probability that she does not have red>green color blindness?\n7.\u00a0Clinical Test When the drug Viagra (sildenafil citrate) was clinically tested, 117 patients \nreported headaches and 617 did not. If one of these patients is randomly selected, find the prob-\nability of getting one who did not report a headache.\n8.\u00a0 Sobriety Checkpoint When one of the authors observed a sobriety checkpoint con-\nducted by the Dutchess County Sheriff Department, he saw that 676 drivers were screened \nand 6 were arrested for driving while intoxicated. Based on those results, we can estimate that \nP1I2 = 0.000888, where I denotes the event of screening a driver and getting someone who is \nintoxicated. What does P1I2 denote, and what is its value?\nIn Exercises 9\u201320, use the data in the following table, which summarizes blood groups and \nRh types for randomly selected subjects. Assume that subjects are randomly selected from \nthose included in the table.\nO\nA\nB\nAB\nType\nRh+\n59\n53\n12\n6\nRh\u2212\n 9\n 8\n 3\n2\n4-2 Basic Skills and Concepts\n\n4-2 Addition Rule and Multiplication Rule \n141\n9.\u00a0Blood Gr",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 156
  },
  {
    "child_id": "38f543d2-20f9-440e-a913-11a8931c4587",
    "parent_id": "6e582e37-e60d-4ab3-b215-cd8a1900203a",
    "text": "hat \nP1I2 = 0.000888, where I denotes the event of screening a driver and getting someone who is \nintoxicated. What does P1I2 denote, and what is its value?\nIn Exercises 9\u201320, use the data in the following table, which summarizes blood groups and \nRh types for randomly selected subjects. Assume that subjects are randomly selected from \nthose included in the table.\nO\nA\nB\nAB\nType\nRh+\n59\n53\n12\n6\nRh\u2212\n 9\n 8\n 3\n2\n4-2 Basic Skills and Concepts\n\n4-2 Addition Rule and Multiplication Rule \n141\n9.\u00a0Blood Groups and Types If one person is selected, find the probability of getting some-\none who is not Group A.\n10.\u00a0 Blood Groups and Types If one person is selected, find the probability of getting \nsomeone who is not type Rh+.\n11.\u00a0 Blood Groups and Types If one person is selected, find the probability of getting \nsomeone who is Group A or type Rh+. Are the events of selecting someone who is Group A and \nthe event of someone who is type Rh+ disjoint events?\n12.\u00a0 Blood Groups and Types If one person is selected, find the probability of getting \nsomeone who is type Rh\u2212 or Group AB. Are the events of selecting someone who is type Rh\u2212\nand the event of someone who is Group AB disjoint events?\n13.\u00a0Blood Groups and Types If two people are selected, find the probability that they are \nboth Group B.\na. Assume that the selections are made with replacement. Are the events independent?\nb. Assume that the selections are made without replacement. Are the events independent?\n14.\u00a0Blood Groups and Types If two people are selected, find the probability that they are \nboth type Rh\u2212.\na. Assume that the selections are made with replacement. Are the events independent?\nb. Assume that the selections are made without replacement. Are the events independent?\n15.\u00a0Blood Groups and Types If two people are selected, find the probability that they are \nboth type Rh+.\na. Assume that the selections are made with replacement. Are the events independent?\nb. Assume that the selections are made without replacement. Are the events independent?\n16.\u00a0Blood Groups and Types If two people are selected, find the probability that they are \nboth Group AB.\na. Assume that the selections are made with replacement. Are the events independent?\nb. Assume that the selections are made without replacement. Are the events independent?\n17.\u00a0 Blood Groups and Types If one person is selected, find the probability of getting \nsomeone who is Group A or Group B or type Rh-.\n18.\u00a0 Blood Groups and Types If one person is selected, find the probability of getting \nsomeone who is Group O or Group AB or type Rh+.\n19.\u00a0Blood Groups and Types If three different people are selected, find the probability that \nthey are all Group A.\n20.\u00a0Blood Groups and Types If three different people are selected, find the probability that \nthey are all type Rh-.\nIn Exercises 21\u201324, use these results from the \u201c1-Panel-THC\u201d test for marijuana use, \nwhich is provided by the company Drug Test Success: Among 143 subjects with positive \ntest results, there",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 156
  },
  {
    "child_id": "51e69daf-fad7-49c0-8769-99e3e63a75fe",
    "parent_id": "6e582e37-e60d-4ab3-b215-cd8a1900203a",
    "text": "the probability of getting \nsomeone who is Group O or Group AB or type Rh+.\n19.\u00a0Blood Groups and Types If three different people are selected, find the probability that \nthey are all Group A.\n20.\u00a0Blood Groups and Types If three different people are selected, find the probability that \nthey are all type Rh-.\nIn Exercises 21\u201324, use these results from the \u201c1-Panel-THC\u201d test for marijuana use, \nwhich is provided by the company Drug Test Success: Among 143 subjects with positive \ntest results, there are 24 false positive results; among 157 negative results, there are 3 false \nnegative results. (Hint: Construct a table similar to Table 4-1, which is included with the \nChapter Problem.)\n21.\u00a0Testing for Marijuana Use\na. How many subjects are included in the study?\nb. How many of the subjects had a true negative result?\nc. What is the probability that a randomly selected test subject had a true negative result?",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 156
  },
  {
    "child_id": "0645dca9-f87b-4b82-b21c-2b5ca4e618ea",
    "parent_id": "6d1a28c8-cd2c-4677-b381-d6969b5889c9",
    "text": "142 \nCHAPTER 4 Probability\n22.\u00a0Testing for Marijuana Use If one of the test subjects is randomly selected, find the \nprobability that the subject tested negative or used marijuana.\n23.\u00a0Testing for Marijuana Use If one of the test subjects is randomly selected, find the \nprobability that the subject tested positive or did not use marijuana.\n24.\u00a0Testing for Marijuana Use If one of the test subjects is randomly selected, find the \nprobability that the subject used marijuana. Do you think that the result reflects the general \npopulation rate of subjects who use marijuana?\nRedundancy. Exercises 25 and 26 involve redundancy.\n25.\u00a0Redundancy in Computer Hard Drives It is generally recognized that it is wise to \nback up computer data. Assume that there is a 3% rate of disk drive failure in a year (based on \ndata from various sources including lifehacker.com).\na. If you store all of your computer data on a single hard disk drive, what is the probability that \nthe drive will fail during a year?\nb. If all of your computer data are stored on a hard disk drive with a copy stored on a second \nhard disk drive, what is the probability that both drives will fail during a year?\nc. If copies of all of your computer data are stored on three independent hard disk drives, what \nis the probability that all three will fail during a year?\nd. Describe the improved reliability that is gained with backup drives.\n26.\u00a0Redundancy in Hospital Generators Hospitals typically require backup generators to \nprovide electricity in the event of a power outage. Assume that emergency backup generators \nfail 22% of the times when they are needed (based on data from Arshad Mansoor, senior vice \npresident with the Electric Power Research Institute). A hospital has two backup generators so \nthat power is available if one of them fails during a power outage.\na. Find the probability that both generators fail during a power outage.\nb. Find the probability of having a working generator in the event of a power outage. Is that \nprobability high enough for the hospital?\nAcceptance Sampling. With one method of a procedure called acceptance sampling, a \nsample of items is randomly selected without replacement and the entire batch is accepted \nif every item in the sample is found to be okay (or conforming). Exercises 27 and 28 involve \nacceptance sampling.\n27.\u00a0Defective Pacemakers Among 8834 cases of heart pacemaker malfunctions, 504 were \nfound to be caused by firmware, which is software programmed into the device (based on data \nfrom \u201cPacemaker and ICD Generator Malfunctions,\u201d by Maisel et al., Journal of the American \nMedical Association, Vol. 295, No. 16). If the firmware is tested in three different pacemak-\ners randomly selected from this batch of 8834 and the entire batch is accepted if there are no \nfailures, what is the probability that the firmware in the entire batch will be accepted? Is this \nprocedure likely to result in the entire batch being accepted?\n28.\u00a0Defective Ultrasound Transducer",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 160
  },
  {
    "child_id": "e27822e4-1a5d-44e7-aa3e-e8e5c3b0afee",
    "parent_id": "6d1a28c8-cd2c-4677-b381-d6969b5889c9",
    "text": "vice (based on data \nfrom \u201cPacemaker and ICD Generator Malfunctions,\u201d by Maisel et al., Journal of the American \nMedical Association, Vol. 295, No. 16). If the firmware is tested in three different pacemak-\ners randomly selected from this batch of 8834 and the entire batch is accepted if there are no \nfailures, what is the probability that the firmware in the entire batch will be accepted? Is this \nprocedure likely to result in the entire batch being accepted?\n28.\u00a0Defective Ultrasound Transducers Among 676 ultrasound transducers tested, 269 \nwere defective with transducer errors (based on data from \u201cHigh Incidence of Defective Ultra-\nsound Transducers in Use in Routine Clinical Practice,\u201d by Martensson et al., European Jour-\nnal of Cardiology, Vol. 10). If four different units are randomly selected and tested, what is the \nprobability that the entire batch will be accepted? Does that probability seem adequate?\nIn Exercises 29 and 30, find the probabilities and indicate when the \u201c5% guideline for cum-\nbersome calculations\u201d is used.\n29.\u00a0Medical Helicopters In a study of helicopter usage and patient survival, results were \nobtained from 47,637 patients transported by helicopter and 111,874 patients transported by \nground (based on data from \u201cAssociation Between Helicopter vs Ground Emergency Medical\n\n4-2 Addition Rule and Multiplication Rule \n143\nServices and Survival for Adults with Major Trauma,\u201d by Galvagno et al., Journal of the Ameri-\ncan Medical Association, Vol. 307, No. 15).\na. If 1 of the 159,511 patients in the study is randomly selected, what is the probability that the \nsubject was transported by helicopter?\nb. If 5 of the subjects in the study are randomly selected without replacement, what is the prob-\nability that all of them were transported by helicopter?\n30.\u00a0Medical Helicopters In the same study cited in the preceding exercise, among the 47,637 \npatients transported by helicopter, 188 of them left the treatment center against medical advice, \nand the other 47,449 did not leave against medical advice. If 40 of the subjects transported by \nhelicopter are randomly selected without replacement, what is the probability that none of them \nleft the treatment center against medical advice?\n31. MRI Reliability Refer to the accompanying figure showing surge protectors p and q used \nto protect an expensive magnetic resonance imaging (MRI) scanner used in a hospital. If there \nis a surge in the voltage, the surge protector reduces it to a safe level. Assume that each surge \nprotector has a 0.985 probability of working correctly when a voltage surge occurs.\na. If the two surge protectors are arranged in series, what is the probability that a voltage surge \nwill not damage the MRI? (Do not round the answer.)\nb. If the two surge protectors are arranged in parallel, what is the probability that a voltage \nsurge will not damage the MRI? (Do not round the answer.)\nc. Which arrangement should be used for better protection?\nSeries con\ufb01guration\np\nq\nMRI",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 160
  },
  {
    "child_id": "1095cb56-779d-4e9c-90d2-958736ef4163",
    "parent_id": "6d1a28c8-cd2c-4677-b381-d6969b5889c9",
    "text": "sume that each surge \nprotector has a 0.985 probability of working correctly when a voltage surge occurs.\na. If the two surge protectors are arranged in series, what is the probability that a voltage surge \nwill not damage the MRI? (Do not round the answer.)\nb. If the two surge protectors are arranged in parallel, what is the probability that a voltage \nsurge will not damage the MRI? (Do not round the answer.)\nc. Which arrangement should be used for better protection?\nSeries con\ufb01guration\np\nq\nMRI\nParallel con\ufb01guration\np\nq\nMRI\n32. Same Birthdays If 25 people are randomly selected, find the probability that no 2 of them \nhave the same birthday. Ignore leap years.\n33. Exclusive Or The exclusive or means either one or the other events occurs, but not both.\na. For the formal addition rule, rewrite the formula for P(A or B) assuming that the addition \nrule uses the exclusive or instead of the inclusive or.\nb. Repeat Exercise 11 \u201cBlood Groups and Types\u201d using the exclusive or instead of the inclu-\nsive\u00a0or.\n34. Complements and the Addition Rule Refer to the table of blood groups and types used \nfor Exercises 9\u201320. Assume that one subject is randomly selected. Let A represent the event \nof getting someone with Group A blood and let B represent the event of getting someone with \nGroup B blood. Find P1A or B2, find P1A or B2, and then compare the results. In general, does \nP1A or B2 = P1A or B2?\n4-2 Beyond the Basics\n\n144 \nCHAPTER 4 Probability\nKey Concept In Part 1 of this section we extend the use of the multiplication rule to \ninclude the probability that among several trials, we get at least one of some specified \nevent. In Part 2 we consider conditional probability: the probability of an event occur-\nring when we have additional information that some other event has already occurred. \nIn Part 3 we provide a brief introduction to the use of Bayes\u2019 theorem.\nPART 1\n  Complements: The Probability  \nof \u201cAt Least One\u201d \nWhen finding the probability of some event occurring \u201cat least once,\u201d we should un-\nderstand the following:\n \n\u25a0\u201cAt least one\u201d has the same meaning as \u201cone or more.\u201d\n \n\u25a0The complement of getting \u201cat least one\u201d particular event is that you get no \noccurrences of that event.\nFor example, not getting at least 1 girl in 10 births is the same as getting no girls, \nwhich is also the same as getting 10 boys.\nNot getting at least 1 girl in 10 births = Getting no girls = Getting 10 boys\nThe following steps describe the details of this backward method of finding the \nprobability of getting at least one of some event:\nFinding the probability of getting at least one of some event:\n1. Let A = getting at least one of some event.\n2. Then A = getting none of the event being considered.\n3. Find P1A2 = probability that event A does not occur. (This is relatively \neasy using the multiplication rule.)\n4. Subtract the result from 1. That is, evaluate this expression:\nP1at least one occurrence of event A2\n  = 1 \u2212P1no occurrences of event A2\n4-3\n \nComplements, Conditi",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 160
  },
  {
    "child_id": "7a4bb0ca-8535-42b3-b8e5-9ed924c02c0b",
    "parent_id": "6d1a28c8-cd2c-4677-b381-d6969b5889c9",
    "text": "e \nprobability of getting at least one of some event:\nFinding the probability of getting at least one of some event:\n1. Let A = getting at least one of some event.\n2. Then A = getting none of the event being considered.\n3. Find P1A2 = probability that event A does not occur. (This is relatively \neasy using the multiplication rule.)\n4. Subtract the result from 1. That is, evaluate this expression:\nP1at least one occurrence of event A2\n  = 1 \u2212P1no occurrences of event A2\n4-3\n \nComplements, Conditional Probability,  \nand Bayes\u2019 Theorem\nEXAMPLE 1  At Least One Subject with Group AB Blood\nThe probability of randomly selecting someone with Group AB blood is 0.0526 \n(based on the table given with Exercises 9\u201320 in the preceding section). A re-\nsearcher needs at least one subject having Group AB blood. If 20 subjects are ran-\ndomly selected, find the probability of getting at least one with Group AB blood. Is \nthe probability high enough so that the researcher can be reasonably sure of getting \nsomeone with Group AB blood?\nSOLUTION\nStep 1: Let A = at least 1 of the 20 subjects has Group AB blood.\nStep 2: Identify the event that is the complement of A.\n A = not getting at least 1 subject with Group AB blood among 20\n = all 20 subjects have blood that is not Group AB\n\n4-3 Complements, Conditional Probability, and Bayes\u2019 Theorem  \n145\nPART 2\n Conditional Probability \nWe now consider the principle that the probability of an event is often affected by \nknowledge that some other event has occurred. For example, the probability of a \ngolfer making a hole in one is 1>12,000 (based on past results), but if you have the \nadditional knowledge that the selected person is a professional golfer, the probability \nchanges to 1>2375 (based on data from USA Today).\nStep 3: Find the probability of the complement by evaluating P1A2 If there is \na 0.0526 probability of a person having Group AB blood, it follows that there \nis a 0.9474 probability of a person not having Group AB blood, and we get the \n following:\n P1A2 = P1all 20 subjects have blood that is not Group AB2\n = 0.9474 # 0.9474 #  g # 0.9474\n = 0.947420 = 0.339365436\nStep 4: Find P(A) by evaluating 1 - P1A2.\nP1A2 = 1 - P1A2 = 1 - 0.339365436 = 0.661 1rounded2\nINTERPRETATION\nFor a group of 20 subjects, there is a 0.661 probability of getting at least 1 person \nwith Group AB blood. This probability is not very high, so if the researcher needs a \nperson with Group AB blood, more than 20 subjects should be used.\nDEFINITION\nA conditional probability of an event is a probability obtained with the additional \ninformation that some other event has already occurred.\nNotation\nP1B\u001eA2 denotes the conditional probability of event B occurring, given that event A \nhas already occurred.\nINTUITIVE APPROACH FOR FINDING P1B\u2223A2\nThe conditional probability of B occurring given that A has occurred can be found \nby assuming that event A has occurred and then calculating the probability that \nevent B will occur, as illustrated in Example",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 160
  },
  {
    "child_id": "52f1b89a-f878-4253-a085-7df6f06171e3",
    "parent_id": "6d1a28c8-cd2c-4677-b381-d6969b5889c9",
    "text": "nditional probability of an event is a probability obtained with the additional \ninformation that some other event has already occurred.\nNotation\nP1B\u001eA2 denotes the conditional probability of event B occurring, given that event A \nhas already occurred.\nINTUITIVE APPROACH FOR FINDING P1B\u2223A2\nThe conditional probability of B occurring given that A has occurred can be found \nby assuming that event A has occurred and then calculating the probability that \nevent B will occur, as illustrated in Example 2.\nFORMAL APPROACH FOR FINDING P1B\u2223A2\nThe probability P1B\u001e A2 can be found by dividing the probability of events A and B \nboth occurring by the probability of event A:\nP1B\u001e A2 = P1A and B2\nP1A2\nProsecutor\u2019s Fallacy\nThe prosecu-\ntor\u2019s fallacy is \nmisunderstand-\ning or confusion \nof two different \nconditional \nprobabilities:  \n(1) the probability \nthat a defendant is innocent, giv-\nen that forensic evidence shows \na match; (2) the probability that \nforensics shows a match, given \nthat a person is innocent. The \nprosecutor\u2019s fallacy has led to \nwrong convictions and imprison-\nment of some innocent people.\nLucia de Berk was a nurse \nwho was convicted of murder \nand sentenced to prison in the \nNetherlands. Hospital administra-\ntors observed suspicious deaths \nthat occurred in hospital wards \nwhere de Berk had been present. \nAn expert testified that there was \nonly 1 chance in 342 million that \nher presence was a coincidence. \nHowever, mathematician Richard \nGill calculated the probability to \nbe closer to 1>150, or possibly as \nlow as 1>5. The court used the \nprobability that the suspicious \ndeaths could have occurred with \nde Berk present, given that she \nwas innocent. The court should \nhave considered the probability \nthat de Berk is innocent, given \nthat the suspicious deaths oc-\ncurred when she was present. \nThis error of the prosecutor\u2019s \nfallacy is subtle and can be \nvery difficult to understand and \nrecognize, yet it can lead to the \nimprisonment of innocent people.",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 160
  },
  {
    "child_id": "6922d320-d9a8-4b0a-9632-549912f37a6b",
    "parent_id": "4a272a5a-052c-4ebc-a310-6200ce8fce88",
    "text": "146 \nCHAPTER 4 Probability\nThe preceding formula is a formal expression of conditional probability, but blind use \nof formulas is not recommended. Instead, we recommend the intuitive approach, as \nillustrated in Example 2.\nTABLE 4-1 Results from Drug Tests of Job Applicants\nPositive Test Result\n(Test shows drug use.)\nNegative Test Result \n(Test shows no drug use.)\nSubject Uses Drugs\n45\n(True Positive)\n5\n(False Negative)\nSubject Does Not Use Drugs\n25\n(False Positive)\n480\n(True Negative)\nEXAMPLE 2  Pre-Employment Drug Screening\nRefer to Table 4-1 to find the following:\n \na. If 1 of the 555 test subjects is randomly selected, \ufb01nd the probability that the \nsubject had a positive test result, given that the subject actually uses drugs. \nThat is, \ufb01nd P(positive test result \u001e subject uses drugs).\n \nb. If 1 of the 555 test subjects is randomly selected, \ufb01nd the probability that the \nsubject actually uses drugs, given that he or she had a positive test result. That \nis, \ufb01nd P(subject uses drugs \u001e positive test result).\nSOLUTION\na. Intuitive Approach: We want P(positive test result \u001e subject uses drugs), the \nprobability of getting someone with a positive test result, given that the se-\nlected subject uses drugs. Here is the key point: If we assume that the selected \nsubject actually uses drugs, we are dealing only with the 50 subjects in the \n\ufb01rst row of Table 4-1. Among those 50 subjects, 45 had positive test results, \nso we get this result:\nP1positive test result \u001esubject uses drugs2 = 45\n50 = 0.900\n \n Formal Approach: The same result can be found by using the formula for \nP1B\u001eA2given with the formal approach. We use the following notation.\nP1B\u001eA2 = P1positive test result \u001esubject uses drugs2\nwhere B = positive test result and A = subject uses drugs.\n \n  \nIn the following calculation, we use P(subject uses drugs and had a posi-\ntive test result) = 45>555 and P(subject uses drugs) = 50>555 to get the \nfollowing results:\nP1B\u001eA2 = P1A and B2\nP1A2\nbecomes\nP1positive test result \u001esubject uses drugs2\n = P1subject uses drugs and had a positive test result2\nP1subject uses drugs2\n = 45>555\n50>555 = 0.900\n\n4-3 Complements, Conditional Probability, and Bayes\u2019 Theorem  \n147\nConfusion of the Inverse\nNote that in Example 2, P(positive test result \u001e subject uses drugs) \u2260P(subject uses \ndrugs \u001e positive test result). This example proves that in general, P1B\u001eA2 \u2260P1A\u001eB2.\n(There could be individual cases where P1A\u001eB2 and P1B\u001eA2 are equal, but they are \ngenerally not equal.) To incorrectly think that P1B\u001eA2 and P1A\u001eB2 are equal or to \nincorrectly use one value in place of the other is called confusion of the inverse.\n \n By comparing the intuitive approach to the formal approach, it should be clear \nthat the intuitive approach is much easier to use, and it is also less likely to \nresult in errors. The intuitive approach is based on an understanding of condi-\ntional probability, instead of manipulation of a formula, and understanding is \nso much better.\n \nb. Here we want P(s",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 164
  },
  {
    "child_id": "eae3f111-80ae-4e63-86a2-f357f9e4cc2b",
    "parent_id": "4a272a5a-052c-4ebc-a310-6200ce8fce88",
    "text": "rrectly think that P1B\u001eA2 and P1A\u001eB2 are equal or to \nincorrectly use one value in place of the other is called confusion of the inverse.\n \n By comparing the intuitive approach to the formal approach, it should be clear \nthat the intuitive approach is much easier to use, and it is also less likely to \nresult in errors. The intuitive approach is based on an understanding of condi-\ntional probability, instead of manipulation of a formula, and understanding is \nso much better.\n \nb. Here we want P(subject uses drugs \u001e positive test result). If we assume that the \nsubject had a positive test result, we are dealing with the 70 subjects in the \n\ufb01rst column of Table 4-1. Among those 70 subjects, 45 use drugs, so\nP1subject uses drugs \u001epositive test result2 = 45\n70 = 0.643\nAgain, the same result can be found by applying the formula for conditional \nprobability, but we will leave that for those with a special fondness for ma-\nnipulations with formulas.\nINTERPRETATION\nThe first result of P(positive test result \u001e subject uses drugs) = 0.900 indicates that \na subject who uses drugs has a 0.900 probability of getting a positive test result. \nThe second result of P(subject uses drugs \u001e positive test result) = 0.643 indicates \nthat for a subject who gets a positive test result, there is a 0.643 probability that this \nsubject actually uses drugs. Note that P1positive test result \u001esubject uses drugs2\nP1subject uses drugs \u001epositive test result2. See \u201cConfusion of the Inverse\u201d that \nfollows.\nEXAMPLE 3  Confusion of the Inverse\nConsider these events:\nD: It is dark outdoors.\nM: It is midnight.\nIn the following, we conveniently ignore the Alaskan winter and other such \nanomalies.\nP1D\u001eM2 = 1 1It is certain to be dark given that it is midnight.2\nP1M \u001eD2 = 0 1The probability that it is exactly midnight given\nthat it is dark is almost zero.2\nHere, P1D\u001eM2 \u2260P1M \u001eD2. Confusion of the inverse occurs when we incorrectly \nswitch those probability values or think that they are equal.\n\n148 \nCHAPTER 4 Probability\nPART 3\nBayes\u2019 Theorem\nIn this section we extend the discussion of conditional probability to include applica-\ntions of Bayes\u2019 theorem (or Bayes\u2019 rule), which we use for revising a probability value \nbased on additional information that is later obtained.\nLet\u2019s consider a study showing that physicians often give very misleading in-\nformation when they experience confusion of the inverse. They tended to confuse \nP(cancer \u001f positive test result) with P(positive test result \u001f cancer). About 95% of physi-\ncians estimated P(cancer \u001f positive test result) to be about 10 times too high, with the \nresult that patients were given diagnoses that were very misleading, and patients were \nunnecessarily distressed by the incorrect information. Let\u2019s take a closer look at this \nclassic example, and let\u2019s hope that we can give physicians information in a better \nformat that is easy to understand.\nEXAMPLE 4  Interpreting Medical Test Results\nAssume cancer has a 1% prevalence rate, meaning th",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 164
  },
  {
    "child_id": "ae5281b7-4b9d-47e7-96f6-4e45360764af",
    "parent_id": "4a272a5a-052c-4ebc-a310-6200ce8fce88",
    "text": "out 95% of physi-\ncians estimated P(cancer \u001f positive test result) to be about 10 times too high, with the \nresult that patients were given diagnoses that were very misleading, and patients were \nunnecessarily distressed by the incorrect information. Let\u2019s take a closer look at this \nclassic example, and let\u2019s hope that we can give physicians information in a better \nformat that is easy to understand.\nEXAMPLE 4  Interpreting Medical Test Results\nAssume cancer has a 1% prevalence rate, meaning that 1% of the population has \ncancer. Denoting the event of having a cancer by C, we have P1C2 = 0.01 for a \nsubject randomly selected from the population. This result is included with the fol-\nlowing performance characteristics of the test for cancer (based on Probabilistic \nReasoning in Clinical Medicine, by David Eddy, Cambridge University Press).\n \n\u25a0There is a 1% prevalence rate of the cancer. That is, P1C2 = 0.01.\n \n\u25a0The false positive rate is 10%. That is, P(positive test result given that cancer is \nnot present) = 0.10.\n \n\u25a0The true positive rate is 80%. That is, P(positive test result given that cancer is \npresent) = 0.80.\nFind P1C\u001fpositive test result2. That is, find the probability that a subject actually \nhas cancer given that he or she has a positive test result.\nSOLUTION\nUsing the given information, we can construct a hypothetical population with the above \ncharacteristics. We can find the entries in Table 4-2 on the next page, as follows.\n \n\u25a0Assume that we have 1000 subjects. With a 1% prevalence rate, 10 of the sub-\njects are expected to have cancer. The sum of the entries in the first row of val-\nues is therefore 10.\n \n\u25a0The other 990 subjects do not have cancer. The sum of the entries in the second \nrow of values is therefore 990.\n \n\u25a0Among the 990 subjects without cancer, 10% get positive test results, so 10% \nof the 990 cancer-free subjects in the second row get positive test results. See \nthe entry of 99 in the second row.\n \n\u25a0For the 990 subjects in the second row, 99 test positive, so the other 891 must \ntest negative. See the entry of 891 in the second row.\n \n\u25a0Among the 10 subjects with cancer in the first row, 80% of the test results are \npositive, so 80% of the 10 subjects in the first row test positive. See the entry of \n8 in the first row.\n \n\u25a0The other 2 subjects in the first row test negative. See the entry of 2 in the \nfirst row.\nIn\nti\nGroup Testing\nDuring World \nWar II, the U.S. \nArmy tested \nfor syphilis \nby giving \neach soldier \nan individual \nblood test that was analyzed \nseparately. One researcher sug-\ngested mixing pairs of blood \nsamples. After the mixed pairs \nwere tested, those with syphilis \ncould be identified by retest-\ning the few blood samples that \nwere in the pairs that tested \npositive. Since the total number \nof analyses was reduced by pair-\ning blood specimens, why not \ncombine them in groups of three \nor four or more? This technique \nof combining samples in groups \nand retesting only those groups \nthat test posit",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 164
  },
  {
    "child_id": "f146cd6b-2cf4-49a8-97ba-c3a8764cc651",
    "parent_id": "4a272a5a-052c-4ebc-a310-6200ce8fce88",
    "text": "ual \nblood test that was analyzed \nseparately. One researcher sug-\ngested mixing pairs of blood \nsamples. After the mixed pairs \nwere tested, those with syphilis \ncould be identified by retest-\ning the few blood samples that \nwere in the pairs that tested \npositive. Since the total number \nof analyses was reduced by pair-\ning blood specimens, why not \ncombine them in groups of three \nor four or more? This technique \nof combining samples in groups \nand retesting only those groups \nthat test positive is known as \ngroup testing or pooled testing, or \ncomposite testing. University of \nNebraska statistician Christopher \nBilder wrote an article about this \ntopic in Chance magazine, and \nhe cited some real applications. \nHe noted that the American \nRed Cross uses group testing \nto screen for specific diseases, \nsuch as hepatitis, and group \n testing is used by veterinarians \nwhen cattle are tested for the \nbovine viral diarrhea virus.\n\n4-3 Complements, Conditional Probability, and Bayes\u2019 Theorem  \n149\nThe solution in Example 4 is not very difficult. Another approach is to compute the \nprobability using this formula commonly given with Bayes\u2019 theorem:\nP1A\u001eB2 =\nP1A2 # P1B\u001eA2\n3P1A2 # P1B\u001eA2 4 + 3P1A2 # P1B\u001eA2 4\nIf we replace A with C and replace B with \u201cpositive,\u201d we get this solution for Example 4:\n P1C\u001epositive2 =\nP1C2 # P1positive \u001eC2\nP1C2 # P1positive \u001eC2 + P1C2 # P1Positive \u001eC2\n =\n0.01 # 0.80\n10.01 # 0.802 + 10.99 # 0.102 = 0.0748\nStudy Results Here is a truly fascinating fact: When 100 physicians were given \nthe information in Example 4, 95 of them estimated P(C \u001e positive) to be around \n0.70 to 0.80, so they were wrong by a factor of 10. Physicians are extremely intel-\nligent, but here they likely suffered from confusion of the inverse. The given rate \nof 80% for positive test results among those who are true positives implies that \nP1positive \u001eC2 = 0.80, but this is very different from P1C\u001epositive2. The physi-\ncians would have done much better if they had seen the given information in the form \nof a table like Table 4-2.\nThe importance and usefulness of Bayes\u2019 theorem is that it can be used with se-\nquential events, whereby new additional information is obtained for a subsequent \nevent, and that new information is used to revise the probability of the initial event. In \nthis context, the terms prior probability and posterior probability are commonly used.\nTo find P1C\u001epositive test result2, see that the first column of values includes the \npositive test results. In that first column, the probability of randomly selecting a \nsubject with cancer is 8>107 or 0.0748, so P1C\u001epositive test result2 = 0.0748.\nINTERPRETATION\nFor the data given in this example, a randomly selected subject has a 1% chance \nof cancer, but for a randomly selected subject given a test with a positive result, \nthe chance of cancer increases to 7.48%. Based on the data given in this example, \na positive test result should not be devastating news, because there is still a good \ncha",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 164
  },
  {
    "child_id": "0f203e70-bea6-4eaf-afb6-2c03439ab26d",
    "parent_id": "4a272a5a-052c-4ebc-a310-6200ce8fce88",
    "text": "lts. In that first column, the probability of randomly selecting a \nsubject with cancer is 8>107 or 0.0748, so P1C\u001epositive test result2 = 0.0748.\nINTERPRETATION\nFor the data given in this example, a randomly selected subject has a 1% chance \nof cancer, but for a randomly selected subject given a test with a positive result, \nthe chance of cancer increases to 7.48%. Based on the data given in this example, \na positive test result should not be devastating news, because there is still a good \nchance that the test is wrong.\nTABLE 4-2 Test Results\nPositive Test Result\n(Test shows cancer.)\nNegative Test Result \n(Test shows no cancer.)\n \nTotal\nCancer\n8\n(True Positive)\n2\n(False Negative)\n10\nNo Cancer\n99\n(False Positive)\n891\n(True Negative)\n990\nDEFINITIONS\nA prior probability is an initial probability value originally obtained before any ad-\nditional information is obtained.\nA posterior probability is a probability value that has been revised by using addi-\ntional information that is later obtained.",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 164
  },
  {
    "child_id": "7a7665fb-89fc-40b1-82a8-8a3fbe39a896",
    "parent_id": "d39f6ef7-5347-42c1-b0f5-e65792d88424",
    "text": "150 \nCHAPTER 4 Probability\nRelative to Example 4, P1C2 = 0.01, which is the probability that a randomly se-\nlected subject has cancer. P(C) is an example of a prior probability. Using the ad-\nditional information that the subject has received a positive test result, we found that \nP1C\u001epositive test result2 = 0.0748, and this is a posterior probability because it uses \nthat additional information of the positive test result.\nStatistical Literacy and Critical Thinking\n1.\u00a0Language: Complement of \u201cAt Least One\u201d Let A = the event of getting at least one \ndefective pacemaker battery when 3 batteries are randomly selected with replacement from a \nbatch. Write a statement describing event A.\n2.\u00a0Probability of At Least One Let A = the event of getting at least 1 defective pacemaker \nbattery when 3 batteries are randomly selected with replacement from a batch. If 5% of the \nbatteries in a batch are defective and the other 95% are all good, which of the following are \ncorrect?\na. P1A2 = 10.95210.95210.952 = 0.857\nb. P1A2 = 1 - 10.95210.95210.952 = 0.143\nc. P1A2 = 10.05210.05210.052 = 0.000125\n3.\u00a0Notation Let event G = subject has glaucoma (disorder of the eye) and let event Y = test \nindicates that \u201cyes,\u201d the subject has glaucoma. Use your own words to translate the notation \nP1Y \u001e G2 into a verbal statement.\n4.\u00a0Confusion of the Inverse Using the same events G and Y described in Exercise 3, de-\nscribe confusion of the inverse.\nAt Least One. In Exercises 5\u201312, find the probability.\n5.\u00a0Three Girls Find the probability that when a couple has three children, at least one of them \nis a girl. (Assume that boys and girls are equally likely.)\n6.\u00a0Probability of a Girl Assuming that boys and girls are equally likely, find the probability \nof a couple having a boy when their third child is born, given that the first two children were \nboth girls.\n7.\u00a0Births in the United States In the United States, the true probability of a baby being a \nboy is 0.512 (based on the data available at this writing). Among the next six randomly selected \nbirths in the United States, what is the probability that at least one of them is a girl?\n8.\u00a0Births in China In China, where many couples were allowed to have only one child, the \nprobability of a baby being a boy was 0.545. Among six randomly selected births in China, \nwhat is the probability that at least one of them is a girl? Could this system continue to work \nindefinitely? (Phasing out of this policy was begun in 2015.)\n9.\u00a0Phone Survey Subjects for the California Health Interview Survey are contacted using \ntelephone numbers in which the last four digits are randomly selected (with replacement). Find \nthe probability that for one such phone number, the last four digits include at least one 0.\n10.\u00a0At Least One Correct Answer If you make random guesses for 10 multiple-choice \nMCAT test questions (each with five possible answers), what is the probability of getting at \nleast 1 correct? If these questions are part of a practice test and",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 168
  },
  {
    "child_id": "ec75feae-2e16-4e48-9b8b-5bf8e1676dfb",
    "parent_id": "d39f6ef7-5347-42c1-b0f5-e65792d88424",
    "text": "ts for the California Health Interview Survey are contacted using \ntelephone numbers in which the last four digits are randomly selected (with replacement). Find \nthe probability that for one such phone number, the last four digits include at least one 0.\n10.\u00a0At Least One Correct Answer If you make random guesses for 10 multiple-choice \nMCAT test questions (each with five possible answers), what is the probability of getting at \nleast 1 correct? If these questions are part of a practice test and an instructor says that you must \nget at least one correct answer before continuing, is there a good chance you will continue?\n11.\u00a0At Least One Defective Ultrasound Transducer A study showed that 39.8% of ultra-\nsound transducers are defective (based on data from \u201cHigh Incidence of Defective  Ultrasound \n4-3 Basic Skills and Concepts\n\n4-3 Complements, Conditional Probability, and Bayes\u2019 Theorem  \n151\nTransducers in Use in Routine Clinical Practice,\u201d by Martensson et al., European Journal of \nEchocardiography, Vol. 10, No. 1093.) An engineer needs at least one defective ultrasound \ntransducer so she can try to identify the problem. If she randomly selects 10 ultrasound trans-\nducers from a very large batch, what is the probability that she will get at least one that is de-\nfective? Is that probability high enough so that she can be reasonably sure of getting a defective \ntransducer for her work?\n12.\u00a0Fruit Flies An experiment with fruit flies involves one parent with normal wings and one \nparent with vestigial wings. When these parents have an offspring, there is a 3>4 probability \nthat the offspring has normal wings and a 1>4 probability of vestigial wings. If the parents give \nbirth to five offspring, what is the probability that at least one of the offspring has vestigial \nwings? If researchers need at least one offspring with vestigial wings, can they be quite confi-\ndent of getting one?\nIdentical and Fraternal Twins. In Exercises 13\u201316, use the data in the following table. \nInstead of summarizing observed results, the entries reflect the actual probabilities based \non births of twins (based on data from the Northern California Twin Registry and the ar-\nticle \u201cBayesians, Frequentists, and Scientists,\u201d by Bradley Efron, Journal of the American \nStatistical Association, Vol. 100, No. 469). Identical twins come from a single egg that splits \ninto two embryos, and fraternal twins are from separate fertilized eggs. The table entries \nreflect the principle that among sets of twins, 1 , 3 are identical and 2 , 3 are fraternal. Also, \nidentical twins must be of the same gender and the genders are equally likely (approxi-\nmately), and genders of fraternal twins are equally likely.\nBoy>boy\nBoy>girl\nGirl>boy\nGirl>girl\nIdentical Twins\n5\n0\n0\n5\nFraternal Twins\n5\n5\n5\n5\n13.\u00a0Identical Twins\na. After having a sonogram, a pregnant woman learns that she will have twins. What is the \nprobability that she will have identical twins?\nb. After studying the sonogram more closely",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 168
  },
  {
    "child_id": "c7860bae-cea3-4ddc-90df-faa98a00b782",
    "parent_id": "d39f6ef7-5347-42c1-b0f5-e65792d88424",
    "text": "ets of twins, 1 , 3 are identical and 2 , 3 are fraternal. Also, \nidentical twins must be of the same gender and the genders are equally likely (approxi-\nmately), and genders of fraternal twins are equally likely.\nBoy>boy\nBoy>girl\nGirl>boy\nGirl>girl\nIdentical Twins\n5\n0\n0\n5\nFraternal Twins\n5\n5\n5\n5\n13.\u00a0Identical Twins\na. After having a sonogram, a pregnant woman learns that she will have twins. What is the \nprobability that she will have identical twins?\nb. After studying the sonogram more closely, the physician tells the pregnant woman that she \nwill give birth to twin boys. What is the probability that she will have identical twins? That is, \nfind the probability of identical twins given that the twins consist of two boys.\n14.\u00a0Fraternal Twins\na. After having a sonogram, a pregnant woman learns that she will have twins. What is the \nprobability that she will have fraternal twins?\nb. After studying the sonogram more closely, the physician tells the pregnant woman that she \nwill give birth to twins consisting of one boy and one girl. What is the probability that she will \nhave fraternal twins?\n15.\u00a0Fraternal Twins If a pregnant woman is told that she will give birth to fraternal twins, \nwhat is the probability that she will have one child of each gender?\n16.\u00a0Fraternal Twins If a pregnant woman is told that she will give birth to fraternal twins, \nwhat is the probability that she will give birth to two girls?\n\n152 \nCHAPTER 4 Probability\nIn Exercises 17\u201320, refer to the accompanying table showing results from a Chembio test \nfor hepatitis C among HIV-infected patients (based on data from a variety of sources).\nPositive Test Result\nNegative Test Result\nHepatitis C\n335\n  10\nNo Hepatitis C\n  2\n1153\n17.\u00a0False Positive Find the probability of selecting a subject with a positive test result, given \nthat the subject does not have hepatitis C. Why is this case problematic for test subjects?\n18.\u00a0False Negative Find the probability of selecting a subject with a negative test result, \ngiven that the subject has hepatitis C. What would be an unfavorable consequence of this error?\n19.\u00a0Positive Predictive Value Find the positive predictive value for the test. That is, find the \nprobability that a subject has hepatitis C, given that the test yields a positive result. Does the \nresult make the test appear to be effective?\n20.\u00a0Negative Predictive Value Find the negative predictive value for the test. That is, find \nthe probability that a subject does not have hepatitis C, given that the test yields a negative re-\nsult. Does the result make the test appear to be effective?\n21.\u00a0Redundancy in Computer Hard Drives Assume that there is a 3% rate of disk drive \nfailures in a year (based on data from various sources including lifehacker.com).\na. If all of your computer data are stored on a hard disk drive with a copy stored on a second \nhard disk drive, what is the probability that during a year, you can avoid catastrophe with at \nleast one working drive? Express the result w",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 168
  },
  {
    "child_id": "204931d5-0e48-47ea-8e5c-7f1142a75016",
    "parent_id": "d39f6ef7-5347-42c1-b0f5-e65792d88424",
    "text": "that the test yields a negative re-\nsult. Does the result make the test appear to be effective?\n21.\u00a0Redundancy in Computer Hard Drives Assume that there is a 3% rate of disk drive \nfailures in a year (based on data from various sources including lifehacker.com).\na. If all of your computer data are stored on a hard disk drive with a copy stored on a second \nhard disk drive, what is the probability that during a year, you can avoid catastrophe with at \nleast one working drive? Express the result with four decimal places.\nb. If copies of all of your computer data are stored on three independent hard disk drives, what \nis the probability that during a year, you can avoid catastrophe with at least one working drive? \nExpress the result with six decimal places. What is wrong with using the usual round-off rule \nfor probabilities in this case?\n22.\u00a0Redundancy in Hospital Generators Assume that emergency backup generators fail \n22% of the times when they are needed (based on data from Arshad Mansoor, senior vice presi-\ndent with the Electric Power Research Institute). A hospital has three backup generators so \nthat power is available if at least one of them works in a power failure. Find the probability of \nhaving at least one of the backup generators working, given that a power failure has occurred. \nDoes the result appear to be adequate for the hospital\u2019s needs?\n23.\u00a0Composite Drug Test Based on the data in Table 4-1 on page 146, assume that the prob-\nability of a randomly selected person testing positive for drug use is 0.126. If drug screening \nsamples are collected from 5 random subjects and combined, find the probability that the com-\nbined sample will reveal a positive result. Is that probability low enough so that further testing \nof the individual samples is rarely necessary?\n24.\u00a0Composite Water Samples The Fairfield County Department of Public Health tests \nwater for the presence of E. coli (Escherichia coli) bacteria. To reduce laboratory costs, water \nsamples from 10 public swimming areas are combined for one test, and further testing is done \nonly if the combined sample tests positive. Based on past results, there is a 0.005 probability of \nfinding E. coli bacteria in a public swimming area. Find the probability that a combined sample \nfrom 10 public swimming areas will reveal the presence of E. coli bacteria. Is that probability \nlow enough so that further testing of the individual samples is rarely necessary?\n25. Shared Birthdays Find the probability that of 25 randomly selected people, at least 2 \nshare the same birthday.\n4-3 Beyond the Basics",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 168
  },
  {
    "child_id": "2ee0b977-b7c9-4714-ba0e-b7a23b3606d3",
    "parent_id": "924b74ed-4ff3-4e57-83e4-a59ca3de6ee3",
    "text": "4-4 Risks and Odds \n153\nKey Concept This section introduces absolute risk reduction, relative risk, and odds \nratio as measures helpful for comparing probability values and measuring risk. This \nsection also introduces \u201cnumber needed to treat\u201d as a measure of the number of sub-\njects that must be treated in order to prevent the single occurrence of some event, such \nas a disease.\nOne simple way to measure risk is to use a probability value. For example, in one \nof the largest medical experiments ever conducted, it was found that among 200,745 \nchildren injected with the Salk vaccine, 33 developed paralytic polio (poliomyelitis). \nIt follows that for this treatment group, P1polio2 = 33>200,745 = 0.000164. How-\never, that single measure does not give us any information about the rate of polio for \nthose children who were injected with a placebo. The risk of polio for children treated \nwith the Salk vaccine should be somehow compared to the risk of polio for those chil-\ndren given a placebo. Let\u2019s consider the data summarized in Table 4-3.\n4-4 \nRisks and Odds\nTABLE 4-3 Prospective Study of Polio and the Salk Vaccine\nPolio\nNo polio\nTotal\nSalk Vaccine\n 33\n200,712\n200,745\nPlacebo\n115\n201,114\n201,229\nBased on the data in Table 4-3, we can identify the following probabilities:\n Polio rate for treatment group: P1polio \u001eSalk vaccine2 =\n33\n200,745 = 0.000164\n Polio rate for placebo group: P1polio \u001eplacebo2 =\n115\n201,229 = 0.00571\nInformal comparison of the preceding two probabilities likely suggests that there is a \nsubstantial difference between the two polio rates. Later chapters will use more effec-\ntive methods for determining whether the apparent difference is actually significant, \nbut in this section we introduce some simple measures for comparing the two rates.\nThe preceding table can be generalized with the following format:\nTABLE 4-4 Generalized Table Summarizing Results of a Prospective Study\nDisease\nNo Disease\nTreatment\na\nb\nPlacebo\nc\nd\nWe noted above that this section introduces some simple measures for comparing \ntwo rates, such as the polio rate for the Salk vaccine treatment group and the polio \nrate for the placebo group, as summarized in Table 4-3. We begin with the absolute \nrisk reduction.\n\n154 \nCHAPTER 4 Probability\nAbsolute Risk Reduction\nDEFINITION\nWhen comparing two probabilities or rates, the absolute risk reduction is simply \nthe absolute value of the following difference.\nAbsolute risk reduction = \u001eP1event occurring in treatment group2\n- P1event occurring in control group2 \u001e\nIf the data are in the generalized format of Table 4\u22124, we can express the absolute \nrisk reduction as follows:\nAbsolute risk reduction = \u001eP1event occurring in treatment group2\n- P1event occurring in control group2 \u001e\n \n= `\na\na + b -\nc\nc + d `\n(In the above expression, \u201ctreatment\u201d might be replaced by the \u201cpresence of some \ncondition\u201d or some other equivalent description.)\nCAUTION: The above definition of absolute risk reduction always results in the \npositive d",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 171
  },
  {
    "child_id": "72087e91-359f-430e-899d-bdcb38e0e471",
    "parent_id": "924b74ed-4ff3-4e57-83e4-a59ca3de6ee3",
    "text": "vent occurring in control group2 \u001e\nIf the data are in the generalized format of Table 4\u22124, we can express the absolute \nrisk reduction as follows:\nAbsolute risk reduction = \u001eP1event occurring in treatment group2\n- P1event occurring in control group2 \u001e\n \n= `\na\na + b -\nc\nc + d `\n(In the above expression, \u201ctreatment\u201d might be replaced by the \u201cpresence of some \ncondition\u201d or some other equivalent description.)\nCAUTION: The above definition of absolute risk reduction always results in the \npositive difference between a probability in the treatment group and a probability \nin the control group. Consider this when interpreting the effectiveness of the \ntreatment in terms of being helpful or harmful. See Exercises 13\u221216, where those \nin an atorvastatin treatment group have a higher rate of infections than those in the \nplacebo group. Be careful to interpret the results correctly.\nEXAMPLE 1  Finding Absolute Risk Reduction\nUsing the data summarized in Table 4-3, find the absolute risk reduction, which can \nbe used to measure the effectiveness of the Salk vaccine.\nSOLUTION\nBased on the data in Table 4-3, we have already found that P(polio \u001e Salk vaccine) \n= 0.000164 and P(polio \u001e placebo) = 0.000571. It follows that:\n Absolute risk reduction = \u001eP1polio\u001eSalk vaccine2 - P1polio\u001eplacebo2 \u001e\n = \u001e0.000164 - 0.000571\u001e = 0.000407\nFor a subject treated with the Salk vaccine, there is an absolute risk reduction of \n0.000407 when compared to a subject given a placebo. That is, there are 0.0407% \nfewer events of polio for subjects treated with the Salk vaccine than for subjects given \na placebo. This doesn\u2019t seem like much of a reduction, but when considered in the con-\ntext of the number of polio events in a large population, it is a significant reduction.\nRelative Risk\nSection 1-3 included definitions of retrospective and prospective studies:\n \n\u25a0Retrospective Study: Data are collected from a past time period by going back in \ntime (through examinations of records, interviews, etc.).\n \n\u25a0Prospective Study: Data are collected in the future from groups or \u201ccohorts\u201d that \nshare common factors.\nA\nMonkey Typists\nA classical \nclaim is that \na monkey \nrandomly \nhitting a key-\nboard would \neventually \nproduce the complete works of \nShakespeare, assuming that it \ncontinues to type century after \ncentury. The multiplication rule \nfor probability has been used to \nfind such estimates. One  \nresult of 1,000,000,000,000,000, \n000,000,000,000,000,000,000 \nyears is considered by some to \nbe too short. In the same spirit, \nSir Arthur Eddington wrote this \npoem: \u201cThere once was a brainy \nbaboon, who always breathed \ndown a bassoon. For he said, \u2018It \nappears that in billions of years, I \nshall certainly hit on a tune.\u2019\u201d\n\n4-4 Risks and Odds \n155\nIn a prospective study, a commonly used measure for comparing risk is relative risk. \nWe first introduce the following notation, and then we define relative risk.\nNotation\npt = proportion (or incidence rate) of some characteristic in a treatment",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 171
  },
  {
    "child_id": "0db834a1-9c39-4eba-ae53-2736d9114437",
    "parent_id": "924b74ed-4ff3-4e57-83e4-a59ca3de6ee3",
    "text": "oo short. In the same spirit, \nSir Arthur Eddington wrote this \npoem: \u201cThere once was a brainy \nbaboon, who always breathed \ndown a bassoon. For he said, \u2018It \nappears that in billions of years, I \nshall certainly hit on a tune.\u2019\u201d\n\n4-4 Risks and Odds \n155\nIn a prospective study, a commonly used measure for comparing risk is relative risk. \nWe first introduce the following notation, and then we define relative risk.\nNotation\npt = proportion (or incidence rate) of some characteristic in a treatment group\npc = proportion (or incidence rate) of some characteristic in a control group\nDEFINITION\nIn a prospective study, the relative risk (or risk ratio or RR) of a characteristic \nis the ratio pt>pc, where pt is the proportion of the characteristic in the treatment \n(or exposed) group and pc is the proportion in the control group (or group not ex-\nposed). If the data are in the same format as the generalized Table 4-4, then the \nrelative risk is found by evaluating\npt\npc\n=\na\na + b\nc\nc + d\nInterpreting Relative Risk A relative risk value of 1 shows that the risk is the same \nfor the treatment group and the control (or placebo) group. A relative risk value much \ngreater than 1 shows that there is a much greater risk for the treatment group. The fol-\nlowing example illustrates how the relative risk of 0.287 shows that the risk of polio in \nthe treatment group is much less than the risk of polio in the placebo group.\nEXAMPLE 2  Computing Relative Risk\nUsing the data in Table 4-3, find the relative risk.\nSOLUTION\nFor the sample data in Table 4-3, we will consider the treatment group to be the \ngroup of children given the Salk vaccine, and the control group is the group of chil-\ndren given a placebo. Using the preceding notation, we have\npt = proportion of polio in treatment group =\n33\n33 + 200,712 = 0.000164\npc = proportion of polio in control 1placebo2 group =\n115\n115 + 201,114 =  0.000571\nUsing the above values, we can now find the relative risk as follows.\nRelative risk = pt\npc\n= 0.000164\n0.000571 = 0.287\nINTERPRETATION\nWe can interpret this result as follows: The polio rate for children given the Salk \nvaccine is 0.287 of the polio rate for children given a placebo. (A relative risk less \nthan 1 indicates that the treatment results in a reduced risk.) If we were to consider \nthe reciprocal value of 0.000571>0.000164 = 3.48, we see that children in the \n placebo group are 3.48 times more likely to get polio.\n\n156 \nCHAPTER 4 Probability\nNumber Needed to Treat\nOne problem with relative risk is that it may be misleading by suggesting that a treat-\nment is superior or inferior, even when the absolute difference between rates is not \nvery large. For example, if 3 out of 10,000 aspirin users were to experience an imme-\ndiate cure of a cold compared to only 1 out of 10,000 placebo users, the relative risk \nof 3.00 correctly indicates that the incidence of immediate cold cures is three times as \nhigh for aspirin users, but the cure rates of 0.0003 and 0.0001 are so",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 171
  },
  {
    "child_id": "2d10c02a-f86b-42e8-a00f-dedcfd4edf5d",
    "parent_id": "924b74ed-4ff3-4e57-83e4-a59ca3de6ee3",
    "text": "lem with relative risk is that it may be misleading by suggesting that a treat-\nment is superior or inferior, even when the absolute difference between rates is not \nvery large. For example, if 3 out of 10,000 aspirin users were to experience an imme-\ndiate cure of a cold compared to only 1 out of 10,000 placebo users, the relative risk \nof 3.00 correctly indicates that the incidence of immediate cold cures is three times as \nhigh for aspirin users, but the cure rates of 0.0003 and 0.0001 are so close that, for all \npractical purposes, aspirin should not be considered as a factor affecting the immedi-\nate cure of a cold. With cure rates of 0.0003 and 0.0001, the absolute risk reduction is \n0.0002. Because the absolute risk reduction is so small, the effectiveness of the aspirin \ntreatment would be negligible. In such a situation, the number needed to treat would \nbe a more effective measure that is not so misleading.\nCAUTION: When interpreting relative risk, consider the incidence rates. If the \nprobability of disease in an exposed group is 5>1,000,000 and the probability \nof disease in an unexposed group is 1>1,000,000, the relative risk is 5.0, which \nsounds really bad, but the very low incidence rates suggest that there isn\u2019t much \nrisk in either group.\nDEFINITION\nThe number needed to treat (NNT) is the number of subjects that must be treated \nin order to prevent one event, such as a disease or adverse reaction. It is calcu-\nlated by dividing 1 by the absolute risk reduction.\nnumber needed to treat =\n1\nabsolute risk reduction\nRound-Off Rule If the calculated value of the number needed to treat is not a whole \nnumber, round it up to the next larger whole number.\nIf the sample data are in the format of the generalized Table 4-4, then:\nNumber needed to treat =\n1\n`\na\na + b -\nc\nc + d `\n 1rounded up to the next\nlarger whole number2\nIf 3 out of 10,000 aspirin users were to experience an immediate cure of a cold \ncompared to only 1 out of 10,000 placebo users, the absolute risk reduction is \n\u001e0.0003 - 0.0001\u001e = 0.0002, and the number needed to treat is 1>0.0002 = 5000.\nThis means that we would need to treat 5000 subjects with colds to get one person \nwho experiences an immediate cure.\nEXAMPLE 3  Computing the Number Needed to Treat\nUsing the polio data in Table 4-3, find the number needed to treat, then interpret the \nresult.\nSOLUTION\nIn Example 1 we found that the absolute risk reduction is 0.000407. It is now easy \nto find the number needed to treat.",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 171
  },
  {
    "child_id": "d0a06dfa-cf16-4904-bc97-bc3c39c2f4c1",
    "parent_id": "dd14a874-c1a6-4110-85e5-d51b1a813893",
    "text": "4-4 Risks and Odds \n157\nOdds\nSo far in this chapter, we have used probability values to express likelihood of various \nevents. Probability values are numbers between 0 and 1 inclusive. However, expres-\nsions of likelihood are often given as odds, such as 50:1 (or \u201c50 to 1\u201d).\n Number needed to treat =\n1\nabsolute risk reduction =\n1\n0.000407 = 2457.002457\n = 2458 1rounded up2\nINTERPRETATION\nThe result of 2458 can be interpreted as follows: We would need to vaccinate 2458 \nchildren with the Salk vaccine (instead of a placebo) to prevent one of the children \nfrom getting polio. Given the extremely serious consequences of polio, the Salk \nvaccine has been found to be very effective and important.\nDEFINITIONS\nThe actual odds against event A occurring are the ratio P1A2>P1A2, usually ex-\npressed in the form of a:b (or \u201ca to b\u201d), where a and b are integers. (Reduce using \nthe largest common factor; if a = 16 and b = 4, express the odds as 4:1 instead \nof 16:4.)\nThe actual odds in favor of event A occurring are the ratio P1A2>P1A2, which is \nthe reciprocal of the actual odds against that event. If the odds against an event \nare a:b, then the odds in favor are b:a.\nNote that in the two preceding definitions, the actual odds against and the actual odds \nin favor describe the actual likelihood of some event. (Gambling situations typically \nuse payoff odds, which describe the amount of profit relative to the amount of a bet. \nFor example, if you bet on the number 7 in roulette, the actual odds against winning \nare 37:1, but the payoff odds are 35:1. Racetracks and casinos are in business to make \na profit, so the payoff odds will usually differ from the actual odds.)\nTABLE 4-5 Retrospective Study of Newborn Discharge and Rehospitalization\nRehospitalized \nwithin a week\nNot rehospitalized \nwithin a week\n \nTotal\nEarly discharge  \n(*30 hours)\n457\n3199\n3656\nLate discharge  \n(30+ hours)\n260\n2860\n3120\nEXAMPLE 4  Rehospitalization and Discharge\nConsider the data in Table 4-5 (based on results from \u201cThe Safety of Newborn Early \nDischarge,\u201d by Liu, Clemens, Shay, Davis, and Novack, Journal of the American \nMedical Association, Vol. 278, No. 4).\n \na. For those babies discharged early, \ufb01nd the probability of being rehospitalized \nwithin a week.\n \nb. For those babies discharged early, \ufb01nd the odds in favor of being rehospital-\nized early.\ncontinued\n\n158 \nCHAPTER 4 Probability\nOdds Ratio\nFor the data in Table 4-5, how does the likelihood of rehospitalization differ between the \nearly discharge group and the late discharge group? One way to address that question is \nto use the odds ratio.\nSOLUTION\na. There were 3656 babies discharged early, and 457 of them were rehospital-\nized within a week, so\nP1rehospitalized2 = 457\n3656 = 1\n8\n \nb. Because P(rehospitalized) = 1>8, it follows that P1rehospitalized2 =\n1 - 1>8= 7>8. We can now \ufb01nd the odds in favor of rehospitalization as follows:\nOdds in favor of rehospitalization for the early discharge group\n= P1rehospitalized2\nP1rehospit",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 175
  },
  {
    "child_id": "43ab34c9-36d9-444a-9831-f9fa87561ded",
    "parent_id": "dd14a874-c1a6-4110-85e5-d51b1a813893",
    "text": " discharge group and the late discharge group? One way to address that question is \nto use the odds ratio.\nSOLUTION\na. There were 3656 babies discharged early, and 457 of them were rehospital-\nized within a week, so\nP1rehospitalized2 = 457\n3656 = 1\n8\n \nb. Because P(rehospitalized) = 1>8, it follows that P1rehospitalized2 =\n1 - 1>8= 7>8. We can now \ufb01nd the odds in favor of rehospitalization as follows:\nOdds in favor of rehospitalization for the early discharge group\n= P1rehospitalized2\nP1rehospitalized2 = 1>8\n7>8 = 1\n7\nThis result is often expressed as 1:7.\nWith odds of 1:7 in favor of rehospitalization for babies discharged early, it \n follows that the odds against rehospitalization for early discharge are 7:1.\nDEFINITION\nIn a retrospective or prospective study, the odds ratio (OR or relative odds) is a \nmeasure of risk found by evaluating the ratio of the odds in favor of the treatment \ngroup (or case group exposed to the risk factor) to the odds in favor of the control \ngroup, evaluated as follows:\nOdds ratio =\nodds in favor of treatment 1or exposed2 group\nodds in favor of control group\nIf the data are in the format of the generalized Table 4-4 on page 153, then the \nodds ratio can be computed as follows:\nOdds ratio = ad\nbc\nEXAMPLE 5  Computing Odds Ratio\nUsing the data in Table 4-5, find the odds ratio for rehospitalization.\nSOLUTION\nFor this example, we consider the case group to be the babies discharged early, and \nwe consider the control group to be the babies discharged late. The preceding exam-\nple showed that for the early discharge group, the odds in favor of rehospitalization \nare 1:7. Using similar calculations for the late discharge group, we get odds in favor \nof rehospitalization of 1>11 or 1:11. We can now find the odds ratio.\n Odds ratio = odds in favor of rehospitalization in early discharge group\nodds in favor of rehospitalization in late discharge group = 1>7\n1>11\n =  11\n7  or 1.571\n\n4-4 Risks and Odds \n159\nWhy Not Use Relative Risk for Retrospective Studies?\nRelative risk makes sense only if the involved probabilities are good estimates of \nthe actual incidence rates, as in a prospective study. Using relative risk for a retro-\nspective study could incorrectly involve a situation in which researchers can choose \ndisease cases that are very different from actual incidence rates, with the result that \nthe relative risk can be very wrong. That is the reason that relative risk is defined for \nprospective studies only. The odds ratio is defined for prospective and retrospective \nstudies.\n Relative Risk: Prospective study\n Odds Ratio:\n Prospective study or retrospective study\nTable 4\u20136 includes the results from a prospective study of 1000 randomly selected sub-\njects, which is conducted to investigate the risk of lung cancer from smoking.  Table 4-6 \ncontains entries that are realistic based on current incidence rates. However, Table 4-7 \nbelow is based on a retrospective study in which the researcher went back in time to \nfind 985 ",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 175
  },
  {
    "child_id": "a8bc11c4-5692-4779-bf42-86325cb46515",
    "parent_id": "dd14a874-c1a6-4110-85e5-d51b1a813893",
    "text": "ned for prospective and retrospective \nstudies.\n Relative Risk: Prospective study\n Odds Ratio:\n Prospective study or retrospective study\nTable 4\u20136 includes the results from a prospective study of 1000 randomly selected sub-\njects, which is conducted to investigate the risk of lung cancer from smoking.  Table 4-6 \ncontains entries that are realistic based on current incidence rates. However, Table 4-7 \nbelow is based on a retrospective study in which the researcher went back in time to \nfind 985 subjects with lung cancer and 985 subjects without lung cancer, so Table 4-7 \ndoes not reflect actual incidence rates. See the following.\nFrom Table 4-6: P1lung cancer \u001esmoker2 = 13>180 = 0.0722\nFrom Table 4-7: P1lung cancer \u001esmoker2 = 854>1021 = 0.836\nThe above probabilities are very different, so both of them cannot be good estimates of \nthe likelihood of getting lung cancer from smoking. The above probability of 0.0722 \nis a good estimate because it is based on a prospective study with realistic incidence \nrates, but the probability of 0.836 is a poor estimate because it is based on the retro-\nspective study designed to include an equal number of subjects with lung cancer and \nsubjects without lung cancer.\nNow compare the relative risk values and the odds ratio values from Tables 4-6 \nand 4-7. See that the odds ratio values are approximately the same, but the relative risk \nvalues are dramatically different. The relative risk value of 29.6 from the prospective \nstudy is a good measure, but the relative risk of 6.1 from the retrospective study is a \npoor measure.\nIf we take advantage of the fact that Table 4-5 does correspond to the generalized \nTable 4-4 on page 153, then the odds ratio can also be calculated as follows:\nOdds ratio = ad\nbc = 14572128602\n13199212602 = 1.571\nINTERPRETATION\nThis result indicates that the odds in favor of rehospitalization are 1.571 times \nhigher for babies discharged early when compared to those discharged late. This \nsuggests that newborns discharged early are at substantially increased risk of rehos-\npitalization.\nTABLE 4-6 Prospective Study\nRR = 29.6; OR = 31.8\nLung Cancer\nNo Lung Cancer\nSmoker\n13\n167\nNonsmoker\n 2\n818\nTABLE 4-7 Retrospective Study\nRR = 6.1; OR = 31.9\nLung Cancer\nNo Lung Cancer\nSmoker\n854\n167\nNonsmoker\n131\n818\nTotal\n985\n985\n\n160 \nCHAPTER 4 Probability\nSUMMARY OF KEY POINTS\nDisease\nNo Disease\nTreatment\na\nb\nPlacebo\nc\nd\nStatistical Literacy and Critical Thinking \n1.\u00a0Notation The relative risk of a characteristic is the ratio pt>pc. What do pt and pc represent?\n2.\u00a0 Relative Risk Identify an important disadvantage of relative risk used with a relatively \nsmall difference between the rates in the treatment and control groups.\n3.\u00a0Number Needed to Treat A measure of the effectiveness of an influenza vaccine is the \nnumber needed to treat, which is 37 (under certain conditions). Interpret that number. Does the \nresult apply to every particular group of 37 subjects?\n4.\u00a0Retrospective , Prospective The odds ratio is",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 175
  },
  {
    "child_id": "02f14a33-886a-475e-a3c7-5e1509c056d1",
    "parent_id": "dd14a874-c1a6-4110-85e5-d51b1a813893",
    "text": "he ratio pt>pc. What do pt and pc represent?\n2.\u00a0 Relative Risk Identify an important disadvantage of relative risk used with a relatively \nsmall difference between the rates in the treatment and control groups.\n3.\u00a0Number Needed to Treat A measure of the effectiveness of an influenza vaccine is the \nnumber needed to treat, which is 37 (under certain conditions). Interpret that number. Does the \nresult apply to every particular group of 37 subjects?\n4.\u00a0Retrospective , Prospective The odds ratio is a measure used in retrospective or pro-\nspective studies. Describe retrospective and prospective studies.\nHeadaches and Viagra In Exercises 5\u221212, use the data in the accompanying table \n(based on data from Pfizer, Inc.). That table describes results from a clinical trial of the \ndrug Viagra. Some subjects were treated with Viagra while others were given a placebo; \nthen headache events were recorded.\nHeadache\nNo Headache\nViagra Treatment\n117\n617\nPlacebo\n 29\n696\n5.\u00a0Type of Study Is the study retrospective or prospective?\n4-4 Basic Skills and Concepts\n \n\u25a0Absolute risk reduction = `\na\na + b -\nc\nc + d `\n \n\u25a0Number Needed to Treat (NNT) =\n1\nAbsolute Risk Reduction\n \n\u25a0Actual odds against event A = P1A2\nP1A2\n \n\u25a0Actual odds in favor of event A = P1A2\nP1A2\nRelative risk 1RR2 = pt\npc\n=\na\na + b\nc\nc + d\nOdds ratio 1OR2 = ad\nbc\n(for prospective only)\n\n4-4 Risks and Odds \n161\n6.\u00a0Probability For those in the Viagra treatment group, find the probability that the subject \nexperienced a headache.\n7.\u00a0Comparing Probabilities Compare P(headache \u001fViagra treatment) and  \nP(headache \u001f placebo).\n8.\u00a0Absolute Risk Reduction Find the value of the absolute risk reduction for headaches in \nthe treatment and placebo groups.\n9.\u00a0Number Needed to Treat Find the number of Viagra users that would need to stop using \nViagra in order to prevent a single headache.\n10.\u00a0Odds For those in the Viagra treatment group, find the odds in favor of a headache, then \nfind the odds against a headache.\n11.\u00a0Relative Risk Find the relative risk of a headache for those in the treatment group com-\npared to those in the placebo group. Interpret the result.\n12.\u00a0Odds Ratio Find the odds ratio for headaches in the treatment group compared to the \nplacebo group, then interpret the result. Should Viagra users be concerned about headaches as \nan adverse reaction?\nClinical Trial of Atorvastatin (Lipitor). In Exercises 13\u221216, use the data in the accom-\npanying table that summarizes results from a clinical trial of atorvastatin (based on data \nfrom Parke-Davis).\nInfection\nNo Infection\nAtorvastatin (10 mg)\n89\n774\nPlacebo\n27\n243\n13.\u00a0Absolute Risk Reduction\na. What is the probability of infection in the atorvastatin treatment group?\nb. What is the probability of infection in the placebo group?\nc. Find the value of the absolute risk reduction for infection in the placebo group and the atorv-\nastatin treatment group. Write a brief statement interpreting the result.\n14.\u00a0Number Needed to Treat Calculate the number needed to tre",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 175
  },
  {
    "child_id": "076f3944-2b49-41cd-a154-7ddca08231b0",
    "parent_id": "dd14a874-c1a6-4110-85e5-d51b1a813893",
    "text": "ased on data \nfrom Parke-Davis).\nInfection\nNo Infection\nAtorvastatin (10 mg)\n89\n774\nPlacebo\n27\n243\n13.\u00a0Absolute Risk Reduction\na. What is the probability of infection in the atorvastatin treatment group?\nb. What is the probability of infection in the placebo group?\nc. Find the value of the absolute risk reduction for infection in the placebo group and the atorv-\nastatin treatment group. Write a brief statement interpreting the result.\n14.\u00a0Number Needed to Treat Calculate the number needed to treat and interpret the result.\n15.\u00a0Odds For those who were treated with atorvastatin, find the odds in favor of an infection. \nAlso find the odds in favor of an infection for those given a placebo. Is there much of a differ-\nence between these two results?\n16.\u00a0Odds Ratio and Relative Risk Find the odds ratio and relative risk for an infection in \nthe group treated with atorvastatin compared to the placebo group. Based on this result, does \natorvastatin appear to increase the risk of an infection? Why or why not?\n17.\u00a0Odds Ratio and Relative Risk In a clinical trial of 2103 subjects treated with Nasonex \n(mometasone), 26 reported headaches. In a control group of 1671 subjects given a placebo, 22 \nreported headaches. Find the relative risk and odds ratio for the headache data. What do the \nresults suggest about the risk of a headache from the Nasonex treatment?\n18.\u00a0Design of Experiments You would like to conduct a study to determine the effective-\nness of seat belts in saving lives in car crashes.\na. What would be wrong with randomly selecting 2000 drivers, then randomly assigning half \nof them to a group that uses seat belts and another group that does not wear seat belts?\nb. If 2000 drivers are randomly selected and separated into two groups according to whether \nthey use seat belts, what is a practical obstacle in conducting a prospective study of the effec-\ntiveness of seat belts in car crashes?",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 175
  },
  {
    "child_id": "e8b6ece6-f2ec-4e4a-99ed-9022f2976269",
    "parent_id": "e11d1b24-dc63-4019-baed-eef07fd6c1de",
    "text": "162 \nCHAPTER 4 Probability\nIn the biological and health sciences, rates are often used to describe the likelihood of \nan event. Rates are used by researchers and health professionals to monitor the health \nstatus of a community or population. Although any specific time interval could be \nused, we assume a time interval of one year throughout this section.\n4-5 \nRates of Mortality, Fertility, and Morbidity\nDEFINITION\nA rate describes the frequency of occurrence of some event. It is the relative fre-\nquency of an event, multiplied by some number, typically a value such as 1000 or \n100,000. A rate can be expressed as\naa\nb bk\nwhere\na = frequency count of the number of people for whom the event occurred\nb = total number of people exposed to the risk of the event occurring\nk = multiplier number, such as 1000 or 100,000\nThe above general definition is commonly applied to measures of mortality, fertility, \nand morbidity. For the following rates, mortality refers to deaths, fertility refers to \nbirths, and morbidity refers to diseases. Here are additional terms and their meanings:\n \n\u25a0Infants: Babies who were born alive\n \n\u25a0Neonates: Infants under the age of 28 days\n \n\u25a0Fetal Death: Occurs when a fetus is delivered without life after 20 weeks of gestation\n \n\u25a0Neonatal Death: Occurs when an infant dies under 28 days of age\nMortality Rates\nCrude 1or unadjusted2 mortality rate = a\ndeaths\npopulation size bk\nInfant mortality rate = adeaths of infants under 1 year of age\nnumber of live births\nbk\nNeonatal mortality rate = adeaths of infants under 28 days of age\nnumber of live births\nbk\nFetal mortality rate =\na\nfetuses delivered without life after 20 weeks of gestation \nnumber of live births +  \n fetuses delivered without life after 20 weeks of gestation bk\nPerinatal mortality rate = afetal deaths + neonatal deaths\nlive births + fetal deaths\nbk\nFertility Rates\nCrude birthrate = a\nlive births\npopulation size bk\nGeneral fertility rate = a\nlive births\nnumber of women aged 15 - 44 bk\n\n4-5 Rates of Mortality, Fertility, and Morbidity \n163\nMorbidity (Disease) Rates\nIncidence rate = areported new cases of disease\npopulation size\nbk\nPrevalence rate = anumber of people with disease at a given time\npopulation size at the given point in time\nbk\nEXAMPLE 1  Crude Mortality Rate\nFor a recent year in the United States, there were 2,515,458 deaths in a population \nof 312,799,495 people. Use those values with a multiplier of 1000 to find the crude \nmortality rate.\nSOLUTION\nWith 2,515,458 people who died, with 312,799,495 people in the population, and \nletting k = 1000, we compute the crude mortality rate as follows:\n Crude mortality rate = a\ndeaths\npopulation size bk = a 2,515,458\n312,799,495b1000\n = 8.0 1rounded2\nINTERPRETATION\nFor this particular year, the death rate is 8.0 people for each 1000 people in the \n population. Using the relative frequency definition of probability given in Section 4-1, \nwe might also say that for a randomly selected person, the probability of death in \nt",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 180
  },
  {
    "child_id": "665619c3-7822-4ff7-b8d8-3246a1f86d2b",
    "parent_id": "e11d1b24-dc63-4019-baed-eef07fd6c1de",
    "text": " who died, with 312,799,495 people in the population, and \nletting k = 1000, we compute the crude mortality rate as follows:\n Crude mortality rate = a\ndeaths\npopulation size bk = a 2,515,458\n312,799,495b1000\n = 8.0 1rounded2\nINTERPRETATION\nFor this particular year, the death rate is 8.0 people for each 1000 people in the \n population. Using the relative frequency definition of probability given in Section 4-1, \nwe might also say that for a randomly selected person, the probability of death in \nthis year is 2,515,458>312,799,495 = 0.00804. One important advantage of the \nmortality rate of 8.0 people (per 1000 people in the population) is that it results in a \nvalue that uses fewer decimal places and is generally easier to use and understand.\nEXAMPLE 2  Infant Mortality Rate\nThe infant mortality rate is a very important measure of the health of a region. \n (According to the United Nations, the worldwide infant mortality rate is 49.4 per \n1000 live births.) For a recent year, there were 3,953,590 live births in the United \nStates, and there were 23,910 deaths of infants under 1 year of age. Using a mul-\ntiplying factor of k = 1000, find the infant mortality rate of the United States and \ncompare it to the rate of 2.1 for Japan.\nSOLUTION\nThe infant mortality rate is computed as shown below.\n Infant mortality rate = adeaths of infants under 1 year of age\nnumber of live births\nbk\n = a 23,910\n3,953,590b1000\n =  6.0 1rounded2\ncontinued\n\n164 \nCHAPTER 4 Probability\nA crude rate, as defined, is a single value based on crude totals. When compar-\ning two different regions, such as Florida and Colorado, a comparison of rates can be \nmisleading because of differences in factors such as age that might affect the rates. In \na recent year, the crude mortality rates (per 1000 population) were 9.1 in Florida and \n6.4 in Colorado. This is not too surprising, considering that in Florida, roughly 18% of \nthe population is over the age of 65, compared to only 11% for Colorado. The higher \nmortality rate for Florida does not mean that Florida is less healthy; in this case, it \nappears that Florida has a higher death rate largely because it has a higher proportion \nof older residents. Instead of using crude rates, we might use either specific rates or \nadjusted rates.\nSpecific rates are rates specific for some particular group, such as people aged \n18\u201324, or rates specific for some particular cause of death, such as deaths due to myo-\ncardial infarction.\nAdjusted rates involve calculations that can be quite complicated, but they basi-\ncally make adjustments for important factors, such as age, gender, or race.\nBecause age is the characteristic that typically affects mortality the most, it is the \nmost common factor used as the basis for adjustment. Calculations of adjusted rates \ninvolve the creation of a theoretical standardized population that is used for the re-\ngions being compared. A population of 1,000,000 people with the same composition \nas the United States is oft",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 180
  },
  {
    "child_id": "a5d9996a-0351-465c-9368-011557075e42",
    "parent_id": "e11d1b24-dc63-4019-baed-eef07fd6c1de",
    "text": "ulations that can be quite complicated, but they basi-\ncally make adjustments for important factors, such as age, gender, or race.\nBecause age is the characteristic that typically affects mortality the most, it is the \nmost common factor used as the basis for adjustment. Calculations of adjusted rates \ninvolve the creation of a theoretical standardized population that is used for the re-\ngions being compared. A population of 1,000,000 people with the same composition \nas the United States is often used as the standardized population. Adjusted rates are \nvaluable for comparing different regions, but they do not necessarily reflect the true \ncrude death rates. Adjusted rates should not be used as death rates and they should not \nbe compared to crude rates.\nWhen assessing the accuracy of rates, we should consider the source. Mortality \nrates found in a source such as the Statistical Abstract of the United States (compiled \nby the U.S. Bureau of the Census) are likely to be quite accurate, because each state \nnow has a mandatory death reporting system, although official government reports \nseem to take years to produce. However, morbidity rates are likely to be less accurate, \nbecause some diseases are known to be underreported or not reported at all. Some \nmorbidity rates might be the result of very questionable surveys. However, some sur-\nveys, such as the annual National Health Survey, involve large samples of people who \nare very carefully chosen, so that results are likely to be very accurate.\nStatistical Literacy and Critical Thinking \n1.\u00a0Birth Rate The birth rate in China is 12.3 per 1000. What exactly does that mean?\n2.\u00a0Rates Exercise 1 describes the birth rate in China as 12.3 per 1000. Another way to describe \nthe birth rate is to give the rate as a proportion or probability of 0.0123. What advantage does \nthe rate of \u201c12.3 per 1000\u201d have over the rate expressed as 0.0123?\n3.\u00a0Expected Births Given that China has a birth rate of 12.3 per 1000 and a population of \n1,360,762,587, about how many births are expected in a year?\n4.\u00a0Incidence and Prevalence What is the difference between a disease incidence rate and a \ndisease prevalence rate?\n4-5 Basic Skills and Concepts\nINTERPRETATION\nThe infant mortality rate of 6.0 deaths per 1000 infants under 1 year of age is sub-\nstantially greater than the infant mortality rate of 2.1 in Japan.\n\n4-5 Rates of Mortality, Fertility, and Morbidity \n165\nFinding Rates. In Exercises 5\u221212, use the data in the accompanying table (based on data \nfor a recent year from various sources, including the U.S. Census Bureau and the National \nInstitutes of Health) to find the indicated rates. Round results to one decimal place, and use \na multiplying factor of k = 1000 unless indicated otherwise.\nVital Statistics for the United States in One Year\nPopulation: 312,799,495\nDeaths: 2,515,458\nWomen aged 15\u201344: 61,488,227\nMotor vehicle deaths: 33,783\nLive births: 3,953,590\nFetuses delivered without life after 20 weeks of \ngestati",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 180
  },
  {
    "child_id": "26304742-fec4-4c44-89f8-7bf4b51a7ecb",
    "parent_id": "e11d1b24-dc63-4019-baed-eef07fd6c1de",
    "text": "able (based on data \nfor a recent year from various sources, including the U.S. Census Bureau and the National \nInstitutes of Health) to find the indicated rates. Round results to one decimal place, and use \na multiplying factor of k = 1000 unless indicated otherwise.\nVital Statistics for the United States in One Year\nPopulation: 312,799,495\nDeaths: 2,515,458\nWomen aged 15\u201344: 61,488,227\nMotor vehicle deaths: 33,783\nLive births: 3,953,590\nFetuses delivered without life after 20 weeks of \ngestation: 26,148\nDeaths of infants under 1 year of age: 23,910\nDeaths of infants under 28 days of age: 15,973\nHIV-infected persons: 1,155,792\nDeaths from HIV infections: 7683\n5.\u00a0Find the neonatal mortality rate.\n6.\u00a0Find the fetal mortality rate.\n7.\u00a0Find the perinatal mortality rate.\n8.\u00a0Find the crude birth rate.\n9.\u00a0Find the general fertility rate.\n10.\u00a0Using a multiplier of k = 100,000, find the motor vehicle death incidence rate.\n11.\u00a0Find the HIV infection prevalence rate.\n12.\u00a0Find the HIV infection mortality rate for HIV-infected persons.\n13.\u00a0Finding Probability An example in this section involved the crude mortality rate, which \nwas found to be 8.0 persons per 1000 population. Find the probability of randomly selecting \nsomeone and getting a person who died within the year. What advantage does the crude mortal-\nity rate have over the probability value?\n14.\u00a0Finding Probability The crude death rate for China was recently 7.4, and that rate was \ncomputed using a multiplier of k = 1000.\na. Find the probability that a randomly selected Chinese person died within the year.\nb. If two Chinese people are randomly selected, find the probability that they both died within \nthe year, and express the result using three significant digits.\nc. If two Chinese people are randomly selected, find the probability that neither of them died \nwithin the year, and express the result using three significant digits.\n15.\u00a0Finding Probability The crude death rate for Spain was recently 8.3, and that rate was \ncomputed using a multiplier of k = 1000.\na. Find the probability that a randomly selected Spaniard died within the year.\nb. If two Spaniards are randomly selected, find the probability that they both died within the \nyear, and express the result using three significant digits.\nc. If two Spaniards are randomly selected, find the probability that at least one of them sur-\nvived the year, and express the result using six decimal places. What would be wrong with \nexpressing the answer using three significant digits?\ncontinued",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 180
  },
  {
    "child_id": "934da47f-8c91-41ad-bb65-b610c783897e",
    "parent_id": "37d5482d-afe8-4709-8fba-7a4b44ac4ef6",
    "text": "166 \nCHAPTER 4 Probability\n16.\u00a0Finding Probability In a recent year in the United States, there were 787,650 deaths due \nto cardiovascular disease, and the population was 312,799,495.\na. Find the crude mortality rate for cardiovascular disease. (This result is sometimes called the \ncause-specific death rate.)\nb. Find the probability that a randomly selected person died of cardiovascular disease and \n express the result using three significant digits.\nc. Find the probability that when three people are randomly selected, none of them died \n because of cardiovascular disease.\n17.\u00a0 Cause-of-Death Ratio In a recent year in the United States, there were 2,515,458 \ndeaths, and 787,650 of them were due to cardiovascular disease. The cause-of-death ratio is \nexpressed as follows:\nadeaths due to specific disease\ntotal number of deaths\nbk where k = 100\na. Find the cause-of-death ratio for cardiovascular disease.\nb. If three of the deaths are randomly selected, find the probability that none of them are due to \ncardiovascular disease.\n18.\u00a0Crude Mortality Rates The table below lists numbers of deaths and population sizes for \ndifferent age groups for Florida and the United States for a recent year.\na. Find the crude mortality rate for Florida and the crude mortality rate for the United States. Al-\nthough we should not compare crude mortality rates, what does the comparison suggest in this case?\nb. Using only the age group of 65 and older, find the mortality rates for Florida and the United \nStates. Compare the results.\nc. What percentage of the Florida population is made up of people aged 65 and older? What is \nthe percentage for the United States? What do the results suggest about the crude mortality for \nFlorida compared to the United States?\nAge\n0\u201324\n25\u201364\n65 and older\nFlorida deaths\n      3625\n     39,820\n   129,395\nFlorida population\n  5,716,861\n   9,842,031\n 3,375,303\nU.S. deaths\n     63,208\n    619,982\n 1,832,268\nU.S. population\n103,542,603\n163,960,163\n45,296,729\n19.\u00a0Number of Deaths The number of deaths in the United States has been steadily increas-\ning each year. Does this mean that the health of the nation is declining? Why or why not?\n20.\u00a0Comparing Rates In a recent year, the crude mortality rate of the United States was 8.0 \n(per 1000 population), and the corresponding crude mortality rate for China was 7.4. What is a \nmajor problem with comparing the crude mortality rates of the United States and China?\n21. Adjusted Mortality Rate Refer to the data listed in Exercise 18. Change the Florida popula-\ntion sizes for the three age categories so that they fit the same age distribution as the U.S. popu-\nlation. Next, adjust the corresponding numbers of deaths proportionately. (Use the same Florida \nmortality rates for the individual age categories, but apply those rates to the adjusted population \nsizes.) Finally, compute the Florida mortality rate using the adjusted values. The result is a mortal-\nity rate adjusted for the variable of age. (Better res",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 184
  },
  {
    "child_id": "0072044f-dd56-43ec-9e1f-e4a29680f387",
    "parent_id": "37d5482d-afe8-4709-8fba-7a4b44ac4ef6",
    "text": " in Exercise 18. Change the Florida popula-\ntion sizes for the three age categories so that they fit the same age distribution as the U.S. popu-\nlation. Next, adjust the corresponding numbers of deaths proportionately. (Use the same Florida \nmortality rates for the individual age categories, but apply those rates to the adjusted population \nsizes.) Finally, compute the Florida mortality rate using the adjusted values. The result is a mortal-\nity rate adjusted for the variable of age. (Better results could be obtained by using more age catego-\nries.) How does this adjusted mortality rate for Florida compare to the mortality rate for the United \nStates? (Note: There are other methods for computing adjusted rates than the one used here.)\n4-5 Beyond the Basics\n\n4-6 Counting \n167\nMULTIPLICATION COUNTING RULE: For a sequence of events in which the first \nevent can occur n1 ways, the second event can occur n2 ways, the third event can \noccur n3 ways, and so on, the total number of possibilities is n1 # n2 # n3 . . ..\nEXAMPLE 1  Multiplication Counting Rule: DNA\nIn a linear triplet of three DNA nucleotides, each of the nucleotides can be any one \nof these four bases (with repetition allowed): A (adenine); C (cytosine); G (guanine); \nT (thymine). Two different examples of triplets are CTA and TTG. What is the total \nnumber of different possible triplets? Given that the four nucleotides are equally \nlikely, what is the probability of getting the triplet of AAA?\nSOLUTION\nThere are 4 different possibilities for each of the three nucleotides, so the total num-\nber of different possible triplets is n1 # n2 # n3 = 4 # 4 # 4 = 64.\nIf the four nucleotides are equally likely, the probability of getting the triplet of \nAAA is 1>64 or 0.0156.\n2. Factorial Rule\nThe factorial rule is used to find the total number of ways that n different items can \nbe rearranged with different arrangements of the same items counted separately. The \nfactorial rule uses the following notation.\nNOTATION\nThe factorial symbol (!) denotes the product of decreasing positive whole num-\nbers. For example, 4! = 4 # 3 # 2 # 1 = 24. By special definition, 0! = 1.\nFACTORIAL RULE The number of different arrangements (order matters) of n \ndifferent items when all n of them are selected is n!.\nThe factorial rule is based on the principle that the first item may be selected n differ-\nent ways, the second item may be selected n - 1 ways, and so on.\nRouting problems often involve applications of the factorial rule, as in the follow-\ning example.\nKey Concept Probability problems typically require that we know the total number of \nsimple events, but finding that number often requires one of the five rules presented in \nthis section. In Section 4-2, with the addition rule, multiplication rule, and conditional \nprobability, we encouraged intuitive rules based on understanding and we discour-\naged blind use of formulas, but this section requires much greater use of formulas as \nwe consider five different met",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 184
  },
  {
    "child_id": "db3b2884-67a6-42c2-9d1b-2dc3001c79c5",
    "parent_id": "37d5482d-afe8-4709-8fba-7a4b44ac4ef6",
    "text": "e, as in the follow-\ning example.\nKey Concept Probability problems typically require that we know the total number of \nsimple events, but finding that number often requires one of the five rules presented in \nthis section. In Section 4-2, with the addition rule, multiplication rule, and conditional \nprobability, we encouraged intuitive rules based on understanding and we discour-\naged blind use of formulas, but this section requires much greater use of formulas as \nwe consider five different methods for counting the number of possible outcomes in a \nvariety of situations. Not all counting problems can be solved with these five methods, \nbut they do provide a strong foundation for the most common real applications.\n1. Multiplication Counting Rule\nThe multiplication counting rule is used to find the total number of possibilities from \nsome sequence of events.\n4-6 \nCounting\n\n168 \nCHAPTER 4 Probability\nPermutations and Combinations: Does Order Count?\nWhen using different counting methods, it is essential to know whether different ar-\nrangements of the same items are counted only once or are counted separately. The \nterms permutations and combinations are standard in this context, and they are de-\nfined as follows:\nEXAMPLE 2  Factorial Rule: Travel Itinerary\nQuest Diagnostics collects blood specimens from different laboratories. A driver is \ndispatched to make collections at 5 different locations. How many different routes \nare possible?\nSOLUTION\nFor those 5 different locations, the number of different routes is 5! =\n5 # 4 # 3 # 2 # 1 = 120.\nNote that this solution could have been done by applying the multiplica-\ntion counting rule. The first stop can be any one of the 5 locations, the second \nstop can be any one of the 4 remaining locations, and so on. The result is again \n5 # 4 # 3 # 2 # 1 = 120. Use of the factorial rule has the advantage of including the \nfactorial symbol, which is sure to impress.\nDEFINITIONS\nPermutations of items are arrangements in which different sequences of the same \nitems are counted separately. (The letter arrangements of abc, acb, bac, bca, cab, \nand cba are all counted separately as six different permutations.)\nCombinations of items are arrangements in which different sequences of the \nsame items are counted as being the same. (The letter arrangements of abc, acb, \nbac, bca, cab, and cba are all considered to be the same single combination.)\nMnemonics for Permutations and Combinations\n \n\u25a0Remember \u201cPermutations Position,\u201d where the alliteration reminds us that with \npermutations, the positions of the items makes a difference.\n \n\u25a0Remember \u201cCombinations Committee,\u201d which reminds us that with members of \na committee, rearrangements of the same members result in the same committee, \nso order does not count.\n3. Permutations Rule (When All of the Items Are Different)\nThe permutations rule is used when there are n different items available for selection, \nwe must select r of them without replacement, and the sequence of the item",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 184
  },
  {
    "child_id": "e9ea4a50-fc0c-43c8-973b-278b500a753e",
    "parent_id": "37d5482d-afe8-4709-8fba-7a4b44ac4ef6",
    "text": " alliteration reminds us that with \npermutations, the positions of the items makes a difference.\n \n\u25a0Remember \u201cCombinations Committee,\u201d which reminds us that with members of \na committee, rearrangements of the same members result in the same committee, \nso order does not count.\n3. Permutations Rule (When All of the Items Are Different)\nThe permutations rule is used when there are n different items available for selection, \nwe must select r of them without replacement, and the sequence of the items matters. \nThe result is the total number of arrangements (or permutations) that are possible. (Re-\nmember: Rearrangements of the same items are counted as different permutations.)\nPERMUTATIONS RULE: When n different items are available and r of them are \nselected without replacement, the number of different permutations (order counts) \nis given by\nnPr =\nn!\n1n - r2!\n\n4-6 Counting \n169\n4. Permutations Rule (When Some Items Are Identical to Others)\nWhen n items are all selected without replacement, but some items are identical, the \nnumber of possible permutations (order matters) is found by using the following rule.\nEXAMPLE 3   Permutations Rule (with Different Items):  \nClinical Trial of New Drug\nWhen testing a new drug, Phase I requires only 5 volunteers, and the objective is \nto assess the drug\u2019s safety. To be very cautious, we plan to treat the 5 subjects in \nsequence, so that any particularly adverse effect can allow us to stop the treatments \nbefore any other subjects are treated. If 8 volunteers are available, how many differ-\nent sequences of 5 subjects are possible?\nSOLUTION\nWe need to select r = 5 subjects from n = 8 volunteers that are available. The num-\nber of different sequences of arrangements is found as shown:\nnPr =\nn!\n1n - r2! =\n8!\n18 - 52! = 6720\nThere are 6720 different possible arrangements of 5 subjects selected from the 8 \nthat are available.\nPERMUTATIONS RULE (WHEN SOME ITEMS ARE IDENTICAL TO OTHERS)\nThe number of different permutations (order counts) when n items are available \nand all n of them are selected without replacement, but some of the items are iden-\ntical to others, is found as follows:\nn!\nn1!n2! . . . nk! where n1 are alike, n2 are alike,\u2026, and nk are alike.\nEXAMPLE 4   Permutations Rule (with Some Identical Items):  \nDesigning Surveys\nWhen designing surveys, pollsters sometimes repeat a question to see if a subject \nis thoughtlessly providing answers just to finish quickly. For one particular survey \nwith 10 questions, 2 of the questions are identical to each other, and 3 other ques-\ntions are also identical to each other. For this survey, how many different arrange-\nments are possible? Is it practical to survey enough subjects so that every different \npossible arrangement is used?\nSOLUTION\nWe have 10 questions with 2 that are identical to each other and 3 others that are \nalso identical to each other, and we want the number of permutations. Using the rule \nfor permutations with some items identical to others, we get\nn",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 184
  },
  {
    "child_id": "a8cafd9a-aa2c-4e27-a034-74603fbbc50e",
    "parent_id": "37d5482d-afe8-4709-8fba-7a4b44ac4ef6",
    "text": "questions are identical to each other, and 3 other ques-\ntions are also identical to each other. For this survey, how many different arrange-\nments are possible? Is it practical to survey enough subjects so that every different \npossible arrangement is used?\nSOLUTION\nWe have 10 questions with 2 that are identical to each other and 3 others that are \nalso identical to each other, and we want the number of permutations. Using the rule \nfor permutations with some items identical to others, we get\nn!\nn1!n2! . . . nk! = 10!\n2!3! = 3,628,800\n2 # 6\n= 302,400\ncontinued",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 184
  },
  {
    "child_id": "dcfbda1c-92d5-4ba0-b4ce-40ba46333637",
    "parent_id": "dc76eca9-9841-422b-89df-2b9a0c820cc5",
    "text": "170 \nCHAPTER 4 Probability\n5. Combinations Rule\nThe combinations rule is used when there are n different items available for selection, \nonly r of them are selected without replacement, and order does not matter. The result \nis the total number of combinations that are possible. (Remember: Rearrangements of \nthe same items are considered to be the same combination.)\nINTERPRETATION\nThere are 302,400 different possible arrangements of the 10 questions. It is not \npractical to accommodate every possible permutation. For typical surveys, the num-\nber of respondents is somewhere around 1000.\nCOMBINATIONS RULE:\nWhen n different items are available, but only r of them are selected without replace-\nment, the number of different combinations (order does not matter) is found as follows:\nnCr =\nn!\n1n - r2!r!\nEXAMPLE 5  Combinations Rule: Phase I of a Clinical Trial\nWhen testing a new drug on humans, a clinical test is normally done in three \nphases. Phase I is conducted with a relatively small number of healthy volunteers. \nAssume that we want to treat 20 healthy humans with a new drug, and we have  \n30 suitable volunteers available. If 20 subjects are selected from the 30 that are \navailable, and the 20 selected subjects are all treated at the same time, how many \ndifferent treatment groups are possible?\nSOLUTION\nBecause all subjects are treated at the same time, order is irrelevant, so we need to \nfind the number of different possible combinations. With n = 30 subjects available \nand with r = 20 subjects selected, the number of combinations is found as follows.\nnCr =\nn!\n1n - r2!r! =\n30!\n130 - 202!20! =\n30!\n10! # 20! = 30,045,015\nINTERPRETATION\nThere are 30,045,015 different possible combinations.\nPermutations or Combinations? Because choosing between permutations and com-\nbinations can often be tricky, we provide the following example that emphasizes the \ndifference between them.\nEXAMPLE 6   Permutations and Combinations:  \nOfficers and Committees\nThe Portland Medical Center must appoint three corporate officers: chief executive \nofficer (CEO), executive chairperson, and chief operating officer (COO). It must \nalso appoint a planning committee with three different members. There are eight \nqualified candidates, and officers can also serve on the planning committee.\n\n4-6 Counting \n171\n \na. How many di\ufb00erent ways can the o\ufb03cers be appointed?\n \nb. How many di\ufb00erent ways can the committee be appointed?\nSOLUTION\nNote that in part (a), order is important because the officers have very different \nfunctions. However, in part (b), the order of selection is irrelevant because the com-\nmittee members all serve the same function.\n \na. Because order does count, we want the number of permutations of r = 3 \npeople selected from the n = 8 available people. We get\nnPr =\nn!\n1n - r2! =\n8!\n18 - 32! = 336\n \nb. Because order does not count, we want the number of combinations of r = 3 \npeople selected from the n = 8 available people. We get\nnCr =\nn!\n1n - r2!r! =\n8!\n18 - 32!3! = ",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 188
  },
  {
    "child_id": "4e5c7368-2439-48d9-be1f-6119ee6e153d",
    "parent_id": "dc76eca9-9841-422b-89df-2b9a0c820cc5",
    "text": "ers have very different \nfunctions. However, in part (b), the order of selection is irrelevant because the com-\nmittee members all serve the same function.\n \na. Because order does count, we want the number of permutations of r = 3 \npeople selected from the n = 8 available people. We get\nnPr =\nn!\n1n - r2! =\n8!\n18 - 32! = 336\n \nb. Because order does not count, we want the number of combinations of r = 3 \npeople selected from the n = 8 available people. We get\nnCr =\nn!\n1n - r2!r! =\n8!\n18 - 32!3! = 56\nWith order taken into account, there are 336 different ways that the officers can be \nappointed, but without order taken into account, there are 56 different possible com-\nmittees.\nStatistical Literacy and Critical Thinking \n1.\u00a0Notation What does the symbol ! represent? Six different patients can be scheduled for \nX-ray films 6! different ways, so what is the actual number of ways that six people can be \nscheduled for X-ray films?\n2.\u00a0 Permutations, Combinations What is the basic difference between permutations and \ncombinations?\n3.\u00a0Notation Evaluate 9C4. What does the result represent?\n4.\u00a0Notation Evaluate 9P4. What does the result represent?\nIn Exercises 5\u201330, express all probabilities as fractions.\n5.\u00a0Pin Numbers The Kinsale Medical Supply Company issues pin numbers to its employees \nso that they can access an online database. A hacker must randomly guess the correct pin code \nfor the Information Technology supervisor, and that pin code consists of four digits (each 0 \nthrough 9) that must be entered in the correct order. Repetition of digits is allowed. What is the \nprobability of a correct guess on the first try?\n6.\u00a0Social Security Numbers A Social Security number consists of nine digits in a particular \norder, and repetition of digits is allowed. After seeing the last four digits printed on a receipt, if \nyou randomly select the other digits, what is the probability of getting the correct Social Secu-\nrity number of the person who was given the receipt?\n7.\u00a0Assigning Shifts The staff supervisor at the Wellington Medical Center must assign a \nteam of two physicians to work the emergency room on Saturday night. If there are 19 physi-\ncians available and two of them are randomly selected, what is the probability of getting the \ntwo youngest physicians?\n4-6 Basic Skills and Concepts\n\n172 \nCHAPTER 4 Probability\n8.\u00a0Review Board The supervisor at the Wellington Medical Center must select three nurses \nfrom 11 who are available for a review board. How many different ways can that be done?\n9.\u00a0Blood Test Quest Diagnostics has just received 8 different blood samples. If they are tested \nin random order, what is the probability that they are tested in the alphabetical order of the sub-\njects who provided the samples?\n10.\u00a0Radio Station Call Letters If radio station call letters must begin with either K or W and \nmust contain a total of either three or four letters, how many different possibilities are there?\n11.\u00a0Scheduling Routes A new director of the Veterans H",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 188
  },
  {
    "child_id": "5c1d4f97-29d9-4b7c-8b26-d3e3c7b0db6e",
    "parent_id": "dc76eca9-9841-422b-89df-2b9a0c820cc5",
    "text": "ways can that be done?\n9.\u00a0Blood Test Quest Diagnostics has just received 8 different blood samples. If they are tested \nin random order, what is the probability that they are tested in the alphabetical order of the sub-\njects who provided the samples?\n10.\u00a0Radio Station Call Letters If radio station call letters must begin with either K or W and \nmust contain a total of either three or four letters, how many different possibilities are there?\n11.\u00a0Scheduling Routes A new director of the Veterans Health Administration plans to visit \none hospital in each of five different states. If the five states are randomly selected from all 50 \nstates without replacement and the order is also random, what is the probability that she visits \nIdaho, Oregon, Alaska, New Jersey, and Ohio, in that order?\n12.\u00a0Survey Reliability A health survey with 12 questions is designed so that 3 of the ques-\ntions are identical and 4 other questions are identical (except for minor changes in wording). \nHow many different ways can the 12 questions be arranged?\n13.\u00a0Safety with Numbers A safe \u201ccombination\u201d consists of four numbers between 0 and 99, \nand the safe is designed so that numbers can be repeated. If someone tries to gain access to the \nsafe, what is the probability that he or she will get the correct combination on the first attempt? \nAssume that the numbers are randomly selected. Given the number of possibilities, does it \nseem feasible to try opening the safe by making random guesses for the combination?\n14.\u00a0Electricity The control panel for an MRI device uses five color-coded wires. If we trou-\nbleshoot by testing two wires at a time, how many different tests are required for every possible \npairing of two wires?\n15.\u00a0Clinical Trial In a clinical trial of the drug atorvastatin (Lipitor), one group of subjects \nwas given placebos, a second group was given treatments of 10 mg, a third group was given \ntreatments of 20 mg, a fourth group was given treatments of 40 mg, and a fifth group was given \ntreatments of 80 mg. If the Phase I trial involved 15 subjects randomly assigned to the five \ngroups with three in each group, how many different ways can the groups be formed?\n16.\u00a0Emergency Room Instead of treating emergency room patients in the order that they \narrive, it is common to treat those with more serious problems first. If an emergency room has \nseven different patients, how many ways can they be arranged in sequence?\n17.\u00a0ZIP Code If you randomly select five digits, each between 0 and 9, with repetition allowed, \nwhat is the probability you will get the ZIP code of the Secretary of Health and Human Services?\n18.\u00a0FedEx Deliveries With a short time remaining in the day, a FedEx driver has time to make \ndeliveries at 6 locations among the 9 locations remaining. How many different routes are possible?\n19.\u00a0Phone Numbers Current rules for telephone area codes allow the use of digits 2\u20139 for \nthe first digit and 0\u20139 for the second and third digits. How many different area code",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 188
  },
  {
    "child_id": "796f5aa7-4e7c-4b21-95c7-8225d8bf0e2c",
    "parent_id": "dc76eca9-9841-422b-89df-2b9a0c820cc5",
    "text": "0 and 9, with repetition allowed, \nwhat is the probability you will get the ZIP code of the Secretary of Health and Human Services?\n18.\u00a0FedEx Deliveries With a short time remaining in the day, a FedEx driver has time to make \ndeliveries at 6 locations among the 9 locations remaining. How many different routes are possible?\n19.\u00a0Phone Numbers Current rules for telephone area codes allow the use of digits 2\u20139 for \nthe first digit and 0\u20139 for the second and third digits. How many different area codes are pos-\nsible with these rules? That same rule applies to the exchange numbers, which are the three \ndigits immediately preceding the last four digits of a phone number. Given both of those rules, \nhow many ten-digit phone numbers are possible? Given that these rules apply to the United \nStates and Canada and a few islands, are there enough possible phone numbers? (Assume that \nthe combined population is about 400,000,000.)\n20.\u00a0Classic Counting Problem A classic counting problem is to determine the number of \ndifferent ways that the letters of \u201cMississippi\u201d can be arranged. Find that number.\n21.\u00a0Corporate Officers and Committees The Newport Medical Supply Company must \nappoint a president, chief executive officer (CEO), chief operating officer (COO), and chief \nfinancial officer (CFO). It must also appoint a strategic planning committee with four different \nmembers. There are 10 qualified candidates, and officers can also serve on the committee.\na. How many different ways can the four officers be appointed?\nb. How many different ways can a committee of four be appointed?\ncontinued",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 188
  },
  {
    "child_id": "2e61a892-bf7b-4d1b-976e-d89223c7e546",
    "parent_id": "d584d187-9cd1-4e09-b11e-dc581188b706",
    "text": "4-6 Counting \n173\nc. What is the probability of randomly selecting the committee members and getting the four \nyoungest of the qualified candidates?\n22.\u00a0Card Access You have an identification card used for access to a secure area of the Wel-\nlington Medical Center. It\u2019s dark and you can\u2019t see your card when you insert it. The card must \nbe inserted with the front side up and the printing configured so that the beginning of your \nname enters first.\na. What is the probability of selecting a random position and inserting the card with the result \nthat the card is inserted correctly?\nb. What is the probability of randomly selecting the card\u2019s position and finding that it is incor-\nrectly inserted on the first attempt, but it is correctly inserted on the second attempt?\nc. How many random selections are required to be absolutely sure that the card works because \nit is inserted correctly?\n23. Amino Acids With 8 different amino acids available, 5 are to be selected to form a chain \n(called a polypeptide chain) in which order counts. How many different chains are possible?\n24.\u00a0Identity Theft with Credit Cards Credit card numbers typically have 16 digits, but not \nall of them are random.\na. What is the probability of randomly generating 16 digits and getting your MasterCard number?\nb. Receipts often show the last four digits of a credit card number. If only those last four digits are \nknown, what is the probability of randomly generating the other digits of your MasterCard number?\nc. Discover cards begin with the digits 6011. If you know that the first four digits are 6011 and \nyou also know the last four digits of a Discover card, what is the probability of randomly gener-\nating the other digits and getting all of them correct? Is this something to worry about?\n25.\u00a0What a Word! One of the longest words in standard statistics terminology is \u201chomosce-\ndasticity.\u201d How many ways can the letters in that word be arranged?\n26.\u00a0Phase I of a Clinical Trial A clinical test on humans of a new drug is normally done \nin three phases. Phase I is conducted with a relatively small number of healthy volunteers. For \nexample, a Phase I test of bexarotene involved only 14 subjects. Assume that we want to treat \n14 healthy humans with this new drug and we have 16 suitable volunteers available.\na. If the subjects are selected and treated one at a time in sequence, how many different sequen-\ntial arrangements are possible if 14 people are selected from the 16 that are available?\nb. If 14 subjects are selected from the 16 that are available, and the 14 selected subjects are all \ntreated at the same time, how many different treatment groups are possible?\nc. If 14 subjects are randomly selected and treated at the same time, what is the probability of \nselecting the 14 youngest subjects?\n27.\u00a0Lightning and Lottery As of this writing, the Mega Millions lottery is run in 44 states. \nWinning the jackpot requires that you select the correct five different numbers between 1 and \n75 and",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 191
  },
  {
    "child_id": "6e1b0915-9c6c-4815-91af-a7b22245b572",
    "parent_id": "d584d187-9cd1-4e09-b11e-dc581188b706",
    "text": "14 subjects are selected from the 16 that are available, and the 14 selected subjects are all \ntreated at the same time, how many different treatment groups are possible?\nc. If 14 subjects are randomly selected and treated at the same time, what is the probability of \nselecting the 14 youngest subjects?\n27.\u00a0Lightning and Lottery As of this writing, the Mega Millions lottery is run in 44 states. \nWinning the jackpot requires that you select the correct five different numbers between 1 and \n75 and, in a separate drawing, you must also select the correct single number between 1 and 15. \nFind the probability of winning the jackpot if you buy one ticket. How does the result compare \nto the probability of being struck by lightning in a year, which the National Weather Service \nestimates to be 1>960,000?\n28.\u00a0Designing Experiment Clinical trials of Nasonex involved a group given placebos and \nanother group given treatments of Nasonex. Assume that a preliminary Phase I trial is to be \nconducted with 12 subjects, including 6 men and 6 women. If 6 of the 12 subjects are randomly \nselected for the treatment group, find the probability of getting 6 subjects of the same gender. \nWould there be a problem with having members of the treatment group all of the same gender?\n\n174 \nCHAPTER 4 Probability\n29.\u00a0Morse Codes The International Morse code is a way of transmitting coded text by using \nsequences of on>off tones. Each character is 1 or 2 or 3 or 4 or 5 segments long, and each seg-\nment is either a dot or a dash. For example, the letter G is transmitted as two dashes followed \nby a dot, as in \u2014 \u2014 \u2022. How many different characters are possible with this scheme? Are there \nenough characters for the alphabet and numbers?\n30.\u00a0Mendel\u2019s Peas Mendel conducted some his famous experiments with peas that were \neither smooth yellow plants or wrinkly green plants. If four peas are randomly selected from a \nbatch consisting of four smooth yellow plants and four wrinkly green plants, find the probabil-\nity that the four selected peas are of the same type.\n31. Computer Variable Names A common computer programming rule is that names of \nvariables must be between one and eight characters long. The first character can be any of the \n26 letters, while successive characters can be any of the 26 letters or any of the 10 digits. For \nexample, allowable variable names include A, BBB, and M3477K. How many different vari-\nable names are possible? (Ignore the difference between uppercase and lowercase letters.)\n32. Handshakes\na. Five physicians gather for a meeting about a patient. If each physician shakes hands with \neach other physician exactly once, what is the total number of handshakes?\nb. If n physicians shake hands with each other exactly once, what is the total number of hand-\nshakes?\nc. How many different ways can five physicians be seated at a round table? (Assume that if \neveryone moves to the right, the seating arrangement is the same.)\nd. How many different ways can n physici",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 191
  },
  {
    "child_id": "c98dbbea-985f-4420-b8a8-5adf911c9f19",
    "parent_id": "d584d187-9cd1-4e09-b11e-dc581188b706",
    "text": "ase letters.)\n32. Handshakes\na. Five physicians gather for a meeting about a patient. If each physician shakes hands with \neach other physician exactly once, what is the total number of handshakes?\nb. If n physicians shake hands with each other exactly once, what is the total number of hand-\nshakes?\nc. How many different ways can five physicians be seated at a round table? (Assume that if \neveryone moves to the right, the seating arrangement is the same.)\nd. How many different ways can n physicians be seated at a round table?\n4-6 Beyond the Basics\n1.\u00a0Standard Tests Standard tests, such as the MCAT, tend to make extensive use of multiple-\nchoice questions because they are easy to grade using software. If one such multiple-choice \nquestion has possible correct answers of a, b, c, d, e, what is the probability of a wrong answer \nif the answer is a random guess?\n2.\u00a0 Likelihood of Disease After obtaining a patient\u2019s positive test result, a physician con-\ncludes that there is a 30% chance that the subject has a disease. What is the probability that the \nsubject does not have the disease?\n3.\u00a0Months If a month is randomly selected after mixing the pages from a calendar, what is the \nprobability that it is a month containing the letter y?\n4.\u00a0 Sigmoidoscopy, Colonoscopy Based on data from the Centers for Disease Control, \n67.7% of males over the age of 50 have had a sigmoidoscopy or colonoscopy. If two males over \nthe age of 60 are randomly selected, what is the probability that they both have had a sigmoid-\noscopy or colonoscopy?\n5.\u00a0Subjective Probability Estimate the probability that the next time you get a cut, it requires \nstitches.\nChapter Quick Quiz\n\nIn Exercises 6\u201310, use the following results from tests of an experiment to test the effective-\nness of an experimental vaccine for children (based on data from USA Today). Express all \nprobabilities in decimal form.\nDeveloped Flu\nDid Not Develop Flu\nVaccine Treatment\n14\n1056\nPlacebo\n95\n 437\n6.\u00a0If 1 of the 1602 subjects is randomly selected, find the probability of getting 1 that devel-\noped flu.\n7.\u00a0If 1 of the 1602 subjects is randomly selected, find the probability of getting 1 who had the \nvaccine treatment or developed flu.\n8.\u00a0If 1 of the 1602 subjects is randomly selected, find the probability of getting 1 who had the \nvaccine treatment and developed flu.\n9.\u00a0Find the probability of randomly selecting 2 subjects without replacement and finding that \nthey both developed flu.\n10.\u00a0Find the probability of randomly selecting 1 of the subjects and getting 1 who developed \nflu, given that the subject was given the vaccine treatment.\nIn Exercises 1\u201310, use the data in the accompanying table and express all results in decimal \nform. (The results are based on \u201cSplinting vs Surgery in the Treatment of Carpal Tunnel Syn-\ndrome,\u201d by Gerritsen et al., Journal of the American Medical Association, Vol. 288, No. 10.)\nTreatment for Carpal Tunnel Syndrome\nSuccessful Treatment\nUnsuccessful Treatment\nSplint Treatment\n60\n",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 191
  },
  {
    "child_id": "51d02083-c96b-4c05-b7d5-139fab9acd55",
    "parent_id": "d584d187-9cd1-4e09-b11e-dc581188b706",
    "text": " selecting 1 of the subjects and getting 1 who developed \nflu, given that the subject was given the vaccine treatment.\nIn Exercises 1\u201310, use the data in the accompanying table and express all results in decimal \nform. (The results are based on \u201cSplinting vs Surgery in the Treatment of Carpal Tunnel Syn-\ndrome,\u201d by Gerritsen et al., Journal of the American Medical Association, Vol. 288, No. 10.)\nTreatment for Carpal Tunnel Syndrome\nSuccessful Treatment\nUnsuccessful Treatment\nSplint Treatment\n60\n23\nSurgery Treatment\n67\n 6\n1. Success If 1 of the patients is randomly selected, find the probability of selecting someone \nwith a successful treatment.\n2. Success Find the probability of randomly selecting a patient and getting one with a suc-\ncessful treatment, given that the patient was treated with splinting.\n3. Success Find the probability of randomly selecting a patient and getting one with a suc-\ncessful treatment, given that the patient was treated with surgery.\n4. Success or Surgery If 1 of the patients is randomly selected, find the probability of get-\nting a patient who had a successful treatment or was treated with surgery.\n5. No Success or Splint If 1 of the patients is randomly selected, find the probability of get-\nting someone who had an unsuccessful treatment or was treated with a splint.\n6. Both Successful If 2 patients are randomly selected without replacement, find the prob-\nability that they both had successful treatments.\n7. Both Successful If 2 patients are randomly selected with replacement, find the probability \nthat they both had successful treatments.\n8. Complement If A represents the event of randomly selecting one patient included in the \ntable and getting someone who was treated with surgery, what does A represent? Find the value \nof P1A2.\nReview Exercises\nCHAPTER 4 Review Exercises \n175",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 191
  },
  {
    "child_id": "b6789ba3-1501-4b06-af06-9a52dab437a1",
    "parent_id": "9bed26f4-3bdd-41fd-bbc2-aceaf274c87e",
    "text": "176 \nCHAPTER 4 Probability\n9. Complement If A represents the event of randomly selecting one patient included in the \ntable and getting someone who had a successful treatment, what does A represent? Find the \nvalue of P1A2.\n10. All Three Successful If 3 patients are randomly selected without replacement, find the \nprobability that all three had successful treatments.\n11. Vision Correction About 75% of the U.S. population uses some type of vision correction \n(such as glasses or contact lenses).\na. If someone is randomly selected, what is the probability that he or she does not use vision \ncorrection?\nb. If four different people are randomly selected, what is the probability that they all use vision \ncorrection?\nc. Would it be unlikely to randomly select four people and find that they all use vision correc-\ntion? Why or why not?\n12. National Statistics Day\na. If a person is randomly selected, find the probability that his or her birthday is October 18, \nwhich is National Statistics Day in Japan. Ignore leap years.\nb. If a person is randomly selected, find the probability that his or her birthday is in October. \nIgnore leap years.\nc. Estimate a subjective probability for the event of randomly selecting an adult American and \ngetting someone who knows that October 18 is National Statistics Day in Japan.\nd. Is it unlikely to randomly select an adult American and get someone who knows that Octo-\nber 18 is National Statistics Day in Japan?\n13. Composite Sampling for Diabetes Currently, the rate for new cases of diabetes in a year \nis 3.4 per 1000 (based on data from the Centers for Disease Control and Prevention). When \ntesting for the presence of diabetes, the Portland Diagnostics Laboratory saves money by com-\nbining blood samples for tests. The combined sample tests positive if at least one person has \ndiabetes. If the combined sample tests positive, then the individual blood tests are performed. \nIn a test for diabetes, blood samples from 10 randomly selected subjects are combined. Find \nthe probability that the combined sample tests positive with at least 1 of the 10 people having \ndiabetes. Is it likely that such combined samples test positive?\n14. Redundancy Using battery-powered alarm clocks, it is estimated that the probability of \nfailure on any given day is 1>1000.\na. What is the probability that the alarm clock works for an important event?\nb. When using two alarm clocks for an important event, what is the probability that at least one \nof them works?\nCumulative Review Exercises\n1. Fatal Drunk Driving Listed below are the blood alcohol concentrations (g>dL) of drivers \nconvicted of drunk driving in fatal car crashes (based on data from the National Highway Traf-\nfic Safety Administration).\n0.09 0.11 0.11 0.13 0.14 0.15 0.17 0.17 0.18 0.18 0.23 0.35\nFind the value of the following statistics and include appropriate units.\na. mean         b. median   c. midrange   d. range\ne. standard deviation   f. variance\n\n2. Fatal Drunk Driving Use the sam",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 194
  },
  {
    "child_id": "f37c793b-0be2-4cf7-a6ec-c26909c80832",
    "parent_id": "9bed26f4-3bdd-41fd-bbc2-aceaf274c87e",
    "text": "\nCumulative Review Exercises\n1. Fatal Drunk Driving Listed below are the blood alcohol concentrations (g>dL) of drivers \nconvicted of drunk driving in fatal car crashes (based on data from the National Highway Traf-\nfic Safety Administration).\n0.09 0.11 0.11 0.13 0.14 0.15 0.17 0.17 0.18 0.18 0.23 0.35\nFind the value of the following statistics and include appropriate units.\na. mean         b. median   c. midrange   d. range\ne. standard deviation   f. variance\n\n2. Fatal Drunk Driving Use the same data given in Exercise 1.\na. Identify the 5-number summary and also identify any values that appear to be outliers.\nb. Construct a boxplot.  c. Construct a stemplot.\n3. Organ Donors USA Today provided information about a survey (conducted for Donate Life \nAmerica) of 5100 adult Internet users. Of the respondents, 2346 said they are willing to donate \norgans after death. In this survey, 100 adults were surveyed in each state and the District of Co-\nlumbia, and results were weighted to account for the different state population sizes.\na. What percentage of respondents said that they are willing to donate organs after death?\nb. Based on the poll results, what is the probability of randomly selecting an adult who is will-\ning to donate organs after death?\nc. What term is used to describe the sampling method of randomly selecting 100 adults from \neach state and the District of Columbia?\n4. Sampling Eye Color Based on a study by Dr. P. Sorita Soni, eye colors in the United States \nare as follows: 40% brown, 35% blue, 12% green, 7% gray, 6% hazel.\na. A statistics instructor collects eye color data from her students. What is the name for this \ntype of sample?\nb. Identify one factor that might make the sample from part (a) biased and not representative of \nthe general population of people in the United States.\nc. What is the probability that a randomly selected person will have brown or blue eyes?\nd. If two people are randomly selected, what is the probability that at least one of them has \nbrown eyes?\n5. Blood Pressure and Platelets Given below are the systolic blood pressure measurements \n(mm Hg) and blood platelet counts (1000 cells>mL) of the first few subjects included in Data \nSet 1 \u201cBody Data\u201d in Appendix B. Construct a graph suitable for exploring an association be-\ntween systolic blood pressure and blood platelet count. What does the graph suggest about that \nassociation?\nSystolic\n100\n112\n134\n126\n114\n134\n118\n138\n114\n124\nPlatelet\n319\n187\n297\n170\n140\n192\n191\n286\n263\n193\nCHAPTER 4 Technology Project \n177\nSimulations Calculating probabilities are sometimes painfully difficult, but simulations pro-\nvide us with a very practical alternative to calculations based on formal rules. A simulation \nof a procedure is a process that behaves the same way as the procedure so that similar results \nare produced. Instead of calculating the probability of getting exactly 5 boys in 10 births, you \ncould repeatedly toss 10 coins and count the number of times that exactly 5 he",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 194
  },
  {
    "child_id": "c9c71727-fc44-4811-bf58-6d2989e12fc8",
    "parent_id": "9bed26f4-3bdd-41fd-bbc2-aceaf274c87e",
    "text": "\n193\nCHAPTER 4 Technology Project \n177\nSimulations Calculating probabilities are sometimes painfully difficult, but simulations pro-\nvide us with a very practical alternative to calculations based on formal rules. A simulation \nof a procedure is a process that behaves the same way as the procedure so that similar results \nare produced. Instead of calculating the probability of getting exactly 5 boys in 10 births, you \ncould repeatedly toss 10 coins and count the number of times that exactly 5 heads (or simulated \n\u201cboys\u201d) occur. Better yet, you could do the simulation with a random number generator on a \ncomputer or calculator to randomly generate 1s (or simulated \u201cboys\u201d) and 0s (or simulated \n\u201cgirls\u201d). Let\u2019s consider this probability exercise:\nFind the probability that among 50 randomly selected people, at least 3 have  \nthe same birthday.\nFor the above problem, a simulation begins by representing birthdays by integers from \n1 through 365, where 1 represents a birthday of January 1, and 2 represents January 2, \nand so on. We can simulate 50 birthdays by using a calculator or computer to generate 50 \nTechnology Project\ncontinued\n\n178 \nCHAPTER 4 Probability\nrandom numbers (with repetition allowed) between 1 and 365. Those numbers can then be \nsorted, so it becomes easy to examine the list to determine whether any 3 of the simulated \nbirth dates are the same. (After sorting, equal numbers are adjacent.) We can repeat the \nprocess as many times as we wish, until we are satisfied that we have a good estimate of the \nprobability. Use technology to simulate 20 different groups of 50 birthdays. Use the results \nto estimate the probability that among 50 randomly selected people, at least 3 have the same \nbirthday.\nSummary of Simulation Functions:\nStatdisk: \n Select Data from the top menu, select Uniform Generator from the \ndropdown menu.\nExcel: \n Click Insert Function fx, select Math & Trig, select  \nRANDBETWEEN. Copy to additional cells.\nTI-83 , 84 Plus:  Press L, select PROB from the top menu, select randInt from the menu.\nStatCrunch: \n Select Data from the top menu, select Simulate from the dropdown \nmenu, select Discrete Uniform from the submenu.\nMinitab: \n Select Calc from the top menu, select Random Data from the drop-\ndown menu, select Integer from the submenu.\nFROM DATA TO DECISION \nCritical Thinking:  \nInterpreting results from a test for smoking\nIt is estimated that roughly half of patients who smoke lie \nwhen asked if they smoke. Pulse CO-oximeters may be a \nway to get information about smoking without relying on pa-\ntients\u2019 statements. Pulse CO-oximeters use light that shines \nthrough a fingernail, and it measures carboxyhemoglobin \n(carbon monoxide in blood). These devices are used by fire-\nmen and emergency departments to detect carbon monoxide \npoisoning, but they can also be used to identify smokers. The \naccompanying table lists results from people aged 18\u201344 \nwhen the pulse CO-oximeter is set to detect a 6% or higher \nlevel of carboxyhem",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 194
  },
  {
    "child_id": "a7614e97-cb03-4ae1-95d2-65af7bf3358f",
    "parent_id": "9bed26f4-3bdd-41fd-bbc2-aceaf274c87e",
    "text": "e a \nway to get information about smoking without relying on pa-\ntients\u2019 statements. Pulse CO-oximeters use light that shines \nthrough a fingernail, and it measures carboxyhemoglobin \n(carbon monoxide in blood). These devices are used by fire-\nmen and emergency departments to detect carbon monoxide \npoisoning, but they can also be used to identify smokers. The \naccompanying table lists results from people aged 18\u201344 \nwhen the pulse CO-oximeter is set to detect a 6% or higher \nlevel of carboxyhemoglobin (based on data from \u201cCarbon \nMonoxide Test Can Be Used to Identify Smoker,\u201d by Patrice \nWendling, Internal Medicine News, Vol. 40., No. 1, and \nCenters for Disease Control and Prevention).\nCO-Oximetry Test for Smoking\nPositive Test Result\nNegative Test Result\nSmoker\n49\n 57\nNonsmoker\n24\n370\nAnalyzing the Results\n1. False Positive Based on the results in the table, find the \nprobability that a subject is not a smoker, given that the test \nresult is positive.\n2. True Positive Based on the results in the table, find the \nprobability that a subject smokes, given that the test result is \npositive.\n3. False Negative Based on the results in the table, find the \nprobability that a subject smokes, given that the test result is \nnegative.\n4. True Negative Based on the results in the table, find the \nprobability that a subject does not smoke, given that the test \nresult is negative.\n5. Sensitivity Find the sensitivity of the test by finding the \nprobability of a true positive, given that the subject actually \nsmokes.\n6. Specificity Find the specificity of the test by finding the \nprobability of a true negative, given that the subject does not \nsmoke.\n7. Positive Predictive Value Find the positive predictive \nvalue of the test by finding the probability that the subject \nsmokes, given that the test yields a positive result.\n8. Negative Predictive Value Find the negative predictive \nvalue of the test by finding the probability that the subject \ndoes not smoke, given that the test yields a negative result.\n9. Confusion of the Inverse Find the following values, \nthen compare them. In this case, what is confusion of the \ninverse?\n\u2022 P(smoker \u001f positive test result)\n\u2022 P(positive test result \u001f smoker)\n\nCooperative Group Activities\n1. In-class activity Divide into groups of three or four and use coin flipping to develop a simula-\ntion that emulates the kingdom that abides by this decree: After a mother gives birth to a son, she \nwill not have any other children. If this decree is followed, does the proportion of girls increase?\n2. In-class activity Divide into groups of three or four and use actual thumbtacks or Hershey\u2019s \nKisses candies, or paper cups, to estimate the probability that when dropped, they will land \nwith the point (or open side) up. How many trials are necessary to get a result that appears to be \nreasonably accurate when rounded to the first decimal place?\n3. Out-of-class activity Marine biologists often use the capture-recapture method as a way \nto es",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 194
  },
  {
    "child_id": "69b0daf5-1ce3-4e3a-94be-b49f89f6b4a4",
    "parent_id": "9bed26f4-3bdd-41fd-bbc2-aceaf274c87e",
    "text": "s followed, does the proportion of girls increase?\n2. In-class activity Divide into groups of three or four and use actual thumbtacks or Hershey\u2019s \nKisses candies, or paper cups, to estimate the probability that when dropped, they will land \nwith the point (or open side) up. How many trials are necessary to get a result that appears to be \nreasonably accurate when rounded to the first decimal place?\n3. Out-of-class activity Marine biologists often use the capture-recapture method as a way \nto estimate the size of a population, such as the number of fish in a lake. This method involves \ncapturing a sample from the population, tagging each member in the sample, and then return-\ning it to the population. A second sample is later captured, and the tagged members are counted \nalong with the total size of this second sample. The results can be used to estimate the size of \nthe population.\nInstead of capturing real fish, simulate the procedure using some uniform collection of \nitems such as colored beads, M&Ms, or index cards. Start with a large collection of at least \n200 of such items. Collect a sample of 50 and use a marker to \u201ctag\u201d each one. Replace the \ntagged items, mix the whole population, then select a second sample and proceed to estimate \nthe population size. Compare the result to the actual population size obtained by counting all \nof the items.\n4. Out-of-class activity In Cumulative Review Exercise 4, it was noted that eye colors in \nthe United States are distributed as follows: 40% brown, 35% blue, 12% green, 7% gray, 6% \nhazel. That distribution can form the basis for probabilities. Conduct a survey by asking fellow \nstudents to identify the color of their eyes. Does the probability of 0.4 for brown eyes appear to \nbe consistent with your results? Why would a large sample be required to confirm that P(hazel \neyes) = 0.06?\nCHAPTER 4 Cooperative Group Activities \n179",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 194
  },
  {
    "child_id": "55c3d925-37b3-4854-8175-b7d751276839",
    "parent_id": "a8845fae-c135-4274-946c-bb285565bdf8",
    "text": "180\nProbability Distributions\nBinomial Probability \nDistributions\nPoisson Probability \nDistributions\n5-1\n5-2\n5-3\nIs the XSORT Gender Selection Method Effective?\nCHAPTER \nPROBLEM\nDiscrete Probability \nDistributions\nWe live in a time with incredible advances in technology, med-\nicine, and health care. Cloning is no longer science  fiction. We \nhave iPads, iPhones, virtual-reality headsets, and self-driving \ncars. We carry calculators that can instantly execute many \ncomplex statistical calculations. Heart  pacemakers have defi-\nbrillators capable of shocking and restarting stopped hearts. \nCouples use procedures that are claimed to greatly increase \nthe chance of having a baby with a desired gender.\nSome people argue that gender selection methods should \nbe banned, regardless of the reason, while others enthusiasti-\ncally support the use of such methods. Lisa Belkin asked in the \nNew York Times Magazine, \u201cIf we allow parents to choose the \nsex of their child today, how long will it be before they order up \neye color, hair color, personality traits, and IQ?\u201d There are some \nconvincing arguments in favor of at least limited use of gender \nselection. One such argument involves couples carrying  \n5\n\nX-linked recessive genes. For some of these couples, any male \nchildren have a 50% chance of inheriting a disorder, but none \nof the female children will inherit the disorder. These couples \nmay want to use gender selection as a way to ensure that they \nhave baby girls, thereby guaranteeing that a disorder will not \nbe inherited by any of their children.\nThe Genetics & IVF Institute in Fairfax, Virginia, devel-\noped a technique called MicroSort and claimed that it in-\ncreases the chances of a couple having a baby with a desired \ngender. (Clinical trials of MicroSort have been discontinued.) \nThe  MicroSort XSORT method is claimed to increase the \nchances of a couple having a baby girl, and the MicroSort \nYSORT method is claimed to increase the chances of a \nbaby boy. The latest results for the XSORT method consist \nof 945 couples who wanted to have baby girls. After using \nthe XSORT technique, 879 of those couples had baby girls. \n(See Figure 5-1 for a bar graph illustrating these results.) \nWe usually expect that in 945 births, the number of girls \nshould be somewhere around 472 or 473. Given that 879 out \nof 945 couples had girls, can we conclude that the XSORT \ntechnique is effective, or might we explain the outcome as \njust a chance sample result? In answering that question, we \nwill use principles of probability to determine whether the \nobserved birth  results differ significantly from results that we \nwould expect from random chance. This is a common goal \nof inferential statistics: Determine whether results can be \nreasonably  explained by random chance or whether random \nchance doesn\u2019t appear to be a feasible explanation, so that \nother  factors are influencing results. In this chapter we pres-\nent methods that allow us to find the probabilities we",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 198
  },
  {
    "child_id": "6aa66315-c295-444d-85a9-e1e0416df21c",
    "parent_id": "a8845fae-c135-4274-946c-bb285565bdf8",
    "text": "at question, we \nwill use principles of probability to determine whether the \nobserved birth  results differ significantly from results that we \nwould expect from random chance. This is a common goal \nof inferential statistics: Determine whether results can be \nreasonably  explained by random chance or whether random \nchance doesn\u2019t appear to be a feasible explanation, so that \nother  factors are influencing results. In this chapter we pres-\nent methods that allow us to find the probabilities we need \nfor  determining whether the XSORT results are significant, \n suggesting that the method is effective.\nFigure 5-2 on the next page provides a visual illustration of what this chapter accom-\nplishes. When investigating the numbers of heads in two coin tosses, we can use the \nfollowing two different approaches:\n\u2022 Use real sample data to find actual results: The approach of Chapters 2 and 3 is \nto collect sample data from actual coin tosses, then summarize the results in a table \nrepresenting the frequency distribution, and then find statistics, such as the sample \nmean x and the sample standard deviation s.\n\u2022 Use probabilities to find expected results: Using principles of probability from \nChapter 4, we can find the probability for each possible number of heads in two \ntosses. Then we could summarize the results in a table representing a probability \ndistribution.\nIn this chapter we merge the above two approaches as we create a table de-\nscribing what we expect to happen (instead of what did happen), then we find the \npopulation mean m and population standard deviation s. The table at the extreme \nright in Figure 5-2 is a probability distribution, because it describes the distribution \nusing probabilities instead of frequency counts. The remainder of this book and  \nthe core of inferential statistics are based on some knowledge of probability  \ndistributions. In this chapter we focus on discrete probability distributions.  \n \nChapter Objectives \n181\nCHAPTER OBJECTIVES\n>>>\nFIGURE 5-1 Results from the XSORT Method of \nGender Selection\n\n182 \nCHAPTER 5 Discrete Probability Distributions\nKey Concept This section introduces the concept of a random variable and the con-\ncept of a probability distribution. We illustrate how a probability histogram is a graph \nthat visually depicts a probability distribution. We show how to find the important \nparameters of mean, standard deviation, and variance for a probability distribution. \nMost importantly, we describe how to determine whether outcomes are significant \n(significantly low or significantly high). We begin with the related concepts of random \nvariable and probability distribution.\n5-1 \n Probability Distributions\nCount numbers of\nheads in tosses of\ntwo coins.\nCollect sample\ndata from two coin\ntosses, then \ufb01nd\nstatistics and\ncreate graphs.\nNumber\nof heads\nx\n0\n1\n2\nf\n27\n56\n17\nCreate a theoretical model\nof the expected results,\nthen \ufb01nd parameters.\nFind the probability for\neach possible number of\nheads in two coi",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 198
  },
  {
    "child_id": "972293cb-822f-4e7e-bc71-c584cc3feaf2",
    "parent_id": "a8845fae-c135-4274-946c-bb285565bdf8",
    "text": "mine whether outcomes are significant \n(significantly low or significantly high). We begin with the related concepts of random \nvariable and probability distribution.\n5-1 \n Probability Distributions\nCount numbers of\nheads in tosses of\ntwo coins.\nCollect sample\ndata from two coin\ntosses, then \ufb01nd\nstatistics and\ncreate graphs.\nNumber\nof heads\nx\n0\n1\n2\nf\n27\n56\n17\nCreate a theoretical model\nof the expected results,\nthen \ufb01nd parameters.\nFind the probability for\neach possible number of\nheads in two coin tosses.\nP(0) 5 0.25\nP(1) 5 0.50\nP(2) 5 0.25\nChapters\n2 and 3\nChapter 4\nChapters 2 and 3\nChapter 5\nChapter 4\nx 5 0.9\ns 5 0.7\nNumber of\nheads in two\ncoin tosses\nx\n0\n1\n2\nP(x)\n0.25\n0.50\n0.25\nm 5 1.0\ns 5 0.7\nFIGURE 5-2\nHere are the chapter objectives:\nProbability Distributions\n\u2022 Define random variable and probability distribution.\n\u2022 Determine when a potential probability distribution actually satisfies the necessary \nrequirements.\n\u2022 Given a probability distribution, compute the mean and standard deviation, then use \nthose results to determine whether results are significantly low or significantly high.\nBinomial Probability Distributions\n\u2022 Describe a binomial probability distribution and find probability values for a binomial \ndistribution.\n\u2022 Compute the mean and standard deviation for a binomial distribution, then use \nthose results to determine whether results are significantly low or significantly high.\nPoisson Probability Distributions\n\u2022 Describe a Poisson probability distribution and find probability values for a Poisson \ndistribution.\n5-1\n5-2\n5-3\nCollect sample\ndata from two coin\ntosses, then \ufb01nd\nstatistics and\ncreate graphs.\nNumber\nof heads\nx\n0\n1\n2\nf\n27\n56\n17\nCreate a theoretical model\nof the expected results,\nthen \ufb01nd parameters.\nFind the probability for\neach possible number of\nheads in two coin tosses.\nP(0) 5 0.25\nP(1) 5 0.50\nP(2) 5 0.25\nChapters 2 and 3\nChapter 5\nChapter 4\nx 5 0.9\ns 5 0.7\nNumber of\nheads in two\ncoin tosses\nx\n0\n1\n2\nP(x)x)x\n0.25\n0.50\n0.25\nm 5 1.0\ns 5 0.7\nHere are the chapter objectives:\nProbability Distributions\n\u2022 Define random variable and probability distribution.\n\u2022 Determine when a potential probability distribution actually satisfies the necessary \nrequirements.\n\u2022 Given a probability distribution, compute the mean and standard deviation, then use\nthose results to determine whether results are significantly low or significantly high.\nBinomial Probability Distributions\n\u2022 Describe a binomial probability distribution and find probability values for a binomial\ndistribution.\n\u2022 Compute the mean and standard deviation for a binomial distribution, then use \nthose results to determine whether results are significantly low or \nw \nw\nsignificantly high.\nPoisson Probability Distributions\n\u2022 Describe a Poisson probability distribution and find probability values for a Poisson \ndistribution.\n\n5-1 Probability Distributions \n183\nPART 1\nBasic Concepts of a Probability Distribution\nDEFINITIONS\nA random variable is a variable (typically represented by x",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 198
  },
  {
    "child_id": "eea9f7c6-a11d-41de-bef6-8053137c699c",
    "parent_id": "a8845fae-c135-4274-946c-bb285565bdf8",
    "text": "for a binomial\ndistribution.\n\u2022 Compute the mean and standard deviation for a binomial distribution, then use \nthose results to determine whether results are significantly low or \nw \nw\nsignificantly high.\nPoisson Probability Distributions\n\u2022 Describe a Poisson probability distribution and find probability values for a Poisson \ndistribution.\n\n5-1 Probability Distributions \n183\nPART 1\nBasic Concepts of a Probability Distribution\nDEFINITIONS\nA random variable is a variable (typically represented by x) that has a single nu-\nmerical value, determined by chance, for each outcome of a procedure.\nA probability distribution is a description that gives the probability for each value \nof the random variable. It is often expressed in the format of a table, formula, or \ngraph.\nIn Section 1-2 we made a distinction between discrete and continuous data. \n Random variables may also be discrete or continuous, and the following two defini-\ntions are consistent with those given in Section 1-2.\nDEFINITIONS\nA discrete random variable has a collection of values that is finite or countable. \n(If there are infinitely many values, the number of values is countable if it is pos-\nsible to count them individually, such as the number of tosses of a coin before \ngetting heads.)\nA continuous random variable has infinitely many values, and the collec-\ntion of values is not countable. (That is, it is impossible to count the individual \nitems because at least some of them are on a continuous scale, such as body \ntemperatures.)\nThis chapter deals exclusively with discrete random variables, but the following \nchapters deal with continuous random variables.\nProbability Distribution: Requirements\nEvery probability distribution must satisfy each of the following three requirements.\n1. There is a numerical (not categorical) random variable x, and its number values \nare associated with corresponding probabilities.\n2. \u03a3P(x)  =   1 where x assumes all possible values. (The sum of all probabilities \nmust be 1, but sums such as 0.999 or 1.001 are acceptable because they result \nfrom rounding errors.)\n3. 0 \u2026 P(x) \u2026 1 for every individual value of the random variable x. (That is, \neach probability value must be between 0 and 1 inclusive.)\nThe second requirement comes from the simple fact that the random variable x \nrepresents all possible events in the entire sample space, so we are certain (with prob-\nability 1) that one of the events will occur. The third requirement comes from the basic \nprinciple that any probability value must be 0 or 1 or a value between 0 and 1.\nEXAMPLE 1  Genetics\nAlthough the Chapter Problem involves 945 births, let\u2019s consider a simpler example \nthat involves only two births with the following random variable:\nx = number of girls in two births\nThe above x is a random variable because its numerical values depend on chance. \nWith two births, the number of girls can be 0, 1, or 2, and Table 5-1 is a probability \ncontinued",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 198
  },
  {
    "child_id": "4df41c32-751e-44b1-82e5-bd673ba27ea0",
    "parent_id": "397d399f-a7d3-4ee9-9c28-701d521b1e4c",
    "text": "184 \nCHAPTER 5 Discrete Probability Distributions\nNotation for 0+\nIn tables such as Table 5-1 or the binomial probabilities listed in Table A-1 in \nAppendix A, we sometimes use 0+ to represent a probability value that is positive \nbut very small, such as 0.000000123. When rounding a probability value for inclu-\nsion in such a table, rounding to 0 would be misleading because it would incor-\nrectly suggest that the event is impossible.\nProbability Histogram: Graph of a Probability Distribution\nThere are various ways to graph a probability distribution, but for now we will con-\nsider only the probability histogram. Figure 5-3 is a probability histogram corre-\nsponding to Table 5-1. Notice that it is similar to a relative frequency histogram (de-\nscribed in Section 2-2), but the vertical scale shows probabilities instead of relative \nfrequencies based on actual sample results.\ndistribution because it gives the probability for each value of the random variable x \nand it satisfies the three requirements listed earlier:\n \n1. The variable x is a numerical random variable and its values are associated \nwith probabilities, as in Table 5-1.\n \n2. \u03a3P(x) = 0.25 + 0.50 + 0.25 = 1\n3. Each value of P(x) is between 0 and 1. (Speci\ufb01cally, 0.25 and 0.50 and 0.25 \nare each between 0 and 1 inclusive.)\nThe random variable x in Table 5-1 is a discrete random variable, because it has \nthree possible values (0, 1, 2), and 3 is a finite number, so this satisfies the require-\nment of being finite or countable.\nTABLE 5-1 Probability \n Distribution for the Number of \nGirls in Two Births\nx: Number  \nof Girls\n \nP(x)\n0\n0.25\n1\n0.50\n2\n0.25\nFIGURE 5-3  Probability Histogram for Number of \nGirls in Two Births\nIn Figure 5-3, we see that the values of 0, 1, 2 along the horizontal axis are lo-\ncated at the centers of the rectangles. This implies that the rectangles are each 1 unit \nwide, so the areas of the rectangles are 0.25, 0.50, and 0.25. The areas of these rectan-\ngles are the same as the probabilities in Table 5-1. We will see in Chapter 6 and future \nchapters that such a correspondence between areas and probabilities is very useful.\nProbability Formula Example 1 involves a table, but a probability distribution \ncould also be in the form of a formula. Consider the formula P(x) =\n1\n2(2 - x)! x!\n\n5-1 Probability Distributions \n185\n(where x can be 0, 1, or 2). Using that formula, we find that P102 = 0.25, P112 = 0.50,\nand P122 = 0.25. The probabilities found using this formula are the same as those in \nTable 5-1. This formula does describe a probability distribution because the three re-\nquirements are satisfied, as shown in Example 1.\nTABLE 5-2 Hospital Job Interview Mistakes\nx\nP(x)\nInappropriate attire\n0.50\nBeing late\n0.44\nLack of eye contact\n0.33\nChecking phone or texting\n0.30\nTotal\n1.57\nEXAMPLE 2  Hospital Job Interview Mistakes\nHiring managers were asked to identify the biggest mistakes that job applicants \nmake during an interview, and Table 5-2 is based on their responses (b",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 202
  },
  {
    "child_id": "258a8770-4de3-4d5f-8818-58f1d88cfc27",
    "parent_id": "397d399f-a7d3-4ee9-9c28-701d521b1e4c",
    "text": "s those in \nTable 5-1. This formula does describe a probability distribution because the three re-\nquirements are satisfied, as shown in Example 1.\nTABLE 5-2 Hospital Job Interview Mistakes\nx\nP(x)\nInappropriate attire\n0.50\nBeing late\n0.44\nLack of eye contact\n0.33\nChecking phone or texting\n0.30\nTotal\n1.57\nEXAMPLE 2  Hospital Job Interview Mistakes\nHiring managers were asked to identify the biggest mistakes that job applicants \nmake during an interview, and Table 5-2 is based on their responses (based on data \nfrom an Adecco survey). Does Table 5-2 describe a probability distribution?\nSOLUTION\nTable 5-2 violates the first requirement because x is not a numerical random vari-\nable. Instead, the \u201cvalues\u201d of x are categorical data, not numbers. Table 5-2 also \nviolates the second requirement because the sum of the probabilities is 1.57, but that \nsum should be 1. Because the three requirements are not all satisfied, we conclude \nthat Table 5-2 does not describe a probability distribution.\nParameters of a Probability Distribution\nRemember that with a probability distribution, we have a description of a population \ninstead of a sample, so the values of the mean, standard deviation, and variance are \nparameters, not statistics. The mean, variance, and standard deviation of a discrete \nprobability distribution can be found with the following formulas:\nFORMULA 5-1 Mean M for a probability distribution\nm = \u03a33x # P1x24 \nFORMULA 5-2 Variance S2 for a probability distribution\ns2 = \u03a33 1x - m2 2 # P1x24 (This format is easier to understand.)\nFORMULA 5-3 Variance S2 for a probability distribution\ns2 = \u03a33x2 # P1x24 - m2 (This format is easier for manual calculations.)\nFORMULA 5-4 Standard deviation S for a probability distribution\ns = 2\u03a33x2 # P1x24 - m2\n\n186 \nCHAPTER 5 Discrete Probability Distributions\nWhen applying Formulas 5-1 through 5-4, use the following rule for rounding results.\nRound-Off Rule For m, s, And s2 From A Probability Distribution\nRound results by carrying one more decimal place than the number of decimal \nplaces used for the random variable x. If the values of x are integers, round m, s, \nand s2 to one decimal place.\nExceptions to Round-Off Rule In some special cases, the above round-off rule re-\nsults in values that are misleading or inappropriate. For example, with four-engine \njets the mean number of jet engines working successfully throughout a flight is \n3.999714286, which becomes 4.0 when rounded, but that is misleading because it \nsuggests that all jet engines always work successfully. Here we need more precision to \ncorrectly  reflect the true mean, such as the precision in 3.999714.\nExpected Value\nThe mean of a discrete random variable x is the theoretical mean outcome for infinitely \nmany trials. We can think of that mean as the expected value in the sense that it is the \naverage value that we would expect to get if the trials could continue indefinitely.\nDEFINITION\nThe expected value of a discrete random variable x is denoted by E, a",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 202
  },
  {
    "child_id": "40225f78-9c00-4fd0-bbf1-60cd78323599",
    "parent_id": "397d399f-a7d3-4ee9-9c28-701d521b1e4c",
    "text": "l jet engines always work successfully. Here we need more precision to \ncorrectly  reflect the true mean, such as the precision in 3.999714.\nExpected Value\nThe mean of a discrete random variable x is the theoretical mean outcome for infinitely \nmany trials. We can think of that mean as the expected value in the sense that it is the \naverage value that we would expect to get if the trials could continue indefinitely.\nDEFINITION\nThe expected value of a discrete random variable x is denoted by E, and it is the \nmean value of the outcomes, so E = m and E can also be found by evaluating \n\u03a3 3x # P1x24, as in Formula 5-1.\nCAUTION An expected value need not be a whole number, even if the different \npossible values of x might all be whole numbers. The expected number of girls in \nfive births is 2.5, even though five particular births can never result in 2.5 girls. If we \nwere to survey many couples with five children, we expect that the mean number of \ngirls will be 2.5.\nEXAMPLE 3   Finding the Mean, Variance, and  \nStandard Deviation\nTable 5-1 on page 184 describes the probability distribution for the number of girls \nin two births (assuming that boys and girls are equally likely). Find the mean, vari-\nance, and standard deviation for the probability distribution described in Table 5-1 \nfrom Example 1.\nSOLUTION\nIn Table 5-3, the two columns at the left describe the probability distribution given \nearlier in Table 5-1. We create the two columns at the right for the purposes of the \ncalculations required.\nUsing Formulas 5-1 and 5-2 and the table results, we get\nMean: m = \u03a33x # P1x2 4 = 1.0\nVariance: s2 = \u03a33 1x - m2 2 # P1x2 4 = 0.5\n\n5-1 Probability Distributions \n187\nINTERPRETATION\nAssuming that boys and girls are equally likely in two births, the mean number of \ngirls is 1.0, the variance is 0.50 girls2, and the standard deviation is 0.7 girl. Also, \nthe expected value for the number of girls in two births is 1.0 girl, which is the same \nvalue as the mean. If we were to collect data on a large number of trials with two \nbirths in each trial, we expect to get a mean of 1.0 girl.\nThe standard deviation is the square root of the variance, so\nStandard deviation: s = 20.5 = 0.707107 = 0.7 1rounded2\nRounding: In Table 5-3, we use m = 1.0. If m had been the value of 1.23456, we \nmight round m to 1.2, but we should use its unrounded value of 1.23456 in \nTable 5-3 calculations. Rounding in the middle of calculations can lead to results \nwith errors that are too large.\nTABLE 5-3 Calculating m and s for a Probability Distribution\nx\nP1x2\nx # P1x2\n1x \u2212m 22 # P1x2\n0\n0.25\n0 # 0.25 = 0.00\n10 - 12 2 # 0.25 =  0.25\n1\n0.50\n1 # 0.50 = 0.50\n11 - 12 2 # 0.50 = 0.00\n2\n0.25\n2 # 0.25 = 0.50\n12 - 12 2 # 0.25 =  0.25\nTotal\n  1.00\n   c\nm = \u03a33x # P1x24\n       0.50\n       \nc\ns2 = \u03a3 31x - m2 2 # P1x24\nMaking Sense of Results: Significant Values\nWe present the following two different approaches for determining whether a value of \na random variable x is significantly low or high.\nIdentif",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 202
  },
  {
    "child_id": "0a612c3a-1fbb-4d8b-9394-7c345f0a96a4",
    "parent_id": "397d399f-a7d3-4ee9-9c28-701d521b1e4c",
    "text": " 5-3 Calculating m and s for a Probability Distribution\nx\nP1x2\nx # P1x2\n1x \u2212m 22 # P1x2\n0\n0.25\n0 # 0.25 = 0.00\n10 - 12 2 # 0.25 =  0.25\n1\n0.50\n1 # 0.50 = 0.50\n11 - 12 2 # 0.50 = 0.00\n2\n0.25\n2 # 0.25 = 0.50\n12 - 12 2 # 0.25 =  0.25\nTotal\n  1.00\n   c\nm = \u03a33x # P1x24\n       0.50\n       \nc\ns2 = \u03a3 31x - m2 2 # P1x24\nMaking Sense of Results: Significant Values\nWe present the following two different approaches for determining whether a value of \na random variable x is significantly low or high.\nIdentifying Significant Results with the Range Rule of Thumb\nThe range rule of thumb (introduced in Section 3-2) may be helpful in interpreting the \nvalue of a standard deviation. According to the range rule of thumb, the vast major-\nity of values should lie within 2 standard deviations of the mean, so we can consider \na value to be significant if it is at least 2 standard deviations away from the mean. We \ncan therefore identify \u201csignificant\u201d values as follows:\nRange Rule of Thumb for Identifying Significant Values\nSigni\ufb01cantly low values are 1m - 2s2 or lower.\nSignificantly high values are 1m + 2s2 or higher.\nValues not signi\ufb01cant: Between 1m -  2s2 and 1m + 2s2\nFigure 3-3 from Section 3-2 illustrates the above criteria:\nValues not signi\ufb01cant\nSigni\ufb01cantly\nlow values\nSigni\ufb01cantly\nhigh values\nm\nm \u2212 2s\nm + 2s\nHINT Know that the use of the number 2 in the range rule of thumb is somewhat \narbitrary, and this is a guideline, not an absolutely rigid rule.\n\n188 \nCHAPTER 5 Discrete Probability Distributions\nIdentifying Significant Results with Probabilities:\n \n\u25a0Significantly high number of successes: x successes among n trials is a signifi-\ncantly high number of successes if the probability of x or more successes is 0.05 or \nless. That is, x is a significantly high number of successes if P(x or more) \u2026 0.05.*\n \n\u25a0Significantly low number of successes: x successes among n trials is a significantly \nlow number of successes if the probability of x or fewer successes is 0.05 or less. \nThat is, x is a significantly low number of successes if P(x or fewer) \u2026 0.05.*\nEXAMPLE 4   Identifying Significant Results with the  \nRange Rule of Thumb\nIn Example 3 we found that with two births, the mean number of girls is m = 1.0 \ngirl and the standard deviation is s = 0.7 girl. Use those results and the range rule \nof thumb to determine whether 2 girls is a significantly high number of girls.\nSOLUTION\nUsing the range rule of thumb, the value of 2 girls is significantly high if it is greater \nthan or equal to m + 2s. With m = 1.0 girl and s = 0.7 girl, we get\nm + 2s = 1 + 210.72 = 2.4 girls\nSignificantly high numbers of girls are 2.4 and above.\nINTERPRETATION\nBased on these results, we conclude that 2 girls is not a significantly high number of \ngirls (because 2 is not greater than or equal to 2.4).\n*The value 0.05 is not absolutely rigid. Other values, such as 0.01, could be used to distinguish between results \nthat are signi\ufb01cant and those that are not signi\ufb01cant.\nIdentification of signi",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 202
  },
  {
    "child_id": "22c12c0b-f593-4aba-b506-af7a87e5436e",
    "parent_id": "397d399f-a7d3-4ee9-9c28-701d521b1e4c",
    "text": "r equal to m + 2s. With m = 1.0 girl and s = 0.7 girl, we get\nm + 2s = 1 + 210.72 = 2.4 girls\nSignificantly high numbers of girls are 2.4 and above.\nINTERPRETATION\nBased on these results, we conclude that 2 girls is not a significantly high number of \ngirls (because 2 is not greater than or equal to 2.4).\n*The value 0.05 is not absolutely rigid. Other values, such as 0.01, could be used to distinguish between results \nthat are signi\ufb01cant and those that are not signi\ufb01cant.\nIdentification of significantly low or significantly high numbers of successes is some-\ntimes used for the purpose of rejecting assumptions, as stated in the following rare \nevent rule.\nThe Rare Event Rule for Inferential Statistics\nIf, under a given assumption, the probability of a particular outcome is \nvery small and the outcome occurs signi\ufb01cantly less than or signi\ufb01cantly \ngreater than what we expect with that assumption, we conclude that the \nassumption is probably not correct.\nFor example, if testing the assumption that boys and girls are equally likely, the out-\ncome of 20 girls in 100 births is significantly low and would be a basis for rejecting \nthat assumption.\nEXAMPLE 5  Identifying Significant Results with Probabilities\nIs 879 girls in 945 births a signi\ufb01cantly high number of girls?\nWhat does the result suggest about the Chapter Problem, which includes results \nfrom the XSORT method of gender selection? (Among 945 births from parents us-\ning the XSORT method, there were 879 girls. Is 879 girls in those 945 births  \nsigni\ufb01cantly high?)",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 202
  },
  {
    "child_id": "fe6e3474-8f34-44f4-bc93-f64623e284d2",
    "parent_id": "de602874-015d-48e2-9995-4043cc942190",
    "text": "5-1 Probability Distributions \n189\nNot Exactly, but \u201cAt Least as Extreme\u201d\nIt should be obvious that among 945 births, 879 girls is significantly high, whereas \n475 girls is not significantly high. What makes 879 girls significant while 475 girls \nis not significant? It is not probabilities of exactly 879 girls and 475 girls (they are \nboth less than 0.026). It is the fact that the probability of 879 or more girls is very low \n(0.0000), but the probability of 475 or more girls is not low (0.448).\nPART 2  Expected Value and Rationale for Formulas\nExpected Value\nIn Part 1 of this section we noted that the expected value of a random variable x is equal \nto the mean m. We can therefore find the expected value by computing \u03a33x # P1x2 4, \njust as we do for finding the value of m.\nSOLUTION\nA result of 879 girls in 945 births is greater than we expect with random chance, \nbut we need to determine whether 879 girls is significantly high. Here, the relevant \nprobability is the probability of getting 879 or more girls in 945 births. Using \nmethods covered later in Section 5-2, we can find that P(879 or more girls in 945 \nbirths) = 0.0000 (rounded). Because the probability of getting 879 or more girls is \nless than or equal to 0.05, we conclude that 879 girls in 945 births is a significantly \nhigh number of girls. See Figure 5-4, which is a probability histogram showing the \nprobability for the different numbers of girls.\nFIGURE 5-4 Probability Histogram of Girls in 945 Births\nEXAMPLE 6  Births\nAssuming that boys and girls are equally likely, find the expected number of girls in \n945 births. Instead of using Formula 5-1, just think about the number of girls  \nexpected in 945 births.\nSOLUTION\nThe expected number of girls in 945 births is 472.5 girls.\ncontinued\nINTERPRETATION\nIt is unlikely that we would get 879 or more girls in 945 births by chance. It follows \nthat 879 girls in 945 births is significantly high, so the XSORT method appears to \nbe effective (but this does not prove that the XSORT method is responsible for the \nlarge number of girls).\nDo Boys or Girls Run in \nthe Family?\nOne of the \nauthors of \nthis book, his \nsiblings, and \nhis siblings\u2019 \nchildren consist \nof 11 males and \nonly 1 female. \nIs this an example of a phenom-\nenon whereby one particular \ngender runs in a family? This \nissue was studied by examin-\ning a random sample of 8770 \nhouseholds in the United States. \nThe results were reported in the \nChance magazine article \u201cDoes \nHaving Boys or Girls Run in the \nFamily?\u201d by  Joseph Rodgers \nand Debby Doughty. Part of \ntheir analysis involves use of the \nbinomial probability distribution \ndiscussed in this section. Their \nconclusion is that \u201cWe found no \ncompelling evidence that sex \nbias runs in the family.\u201d\n\n190 \nCHAPTER 5 Discrete Probability Distributions\nRationale for Formulas 5-1 Through 5-4\nInstead of blindly accepting and using formulas, it is much better to have some un-\nderstanding of why they work. When computing the mean from a fr",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 207
  },
  {
    "child_id": "bda8c632-3daf-48d7-bd9b-d60ff5570750",
    "parent_id": "de602874-015d-48e2-9995-4043cc942190",
    "text": "Run in the \nFamily?\u201d by  Joseph Rodgers \nand Debby Doughty. Part of \ntheir analysis involves use of the \nbinomial probability distribution \ndiscussed in this section. Their \nconclusion is that \u201cWe found no \ncompelling evidence that sex \nbias runs in the family.\u201d\n\n190 \nCHAPTER 5 Discrete Probability Distributions\nRationale for Formulas 5-1 Through 5-4\nInstead of blindly accepting and using formulas, it is much better to have some un-\nderstanding of why they work. When computing the mean from a frequency distribu-\ntion, f represents class frequency and N represents population size. In the expression \nbelow, we rewrite the formula for the mean of a frequency table so that it applies to a \npopulation. In the fraction f>N, the value of f is the frequency with which the value x \noccurs and N is the population size, so f>N is the probability for the value of x. When \nwe replace f>N with P(x), we make the transition from relative frequency based on \na limited number of observations to probability based on infinitely many trials. This \nresult shows why Formula 5-1 is as given earlier in this section.\nm = \u03a31f # x2\nN\n= \u03a3c f # x\nN d = \u03a3cx # f\nN d = \u03a33x # P1x2 4\nSimilar reasoning enables us to take the variance formula from Chapter 3 and \n apply it to a random variable for a probability distribution; the result is Formula 5-2. \nFormula 5-3 is a shortcut version that will always produce the same result as Formula 5-2. \nAlthough Formula 5-3 is usually easier to work with, Formula 5-2 is easier to under-\nstand directly. Based on Formula 5-2, we can express the standard deviation as\ns = 2\u03a33 1x - m2 2 # P1x2 4\nor as the equivalent form given in Formula 5-4.\nINTERPRETATION\nIn any specific sample of 945 births, we can never get 472.5 girls, but 472.5 girls \nis the expected value in the sense that it would be the mean from many samples of \n945 births.\nStatistical Literacy and Critical Thinking \n1.\u00a0Random Variable The accompanying table lists probabilities for the corresponding num-\nbers of girls in four births. What is the random variable, what are its possible values, and are its \nvalues numerical?\n5-1 Basic Skills and Concepts\nNumber of Girls in Four Births\nNumber of \nGirls x\n \nP(x)\n0\n0.063\n1\n0.250\n2\n0.375\n3\n0.250\n4\n0.063\n2.\u00a0Discrete or Continuous? Is the random variable given in the accompanying table discrete \nor continuous? Explain.\n3.\u00a0Probability Distribution For the accompanying table, is the sum of the values of P(x) \nequal to 1, as required for a probability distribution? Does the table describe a probability \ndistribution?\n4.\u00a0Significant For 100 births, P(exactly 56 girls) = 0.0390 and P(56 or more girls) = 0.136. \nIs 56 girls in 100 births a significantly high number of girls? Which probability is relevant to \nanswering that question?\nIdentifying Discrete and Continuous Random Variables. In Exercises 5 and 6, refer \nto the given values, then identify which of the following is most appropriate: discrete ran-\ndom variable, continuous random variable, or not ",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 207
  },
  {
    "child_id": "52683731-0e44-4996-ab09-da6594da7e39",
    "parent_id": "de602874-015d-48e2-9995-4043cc942190",
    "text": "ion? Does the table describe a probability \ndistribution?\n4.\u00a0Significant For 100 births, P(exactly 56 girls) = 0.0390 and P(56 or more girls) = 0.136. \nIs 56 girls in 100 births a significantly high number of girls? Which probability is relevant to \nanswering that question?\nIdentifying Discrete and Continuous Random Variables. In Exercises 5 and 6, refer \nto the given values, then identify which of the following is most appropriate: discrete ran-\ndom variable, continuous random variable, or not a random variable.\n5. a. Exact weights of the next 100 babies born in the United States\nb. Responses to the survey question \u201cWhich health plan do you have?\u201d\ncontinued\n\n5-1 Probability Distributions \n191\nc. Numbers of families that must be surveyed before finding one with 10 children\nd. Exact foot lengths of humans\ne. Shoe sizes (such as 8 or 8\u00bd) of humans\n6. a. Grades (A, B, C, D, F) earned in biostatistics classes\nb. Heights of students in biostatistics classes\nc. Numbers of students in biostatistics classes\nd. Eye colors of biostatistics students\ne. Numbers of times biostatistics students must toss a coin before getting heads\nIdentifying Probability Distributions. In Exercises 7\u201314, determine whether a prob-\nability distribution is given. If a probability distribution is given, find its mean and standard \ndeviation. If a probability distribution is not given, identify the requirements that are not \nsatisfied.\n7.\u00a0Genetic Disorder Five males with an X-linked genetic disorder \nhave one child each. The random variable x is the number of children \namong the five who inherit the X-linked genetic disorder.\nx\nP(x)\n0\n0.031\n1\n0.156\n2\n0.313\n3\n0.313\n4\n0.156\n5\n0.031\n8.\u00a0 Male Color Blindness When conducting research on color \nblindness in males, a researcher forms random groups with five \nmales in each group. The random variable x is the number of males \nin the group who have a form of color blindness (based on data from \nthe National Institutes of Health).\nx\nP(x)\n0\n0.659\n1\n0.287\n2\n0.050\n3\n0.004\n4\n0.001\n5\n0+\n9.\u00a0 Genetics Experiment A genetics experiment involves off-\nspring peas in groups of four. A researcher reports that for one \ngroup, the number of peas with white flowers has a probability dis-\ntribution as given in the accompanying table.\nx\nP(x)\n0\n0.04\n1\n0.26\n2\n0.36\n3\n0.20\n4\n0.08\n10.\u00a0Mortality Study For a group of four men, the probability dis-\ntribution for the number x who live through the next year is as given \nin the accompanying table.\nx\nP(x)\n0\n0.0000\n1\n0.0001\n2\n0.0006\n3\n0.0387\n4\n0.9606\n\n192 \nCHAPTER 5 Discrete Probability Distributions\n11.\u00a0Genetic Disorder Three males with an X-linked genetic dis-\norder have one child each. The random variable x is the number of \nchildren among the three who inherit the X-linked genetic disorder.\nx\nP(x)\n0\n0.4219\n1\n0.4219\n2\n0.1406\n3\n0.0156\n12.\u00a0Diseased Seedlings An experiment involves groups of four \nseedlings grown under controlled conditions. The random variable x \nis the number of seedlings in a group that meet specific c",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 207
  },
  {
    "child_id": "4e985674-6249-41af-91b9-3c65be9310a8",
    "parent_id": "de602874-015d-48e2-9995-4043cc942190",
    "text": "6\n3\n0.0387\n4\n0.9606\n\n192 \nCHAPTER 5 Discrete Probability Distributions\n11.\u00a0Genetic Disorder Three males with an X-linked genetic dis-\norder have one child each. The random variable x is the number of \nchildren among the three who inherit the X-linked genetic disorder.\nx\nP(x)\n0\n0.4219\n1\n0.4219\n2\n0.1406\n3\n0.0156\n12.\u00a0Diseased Seedlings An experiment involves groups of four \nseedlings grown under controlled conditions. The random variable x \nis the number of seedlings in a group that meet specific criteria for \nbeing classified as \u201cdiseased.\u201d\nx\nP(x)\n0\n0.805\n1\n0.113\n2\n0.057\n3\n0.009\n4\n0.002\nGenetics. In Exercises 13\u201318, refer to the accompanying table, \nwhich describes results from groups of 8 births from 8 different \nsets of parents. The random variable x represents the number of \ngirls among 8 children.\nNumber \nof Girls x\n \nP(x)\n0\n0.004\n1\n0.031\n2\n0.109\n3\n0.219\n4\n0.273\n5\n0.219\n6\n0.109\n7\n0.031\n8\n0.004\n13.\u00a0Mean and Standard Deviation Find the mean and standard \ndeviation for the numbers of girls in 8 births.\n14.\u00a0Range Rule of Thumb for Significant Events Use the \nrange rule of thumb to determine whether 1 girl in 8 births is a sig-\nnificantly low number of girls.\n15.\u00a0Range Rule of Thumb for Significant Events Use the \nrange rule of thumb to determine whether 6 girls in 8 births is a sig-\nnificantly high number of girls.\n16.\u00a0Using Probabilities for Significant Events\na. Find the probability of getting exactly 7 girls in 8 births.\nb. Find the probability of getting 7 or more girls in 8 births.\nc. Which probability is relevant for determining whether 7 is a significantly high number of \ngirls in 10 births: the result from part (a) or part (b)?\nd. Is 7 a significantly high number of girls in 8 births? Why or why not?\n17.\u00a0Using Probabilities for Significant Events \na. Find the probability of getting exactly 6 girls in 8 births.\nb. Find the probability of getting 6 or more girls in 8 births.\nc. Which probability is relevant for determining whether 6 is a significantly high number of \ngirls in 8 births: the result from part (a) or part (b)?\nd. Is 6 a significantly high number of girls in 8 births? Why or why not?\n18.\u00a0Using Probabilities for Significant Events \na. Find the probability of getting exactly 1 girl in 8 births.\nb. Find the probability of getting 1 or fewer girls in 8 births.\nc. Which probability is relevant for determining whether 1 is a significantly low number of \ngirls in 8 births: the result from part (a) or part (b)?\nd. Is 1 a significantly low number of girls in 8 births? Why or why not?",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 207
  },
  {
    "child_id": "27e01a0d-cd78-4e66-9f34-52eae438a8b7",
    "parent_id": "bd11b076-1477-4f1e-a910-be0f79b2fcfb",
    "text": "5-2 Binomial Probability Distributions \n193\nSleepwalking. In Exercises 19\u201323, refer to the accompanying \ntable, which describes the numbers of adults in groups of five \nwho reported sleepwalking (based on data from \u201cPrevalence and \nComorbidity of Nocturnal Wandering In the U.S. Adult General \nPopulation,\u201d by Ohayon et al., Neurology, Vol. 78, No. 20).\n19.\u00a0Mean and Standard Deviation Find the mean and standard \ndeviation for the numbers of sleepwalkers in groups of five.\nx\nP(x)\n0\n0.172\n1\n0.363\n2\n0.306\n3\n0.129\n4\n0.027\n5\n0.002\n20.\u00a0Range Rule of Thumb for Significant Events Use the \nrange rule of thumb to determine whether 4 is a significantly high \nnumber of sleepwalkers in a group of 5 adults.\n21.\u00a0Range Rule of Thumb for Significant Events Use the \nrange rule of thumb to determine whether 3 is a significantly high \nnumber of sleepwalkers in a group of 5 adults.\nKey Concept Section 5-1 introduced the important concept of a discrete proba-\nbility distribution. Among the various discrete probability distributions that exist, \nthe focus of this section is the binomial probability distribution. Part 1 of this sec-\ntion introduces the binomial probability distribution along with methods for find-\ning probabilities. Part 2 presents easy methods for finding the mean and standard \ndeviation of a binomial distribution. As in other sections, we stress the importance \nof interpreting probability values to determine whether events are significantly low \nor significantly high.\nPART 1\n Basics of Binomial Probability Distribution\nBinomial probability distributions allow us to deal with circumstances in which the \noutcomes belong to two categories, such as cured>not cured or acceptable>defective \nor survived>died.\n5-2 \nBinomial Probability Distributions\n22.\u00a0Using Probabilities for Identifying Significant Events\na. Find the probability of getting exactly 4 sleepwalkers among 5 adults.\nb. Find the probability of getting 4 or more sleepwalkers among 5 adults.\nc. Which probability is relevant for determining whether 4 is a significantly high number of \nsleepwalkers among 5 adults: the result from part (a) or part (b)?\nd. Is 4 a significantly high number of sleepwalkers among 5 adults? Why or why not?\n23.\u00a0Using Probabilities for Identifying Significant Events\na. Find the probability of getting exactly 1 sleepwalker among 5 adults.\nb. Find the probability of getting 1 or fewer sleepwalkers among 5 adults.\nc. Which probability is relevant for determining whether 1 is a significantly low number of \nsleepwalkers among 5 adults: the result from part (a) or part (b)?\nd. Is 1 a significantly low number of sleepwalkers among 5 adults? Why or why not?\n\n194 \nCHAPTER 5 Discrete Probability Distributions\nNotation For Binomial Probability Distributions\nS and F (success and failure) denote the two possible categories of all outcomes.\nP1S2 = p \n1p = probability of a success2\nP1F2 = 1 - p = q \n1q = probability of a failure2\nn\nthe fixed number of trials\nx \na specific number of successes",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 211
  },
  {
    "child_id": "c3f8e5f8-4b3c-4882-94dd-df14cc1d1e25",
    "parent_id": "bd11b076-1477-4f1e-a910-be0f79b2fcfb",
    "text": "y low number of \nsleepwalkers among 5 adults: the result from part (a) or part (b)?\nd. Is 1 a significantly low number of sleepwalkers among 5 adults? Why or why not?\n\n194 \nCHAPTER 5 Discrete Probability Distributions\nNotation For Binomial Probability Distributions\nS and F (success and failure) denote the two possible categories of all outcomes.\nP1S2 = p \n1p = probability of a success2\nP1F2 = 1 - p = q \n1q = probability of a failure2\nn\nthe fixed number of trials\nx \na specific number of successes in n trials, so x can be any \nwhole number between 0 and n, inclusive\np\nprobability of success in one of the n trials\nq\nprobability of failure in one of the n trials\nP(x) \nprobability of getting exactly x successes among the n trials\nThe word success as used here is arbitrary and does not necessarily represent \nsomething good. Either of the two possible categories may be called the success S \nas long as its probability is identified as p. (The value of q can always be found from \nq = 1 - p. If p = 0.95, then q = 1 - 0.95 = 0.05.)\nDEFINITION\nA binomial probability distribution results from a procedure that meets these four \nrequirements:\n 1.  The procedure has a \ufb01xed number of  trials. (A trial is a single observation.)\n 2.  The trials must be independent, meaning that the outcome of any individual trial \ndoesn\u2019t a\ufb00ect the probabilities in the other trials.\n 3.  Each trial must have all outcomes classi\ufb01ed into exactly two categories, com-\nmonly referred to as success and failure.\n 4.  The probability of a success remains the same in all trials.\nCAUTION When using a binomial probability distribution, always be sure that x \nand p are consistent in the sense that they both refer to the same category being \ncalled a success.\nEXAMPLE 1  Hybridization Experiments\nWhen Gregor Mendel conducted his famous hybridization experiments, he used \npeas with green pods and peas with yellow pods. Because green is dominant and \nyellow is recessive, when crossing two parents with the green>yellow pair of genes, \nwe expect that 3>4 of the offspring peas should have green pods. That is, P(green \npod) = 3>4. Assume that all parents have the green>yellow combination of genes, \nand we want to find the probability that exactly three of five offspring peas have \ngreen pods.\n \na. Does this procedure result in a binomial distribution?\n \nb. If this procedure does result in a binomial distribution, identify the values of \nn, x, p, and q.\n\n5-2 Binomial Probability Distributions \n195\nTreating Dependent Events as Independent\nWhen selecting a sample (as in a survey), we usually sample without replacement. \nSampling without replacement results in dependent events, which violates a require-\nment of a binomial distribution. However, we can often treat the events as if they were \nindependent by applying the following 5% guideline introduced in Section 4-2:\n5% Guideline for Cumbersome Calculations\nWhen sampling without replacement and the sample size is no more than \n5% of the size of the popula",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 211
  },
  {
    "child_id": "a9fa05a2-0177-4957-b16c-99b26a973f4c",
    "parent_id": "bd11b076-1477-4f1e-a910-be0f79b2fcfb",
    "text": "dent Events as Independent\nWhen selecting a sample (as in a survey), we usually sample without replacement. \nSampling without replacement results in dependent events, which violates a require-\nment of a binomial distribution. However, we can often treat the events as if they were \nindependent by applying the following 5% guideline introduced in Section 4-2:\n5% Guideline for Cumbersome Calculations\nWhen sampling without replacement and the sample size is no more than \n5% of the size of the population, treat the selections as being independent \n(even though they are actually dependent).\nMethods for Finding Binomial Probabilities\nWe now proceed with three methods for finding the probabilities corresponding to the \nrandom variable x in a binomial distribution. The first method involves calculations \nusing the binomial probability formula and is the basis for the other two methods. \nThe second method involves the use of software or a calculator, and the third method \ninvolves the use of the Appendix Table A-1. (With technology so widespread, such \ntables are becoming obsolete.) If using technology that automatically produces bino-\nmial probabilities, we recommend that you solve one or two exercises using Method 1 \nto better understand the basis for the calculations.\nSOLUTION\na. This procedure does satisfy the requirements for a binomial distribution, as \nshown below.\n \n 1. The number of trials (5) is \ufb01xed.\n \n 2. The 5 trials are independent because the probability of any o\ufb00spring \npea\u00a0having a green pod is not a\ufb00ected by the outcome of any other \n o\ufb00spring pea.\n \n 3. Each of the 5 trials has two categories of outcomes: The pea has a green \npod or it does not.\n \n 4. For each o\ufb00spring pea, the probability that it has a green pod is 3>4 or \n0.75, and that probability remains the same for each of the 5 peas.\n \nb. Having concluded that the given procedure does result in a binomial distribu-\ntion, we now proceed to identify the values of n, x, p, and q.\n \n 1. With 5 o\ufb00spring peas, we have n = 5.\n2. We want the probability of exactly 3 peas with green pods, so x = 3.\n3. The probability of success (getting a pea with a green pod) for one selec-\ntion is 0.75, so p = 0.75.\n4. The probability of failure (not getting a green pod) is 0.25, so q = 0.25.\nAgain, it is very important to be sure that x and p both refer to the same concept of \n\u201csuccess.\u201d In this example, we use x to count the number of peas with green pods, \nso p must be the probability that a pea has a green pod. Therefore, x and p do use \nthe same concept of success (green pod) here.\nNot at Home\nPollsters cannot \nsimply ignore \nthose who were \nnot at home \nwhen they \nwere called \nthe first time. \nOne solution \nis to make repeated callback \nattempts until the person can \nbe reached.  Alfred Politz and \nWillard Simmons describe a way \nto compensate for those missed \ncalls without making repeated \ncallbacks. They suggest weight-\ning results based on how often \npeople are not at home. For \nexample, a pers",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 211
  },
  {
    "child_id": "6465e15d-9dc2-4c92-9445-a7db80e26be6",
    "parent_id": "bd11b076-1477-4f1e-a910-be0f79b2fcfb",
    "text": ". Therefore, x and p do use \nthe same concept of success (green pod) here.\nNot at Home\nPollsters cannot \nsimply ignore \nthose who were \nnot at home \nwhen they \nwere called \nthe first time. \nOne solution \nis to make repeated callback \nattempts until the person can \nbe reached.  Alfred Politz and \nWillard Simmons describe a way \nto compensate for those missed \ncalls without making repeated \ncallbacks. They suggest weight-\ning results based on how often \npeople are not at home. For \nexample, a person at home only \ntwo days out of six will have a  \n2>6 or 1>3 probability of being at \nhome when called the first time. \nWhen such a person is reached \nthe first time, his or her results \nare weighted to count three \ntimes as much as someone who \nis always home. This weighting \nis a compensation for the other \nsimilar people who are home two \ndays out of six and were not at \nhome when called the first time. \nThis clever solution was first \npresented in 1949.\n\n196 \nCHAPTER 5 Discrete Probability Distributions\nFORMULA 5-5  Binomial Probability Formula\nP1x2 =\nn!\n1n - x2!x! # px # qn-x  for x = 0, 1, 2, c, n\nwhere\n n = number of trials\n x = number of successes among n trials\n p = probability of success in any one trial\n q = probability of failure in any one trial 1q = 1 - p2\nFormula 5-5 can also be expressed as P1x2 = nCx # px # qn-x. With x items identi-\ncal to themselves, and n - x other items identical to themselves, the number of \npermutations is nCx = n!3 1n - x2!x!4, so the two sides of this equation are inter-\nchangeable. The factorial symbol !, introduced in Section 4-6, denotes the product \nof decreasing factors. Two examples of factorials are 3! = 3 # 2 # 1 = 6 and 0! = 1 \n(by definition).\nEXAMPLE 2  Hybridization Experiment \nAssuming that the probability of a pea having a green pod is 0.75 (as in Example 1), \nuse the binomial probability formula to find the probability of getting exactly 3 peas \nwith green pods when 5 offspring peas are generated. That is, find P(3) given that \nn = 5, x = 3, p = 0.75, and q = 0.25.\nSOLUTION\nUsing the given values of n, x, p, and q in the binomial probability formula \n (Formula 5-5), we get\n P132 =\n5!\n15 - 32!3! # 0.753 # 0.255-3\n =\n5!\n2!3! # 0.421875 # 0.0625\n = 110210.421875210.06252 = 0.263671875\nThe probability of getting exactly 3 peas with green pods among 5 offspring peas is \n0.264 (rounded to three significant digits).\nCalculation hint: When computing a probability with the binomial probability for-\nmula, it\u2019s helpful to get a single number for n!> 3 1n - x2!x!4 or nCx, a single num-\nber for px, and a single number for qn-x, and then simply multiply the three factors \ntogether as shown in the third line of the calculation in the preceding example. Don\u2019t \nround when you find those three factors; round only at the end, and round to three \nsignificant digits.\nMethod 1: Using the Binomial Probability Formula In a binomial probability \ndistribution, probabilities can be calculated by using Formula 5-5.\n\n5-2 Binomi",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 211
  },
  {
    "child_id": "bc7a0749-daf1-4e75-972c-b00df9e540e3",
    "parent_id": "bd11b076-1477-4f1e-a910-be0f79b2fcfb",
    "text": "to get a single number for n!> 3 1n - x2!x!4 or nCx, a single num-\nber for px, and a single number for qn-x, and then simply multiply the three factors \ntogether as shown in the third line of the calculation in the preceding example. Don\u2019t \nround when you find those three factors; round only at the end, and round to three \nsignificant digits.\nMethod 1: Using the Binomial Probability Formula In a binomial probability \ndistribution, probabilities can be calculated by using Formula 5-5.\n\n5-2 Binomial Probability Distributions \n197\nMethod 2: Using Technology Technology can be used to find binomial probabili-\nties. The screen displays listing binomial probabilities for n = 5 and p = 0.75, as in \nExample 2, are given. Notice that in each display, the probability distribution is given \nas a table.\nStatdisk\nMinitab\nExcel\nTI-83>84 Plus\nMethod 3: Using Table A-1 in Appendix A This method can be skipped if tech-\nnology is available. Table A-1 in Appendix A lists binomial probabilities for select \nvalues of n and p. It cannot be used if n > 8 or if the probability p is not one of the 13 \nvalues included in the table.\nTo use the table of binomial probabilities, we must first locate n and the desired \ncorresponding value of x. At this stage, one row of numbers should be isolated. Now \nalign that row with the desired probability of p by using the column across the top. \nThe isolated number represents the desired probability. A very small probability, such \nas 0.000064, is indicated by 0+.\nEXAMPLE 3  Births \nAssuming that boys and girls are equally likely, find the probability of getting ex-\nactly 5 boys in 8 randomly selected births.\ncontinued",
    "source_file": "Marc M. Triola, Mario F. Triola, Jason Roy - Biostatistics for the Biological and Health Sciences (2nd Edition) (2017, Pearson).pdf",
    "page_number": 211
  }
]